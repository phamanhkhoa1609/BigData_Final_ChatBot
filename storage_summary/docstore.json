{"docstore/data": {"1c499b06-8d39-4018-8cba-3072a31162a2": {"__data__": {"id_": "1c499b06-8d39-4018-8cba-3072a31162a2", "embedding": null, "metadata": {"page_label": "C1", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "990d5a0a-ff21-49ae-9f9b-aca070ee1d3b", "node_type": "4", "metadata": {"page_label": "C1", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "563c33d69d041c21fce0901677202a1f010be628e6b9679e27353c15c0f635f4", "class_name": "RelatedNodeInfo"}}, "text": "www.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 18, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bfa46f02-06da-4e91-99e9-73c82ebc0422": {"__data__": {"id_": "bfa46f02-06da-4e91-99e9-73c82ebc0422", "embedding": null, "metadata": {"page_label": "C2", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7da7c154-5ce3-4f09-bcce-23bad9759c26", "node_type": "4", "metadata": {"page_label": "C2", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "5fc3dde0218b9a9afc5152381895776ec19152b3b78698904078ccb49cb896ce", "class_name": "RelatedNodeInfo"}}, "text": "www.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 18, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "627b8055-2ea7-4761-aac0-ee50e34d6e65": {"__data__": {"id_": "627b8055-2ea7-4761-aac0-ee50e34d6e65", "embedding": null, "metadata": {"page_label": "i", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "30588c47-3769-4559-9150-191e3ee64deb", "node_type": "4", "metadata": {"page_label": "i", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "03f14dd96b60b74f60cbeefd2f3830f54e9d035263beb5ae5e2c60dc684e9c3e", "class_name": "RelatedNodeInfo"}}, "text": "Big Data\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 27, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dceb6d32-1239-45f8-b672-48fd07225ad1": {"__data__": {"id_": "dceb6d32-1239-45f8-b672-48fd07225ad1", "embedding": null, "metadata": {"page_label": "ii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a9d49cfa-13a0-4363-b27e-da21f2171d12", "node_type": "4", "metadata": {"page_label": "ii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1c641c51dd7ca2c8e520dd2a95e0b9ea72ddb7756463c8d30106bd645635d414", "class_name": "RelatedNodeInfo"}}, "text": "www.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 18, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8ca971c7-6224-40d6-b8bf-d36fd949c430": {"__data__": {"id_": "8ca971c7-6224-40d6-b8bf-d36fd949c430", "embedding": null, "metadata": {"page_label": "iii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "623c07c6-dc64-48ec-b3e2-3a11e8eca303", "node_type": "4", "metadata": {"page_label": "iii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "fa9f4d42a9b8fcbf0c4bb5062920118351bb9ddad05f922546cf9590f1422ad6", "class_name": "RelatedNodeInfo"}}, "text": "by Judith Hurwitz, Alan Nugent, Dr. Fern Halper, \nand Marcia KaufmanBig Data\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 95, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "22cc4735-9ae6-4ca6-9759-2f4ba7402ca3": {"__data__": {"id_": "22cc4735-9ae6-4ca6-9759-2f4ba7402ca3", "embedding": null, "metadata": {"page_label": "iv", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "182ed2b9-c4bb-44dd-b185-688eee6a42f8", "node_type": "4", "metadata": {"page_label": "iv", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1c5256e82a3adf5d8a00c726811e65a7ad7891bcceff989ef7e5507173298a9d", "class_name": "RelatedNodeInfo"}}, "text": "Big Data For Dummies\u00ae\nPublished by  \nJohn Wiley & Sons, Inc.  \n111 River Street  \nHoboken, NJ 07030-5774\nwww.wiley.com\nCopyright \u00a9 2013 by John Wiley & Sons, Inc., Hoboken, New Jersey\nPublished simultaneously in Canada\nNo part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or \nby any means, electronic, mechanical, photocopying, recording, scanning or otherwise, except as permit -\nted under Sections 107 or 108 of the 1976 United States Copyright Act, without either the prior written \npermission of the Publisher, or authorization through payment of the appropriate per-copy fee to the \nCopyright Clearance Center, 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax (978) 646-8600. \nRequests to the Publisher for permission should be addressed to the Permissions Department, John Wiley \n& Sons, Inc., 111 River Street, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at http://\nwww.wiley.com/go/permissions .\nTrademarks:  Wiley, the Wiley logo, For Dummies, the Dummies Man logo, A Reference for the Rest of Us!, \nThe Dummies Way, Dummies Daily, The Fun and Easy Way, Dummies.com, Making Everything Easier, and \nrelated trade dress are trademarks or registered trademarks of John Wiley & Sons, Inc. and/or its affili -\nates in the United States and other countries, and may not be used without written permission. All other \ntrademarks are the property of their respective owners. John Wiley & Sons, Inc. is not associated with any \nproduct or vendor mentioned in this book.\nLIMIT OF LIABILITY/DISCLAIMER OF WARRANTY:  THE PUBLISHER AND THE AUTHOR MAKE NO \nREPRESENTATIONS OR WARRANTIES WITH RESPECT TO THE ACCURACY OR COMPLETENESS OF \nTHE CONTENTS OF THIS WORK AND SPECIFICALLY DISCLAIM ALL WARRANTIES, INCLUDING WITH -\nOUT LIMITATION WARRANTIES OF FITNESS FOR A PARTICULAR PURPOSE. NO WARRANTY MAY BE \nCREATED OR EXTENDED BY SALES OR PROMOTIONAL MATERIALS. THE ADVICE AND STRATEGIES \nCONTAINED HEREIN MAY NOT BE SUITABLE FOR EVERY SITUATION. THIS WORK IS SOLD WITH THE \nUNDERSTANDING THAT THE PUBLISHER IS NOT ENGAGED IN RENDERING LEGAL, ACCOUNTING, OR \nOTHER PROFESSIONAL SERVICES. IF PROFESSIONAL ASSISTANCE IS REQUIRED, THE SERVICES OF \nA COMPETENT PROFESSIONAL PERSON SHOULD BE SOUGHT. NEITHER THE PUBLISHER NOR THE \nAUTHOR SHALL BE LIABLE FOR DAMAGES ARISING HEREFROM. THE FACT THAT AN ORGANIZATION \nOR WEBSITE IS REFERRED TO IN THIS WORK AS A CITATION AND/OR A POTENTIAL SOURCE OF FUR -\nTHER INFORMATION DOES NOT MEAN THAT THE AUTHOR OR THE PUBLISHER ENDORSES THE INFOR -\nMATION THE ORGANIZATION OR WEBSITE MAY PROVIDE OR RECOMMENDATIONS IT MAY MAKE. \nFURTHER, READERS SHOULD BE AWARE THAT INTERNET WEBSITES LISTED IN THIS WORK MAY HAVE \nCHANGED OR DISAPPEARED BETWEEN WHEN THIS WORK WAS WRITTEN AND WHEN IT IS READ. \nFor general information on our other products and services, please contact our Customer Care \nDepartment within the U.S. at 877-762-2974, outside the U.S. at 317-572-3993, or fax 317-572-4002.\nFor technical support, please visit www.wiley.com/techsupport .\nWiley publishes in a variety of print and electronic formats and by print-on-demand. Some material \nincluded with standard print versions of this book may not be included in e-books or in print-on-demand. \nIf this book refers to media such as a CD or DVD that is not included in the version you purchased, you \nmay download this material at http://booksupport.wiley.com . For more information about Wiley \nproducts, visit www.wiley.com .\nLibrary of Congress Control Number: 2013933950\nISBN: 978-1-118-50422-2 (pbk); ISBN 978-1-118-64417-1 (ebk); ISBN 978-1-118-64396-9 (ebk);  \nISBN 978-1-118-64401-0 (ebk)\nManufactured in the United States of America\n10   9   8   7   6   5   4   3   2   1\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3768, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f41a260-27fa-4fc8-924c-14c518735e49": {"__data__": {"id_": "4f41a260-27fa-4fc8-924c-14c518735e49", "embedding": null, "metadata": {"page_label": "v", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fdd210c7-6472-4898-9275-488f37d13d07", "node_type": "4", "metadata": {"page_label": "v", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "a9d4ae61d96f199053377b8d8cacf12d75a20523169976580cf5cbb379292afe", "class_name": "RelatedNodeInfo"}}, "text": "About the Authors\nJudith S. Hurwitz is President and CEO of Hurwitz & Associates, a research \nand consulting firm focused on emerging technology, including cloud comput -\ning, big data, analytics, software development, service management, and secu -\nrity and governance. She is a technology strategist, thought leader, and author. \nA pioneer in anticipating technology innovation and adoption, she has served \nas a trusted advisor to many industry leaders over the years. Judith has helped \nthese companies make the transition to a new business model focused on the \nbusiness value of emerging platforms. She was the founder of Hurwitz Group. \nShe has worked in various corporations, including Apollo Computer and John \nHancock. She has written extensively about all aspects of distributed software. \nIn 2011 she authored Smart or Lucky? How Technology Leaders Turn Chance into \nSuccess  (Jossey Bass, 2011). Judith is a co-author on five retail For Dummies \ntitles including Hybrid Cloud For Dummies  (John Wiley & Sons, Inc., 2012), Cloud \nComputing For Dummies  (John Wiley & Sons, Inc., 2010), Service Management \nFor Dummies,  and Service Oriented Architecture For Dummies,  2nd Edition \n(both John Wiley & Sons, Inc., 2009). She is also a co-author on many custom \npublished For Dummies  titles including Platform as a Service For Dummies, \nCloudBees Special Edition (John Wiley & Sons, Inc., 2012), Cloud For Dummies, \nIBM Midsize Company Limited Edition (John Wiley & Sons, Inc., 2011), Private \nCloud For Dummies, IBM Limited Edition (2011), and Information on Demand For \nDummies, IBM Limited Edition (2008) (both John Wiley & Sons, Inc.).\nJudith holds BS and MS degrees from Boston University, serves on several \nadvisory boards of emerging companies, and was named a distinguished \nalumnus of Boston University\u2019s College of Arts & Sciences in 2005. She serves \non Boston University\u2019s Alumni Council.  She is also a recipient of the 2005 \nMassachusetts Technology Leadership Council award.\nAlan F. Nugent  is a Principal Consultant with Hurwitz & Associates.  Al is \nan experienced technology leader and industry veteran of more than three \ndecades. Most recently, he was the Chief Executive and Chief Technology \nOfficer at Mzinga, Inc., a leader in the development and delivery of cloud-based  \nsolutions for big data, real-time analytics, social intelligence, and community  \nmanagement. Prior to Mzinga, he was executive vice president and Chief \nTechnology Officer at CA, Inc. where he was responsible for setting the strategic \ntechnology direction for the company. He joined CA as senior vice president \nand general manager of CA\u2019s Enterprise Systems Management (ESM) business \nunit and managed the product portfolio for infrastructure and data management. \nPrior to joining CA in April of 2005, Al was senior vice president and CTO of \nNovell, where he was the innovator behind the company\u2019s moves into open \nsource and identity-driven solutions.  As consulting CTO for BellSouth he led \nthe corporate initiative to consolidate and transform all of BellSouth\u2019s disparate \ncustomer and operational data into a single data instance.\nAl is the independent member of the Board of Directors of Adaptive \nComputing in Provo, UT, chairman of the advisory board of SpaceCurve in \nSeattle, WA, and a member of the advisory board of N-of-one in Waltham, MA. \nHe is a frequent writer on business and technology topics and has shared his \nthoughts and expertise at many industry events throughout the years. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3534, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f632140f-2f08-48a4-a0b5-b6e1985a0b4f": {"__data__": {"id_": "f632140f-2f08-48a4-a0b5-b6e1985a0b4f", "embedding": null, "metadata": {"page_label": "vi", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5eb4a6a2-51f8-4512-bc8c-5970d58995a6", "node_type": "4", "metadata": {"page_label": "vi", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "82eaa5164e7dcf68f906f62d93ca2a73cc5bbcd48b812b2a09116beda313601e", "class_name": "RelatedNodeInfo"}}, "text": "He is an instrument rated private pilot and has played professional poker for \nthe past three decades. In his sparse spare time he enjoys rebuilding older \nAmerican muscle cars and motorcycles, collecting antiquarian books, epicu -\nrean cooking, and has passion for cellaring American and Italian wines.\nFern Halper, PhD, is a Fellow with Hurwitz & Associates and Director of \nTDWI Research for Advanced Analytics.  She has more than 20 years of \nexperience in data analysis, business analysis, and strategy development. \nFern has published numerous articles on data analysis and advanced ana -\nlytics. She has done extensive research, writing, and speaking on the topic \nof predictive analytics and text analytics. Fern publishes a regular technol -\nogy blog. She has held key positions at AT&T Bell Laboratories and Lucent \nTechnologies, where she was responsible for developing innovative data \nanalysis systems as well as developing strategy and product-line plans for \nInternet businesses. Fern has taught courses in information technology at \nseveral universities. She received her BA from Colgate University and her \nPhD from Texas A&M University. \nFern is a co-author on four retail For Dummies  titles including Hybrid Cloud \nFor Dummies  (John Wiley & Sons, Inc., 2012), Cloud Computing For Dummies  \n(John Wiley & Sons, Inc., 2010), Service Oriented Architecture For Dummies,  \n2nd Edition, and Service Management For Dummies  (both John Wiley & Sons, \nInc., 2009). She is also a co-author on many custom published For Dummies  \ntitles including Cloud For Dummies, IBM Midsize Company Limited Edition \n(John Wiley & Sons, Inc., 2011), Platform as a Service For Dummies, CloudBees \nSpecial Edition (John Wiley & Sons, Inc., 2012), and Information on Demand \nFor Dummies, IBM Limited Edition (John Wiley & Sons, Inc., 2008).\nMarcia A. Kaufman is a founding Partner and COO of Hurwitz & Associates, a \nresearch and consulting firm focused on emerging technology, including cloud \ncomputing, big data, analytics, software development, service management, and \nsecurity and governance. She has written extensively on the business value \nof virtualization and cloud computing, with an emphasis on evolving cloud \ninfrastructure and business models, data-encryption and end-point security, \nand online transaction processing in cloud environments. Marcia has more \nthan 20 years of experience in business strategy, industry research, distributed \nsoftware, software quality, information management, and analytics. Marcia has \nworked within the financial services, manufacturing, and services industries. \nDuring her tenure at Data Resources, Inc. (DRI), she developed sophisticated \nindustry models and forecasts. She holds an AB from Connecticut College in \nmathematics and economics and an MBA from Boston University.\nMarcia is a co-author on five retail For Dummies  titles including Hybrid Cloud \nFor Dummies  (John Wiley & Sons, Inc., 2012), Cloud Computing For Dummies  \n(John Wiley & Sons, Inc., 2010), Service Oriented Architecture For Dummies,  \n2nd Edition, and Service Management For Dummies  (both John Wiley & Sons, \nInc., 2009). She is also a co-author on many custom published For Dummies  \ntitles including Platform as a Service For Dummies, CloudBees Special Edition \n(John Wiley & Sons, Inc., 2012), Cloud For Dummies, IBM Midsize Company \nLimited Edition (John Wiley & Sons, Inc., 2011), Private Cloud For Dummies, \nIBM Limited Edition (2011), and Information on Demand For Dummies  (2008) \n(both John Wiley & Sons, Inc.).\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3564, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "64db8ff5-b779-4d6c-93ce-c0417d026c47": {"__data__": {"id_": "64db8ff5-b779-4d6c-93ce-c0417d026c47", "embedding": null, "metadata": {"page_label": "vii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1515bd40-cb74-46a7-b259-d7ada9c2b694", "node_type": "4", "metadata": {"page_label": "vii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "5ddeb02bba0516fa785f8e8845d2ea796dbc225d2c8658ad2ae4d5d38443a094", "class_name": "RelatedNodeInfo"}}, "text": "Dedication\nJudith dedicates this book to her husband, Warren, her children, Sara and \nDavid, and her mother, Elaine. She also dedicates this book in memory of her \nfather, David.\nAlan dedicates this book to his wife Jane for all her love and support; his \nthree children Chris, Jeff, and Greg; and the memory of his parents who \nstarted him on this journey.\nFern dedicates this book to her husband, Clay, daughters, Katie and Lindsay, \nand her sister Adrienne.\nMarcia dedicates this book to her husband, Matthew, her children, Sara and \nEmily, and her parents, Gloria and Larry.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 597, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "52191274-fa0f-4415-ab2a-ff42f4525039": {"__data__": {"id_": "52191274-fa0f-4415-ab2a-ff42f4525039", "embedding": null, "metadata": {"page_label": "viii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ee1eb0b2-ca53-47ac-b549-cfbac4f2ef9e", "node_type": "4", "metadata": {"page_label": "viii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d895565d5a036a8075fa1a700b1602bf2a96caca85e7f310616a8bb8c625ad20", "class_name": "RelatedNodeInfo"}}, "text": "www.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 18, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "10cd6d67-a197-4ee6-a965-58939962ac27": {"__data__": {"id_": "10cd6d67-a197-4ee6-a965-58939962ac27", "embedding": null, "metadata": {"page_label": "ix", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5f5b7b95-c49a-4d68-9add-63261a940cd6", "node_type": "4", "metadata": {"page_label": "ix", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b305576528f7db70f91b0b5ee3772a7a88f6e9257cd871f1b1a2b8f33aa5f386", "class_name": "RelatedNodeInfo"}}, "text": "Authors\u2019 Acknowledgments\nWe heartily thank our friends at Wiley, most especially our editor, Nicole \nSholly. In addition, we would like to thank our technical editor, Brenda \nMichelson, for her insightful contributions.\nThe authors would like to acknowledge the contribution of the following \ntechnology industry thought leaders who graciously offered their time to \nshare their technical and business knowledge on a wide range of issues \nrelated to hybrid cloud. Their assistance was provided in many ways, \nincluding technology briefings, sharing of research, case study examples, and \nreviewing content. We thank the following people and their organizations for \ntheir valuable assistance:\nContext Relevant:  Forrest Carman\nDell:  Matt Walken\nEpsilon:  Bob Zurek\nIBM:  Rick Clements, David Corrigan, Phil Francisco, Stephen Gold, Glen \nHintze, Jeff Jones, Nancy Kop, Dave Lindquist, Angel Luis Diaz, Bill Mathews, \nKim Minor, Tracey Mustacchio, Bob Palmer, Craig Rhinehart, Jan Shauer, \nBrian Vile, Glen Zimmerman\nKognitio:  Michael Hiskey, Steve Millard\nOpera Solutions:  Jacob Spoelstra\nRainStor:  Ramon Chen, Deidre Mahon\nSAS Institute:  Malcom Alexander, Michael Ames\nVMware:  Chris Keene\nXtremedata:  Michael Lamble\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1242, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0c9fdd17-2bbf-4291-b81b-ff72b815ac0f": {"__data__": {"id_": "0c9fdd17-2bbf-4291-b81b-ff72b815ac0f", "embedding": null, "metadata": {"page_label": "x", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "db087b54-6335-4f07-b24c-9484120257b8", "node_type": "4", "metadata": {"page_label": "x", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b33cb06b05a292e89e6df8aa2bc9b15d5c8d4d86770a288697fdb8f20a8d50d6", "class_name": "RelatedNodeInfo"}}, "text": "Publisher\u2019s Acknowledgments\nWe\u2019re proud of this book; please send us your comments at http://dummies.custhelp.com . For \nother comments, please contact our Customer Care Department within the U.S. at 877-762-2974, out -\nside the U.S. at 317-572-3993, or fax 317-572-4002.\nSome of the people who helped bring this book to market include the following:\nAcquisitions, Editorial\nSenior Project Editor:  Nicole Sholly\nProject Editor:  Dean Miller\nAcquisitions Editor:  Constance Santisteban\nCopy Editor:  John Edwards\nTechnical Editor:  Brenda Michelson\nEditorial Manager:  Kevin Kirschner\nEditorial Assistant:  Anne Sullivan\nSr. Editorial Assistant:  Cherie Case\nCover Photo:  \u00a9 Baris Simsek / iStockphotoComposition Services\nProject Coordinator:  Sheree Montgomery\nLayout and Graphics: Jennifer Creasey,  \nJoyce Haughey\nProofreaders:  Debbye Butler, Lauren \nMandelbaum\nIndexer:  Valerie Haynes Perry\nPublishing and Editorial for Technology Dummies\nRichard Swadley,  Vice President and Executive Group Publisher\nAndy Cummings,  Vice President and Publisher\nMary Bednarek,  Executive Acquisitions Director\nMary C. Corder,  Editorial Director\nPublishing for Consumer Dummies\nKathleen Nebenhaus,  Vice President and Executive Publisher\nComposition Services\nDebbie Stailey,  Director of Composition Services\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1318, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "58257069-7df7-448f-b3cb-7c42c8988c86": {"__data__": {"id_": "58257069-7df7-448f-b3cb-7c42c8988c86", "embedding": null, "metadata": {"page_label": "xi", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1afbaf7a-26b1-4a39-9785-630dc7dff1b7", "node_type": "4", "metadata": {"page_label": "xi", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "3c24cd1b77cca0f16ba3281427c10c8b2e92a90b7ddc128856735d57e05f9ca9", "class_name": "RelatedNodeInfo"}}, "text": "Contents at a Glance\nIntroduction  ................................................................ 1\nPart I : Getting Started with Big Data  ............................ 7\nChapter 1 : Grasping the Fundamentals of Big Data  ....................................................... 9\nChapter 2 : Examining Big Data Types  ........................................................................... 25\nChapter 3 : Old Meets New: Distributed Computing  .................................................... 37\nPart II : Technology Foundations for Big Data  ............... 45\nChapter 4 : Digging into Big Data Technology Components  ....................................... 47\nChapter 5 : Virtualization and How It Supports Distributed Computing  ................... 61\nChapter 6 : Examining the Cloud and Big Data  ............................................................. 71\nPart III : Big Data Management  .................................. 83\nChapter 7 : Operational Databases  ................................................................................. 85\nChapter 8 : MapReduce Fundamentals  ........................................................................ 101\nChapter 9 : Exploring the World of Hadoop  ................................................................ 111\nChapter 10 : The Hadoop Foundation and Ecosystem  ............................................... 121\nChapter 11 : Appliances and Big Data Warehouses  ................................................... 129\nPart IV : Analytics and Big Data  ............................... 139\nChapter 12 : Defining Big Data Analytics  ..................................................................... 141\nChapter 13 : Understanding Text Analytics and Big Data .......................................... 153\nChapter 14 : Customized Approaches for Analysis of Big Data  ................................ 167\nPart V : Big Data Implementation  .............................. 179\nChapter 15 : Integrating Data Sources  .......................................................................... 181\nChapter 16 : Dealing with Real-Time Data Streams and Complex  \nEvent Processing  ......................................................................................................... 193\nChapter 17 : Operationalizing Big Data  ........................................................................ 201\nChapter 18 : Applying Big Data within Your Organization  ........................................ 211\nChapter 19 : Security and Governance for Big Data Environments  ......................... 225\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2592, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b5a639e0-00fb-4377-a143-1dd97e22ba7f": {"__data__": {"id_": "b5a639e0-00fb-4377-a143-1dd97e22ba7f", "embedding": null, "metadata": {"page_label": "xii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4e6f2ad7-d964-400b-9090-04bd5f064076", "node_type": "4", "metadata": {"page_label": "xii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "13637b9186fb7e9a6c6374934dc8a7e3f5cf7583cc66fd98910b99baa6f4418f", "class_name": "RelatedNodeInfo"}}, "text": "Part VI : Big Data Solutions in the Real World  ............ 235\nChapter 20 : The Importance of Big Data to Business  ............................................... 237\nChapter 21 : Analyzing Data in Motion: A Real-World View  ...................................... 245\nChapter 22 : Improving Business Processes with Big Data Analytics:  \nA Real-World View  ....................................................................................................... 255\nPart VII : The Part of Tens  ......................................... 263\nChapter 23 : Ten Big Data Best Practices  .................................................................... 265\nChapter 24 : Ten Great Big Data Resources  ................................................................ 271\nChapter 25 : Ten Big Data Do\u2019s and Don\u2019ts  .................................................................. 275\nGlossary  .................................................................. 279\nIndex  ...................................................................... 295\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1064, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b46bd0b9-cb37-4f9b-98b9-70b522c48cd5": {"__data__": {"id_": "b46bd0b9-cb37-4f9b-98b9-70b522c48cd5", "embedding": null, "metadata": {"page_label": "xiii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "add41a6d-9cd4-4329-96b7-1fc9fb599b59", "node_type": "4", "metadata": {"page_label": "xiii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "399cf2dee9d092cf8a2a9aa2e4fe082d54bda324ba0ca7d97a1fdd3af06a754e", "class_name": "RelatedNodeInfo"}}, "text": "Table of Contents\nIntroduction  ................................................................. 1\nAbout This Book  .............................................................................................. 2\nFoolish Assumptions  ....................................................................................... 2\nHow This Book Is Organized  .......................................................................... 3\nPart I: Getting Started with Big Data  .................................................... 3\nPart II: Technology Foundations for Big Data  .................................... 3\nPart III: Big Data Management  .............................................................. 3\nPart IV: Analytics and Big Data  ............................................................ 4\nPart V: Big Data Implementation  .......................................................... 4\nPart VI: Big Data Solutions in the Real World  ..................................... 4\nPart VII: The Part of Tens  ...................................................................... 4\nGlossary  .................................................................................................. 4\nIcons Used in This Book  ................................................................................. 5\nWhere to Go from Here  ................................................................................... 5\nPart I : Getting Started with Big Data  ............................. 7\nChapter 1 : Grasping the Fundamentals of Big Data  . . . . . . . . . . . . . . . . . 9\nThe Evolution of Data Management  ............................................................ 10\nUnderstanding the Waves of Managing Data  ............................................. 11\nWave 1: Creating manageable data structures ................................. 11\nWave 2: Web and content management  ........................................... 13\nWave 3: Managing big data  ................................................................. 14\nDefining Big Data  ............................................................................................ 15\nBuilding a Successful Big Data Management Architecture  ...................... 16\nBeginning with capture, organize, integrate, analyze, and act  ......16\nSetting the architectural foundation  ................................................. 17\nPerformance matters  ........................................................................... 20\nTraditional and advanced analytics  .................................................. 22\nThe Big Data Journey  .................................................................................... 23\nChapter 2 : Examining Big Data Types   . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\nDefining Structured Data  .............................................................................. 26\nExploring sources of big structured data  ......................................... 26\nUnderstanding the role of relational databases in big data  ........... 27\nDefining Unstructured Data  .......................................................................... 29\nExploring sources of unstructured data  ........................................... 29\nUnderstanding the role of a CMS in big data management  ............ 31\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3329, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b7f6a232-4405-428e-b5f4-ff10e689b86b": {"__data__": {"id_": "b7f6a232-4405-428e-b5f4-ff10e689b86b", "embedding": null, "metadata": {"page_label": "xiv", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "24c290db-6e80-4b5d-ab45-2a4f277f0da2", "node_type": "4", "metadata": {"page_label": "xiv", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e0cb07ac7a0f6da493f636a4ae97e774180fd94a490117538e77a60381cf4536", "class_name": "RelatedNodeInfo"}}, "text": "Big Data For Dummies xiv\nLooking at Real-Time and Non-Real-Time Requirements  ......................... 32\nPutting Big Data Together  ............................................................................ 33\nManaging different data types  ............................................................ 33\nIntegrating data types into a big data environment  ........................ 34\nChapter 3 : Old Meets New: Distributed Computing  . . . . . . . . . . . . . . . . 37\nA Brief History of Distributed Computing  .................................................. 37\nGiving thanks to DARPA  ...................................................................... 38\nThe value of a consistent model  ........................................................ 39\nUnderstanding the Basics of Distributed Computing  ............................... 40\nWhy we need distributed computing for big data  ........................... 40\nThe changing economics of computing  ............................................ 40\nThe problem with latency  ................................................................... 41\nDemand meets solutions ..................................................................... 41\nGetting Performance Right  ........................................................................... 42\nPart II : Technology Foundations for Big Data  ............... 45\nChapter 4 : Digging into Big Data Technology Components  . . . . . . . . . 47\nExploring the Big Data Stack  ........................................................................ 48\nLayer 0: Redundant Physical Infrastructure  .............................................. 49\nPhysical redundant networks  ............................................................ 51\nManaging hardware: Storage and servers  ........................................ 51\nInfrastructure operations  ................................................................... 51\nLayer 1: Security Infrastructure  ................................................................... 52\nInterfaces and Feeds to and from Applications and the Internet  ............ 53\nLayer 2: Operational Databases  ................................................................... 54\nLayer 3: Organizing Data Services and Tools  ............................................. 56\nLayer 4: Analytical Data Warehouses  ......................................................... 56\nBig Data Analytics  .......................................................................................... 58\nBig Data Applications  .................................................................................... 58\nChapter 5 : Virtualization and How It Supports  \nDistributed Computing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\nUnderstanding the Basics of Virtualization  ............................................... 61\nThe importance of virtualization to big data  ................................... 63\nServer virtualization  ............................................................................ 64\nApplication virtualization  ................................................................... 65\nNetwork virtualization ......................................................................... 66\nProcessor and memory virtualization  ............................................... 66\nData and storage virtualization  .......................................................... 67\nManaging Virtualization with the Hypervisor  ............................................ 68\nAbstraction and Virtualization  .................................................................... 69\nImplementing Virtualization to Work with Big Data  ................................. 69\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3759, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1a7469ed-d316-4acb-9c87-72301c2a0cc3": {"__data__": {"id_": "1a7469ed-d316-4acb-9c87-72301c2a0cc3", "embedding": null, "metadata": {"page_label": "xv", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "38193ee0-f7f2-4ac6-a473-4769d7153f8a", "node_type": "4", "metadata": {"page_label": "xv", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "a3b28051f3c30b2edc0b4b128cc28c39fcba0d627c62ce29e19f6d9b0f1ac405", "class_name": "RelatedNodeInfo"}}, "text": "xv  Table of Contents\nChapter 6 : Examining the Cloud and Big Data   . . . . . . . . . . . . . . . . . . . . 71\nDefining the Cloud in the Context of Big Data  ........................................... 71\nUnderstanding Cloud Deployment and Delivery Models  ......................... 72\nCloud deployment models  .................................................................. 73\nCloud delivery models  ........................................................................ 74\nThe Cloud as an Imperative for Big Data  .................................................... 75\nMaking Use of the Cloud for Big Data  ......................................................... 77\nProviders in the Big Data Cloud Market  ..................................................... 78\nAmazon\u2019s Public Elastic Compute Cloud  .......................................... 78\nGoogle big data services  ..................................................................... 79\nMicrosoft Azure  .................................................................................... 80\nOpenStack  ............................................................................................. 80\nWhere to be careful when using cloud services  .............................. 81\nPart III : Big Data Management  ................................... 83\nChapter 7 : Operational Databases   . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\nRDBMSs Are Important in a Big Data Environment  ................................... 87\nPostgreSQL relational database  ......................................................... 87\nNonrelational Databases  ............................................................................... 88\nKey-Value Pair Databases  ............................................................................. 89\nRiak key-value database  ...................................................................... 90\nDocument Databases  .................................................................................... 91\nMongoDB  ............................................................................................... 92\nCouchDB  ............................................................................................... 93\nColumnar Databases  ..................................................................................... 94\nHBase columnar database  .................................................................. 94\nGraph Databases  ............................................................................................ 95\nNeo4J graph database  ......................................................................... 96\nSpatial Databases  ........................................................................................... 97\nPostGIS/OpenGEO Suite  ...................................................................... 98\nPolyglot Persistence  ...................................................................................... 99\nChapter 8 : MapReduce Fundamentals   . . . . . . . . . . . . . . . . . . . . . . . . . . 101\nTracing the Origins of MapReduce  ............................................................ 101\nUnderstanding the map Function  .............................................................. 103\nAdding the reduce Function  ....................................................................... 104\nPutting map and reduce Together  ............................................................ 105\nOptimizing MapReduce Tasks  ................................................................... 108\nHardware/network topology  ............................................................ 108\nSynchronization  ................................................................................. 108\nFile system  .......................................................................................... 108\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3893, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1c18d600-cb18-4830-8d16-cc45f9f449fb": {"__data__": {"id_": "1c18d600-cb18-4830-8d16-cc45f9f449fb", "embedding": null, "metadata": {"page_label": "xvi", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e5f26531-e198-4035-bff8-1af96ff50c08", "node_type": "4", "metadata": {"page_label": "xvi", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "6f313a8c4902694c76b78e3f8e17fc3513313b9c4b983b9d4093965b142d1ed4", "class_name": "RelatedNodeInfo"}}, "text": "Big Data For Dummies xvi\nChapter 9 : Exploring the World of Hadoop   . . . . . . . . . . . . . . . . . . . . . . 111\nExplaining Hadoop  ...................................................................................... 111\nUnderstanding the Hadoop Distributed File System (HDFS)  ................. 112\nNameNodes  ......................................................................................... 113\nData nodes  .......................................................................................... 114\nUnder the covers of HDFS  ................................................................. 115\nHadoop MapReduce  .................................................................................... 116\nGetting the data ready  ....................................................................... 117\nLet the mapping begin  ....................................................................... 118\nReduce and combine  ......................................................................... 118\nChapter 10 : The Hadoop Foundation and Ecosystem  . . . . . . . . . . . . . . 121\nBuilding a Big Data Foundation with the Hadoop Ecosystem  ............... 121\nManaging Resources and Applications with Hadoop YARN  .................. 122\nStoring Big Data with HBase  ....................................................................... 123\nMining Big Data with Hive  .......................................................................... 124\nInteracting with the Hadoop Ecosystem  .................................................. 125\nPig and Pig Latin ................................................................................. 125\nSqoop  ................................................................................................... 126\nZookeeper  ........................................................................................... 127\nChapter 11 : Appliances and Big Data Warehouses  . . . . . . . . . . . . . . . 129\nIntegrating Big Data with the Traditional Data Warehouse  ................... 129\nOptimizing the data warehouse  ....................................................... 130\nDifferentiating big data structures from data warehouse data  ....130\nExamining a hybrid process case study  ......................................... 131\nBig Data Analysis and the Data Warehouse  ............................................. 133\nThe integration lynchpin  .................................................................. 134\nRethinking extraction, transformation, and loading  ..................... 134\nChanging the Role of the Data Warehouse  ............................................... 135\nChanging Deployment Models in the Big Data Era  .................................. 136\nThe appliance model  ......................................................................... 136\nThe cloud model  ................................................................................ 137\nExamining the Future of Data Warehouses  .............................................. 137\nPart IV : Analytics and Big Data  ................................ 139\nChapter 12 : Defining Big Data Analytics   . . . . . . . . . . . . . . . . . . . . . . . . 141\nUsing Big Data to Get Results  ..................................................................... 142\nBasic analytics  .................................................................................... 142\nAdvanced analytics ............................................................................ 143\nOperationalized analytics  ................................................................. 146\nMonetizing analytics  .......................................................................... 146\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3726, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "84a2e502-7962-4995-aa49-7c39b285357c": {"__data__": {"id_": "84a2e502-7962-4995-aa49-7c39b285357c", "embedding": null, "metadata": {"page_label": "xvii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f9c9bf02-14ff-44f0-b6b4-e176d85f1243", "node_type": "4", "metadata": {"page_label": "xvii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "20d020627b3b9b513619b670da9ad6de397bacb6f33d03c8572c41164e1f21ff", "class_name": "RelatedNodeInfo"}}, "text": "xvii  Table of Contents\nModifying Business Intelligence Products to Handle Big Data  .............. 147\nData  ...................................................................................................... 147\nAnalytical algorithms  ........................................................................ 148\nInfrastructure support  ...................................................................... 148\nStudying Big Data Analytics Examples  ...................................................... 149\nOrbitz  ................................................................................................... 149\nNokia  .................................................................................................... 150\nNASA  .................................................................................................... 150\nBig Data Analytics Solutions  ...................................................................... 151\nChapter 13 : Understanding Text Analytics and Big Data   . . . . . . . . . . 153\nExploring Unstructured Data  ..................................................................... 154\nUnderstanding Text Analytics  ................................................................... 155\nThe difference between text analytics and search  ........................ 156\nAnalysis and Extraction Techniques  ......................................................... 157\nUnderstanding the extracted information  ...................................... 159\nTaxonomies  ........................................................................................ 160\nPutting Your Results Together with Structured Data  ............................. 160\nPutting Big Data to Use  ............................................................................... 161\nVoice of the customer  ....................................................................... 161\nSocial media analytics  ....................................................................... 162\nText Analytics Tools for Big Data  .............................................................. 164\nAttensity  .............................................................................................. 164\nClarabridge  ......................................................................................... 165\nIBM ....................................................................................................... 165\nOpenText  ............................................................................................ 165\nSAS ....................................................................................................... 166\nChapter 14 : Customized Approaches for Analysis of Big Data   . . . . . 167\nBuilding New Models and Approaches to Support Big Data  .................. 168\nCharacteristics of big data analysis  ................................................ 168\nUnderstanding Different Approaches to Big Data Analysis  ................... 170\nCustom applications for big data analysis  ..................................... 171\nSemi-custom applications for big data analysis ............................. 173\nCharacteristics of a Big Data Analysis Framework  ................................. 174\nBig to Small: A Big Data Paradox  ............................................................... 177\nPart V : Big Data Implementation  ............................... 179\nChapter 15 : Integrating Data Sources  . . . . . . . . . . . . . . . . . . . . . . . . . . . 181\nIdentifying the Data You Need  ................................................................... 181\nExploratory stage  ............................................................................... 182\nCodifying stage  ................................................................................... 184\nIntegration and incorporation stage  ............................................... 184\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3917, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7df46486-3d2d-4d7b-a149-fe5aedf8abba": {"__data__": {"id_": "7df46486-3d2d-4d7b-a149-fe5aedf8abba", "embedding": null, "metadata": {"page_label": "xviii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7bde4a0c-3abb-4812-a776-0081cb0f041d", "node_type": "4", "metadata": {"page_label": "xviii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "fe7c98933fb88811fc8048674884cd8af7b11381628ffbcb6d90120c833303f7", "class_name": "RelatedNodeInfo"}}, "text": "Big Data For Dummies xviii\nUnderstanding the Fundamentals of Big Data Integration  ..................... 186\nDefining Traditional ETL  ............................................................................. 187\nData transformation  .......................................................................... 188\nUnderstanding ELT \u2014 Extract, Load, and Transform  ............................. 189\nPrioritizing Big Data Quality  ....................................................................... 189\nUsing Hadoop as ETL  .................................................................................. 191\nBest Practices for Data Integration in a Big Data World  ......................... 191\nChapter 16 : Dealing with Real-Time Data Streams and  \nComplex Event Processing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193\nExplaining Streaming Data and Complex Event Processing  ................... 194\nUsing Streaming Data  .................................................................................. 194\nData streaming  ................................................................................... 195\nThe need for metadata in streams  ................................................... 196\nUsing Complex Event Processing  .............................................................. 198\nDifferentiating CEP from Streams  .............................................................. 199\nUnderstanding the Impact of Streaming Data and CEP on Business  ....200\nChapter 17 : Operationalizing Big Data  . . . . . . . . . . . . . . . . . . . . . . . . . . 201\nMaking Big Data a Part of Your Operational Process  ............................. 201\nIntegrating big data  ............................................................................ 202\nIncorporating big data into the diagnosis of diseases  .................. 203\nUnderstanding Big Data Workflows  .......................................................... 205\nWorkload in context to the business problem  ............................... 206\nEnsuring the Validity, Veracity, and Volatility of Big Data  ..................... 207\nData validity  ........................................................................................ 207\nData volatility  ..................................................................................... 208\nChapter 18 : Applying Big Data within Your Organization  . . . . . . . . . . 211\nFiguring the Economics of Big Data  .......................................................... 212\nIdentification of data types and sources ......................................... 212\nBusiness process modifications or new process creation  ........... 215\nThe technology impact of big data workflows  ............................... 215\nFinding the talent to support big data projects  ............................. 216\nCalculating the return on investment (ROI) from  \nbig data investments  ...................................................................... 216\nEnterprise Data Management and Big Data  .............................................. 217\nDefining Enterprise Data Management  ............................................ 217\nCreating a Big Data Implementation Road Map  ....................................... 218\nUnderstanding business urgency  .................................................... 218\nProjecting the right amount of capacity  ......................................... 219\nSelecting the right software development methodology  .............. 219\nBalancing budgets and skill sets  ...................................................... 219\nDetermining your appetite for risk  .................................................. 220\nStarting Your Big Data Road Map  .............................................................. 220\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3826, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a127573a-66cf-4185-80e8-efc416c418c3": {"__data__": {"id_": "a127573a-66cf-4185-80e8-efc416c418c3", "embedding": null, "metadata": {"page_label": "xix", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0fc55273-b276-416c-9c81-358af7196828", "node_type": "4", "metadata": {"page_label": "xix", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "2c432fa211069e6f782c8279c7b61b958bd97ff4bdcc477787a041552767a90d", "class_name": "RelatedNodeInfo"}}, "text": "xix  Table of Contents\nChapter 19 : Security and Governance for Big Data Environments   . . .225\nSecurity in Context with Big Data  .............................................................. 225\nAssessing the risk for the business  ................................................. 226\nRisks lurking inside big data  ............................................................. 226\nUnderstanding Data Protection Options  .................................................. 227\nThe Data Governance Challenge  ............................................................... 228\nAuditing your big data process  ........................................................ 230\nIdentifying the key stakeholders  ...................................................... 231\nPutting the Right Organizational Structure in Place  ............................... 231\nPreparing for stewardship and management of risk  ..................... 232\nSetting the right governance and quality policies  ......................... 232\nDeveloping a Well-Governed and Secure Big Data Environment  .......... 233\nPart VI : Big Data Solutions in the Real World  ............. 235\nChapter 20 : The Importance of Big Data to Business   . . . . . . . . . . . . . 237\nBig Data as a Business Planning Tool  ....................................................... 238\nStage 1: Planning with data  ............................................................... 238\nStage 2: Doing the analysis  ............................................................... 239\nStage 3: Checking the results ............................................................ 239\nStage 4: Acting on the plan  ............................................................... 240\nAdding New Dimensions to the Planning Cycle  ....................................... 240\nStage 5: Monitoring in real time  ....................................................... 240\nStage 6: Adjusting the impact  ........................................................... 241\nStage 7: Enabling experimentation  .................................................. 241\nKeeping Data Analytics in Perspective  ..................................................... 241\nGetting Started with the Right Foundation  .............................................. 242\nGetting your big data strategy started  ............................................ 242\nPlanning for Big Data  ................................................................................... 243\nTransforming Business Processes with Big Data  .................................... 244\nChapter 21 : Analyzing Data in Motion: A Real-World View  . . . . . . . . 245\nUnderstanding Companies\u2019 Needs for Data in Motion  ........................... 246\nThe value of streaming data  ............................................................. 247\nStreaming Data with an Environmental Impact  ....................................... 247\nUsing sensors to provide real-time information about  \nrivers and oceans  ........................................................................... 248\nThe benefits of real-time data  .......................................................... 249\nStreaming Data with a Public Policy Impact  ............................................ 249\nStreaming Data in the Healthcare Industry  .............................................. 251\nCapturing the data stream  ................................................................ 251\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3463, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ede77671-55ee-4ccf-a1e0-f64f6ca95335": {"__data__": {"id_": "ede77671-55ee-4ccf-a1e0-f64f6ca95335", "embedding": null, "metadata": {"page_label": "xx", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1f06629b-27e4-4894-9d8b-0b07da8e72da", "node_type": "4", "metadata": {"page_label": "xx", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "2407aa6479311c0bde0f563cf9d6a155878009ba42707c0a974b9e2b5eccd2af", "class_name": "RelatedNodeInfo"}}, "text": "Big Data For Dummies xx\nStreaming Data in the Energy Industry  ..................................................... 252\nUsing streaming data to increase energy efficiency  ...................... 252\nUsing streaming data to advance the production of  \nalternative sources of energy  ....................................................... 252\nConnecting Streaming Data to Historical and Other  \nReal-Time Data Sources  .......................................................................... 253\nChapter 22 : Improving Business Processes with Big  \nData Analytics: A Real-World View  . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255\nUnderstanding Companies\u2019 Needs for Big Data Analytics  ..................... 256\nImproving the Customer Experience with Text Analytics  ..................... 256\nThe business value to the big data analytics implementation  ....257\nUsing Big Data Analytics to Determine Next Best Action  ....................... 257\nPreventing Fraud with Big Data Analytics  ................................................ 260\nThe Business Benefit of Integrating  \nNew Sources of Data  ................................................................................ 262\nPart VII : The Part of Tens  .......................................... 263\nChapter 23 : Ten Big Data Best Practices  . . . . . . . . . . . . . . . . . . . . . . . . 265\nUnderstand Your Goals  .............................................................................. 265\nEstablish a Road Map  .................................................................................. 266\nDiscover Your Data  ..................................................................................... 266\nFigure Out What Data You Don\u2019t Have  ...................................................... 267\nUnderstand the Technology Options  ........................................................ 267\nPlan for Security in Context with Big Data  ............................................... 268\nPlan a Data Governance Strategy  .............................................................. 268\nPlan for Data Stewardship  .......................................................................... 268\nContinually Test Your Assumptions  ......................................................... 269\nStudy Best Practices and Leverage Patterns  ........................................... 269\nChapter 24 : Ten Great Big Data Resources  . . . . . . . . . . . . . . . . . . . . . . 271\nHurwitz & Associates  .................................................................................. 271\nStandards Organizations  ............................................................................ 271\nThe Open Data Foundation  ............................................................... 272\nThe Cloud Security Alliance  ............................................................. 272\nNational Institute of Standards and Technology  ........................... 272\nApache Software Foundation  ........................................................... 273\nOASIS  ................................................................................................... 273\nVendor Sites  ................................................................................................. 273\nOnline Collaborative Sites  .......................................................................... 274\nBig Data Conferences  .................................................................................. 274\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3506, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1f20346c-450b-4af7-8b32-eb4b1ff9ee95": {"__data__": {"id_": "1f20346c-450b-4af7-8b32-eb4b1ff9ee95", "embedding": null, "metadata": {"page_label": "xxi", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f7694119-2b09-4d92-a212-8997d53de37f", "node_type": "4", "metadata": {"page_label": "xxi", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "68692da20bf4bc29ba576d0129b474870b23fafcfa94950610284cef00d58e08", "class_name": "RelatedNodeInfo"}}, "text": "xxi  Table of Contents\nChapter 25 : Ten Big Data Do\u2019s and Don\u2019ts  . . . . . . . . . . . . . . . . . . . . . . . 275\nDo Involve All Business Units in Your Big Data Strategy  ....................... 275\nDo Evaluate All Delivery Models for Big Data  .......................................... 276\nDo Think about Your Traditional Data Sources as Part of  \nYour Big Data Strategy  ............................................................................ 276\nDo Plan for Consistent Metadata  ............................................................... 276\nDo Distribute Your Data  ............................................................................. 277\nDon\u2019t Rely on a Single Approach to Big Data Analytics  .......................... 277\nDon\u2019t Go Big Before You Are Ready  .......................................................... 277\nDon\u2019t Overlook the Need to Integrate Data  .............................................. 277\nDon\u2019t Forget to Manage Data Securely  ...................................................... 278\nDon\u2019t Overlook the Need to Manage the Performance of Your Data  ....278\nGlossary  .................................................................. 279\nIndex  ....................................................................... 295\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1294, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b4838e3b-5c31-40aa-aa36-fcbdefd53486": {"__data__": {"id_": "b4838e3b-5c31-40aa-aa36-fcbdefd53486", "embedding": null, "metadata": {"page_label": "xxii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e9e1d51a-6ebe-45a3-8078-ef5a067f60b3", "node_type": "4", "metadata": {"page_label": "xxii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "26d0590b717eb8362522c99c3a698b333565cc490a44383b366eed7de310a721", "class_name": "RelatedNodeInfo"}}, "text": "Big Data For Dummies xxii\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 44, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7dba5258-79b1-4fd1-b861-c5885f73f725": {"__data__": {"id_": "7dba5258-79b1-4fd1-b861-c5885f73f725", "embedding": null, "metadata": {"page_label": "1", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fdee8dbf-d211-425d-bfdf-ac1c031e3456", "node_type": "4", "metadata": {"page_label": "1", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b104e0a85c6c143062e514961eb0df679ed8abd33ed30fac29bae0a4b23fc0fd", "class_name": "RelatedNodeInfo"}}, "text": "Introduction\nW \nelcome to Big Data For Dummies.  Big data is becoming one of the \nmost important technology trends that has the potential for dramati -\ncally changing the way organizations use information to enhance the cus -\ntomer experience and transform their business models. How does a company \ngo about using data to the best advantage? What does it mean to transform \nmassive amounts of data into knowledge? In this book, we provide you with \ninsights into how technology transitions in software, hardware, and delivery \nmodels are changing the way that data can be used in new ways.\nBig data is not a single market. Rather, it is a combination of data-manage -\nment technologies that have evolved over time. Big data enables organiza -\ntions to store, manage, and manipulate vast amounts of data at the right \nspeed and at the right time to gain the right insights. The key to understand -\ning big data is that data has to be managed so that it can meet the business \nrequirement a given solution is designed to support. Most companies are at \nan early stage with their big data journey. Many companies are experiment -\ning with techniques that allow them to collect massive amounts of data to \ndetermine whether hidden patterns exist within that data that might be an \nearly indication of an important change. Some data may indicate that cus -\ntomer buying patterns are changing or that new elements are in the business \nthat need to be addressed before it is too late.\nAs companies begin to evaluate new types of big data solutions, many new \nopportunities will unfold. For example, manufacturing companies may be \nable to monitor data coming from machine sensors to determine how pro -\ncesses need to be modified before a catastrophic event happens. It will be \npossible for retailers to monitor data in real time to upsell customers related \nproducts as they are executing a transaction. Big data solutions can be used \nin healthcare to determine the cause of an illness and provide a physician \nwith guidance on treatment options.\nBig data is not an isolated solution, however. Implementing a big data solu -\ntion requires that the infrastructure be in place to support the scalability, \ndistribution, and management of that data. Therefore, it is important to put \nboth a business and technical strategy in place to make use of this important \ntechnology trend.\nFor many important reasons, we think that it is important for you to under -\nstand big data technologies and know the ways that companies are using \nemerging technologies such as Hadoop, MapReduce, and new database \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2610, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "71d3b5d7-0e4f-44fd-94ff-28dfe80b0cc3": {"__data__": {"id_": "71d3b5d7-0e4f-44fd-94ff-28dfe80b0cc3", "embedding": null, "metadata": {"page_label": "2", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "687719a0-d285-44c5-88d4-815633ba23ac", "node_type": "4", "metadata": {"page_label": "2", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "707f2086736cd2d06425e1b1d6074c877b5ac07343f695bf72c987c9b49a39a3", "class_name": "RelatedNodeInfo"}}, "text": "2 Big Data For Dummies \nengines to transform the value of their data. We wrote this book to provide a \nperspective on what big data is and how it\u2019s changing the way that organiza -\ntions can leverage more data than was possible in the past. We think that this \nbook will give you the context to make informed decisions.\nAbout This Book\nBig data is new to many people, so it requires some investigation and under -\nstanding of both the technical and business requirements. Many different \npeople need knowledge about big data. Some of you want to delve into the \ntechnical details, while others want to understand the economic implica -\ntions of making use of big data technologies. Other executives need to know \nenough to be able to understand how big data can affect business decisions. \nImplementing a big data environment requires both an architectural and a \nbusiness approach \u2014 and lots of planning.\nNo matter what your goal is in reading this book, we address the following \nissues to help you understand big data and the impact it can have on your \nbusiness:\n \u2713 What is the architecture for big data? How can you manage huge vol -\numes of data without causing major disruptions in your data center?\n \u2713 When should you integrate the outcome of your big data analysis with \nyour data warehouse?\n \u2713 What are the implications of security and governance on the use of big \ndata? How can you keep your company safe?\n \u2713 What is the value of different data technologies, and when should you \nconsider them as part of your big data strategy?\n \u2713 What types of data sources can you take advantage of with big data  \nanalytics? How can you apply different types of analytics to business \nproblems?\nFoolish Assumptions\nTry as we might to be all things to all people, when it came to writing this \nbook, we had to pick who we thought would be most interested in Big Data \nFor Dummies.  Here\u2019s who we think you are:\n \u2713 You\u2019re smart.  You\u2019re no dummy, yet the topic of big data gives you an \nuneasy feeling. You can\u2019t quite get your head around it, and if you\u2019re \npressed for a definition, you might try to change the subject.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2137, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e8eb14d5-7623-48de-949f-e2a0e40d9545": {"__data__": {"id_": "e8eb14d5-7623-48de-949f-e2a0e40d9545", "embedding": null, "metadata": {"page_label": "3", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cbdd4b20-05a2-440a-b858-75c72c490441", "node_type": "4", "metadata": {"page_label": "3", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f21300548330fec5e3ae6739391610ad6cae7a0dd818e0da696965fe4ff8f086", "class_name": "RelatedNodeInfo"}}, "text": "3  Introduction\n \u2713 You\u2019re a businessperson who wants little or nothing to do with tech -\nnology.  But you live in the 21st century, so you can\u2019t escape it. People \nare saying, \u201cIt\u2019s all about big data,\u201d so you think that you better find out \nwhat they\u2019re talking about.\n \u2713 You\u2019re an IT person who knows a heck of a lot about technology.  The \nthing is, you\u2019re new to big data. Everybody says it\u2019s something different. \nOnce and for all, you want the whole picture.\nWhoever you are, welcome. We\u2019re here to help.\nHow This Book Is Organized\nWe divided our book into seven parts for easy reading. Feel free to skip \nabout.\nPart I: Getting Started with Big Data\nIn this part, we explain the basic concepts you need for a full understanding \nof big data, from both a technical and a business perspective. We also intro -\nduce you to the major concepts and components so that you can hold your \nown in any meaningful conversation about big data.\nPart II: Technology Foundations  \nfor Big Data\nPart II is for both technical and business professionals who need to under -\nstand the different types of big data components and the underlying tech -\nnology concepts that support big data. In this section, we give you an \nunderstanding about the type of infrastructure that will make big data more \npractical.\nPart III: Big Data Management\nPart III is for both technical and business professionals, but it gets into a lot \nmore of the details of different database options and emerging technologies \nsuch as MapReduce and Hadoop. Understanding these underlying technolo -\ngies can help you understand what is behind this important trend.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1644, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cc598e55-3726-463d-a41c-e3f164fed00f": {"__data__": {"id_": "cc598e55-3726-463d-a41c-e3f164fed00f", "embedding": null, "metadata": {"page_label": "4", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9fd7f062-5d6b-45af-ab7e-045f9e8f93e8", "node_type": "4", "metadata": {"page_label": "4", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "43e598c3be396535d3c3f9696d8dd4de932ddad4c72f9a2de4b68fdc6dc49037", "class_name": "RelatedNodeInfo"}}, "text": "4 Big Data For Dummies \nPart IV: Analytics and Big Data\nHow do you analyze the massive amounts of data that become part of your \nbig data infrastructure? In this part of the book, we go deeper into the differ -\nent types of analytics that are helpful in getting real meaning from your data. \nThis part helps you think about ways that you can turn big data into action \nfor your business.\nPart V: Big Data Implementation\nThis part gets to the details of what it means to actually manage data, includ -\ning issues such as operationalizing your data and protecting the security and \nprivacy of that data. This section gives you plenty to think about in this criti -\ncal area.\nPart VI: Big Data Solutions  \nin the Real World\nIn this section, you get an understanding of how companies are beginning to \nuse big data to transform their business operations. If you want to get a peek \ninto the future at what you might be able to do with data, this section is for \nyou.\nPart VII: The Part of Tens\nIf you\u2019re new to the For Dummies treasure-trove, you\u2019re no doubt unfamiliar \nwith The Part of Tens. In this section, Wiley editors torture For Dummies  \nauthors into creating useful bits of information that are easily accessible in \nlists containing ten (or so) elucidating elements. We started these chapters \nkicking and screaming but are ultimately very glad that they\u2019re here. After \nyou read through the big data best practices, and the do\u2019s and don\u2019ts we pro -\nvide in The Part of Tens, we think you\u2019ll be glad, too.\nGlossary\nWe include a glossary of terms frequently used when people discuss big data. \nAlthough we strive to define terms as we introduce them in this book, we \nthink you\u2019ll find the glossary a useful resource.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1742, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6912f116-7f59-4849-bf1a-dc01e725e38d": {"__data__": {"id_": "6912f116-7f59-4849-bf1a-dc01e725e38d", "embedding": null, "metadata": {"page_label": "5", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c709785d-1ba9-49cd-a20c-2af8e62503e9", "node_type": "4", "metadata": {"page_label": "5", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ef6f65cf33605216c262d88a3cb459f88bd9b6416fcc3b87e37b1a5d0013656c", "class_name": "RelatedNodeInfo"}}, "text": "5  Introduction\nIcons Used in This Book\n Pay attention. The bother you save may be your own.\n You may be sorry if this little tidbit slips your mind.\n With this icon, we mark particularly useful points to pay attention to.\n Here you find tidbits for the more technically inclined.\nWhere to Go from Here\nWe\u2019ve created an overview of big data and introduced you to all its signifi -\ncant components. We recommend that you read the first four chapters to \ngive you the context for what big data is about and what technologies are in \nplace to make implementations a reality. The next two chapters introduce \nyou to some of the underlying infrastructure issues that are important to \nunderstand. The following eight chapters get into a lot more detail about the \ndifferent types of data structures that are foundational to big data.\nYou can read the book from cover to cover, but if you\u2019re not that kind of \nperson, we\u2019ve tried to adhere to the For Dummies  style of keeping chapters \nself-contained so that you can go straight to the topics that interest you \nmost. Wherever you start, we wish you well.\nMany of these chapters could be expanded into full-length books of their \nown. Big data and the emerging technology landscape are a big focus for us \nat Hurwitz & Associates, and we invite you to visit our website and read our \nblogs and insights at www.hurwitz.com .\nOccasionally, John Wiley & Sons, Inc., has updates to its technology books. If \nthis book has technical updates, they will be posted at www.dummies.com/\ngo/bigdatafdupdates .\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1562, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "96d1d749-48e1-4036-a7d1-18486720c458": {"__data__": {"id_": "96d1d749-48e1-4036-a7d1-18486720c458", "embedding": null, "metadata": {"page_label": "6", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "18404ac8-1ea3-4b5a-ba6e-3be614d4c79b", "node_type": "4", "metadata": {"page_label": "6", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "2a33e33d25adf3833c796f51b878f13a75a898ddb50572512c90d88e3ad36e90", "class_name": "RelatedNodeInfo"}}, "text": "6 Big Data For Dummies \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 42, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f30623c8-d72f-40ec-9ddc-966bfbe57c7f": {"__data__": {"id_": "f30623c8-d72f-40ec-9ddc-966bfbe57c7f", "embedding": null, "metadata": {"page_label": "7", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2833af7b-0f23-46eb-a7f4-0ab540839ee7", "node_type": "4", "metadata": {"page_label": "7", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "09ec5b42bb5b198d3240b5cf60acedb64af12ef7abfdba6c75f7fb1ec9111d60", "class_name": "RelatedNodeInfo"}}, "text": "Part I\nBig \nDatagetting star ted\nwith\n Visit www.dummies.com  for more great Dummies  content online.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 120, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fc0a2d95-b0c1-490e-af6d-c13f356b2b08": {"__data__": {"id_": "fc0a2d95-b0c1-490e-af6d-c13f356b2b08", "embedding": null, "metadata": {"page_label": "8", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f881c3f0-275c-4869-8d2b-9b3cb254d004", "node_type": "4", "metadata": {"page_label": "8", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f6fe8f3f4aa5203c9b7bd329b218ef9ea2f4e5defcdb79692832c9148b7a0bc4", "class_name": "RelatedNodeInfo"}}, "text": "In this part . . .\n \u2713 Trace the evolution of data management.\n \u2713 Define big data and its technology components.\n \u2713 Understand the different types of big data.\n \u2713 Integrate structured and unstructured data.\n \u2713 Understand the difference between real-time and non-  \nreal-time data.\n \u2713 Scale your big data operation with distributed computing.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 359, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "df827497-e7f8-47f0-bd42-900afc0c851c": {"__data__": {"id_": "df827497-e7f8-47f0-bd42-900afc0c851c", "embedding": null, "metadata": {"page_label": "9", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dc7b01c0-4fe2-4f7b-9ae3-5bcd84cbbb6f", "node_type": "4", "metadata": {"page_label": "9", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "905c9c7749fda58d057cf61fcb2a263e234b26da64594aaeff7a0e8105db495e", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 1\nGrasping the Fundamentals of  \nBig Data\nIn This Chapter\n\u25b6 Looking at a history of data management\n\u25b6 Understanding why big data matters to business\n\u25b6 Applying big data to business effectiveness\n\u25b6 Defining the foundational elements of big data\n\u25b6 Examining big data\u2019s role in the future\nM \nanaging and analyzing data have always offered the greatest benefits \nand the greatest challenges for organizations of all sizes and across all \nindustries. Businesses have long struggled with finding a pragmatic approach \nto capturing information about their customers, products, and services. \nWhen a company only had a handful of customers who all bought the same \nproduct in the same way, things were pretty straightforward and simple. But \nover time, companies and the markets they participate in have grown more \ncomplicated. To survive or gain a competitive advantage with customers, \nthese companies added more product lines and diversified how they deliver \ntheir product. Data struggles are not limited to business. Research and devel -\nopment (R&D) organizations, for example, have struggled to get enough com -\nputing power to run sophisticated models or to process images and other \nsources of scientific data.\nIndeed, we are dealing with a lot of complexity when it comes to data. Some \ndata is structured and stored in a traditional relational database, while other \ndata, including documents, customer service records, and even pictures and \nvideos, is unstructured. Companies also have to consider new sources of \ndata generated by machines such as sensors. Other new information sources \nare human generated, such as data from social media and the click-stream \ndata generated from website interactions. In addition, the availability and \nadoption of newer, more powerful mobile devices, coupled with ubiquitous \naccess to global networks will drive the creation of new sources for data.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1921, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "416304b8-e98c-4eb1-af50-e8278024caa7": {"__data__": {"id_": "416304b8-e98c-4eb1-af50-e8278024caa7", "embedding": null, "metadata": {"page_label": "10", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "aad7331f-3acb-45f6-9c15-598b82182840", "node_type": "4", "metadata": {"page_label": "10", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "7141d3484fe622e0efdb9ccceeb8f95340ad08602a4df421a12f0fc4ff5a5a6a", "class_name": "RelatedNodeInfo"}}, "text": "10 Part I: Getting Started with Big Data \nAlthough each data source can be independently managed and searched, the \nchallenge today is how companies can make sense of the intersection of all \nthese different types of data. When you are dealing with so much information \nin so many different forms, it is impossible to think about data management \nin traditional ways. Although we have always had a lot of data, the difference \ntoday is that significantly more of it exists, and it varies in type and timeli -\nness. Organizations are also finding more ways to make use of this informa -\ntion than ever before. Therefore, you have to think about managing data \ndifferently. That is the opportunity and challenge of big data. In this chapter, \nwe provide you a context for what the evolution of the movement to big data \nis all about and what it means to your organization.\nThe Evolution of Data Management\nIt would be nice to think that each new innovation in data management is a \nfresh start and disconnected from the past. However, whether revolution -\nary or incremental, most new stages or waves of data management build on \ntheir predecessors. Although data management is typically viewed through \na software lens, it actually has to be viewed from a holistic perspective. Data \nmanagement has to include technology advances in hardware, storage, net -\nworking, and computing models such as virtualization and cloud computing. \nThe convergence of emerging technologies and reduction in costs for every -\nthing from storage to compute cycles have transformed the data landscape \nand made new opportunities possible.\nAs all these technology factors converge, it is transforming the way we \nmanage and leverage data. Big data is the latest trend to emerge because of \nthese factors. So, what is big data and why is it so important? Later in the \nbook, we provide a more comprehensive definition. To get you started, big \ndata is defined as any kind of data source that has at least three shared char -\nacteristics: \n \u2713 Extremely large Volumes  of data\n \u2713 Extremely high Velocity  of data\n \u2713 Extremely wide Variety  of data\nBig data is important because it enables organizations to gather, store, \nmanage, and manipulate vast amounts data at the right speed, at the right \ntime, to gain the right insights. But before we delve into the details of big \ndata, it is important to look at the evolution of data management and how \nit has led to big data. Big data is not a stand-alone technology; rather, it is a \ncombination of the last 50 years of technology evolution.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2586, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "83647c3a-18a1-497e-8fe3-8fc7c1b8f57b": {"__data__": {"id_": "83647c3a-18a1-497e-8fe3-8fc7c1b8f57b", "embedding": null, "metadata": {"page_label": "11", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f83de73f-8a35-4668-940e-d1d2009b49aa", "node_type": "4", "metadata": {"page_label": "11", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b3ce0ba692a050f01da9b3a70eb03d17b152c8a63750131e5524c18ebe12722d", "class_name": "RelatedNodeInfo"}}, "text": "11  Chapter 1: Grasping the Fundamentals of Big Data\nOrganizations today are at a tipping point in data management. We have \nmoved from the era where the technology was designed to support a specific \nbusiness need, such as determining how many items were sold to how many \ncustomers, to a time when organizations have more data from more sources \nthan ever before. All this data looks like a potential gold mine, but like a gold \nmine, you only have a little gold and lot more of everything else. The tech -\nnology challenges are \u201cHow do you make sense of that data when you can\u2019t \neasily recognize the patterns that are the most meaningful for your business \ndecisions? How does your organization deal with massive amounts of data in \na meaningful way?\u201d Before we get into the options, we take a look at the evo -\nlution of data management and see how these waves are connected.\nUnderstanding the Waves  \nof Managing Data\nEach data management wave is born out of the necessity to try and solve a \nspecific type of data management problem. Each of these waves or phases \nevolved because of cause and effect. When a new technology solution came \nto market, it required the discovery of new approaches. When the relational \ndatabase came to market, it needed a set of tools to allow managers to study \nthe relationship between data elements. When companies started storing \nunstructured data, analysts needed new capabilities such as natural lan -\nguage\u2013based analysis tools to gain insights that would be useful to business. \nIf you were a search engine company leader, you began to realize that you \nhad access to immense amounts of data that could be monetized. To gain \nvalue from that data required new innovative tools and approaches.\nThe data management waves over the past five decades have culminated in \nwhere we are today: the initiation of the big data era. So, to understand big \ndata, you have to understand the underpinning of these previous waves. You \nalso need to understand that as we move from one wave to another, we don\u2019t \nthrow away the tools and technology and practices that we have been using \nto address a different set of problems.\nWave 1: Creating manageable  \ndata structures\nAs computing moved into the commercial market in the late 1960s, data was \nstored in flat files that imposed no structure. When companies needed to \nget to a level of detailed understanding about customers, they had to apply \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2449, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aa09dd1a-df2d-405d-87e9-c474b6085fde": {"__data__": {"id_": "aa09dd1a-df2d-405d-87e9-c474b6085fde", "embedding": null, "metadata": {"page_label": "12", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "770f4e5d-7f66-45fa-9613-a346e9166ba9", "node_type": "4", "metadata": {"page_label": "12", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "712ab055044848777f3b1018323751796f14b984b0bb334c57380be769638483", "class_name": "RelatedNodeInfo"}}, "text": "12 Part I: Getting Started with Big Data \nbrute-force methods, including very detailed programming models to create \nsome value. Later in the 1970s, things changed with the invention of the rela -\ntional data model and the relational database management system (RDBMS) \nthat imposed structure and a method for improving performance. Most \nimportantly, the relational model added a level of abstraction (the structured \nquery language [SQL], report generators, and data management tools) so that \nit was easier for programmers to satisfy the growing business demands to \nextract value from data.\nThe relational model offered an ecosystem of tools from a large number \nof emerging software companies. It filled a growing need to help compa -\nnies better organize their data and be able to compare transactions from \none geography to another. In addition, it helped business managers who \nwanted to be able to examine information such as inventory and compare \nit to customer order information for decision-making purposes. But a prob -\nlem emerged from this exploding demand for answers: Storing this growing \nvolume of data was expensive and accessing it was slow. Making matters \nworse, lots of data duplication existed, and the actual business value of that \ndata was hard to measure.\nAt this stage, an urgent need existed to find a new set of technologies to \nsupport the relational model. The Entity-Relationship (ER) model emerged, \nwhich added additional abstraction to increase the usability of the data. In \nthis model, each item was defined independently of its use. Therefore, devel -\nopers could create new relationships between data sources without complex \nprogramming. It was a huge advance at the time, and it enabled developers \nto push the boundaries of the technology and create more complex models \nrequiring complex techniques for joining entities together. The market for \nrelational databases exploded and remains vibrant today. It is especially \nimportant for transactional data management of highly structured data.\nWhen the volume of data that organizations needed to manage grew out \nof control, the data warehouse provided a solution. The data warehouse \nenabled the IT organization to select a subset of the data being stored so \nthat it would be easier for the business to try to gain insights. The data ware -\nhouse was intended to help companies deal with increasingly large amounts \nof structured data that they needed to be able to analyze by reducing the \nvolume of the data to something smaller and more focused on a particu -\nlar area of the business. It filled the need to separate operational decision \nsupport processing and decision support \u2014 for performance reasons. In \naddition, warehouses often store data from prior years for understanding \norganizational performance, identifying trends, and helping to expose pat -\nterns of behavior. It also provided an integrated source of information from \nacross various data sources that could be used for analysis. Data warehouses \nwere commercialized in the 1990s, and today, both content management \nsystems and data warehouses are able to take advantage of improvements in \nscalability of hardware, virtualization technologies, and the ability to create \nintegrated hardware and software systems, also known as appliances.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3329, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f75ad44c-6312-4d54-bdf2-660cc74eb0f6": {"__data__": {"id_": "f75ad44c-6312-4d54-bdf2-660cc74eb0f6", "embedding": null, "metadata": {"page_label": "13", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "25badc8a-7be7-428a-bd7c-3c24b46a02da", "node_type": "4", "metadata": {"page_label": "13", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "275f04fc99e293cc911cb7b51d1b418d3744681a76b1a547eb75eefc7f700dd8", "class_name": "RelatedNodeInfo"}}, "text": "13  Chapter 1: Grasping the Fundamentals of Big Data\nSometimes these data warehouses themselves were too complex and large \nand didn\u2019t offer the speed and agility that the business required. The answer \nwas a further refinement of the data being managed through data marts. \nThese data marts were focused on specific business issues and were much \nmore streamlined and supported the business need for speedy queries than \nthe more massive data warehouses. Like any wave of data management, the \nwarehouse has evolved to support emerging technologies such as integrated \nsystems and data appliances.\nData warehouses and data marts solved many problems for companies need -\ning a consistent way to manage massive transactional data. But when it came \nto managing huge volumes of unstructured or semi-structured data, the ware -\nhouse was not able to evolve enough to meet changing demands. To com -\nplicate matters, data warehouses are typically fed in batch intervals, usually \nweekly or daily. This is fine for planning, financial reporting, and traditional \nmarketing campaigns, but is too slow for increasingly real-time business and \nconsumer environments.\nHow would companies be able to transform their traditional data manage -\nment approaches to handle the expanding volume of unstructured data  \nelements? The solution did not emerge overnight. As companies began to \nstore unstructured data, vendors began to add capabilities such as BLOBs \n(binary large objects).  In essence, an unstructured data element would be \nstored in a relational database as one contiguous chunk of data. This object \ncould be labeled (that is, a customer inquiry) but you couldn\u2019t see what was \ninside that object. Clearly, this wasn\u2019t going to solve changing customer or \nbusiness needs.\nEnter the object database management system (ODBMS). The object data -\nbase stored the BLOB as an addressable set of pieces so that we could \nsee what was in there. Unlike the BLOB, which was an independent unit \nappended to a traditional relational database, the object database provided \na unified approach for dealing with unstructured data. Object databases \ninclude a programming language and a structure for the data elements so \nthat it is easier to manipulate various data objects without programming and \ncomplex joins. The object databases introduced a new level of innovation \nthat helped lead to the second wave of data management.\nWave 2: Web and content management \nIt\u2019s no secret that most data available in the world today is unstructured. \nParadoxically, companies have focused their investments in the systems  \nwith structured data that were most closely associated with revenue: line-\nof-business transactional systems. Enterprise Content Management systems \nevolved in the 1980s to provide businesses with the capability to better \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2846, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b23dc2fa-1750-4014-8fd0-c73df41ddde5": {"__data__": {"id_": "b23dc2fa-1750-4014-8fd0-c73df41ddde5", "embedding": null, "metadata": {"page_label": "14", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7d898864-7f27-4f06-b4f0-e27bed0645dd", "node_type": "4", "metadata": {"page_label": "14", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d046b3ea33f66e1382534e1d2792a47a00d6fcbe37751a15fe150994cf4a69ff", "class_name": "RelatedNodeInfo"}}, "text": "14 Part I: Getting Started with Big Data \nmanage unstructured data, mostly documents. In the 1990s with the rise of \nthe web, organizations wanted to move beyond documents and store and \nmanage web content, images, audio, and video.\nThe market evolved from a set of disconnected solutions to a more unified \nmodel that brought together these elements into a platform that incorporated \nbusiness process management, version control, information recognition, text \nmanagement, and collaboration. This new generation of systems added meta -\ndata (information about the organization and characteristics of the stored \ninformation). These solutions remain incredibly important for companies \nneeding to manage all this data in a logical manner. But at the same time, a \nnew generation of requirements has begun to emerge that drive us to the next \nwave. These new requirements have been driven, in large part, by a conver -\ngence of factors including the web, virtualization, and cloud computing. In \nthis new wave, organizations are beginning to understand that they need to \nmanage a new generation of data sources with an unprecedented amount and \nvariety of data that needs to be processed at an unheard-of speed.\nWave 3: Managing big data\nIs big data really new or is it an evolution in the data management journey? \nThe answer is yes \u2014 it is actually both. As with other waves in data manage -\nment, big data is built on top of the evolution of data management practices \nover the past five decades. What is new is that for the first time, the cost \nof computing cycles and storage has reached a tipping point. Why is this \nimportant? Only a few years ago, organizations typically would compromise \nby storing snapshots or subsets of important information because the cost of \nstorage and processing limitations prohibited them from storing everything \nthey wanted to analyze.\nIn many situations, this compromise worked fine. For example, a manufactur -\ning company might have collected machine data every two minutes to deter -\nmine the health of systems. However, there could be situations where the \nsnapshot would not contain information about a new type of defect and that \nmight go unnoticed for months.\nWith big data, it is now possible to virtualize data so that it can be stored \nefficiently and, utilizing cloud-based storage, more cost-effectively as well. In \naddition, improvements in network speed and reliability have removed other \nphysical limitations of being able to manage massive amounts of data at an \nacceptable pace. Add to this the impact of changes in the price and sophisti -\ncation of computer memory. With all these technology transitions, it is now \npossible to imagine ways that companies can leverage data that would have \nbeen inconceivable only five years ago.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2814, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "016cf1bc-154a-4154-a7d2-12ee63880b6a": {"__data__": {"id_": "016cf1bc-154a-4154-a7d2-12ee63880b6a", "embedding": null, "metadata": {"page_label": "15", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "53d20576-64c6-48ff-8fde-7f89b326f1b4", "node_type": "4", "metadata": {"page_label": "15", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "57c27e9506d11ad084fd91938cbeecdaa8a1a012a4191ec0fbb03f3553f96b10", "class_name": "RelatedNodeInfo"}}, "text": "15  Chapter 1: Grasping the Fundamentals of Big Data\nBut no technology transition happens in isolation; it happens when an impor -\ntant need exists that can be met by the availability and maturation of technol -\nogy. Many of the technologies at the heart of big data, such as virtualization, \nparallel processing, distributed file systems, and in-memory databases, have \nbeen around for decades. Advanced analytics have also been around for \ndecades, although they have not always been practical. Other technologies \nsuch as Hadoop and MapReduce have been on the scene for only a few years. \nThis combination of technology advances can now address significant busi -\nness problems. Businesses want to be able to gain insights and actionable \nresults from many different kinds of data at the right speed \u2014 no matter how \nmuch data is involved.\nIf companies can analyze petabytes of data (equivalent to 20 million four-\ndrawer file cabinets filled with text files or 13.3 years of HDTV content) with \nacceptable performance to discern patterns and anomalies, businesses can \nbegin to make sense of data in new ways. The move to big data is not just \nabout businesses. Science, research, and government activities have also \nhelped to drive it forward. Just think about analyzing the human genome or \ndealing with all the astronomical data collected at observatories to advance \nour understanding of the world around us. Consider the amount of data the \ngovernment collects in its antiterrorist activities as well, and you get the idea \nthat big data is not just about business.\nDifferent approaches to handling data exist based on whether it is data in \nmotion or data at rest. Here\u2019s a quick example of each. Data in motion would \nbe used if a company is able to analyze the quality of its products during the \nmanufacturing process to avoid costly errors. Data at rest would be used by \na business analyst to better understand customers\u2019 current buying patterns \nbased on all aspects of the customer relationship, including sales, social \nmedia data, and customer service interactions.\nKeep in mind that we are still at an early stage of leveraging huge volumes \nof data to gain a 360-degree view of the business and anticipate shifts and \nchanges in customer expectations. The technologies required to get the \nanswers the business needs are still isolated from each other. To get to the \ndesired end state, the technologies from all three waves will have to come \ntogether. As you will see as you read this book, big data is not simply about \none tool or one technology. It is about how all these technologies come \ntogether to give the right insights, at the right time, based on the right data \u2014 \nwhether it is generated by people, machines, or the web.\nDefining Big Data\nBig data is not a single technology but a combination of old and new tech -\nnologies that helps companies gain actionable insight. Therefore, big data is \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2949, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f056b2e8-cba1-4c65-948a-cd4e8c818767": {"__data__": {"id_": "f056b2e8-cba1-4c65-948a-cd4e8c818767", "embedding": null, "metadata": {"page_label": "16", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "18197570-beb4-4df9-96a1-3515edd0435e", "node_type": "4", "metadata": {"page_label": "16", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "7e6f38cb1180cb286ca18349f9f16f3070894658f66ad46ed5a4777c45c2df1d", "class_name": "RelatedNodeInfo"}}, "text": "16 Part I: Getting Started with Big Data \nthe capability to manage a huge volume of disparate data, at the right speed, \nand within the right time frame to allow real-time analysis and reaction. As \nwe note earlier in this chapter, big data is typically broken down by three \ncharacteristics:\n \u2713 Volume:  How much data\n \u2713 Velocity:  How fast that data is processed\n \u2713 Variety:  The various types of data\n Although it\u2019s convenient to simplify big data into the three Vs, it can be mis -\nleading and overly simplistic. For example, you may be managing a relatively \nsmall amount of very disparate, complex data or you may be processing a \nhuge volume of very simple data. That simple data may be all structured or \nall unstructured. Even more important is the fourth V: veracity. How accurate \nis that data in predicting business value? Do the results of a big data analysis \nactually make sense?\nIt is critical that you don\u2019t underestimate the task at hand. Data must be able \nto be verified based on both accuracy and context. An innovative business \nmay want to be able to analyze massive amounts of data in real time to quickly \nassess the value of that customer and the potential to provide additional \noffers to that customer. It is necessary to identify the right amount and types \nof data that can be analyzed to impact business outcomes. Big data incorpo -\nrates all data, including structured data and unstructured data from e-mail, \nsocial media, text streams, and more. This kind of data management requires \nthat companies leverage both their structured and unstructured data.\nBuilding a Successful Big Data \nManagement Architecture\nWe have moved from an era where an organization could implement a data -\nbase to meet a specific project need and be done. But as data has become \nthe fuel of growth and innovation, it is more important than ever to have an \nunderlying architecture to support growing requirements.\nBeginning with capture, organize,  \nintegrate, analyze, and act\nBefore we delve into the architecture, it is important to take into account the \nfunctional requirements for big data. Figure 1-1 illustrates that data must first \nbe captured, and then organized and integrated. After this phase is  \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2242, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "05927414-2f6d-4783-ac0f-c50b84b61425": {"__data__": {"id_": "05927414-2f6d-4783-ac0f-c50b84b61425", "embedding": null, "metadata": {"page_label": "17", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ae261330-b637-4903-97f6-c898d15dda64", "node_type": "4", "metadata": {"page_label": "17", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b6ffbb97a1f1e879ed6f4615aafab0204c97ba37c43476b7e38c6cf6e77d5dbf", "class_name": "RelatedNodeInfo"}}, "text": "17  Chapter 1: Grasping the Fundamentals of Big Data\nsuccessfully implemented, data can be analyzed based on the problem being \naddressed. Finally, management takes action based on the outcome of that \nanalysis. For example, Amazon.com might recommend a book based on a \npast purchase or a customer might receive a coupon for a discount for a \nfuture purchase of a related product to one that was just purchased.\n Figure 1-1:  \nThe cycle \nof big data \nmanagement.\n \nAlthough this sounds straightforward, certain nuances of these functions are \ncomplicated. Validation is a particularly important issue. If your organization \nis combining data sources, it is critical that you have the ability to validate that \nthese sources make sense when combined. Also, certain data sources may con -\ntain sensitive information, so you must implement sufficient levels of security \nand governance. We cover data management in more detail in Chapter 7.\n Of course, any foray into big data first needs to start with the problem you\u2019re \ntrying to solve. That will dictate the kind of data that you need and what the \narchitecture might look like.\nSetting the architectural foundation\nIn addition to supporting the functional requirements, it is important to sup -\nport the required performance. Your needs will depend on the nature of the \nanalysis you are supporting. You will need the right amount of computational \npower and speed. While some of the analysis you will do will be performed \nin real time, you will inevitably be storing some amount of data as well. Your \narchitecture also has to have the right amount of redundancy so that you are \nprotected from unanticipated latency and downtime.\nYour organization and its needs will determine how much attention you have \nto pay to these performance issues. So, start out by asking yourself the fol -\nlowing questions:\n \u2713 How much data will my organization need to manage today and in the \nfuture?\n \u2713 How often will my organization need to manage data in real time or near \nreal time?\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2043, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6bad8a95-b7f9-42a2-bc1a-99fa597fe34f": {"__data__": {"id_": "6bad8a95-b7f9-42a2-bc1a-99fa597fe34f", "embedding": null, "metadata": {"page_label": "18", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "70b35b3e-f04d-45fd-860a-1b1c97c568c0", "node_type": "4", "metadata": {"page_label": "18", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "aa6e05d87b9942654d0e9480d30b973502c490dd45e5fc37c70468685ff9c7a9", "class_name": "RelatedNodeInfo"}}, "text": "18 Part I: Getting Started with Big Data \n \u2713 How much risk can my organization afford? Is my industry subject to \nstrict security, compliance, and governance requirements?\n \u2713 How important is speed to my need to manage data?\n \u2713 How certain or precise does the data need to be?\nTo understand big data, it helps to lay out the components of the architec -\nture. A big data management architecture must include a variety of services \nthat enable companies to make use of myriad data sources in a fast and effec -\ntive manner. To help you make sense of this, we put the components into a \ndiagram (see Figure 1-2) that will help you see what\u2019s there and the relation -\nship between the components. In the next section, we explain each compo -\nnent and describe how these components are related to each other.\n Figure 1-2:  \nThe big data \narchitecture.\n \nInterfaces and feeds\nBefore we get into the nitty-gritty of the big data technology stack itself, we\u2019d \nlike you to notice that on either side of the diagram are indications of inter -\nfaces and feeds into and out of both internally managed data and data feeds \nfrom external sources. To understand how big data works in the real world, \nit is important to start by understanding this necessity. In fact, what makes \nbig data big is the fact that it relies on picking up lots of data from lots of \nsources. Therefore, open application programming interfaces (APIs) will be \ncore to any big data architecture. In addition, keep in mind that interfaces \nexist at every level and between every layer of the stack. Without integration \nservices, big data can\u2019t happen.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1633, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b9172eb0-ec3b-4bbb-bdab-6526d904b1f4": {"__data__": {"id_": "b9172eb0-ec3b-4bbb-bdab-6526d904b1f4", "embedding": null, "metadata": {"page_label": "19", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b4ecd103-8507-4004-ad74-c205df9e9ffd", "node_type": "4", "metadata": {"page_label": "19", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "3096f100cc32e252c4441c65aa4eed948291747339064e6df9de8daae8fc7f3f", "class_name": "RelatedNodeInfo"}}, "text": "19  Chapter 1: Grasping the Fundamentals of Big Data\nRedundant physical infrastructure\nThe supporting physical infrastructure is fundamental to the operation and \nscalability of a big data architecture. In fact, without the availability of robust \nphysical infrastructures, big data would probably not have emerged as such \nan important trend. To support an unanticipated or unpredictable volume \nof data, a physical infrastructure for big data has to be different than that \nfor traditional data. The physical infrastructure is based on a distributed \ncomputing model. This means that data may be physically stored in many \ndifferent locations and can be linked together through networks, the use of a \ndistributed file system, and various big data analytic tools and applications.\nRedundancy is important because we are dealing with so much data from \nso many different sources. Redundancy comes in many forms. If your com -\npany has created a private cloud, you will want to have redundancy built \nwithin the private environment so that it can scale out to support changing \nworkloads. If your company wants to contain internal IT growth, it may use \nexternal cloud services to augment its internal resources. In some cases, this \nredundancy may come in the form of a Software as a Service (SaaS) offering \nthat allows companies to do sophisticated data analysis as a service. The \nSaaS approach offers lower costs, quicker startup, and seamless evolution of \nthe underlying technology.\nSecurity infrastructure\nThe more important big data analysis becomes to companies, the more \nimportant it will be to secure that data. For example, if you are a healthcare \ncompany, you will probably want to use big data applications to determine \nchanges in demographics or shifts in patient needs. This data about your \nconstituents needs to be protected both to meet compliance requirements \nand to protect the patients\u2019 privacy. You will need to take into account who \nis allowed to see the data and under what circumstances they are allowed to \ndo so. You will need to be able to verify the identity of users as well as pro -\ntect the identity of patients. These types of security requirements need to be \npart of the big data fabric from the outset and not an afterthought.\nOperational data sources\nWhen you think about big data, it is important to understand that you have \nto incorporate all the data sources that will give you a complete picture of \nyour business and see how the data impacts the way you operate your busi -\nness. Traditionally, an operational data source consisted of highly structured \ndata managed by the line of business in a relational database. But as the \nworld changes, it is important to understand that operational data now has \nto encompass a broader set of data sources, including unstructured sources \nsuch as customer and social media data in all its forms.\nYou find new emerging approaches to data management in the big data \nworld, including document, graph, columnar, and geospatial database  \narchitectures. Collectively, these are referred to as NoSQL,  or not only SQL, \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3125, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "38a35138-9888-490c-9112-205ee13926cb": {"__data__": {"id_": "38a35138-9888-490c-9112-205ee13926cb", "embedding": null, "metadata": {"page_label": "20", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "154704b8-3bcc-411c-8901-8d3fe0c953f9", "node_type": "4", "metadata": {"page_label": "20", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f0612299921ad451cc712e100568deb0145f0d4651368306f2ab858d23578769", "class_name": "RelatedNodeInfo"}}, "text": "20 Part I: Getting Started with Big Data \ndatabases. In essence, you need to map the data architectures to the types of \ntransactions. Doing so will help to ensure the right  data is available when you \nneed it. You also need data architectures that support complex unstructured \ncontent. You need to include both relational databases and nonrelational \ndatabases in your approach to harnessing big data. It is also necessary to \ninclude unstructured data sources, such as content management systems, so \nthat you can get closer to that 360-degree business view.\nAll these operational data sources have several characteristics in common:\n \u2713 They represent systems of record that keep track of the critical data \nrequired for real-time, day-to-day operation of the business.\n \u2713 They are continually updated based on transactions happening within \nbusiness units and from the web.\n \u2713 For these sources to provide an accurate representation of the business, \nthey must blend structured and unstructured data.\n \u2713 These systems also must be able to scale to support thousands of users \non a consistent basis. These might include transactional e-commerce \nsystems, customer relationship management systems, or call center \napplications.\nPerformance matters\nYour data architecture also needs to perform in concert with your organiza -\ntion\u2019s supporting infrastructure. For example, you might be interested in \nrunning models to determine whether it is safe to drill for oil in an offshore \narea given real-time data of temperature, salinity, sediment resuspension, \nand a host of other biological, chemical, and physical properties of the water \ncolumn. It might take days to run this model using a traditional server con -\nfiguration. However, using a distributed computing model, what took days \nmight now take minutes.\nPerformance might also determine the kind of database you would use. For \nexample, in some situations, you may want to understand how two very \ndistinct data elements are related. What is the relationship between buzz on \na social network and the growth in sales? This is not the typical query you \ncould ask of a structured, relational database. A graphing database might \nbe a better choice, as it is specifically designed to separate the \u201cnodes\u201d or \nentities from its \u201cproperties\u201d or the information that defines that entity, and \nthe \u201cedge\u201d or relationship between nodes and properties. Using the right \ndatabase will also improve performance. Typically the graph database will be \nused in scientific and technical applications.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2566, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "01b12f0c-a34c-4d14-86a9-06d77d785dc4": {"__data__": {"id_": "01b12f0c-a34c-4d14-86a9-06d77d785dc4", "embedding": null, "metadata": {"page_label": "21", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2be2394a-cc8c-4a4e-ae04-1811d458e1ef", "node_type": "4", "metadata": {"page_label": "21", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "3d976e5fab98e8bd282f5f5a4c191b0b7d7021fb3ec15453579499f3ce2a9daf", "class_name": "RelatedNodeInfo"}}, "text": "21  Chapter 1: Grasping the Fundamentals of Big Data\nOther important operational database approaches include columnar data -\nbases that store information efficiently in columns rather than rows. This \napproach leads to faster performance because input/output is extremely fast. \nWhen geographic data storage is part of the equation, a spatial database is \noptimized to store and query data based on how objects are related in space.\nOrganizing data services and tools\nNot all the data that organizations use is operational. A growing amount \nof data comes from a variety of sources that aren\u2019t quite as organized or \nstraightforward, including data that comes from machines or sensors, and \nmassive public and private data sources. In the past, most companies weren\u2019t \nable to either capture or store this vast amount of data. It was simply too \nexpensive or too overwhelming. Even if companies were able to capture \nthe data, they did not have the tools to do anything about it. Very few tools \ncould make sense of these vast amounts of data. The tools that did exist were \ncomplex to use and did not produce results in a reasonable time frame. In \nthe end, those who really wanted to go to the enormous effort of analyzing \nthis data were forced to work with snapshots of data. This has the undesir -\nable effect of missing important events because they were not in a particular \nsnapshot.\nMapReduce, Hadoop, and Big Table\nWith the evolution of computing technology, it is now possible to manage \nimmense volumes of data that previously could have only been handled by \nsupercomputers at great expense. Prices of systems have dropped, and as a \nresult, new techniques for distributed computing are mainstream. The real \nbreakthrough in big data happened as companies like Yahoo!, Google, and \nFacebook came to the realization that they needed help in monetizing the \nmassive amounts of data their offerings were creating.\nThese emerging companies needed to find new technologies that would allow \nthem to store, access, and analyze huge amounts of data in near real time \nso that they could monetize the benefits of owning this much data about \nparticipants in their networks. Their resulting solutions are transforming the \ndata management market. In particular, the innovations MapReduce, Hadoop, \nand Big Table proved to be the sparks that led to a new generation of data \nmanagement. These technologies address one of the most fundamental prob -\nlems \u2014 the capability to process massive amounts of data efficiently, cost-\neffectively, and in a timely fashion.\nMapReduce\nMapReduce was designed by Google as a way of efficiently executing a set of \nfunctions against a large amount of data in batch mode. The \u201cmap\u201d compo -\nnent distributes the programming problem or tasks across a large number of \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2821, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9e6db758-6838-45fc-a3fc-3165f2035758": {"__data__": {"id_": "9e6db758-6838-45fc-a3fc-3165f2035758", "embedding": null, "metadata": {"page_label": "22", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6b2ab650-88c9-4865-9b72-d01ca08b4929", "node_type": "4", "metadata": {"page_label": "22", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1d825cc0fe0f53b6cb237c03e153b9933f98f8fd33394212a3bd0fde14349534", "class_name": "RelatedNodeInfo"}}, "text": "22 Part I: Getting Started with Big Data \nsystems and handles the placement of the tasks in a way that balances the \nload and manages recovery from failures. After the distributed computation \nis completed, another function called \u201creduce\u201d aggregates all the elements \nback together to provide a result. An example of MapReduce usage would be \nto determine how many pages of a book are written in each of 50 different \nlanguages.\nBig Table\nBig Table was developed by Google to be a distributed storage system \nintended to manage highly scalable structured data. Data is organized into \ntables with rows and columns. Unlike a traditional relational database model, \nBig Table is a sparse, distributed, persistent multidimensional sorted map. It \nis intended to store huge volumes of data across commodity servers.\nHadoop\nHadoop is an Apache-managed software framework derived from MapReduce \nand Big Table. Hadoop allows applications based on MapReduce to run on \nlarge clusters of commodity hardware. The project is the foundation for the \ncomputing architecture supporting Yahoo!\u2019s business. Hadoop is designed to \nparallelize data processing across computing nodes to speed computations \nand hide latency. Two major components of Hadoop exist: a massively scal -\nable distributed file system that can support petabytes of data and a mas -\nsively scalable MapReduce engine that computes results in batch.\nTraditional and advanced analytics\nWhat does your business now do with all the data in all its forms to try to \nmake sense of it for the business? It requires many different approaches to \nanalysis, depending on the problem being solved. Some analyses will use \na traditional data warehouse, while other analyses will take advantage of \nadvanced predictive analytics. Managing big data holistically requires many \ndifferent approaches to help the business to successfully plan for the future.\nAnalytical data warehouses and data marts\nAfter a company sorts through the massive amounts of data available, it is \noften pragmatic to take the subset of data that reveals patterns and put it \ninto a form that\u2019s available to the business. These warehouses and marts pro -\nvide compression, multilevel partitioning, and a massively parallel process -\ning architecture.\nBig data analytics\nThe capability to manage and analyze petabytes of data enables companies \nto deal with clusters of information that could have an impact on the busi -\nness. This requires analytical engines that can manage this highly distributed \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2537, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9c74de90-8788-45c4-bc89-78cbd3771056": {"__data__": {"id_": "9c74de90-8788-45c4-bc89-78cbd3771056", "embedding": null, "metadata": {"page_label": "23", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "861d2581-e95f-45d9-b4b8-9c8543eb9da4", "node_type": "4", "metadata": {"page_label": "23", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d36f183eb58669bedfe00d10e6e5da87cd9941df7b7b560c570916f7fd923e2e", "class_name": "RelatedNodeInfo"}}, "text": "23  Chapter 1: Grasping the Fundamentals of Big Data\ndata and provide results that can be optimized to solve a business problem. \nAnalytics can get quite complex with big data. For example, some organiza -\ntions are using predictive models that couple structured and unstructured \ndata together to predict fraud. Social media analytics, text analytics, and new \nkinds of analytics are being utilized by organizations looking to gain insight \ninto big data. Big data analytics are described in more detail in chapters 12, \n13, and 14. \nReporting and visualization\nOrganizations have always relied on the capability to create reports to give \nthem an understanding of what the data tells them about everything from \nmonthly sales figures to projections of growth. Big data changes the way \nthat data is managed and used. If a company can collect, manage, and ana -\nlyze enough data, it can use a new generation of tools to help management \ntruly understand the impact not just of a collection of data elements but also \nhow these data elements offer context based on the business problem being \naddressed. With big data, reporting and data visualization become tools for \nlooking at the context of how data is related and the impact of those relation -\nships on the future.\nBig data applications\nTraditionally, the business expected that data would be used to answer ques -\ntions about what to do and when to do it. Data was often integrated as fields \ninto general-purpose business applications. With the advent of big data, this is \nchanging. Now, we are seeing the development of applications that are designed \nspecifically to take advantage of the unique characteristics of big data.\nSome of the emerging applications are in areas such as healthcare, manu -\nfacturing management, traffic management, and so on. What do all these big \ndata applications have in common? They rely on huge volumes, velocities, \nand varieties of data to transform the behavior of a market. In healthcare, \na big data application might be able to monitor premature infants to deter -\nmine when data indicates when intervention is needed. In manufacturing, a \nbig data application can be used to prevent a machine from shutting down \nduring a production run. A big data traffic management application can \nreduce the number of traffic jams on busy city highways to decrease acci -\ndents, save fuel, and reduce pollution.\nThe Big Data Journey\nCompanies have always had to deal with lots of data in lots of forms. The \nchange that big data brings is what you can do with that information. If you \nhave the right technology in place, you can use big data to anticipate and \nsolve business problems and react to opportunities. With big data, you can \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2745, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "69a52692-289e-4636-ba2f-2908048d16d3": {"__data__": {"id_": "69a52692-289e-4636-ba2f-2908048d16d3", "embedding": null, "metadata": {"page_label": "24", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7f54e9a-aa39-4e06-a0c7-345c072dece2", "node_type": "4", "metadata": {"page_label": "24", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "7eaffc3a9371698d02956471abf4b37989881efd7f383b8aef7b298716538071", "class_name": "RelatedNodeInfo"}}, "text": "24 Part I: Getting Started with Big Data \nanalyze data patterns to change everything, from the way you manage cities, \nprevent failures, conduct experiments, manage traffic, improve customer \nsatisfaction, or enhance product quality, just to name a few examples. The \nemerging technologies and tools that are the heart of this book can help you \nunderstand and unleash the tremendous power of big data, changing the \nworld as we know it.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 456, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ae862104-0c74-4494-9bdf-5527bc020690": {"__data__": {"id_": "ae862104-0c74-4494-9bdf-5527bc020690", "embedding": null, "metadata": {"page_label": "25", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "abb4fca6-7932-4eb8-8e20-52f63333a267", "node_type": "4", "metadata": {"page_label": "25", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "3766dd385a25aebf07eb1b78fddbaf8059f1bf45df4edad7823447d5f97134cc", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 2\nExamining Big Data Types\nIn This Chapter\n\u25b6 Identifying structured and unstructured data\n\u25b6 Recognizing real-time and non-real-time requirements for data types\n\u25b6 Integrating data types into a big data environment\nV \nariety is the spice of life, and variety is one of the principles of big data. \nIn Chapter 1, we discuss the importance of being able to manage the \nvariety of data types. Clearly, big data encompasses everything from dollar \ntransactions to tweets to images to audio. Therefore, taking advantage of \nbig data requires that all this information be integrated for analysis and data \nmanagement. Doing this type of activity is harder than it sounds. In this  \nchapter, we examine the two main types of data that make up big data \u2014 \nstructured and unstructured \u2014 and provide you with definitions and  \nexamples of each.\nAlthough data management has been around for a long time, two factors are \nnew in the big data world:\n \u2713 Some sources of big data are actually new like the data generated from \nsensors, smartphone, and tablets. \n \u2713 Previously produced data hadn\u2019t been captured or stored and analyzed \nin a usable way. The main reason for this is that the technology wasn\u2019t \nthere to do so. In other words, we didn\u2019t have a cost-effective way to \ndeal with all that data.\nYou have many different ways to put big data to use to solve problems. For \nexample, in some situations, you want to deal with data in real time, such \nas when you\u2019re monitoring traffic data. In other situations, real-time data \nmanagement won\u2019t be necessary, such as when you\u2019re collecting massive \namounts of data that you want to analyze in batch mode to determine an \nunsuspected pattern. Likewise, you sometimes need to integrate multiple \nsources of data as part of a big data solution, so we look at why you might \nwant to integrate data sources. The bottom line is that what you want to do \nwith your structured and unstructured data informs the technology pur -\nchases that you make.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2007, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7f72acc5-8565-421b-8bf6-2e11ed905a42": {"__data__": {"id_": "7f72acc5-8565-421b-8bf6-2e11ed905a42", "embedding": null, "metadata": {"page_label": "26", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9da4a0cf-c59c-4a80-8d23-5b1d11bd8ce0", "node_type": "4", "metadata": {"page_label": "26", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d9084575ba234b559b9961f384d4be1f0458b814d16f9a04150d43ce1b84d3d3", "class_name": "RelatedNodeInfo"}}, "text": "26 Part I: Getting Started with Big Data \nDefining Structured Data\nThe term structured data  generally refers to data that has a defined length and \nformat. Examples of structured data include numbers, dates, and groups of \nwords and numbers called strings  (for example, a customer\u2019s name, address, \nand so on). Most experts agree that this kind of data accounts for about 20 \npercent of the data that is out there. Structured data is the data that you\u2019re \nprobably used to dealing with. It\u2019s usually stored in a database. You can \nquery it using a language like structured query language (SQL), which we dis -\ncuss later in the \u201cDefining Unstructured Data\u201d section.\nYour company may already be collecting structured data from \u201ctraditional\u201d \nsources. These might include your customer relationship management (CRM) \ndata, operational enterprise resource planning (ERP) data, and financial data. \nOften these data elements are integrated in a data warehouse for analysis.\nExploring sources of big structured data\nAlthough this might seem like business as usual, in reality, structured data is \ntaking on a new role in the world of big data. The evolution of technology pro -\nvides newer sources of structured data being produced \u2014 often in real time \nand in large volumes. The sources of data are divided into two categories:\n \u2713 Computer- or machine-generated:  Machine-generated data generally \nrefers to data that is created by a machine without human intervention.\n \u2713 Human-generated: This is data that humans, in interaction with comput -\ners, supply.\nSome experts argue that a third category exists that is a hybrid between \nmachine and human. Here though, we\u2019re concerned with the first two  \ncategories.\nMachine-generated structured data can include the following:\n \u2713 Sensor data: Examples include radio frequency ID (RFID) tags, smart \nmeters, medical devices, and Global Positioning System (GPS) data. For \nexample, RFID is rapidly becoming a popular technology. It uses tiny \ncomputer chips to track items at a distance. An example of this is track -\ning containers of produce from one location to another. When informa -\ntion is transmitted from the receiver, it can go into a server and then be \nanalyzed. Companies are interested in this for supply chain management \nand inventory control. Another example of sensor data is smartphones \nthat contain sensors like GPS that can be used to understand customer \nbehavior in new ways.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2461, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d5befd32-df74-4378-9322-2ed57576b223": {"__data__": {"id_": "d5befd32-df74-4378-9322-2ed57576b223", "embedding": null, "metadata": {"page_label": "27", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e9e1582e-fbc9-43c7-9d78-e84159661848", "node_type": "4", "metadata": {"page_label": "27", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "86813f3ed381f82e83bf78caf3fa9ee90a72753f03cd34919b91a5abd7435876", "class_name": "RelatedNodeInfo"}}, "text": "27  Chapter 2: Examining Big Data Types\n \u2713 Web log data: When servers, applications, networks, and so on oper -\nate, they capture all kinds of data about their activity. This can amount \nto huge volumes of data that can be useful, for example, to deal with \nservice-level agreements or to predict security breaches.\n \u2713 Point-of-sale data: When the cashier swipes the bar code of any product \nthat you are purchasing, all that data associated with the product is gen -\nerated. Just think of all the products across all the people who purchase \nthem, and you can understand how big this data set can be.\n \u2713 Financial data: Lots of financial systems are now programmatic; they \nare operated based on predefined rules that automate processes. Stock-\ntrading data is a good example of this. It contains structured data such \nas the company symbol and dollar value. Some of this data is machine \ngenerated, and some is human generated.\nExamples of structured human-generated data might include the following:\n \u2713 Input data: This is any piece of data that a human might input into a \ncomputer, such as name, age, income, non-free-form survey responses, \nand so on. This data can be useful to understand basic customer  \nbehavior.\n \u2713 Click-stream data: Data is generated every time you click a link on a \nwebsite. This data can be analyzed to determine customer behavior and \nbuying patterns.\n \u2713 Gaming-related data: Every move you make in a game can be recorded. \nThis can be useful in understanding how end users move through a \ngaming portfolio.\nYou get the idea. Some of this data may not be that big on its own, such as \nprofile data. However, when taken together with millions of other users sub -\nmitting the same information, the size is astronomical. Additionally, much of \nthis data has a real-time component to it that can be useful for understanding \npatterns that have the potential of predicting outcomes. The bottom line is \nthat this kind of information can be powerful and can be utilized for many \npurposes.\nUnderstanding the role of relational  \ndatabases in big data\nData persistence  refers to how a database retains versions of itself when \nmodified. The great granddaddy of persistent data stores is the relational \ndatabase management system  (RDBMS).  In its infancy, the computing industry \nused what are now considered primitive techniques for data persistence. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2400, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6430b7fc-dcfe-4574-9881-6c8b779fd948": {"__data__": {"id_": "6430b7fc-dcfe-4574-9881-6c8b779fd948", "embedding": null, "metadata": {"page_label": "28", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a35943a2-5165-409b-9bc3-1a9558727e77", "node_type": "4", "metadata": {"page_label": "28", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "89cf549b73820ab3cb12b1728efa647fd0aff6da262857cca09a1883ac7da366", "class_name": "RelatedNodeInfo"}}, "text": "28 Part I: Getting Started with Big Data \nYou may recall \u201cflat files\u201d or \u201cnetwork\u201d data stores that were prevalent before \n1980 or so. Although these mechanisms were useful, they were very difficult \nto master and always required system programmers to write custom pro -\ngrams to manipulate the data.\nThe relational model was invented by Edgar Codd, an IBM scientist, in \nthe 1970s and was used by IBM, Oracle, Microsoft, and others. It is still in \nwide usage today and plays an important role in the evolution of big data. \nUnderstanding the relational database is important because other types of \ndatabases are used with big data. We contrast various kinds of databases \nused for big data throughout this book.\nIn a relational model, the data is stored in a table. This database would con -\ntain a schema  \u2014 that is, a structural representation of what is in the data -\nbase. For example, in a relational database, the schema defines the tables, \nthe fields in the tables, and the relationships between the two. The data \nis stored in columns, one each for each specific attribute. The data is also \nstored in the rows. For instance, the two tables shown in Figure 2-1 represent \nthe schema for a simple database. The first table stores product information; \nthe second stores demographic information. Each has various attributes \n(customer ID, order number, purchase code for a product, and so on). Each \ntable can be updated with new data, and data can be deleted, read, and \nupdated. This is often accomplished in a relational model using a structured \nquery language (SQL).\n Figure 2-1:  \nThe  \nrelationships \nbetween \ntables.\n \nAnother aspect of the relational model using SQL is that tables can be que -\nried using a common key (that is, the relationship). In Figure 2-1, the common \nkey in the tables is CustomerID. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1846, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "55b64325-ab98-4cc9-97b3-e0b39b4e320c": {"__data__": {"id_": "55b64325-ab98-4cc9-97b3-e0b39b4e320c", "embedding": null, "metadata": {"page_label": "29", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8809e13c-4214-4be4-be77-d93d7ba83c97", "node_type": "4", "metadata": {"page_label": "29", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "c64cc6858fa24a7c97c67113e2df1df2a301a35e4f41949d8ad58afd5f4602fb", "class_name": "RelatedNodeInfo"}}, "text": "29  Chapter 2: Examining Big Data Types\nYou can submit a query, for example, to determine the gender of customers \nwho purchased a specific product. It might look something like this:\nSelect CustomerID, State, Gender, Product from \n\u201cdemographic table\u201d, \u201cproduct table\u201d where \nProduct= XXYY\nAlthough relational databases have ruled the roost for the last several \ndecades, they can be difficult to use when you\u2019re dealing with huge streams \nof disparate data types. Relational database vendors are not standing still, \nhowever, and are starting to introduce relational databases designed for big \ndata. In addition, new database models have evolved to help people manage \nbig data. We talk a little bit about technologies like NoSQL, streaming data -\nbases, and others in Chapter 1. These data management systems are a sub -\nject unto themselves, so we devote all of Part III to them.\n PostgresSQL ( www.postgressql.org ), a technology we talk about in \nChapter 7, is the most widely used open source relational database available. Its \nextensibility and the fact that it is available on many varieties of mainframes \nmake it a foundation technology for some relational big data databases.\nDefining Unstructured Data\nUnstructured data  is data that does not follow a specified format. If 20 percent \nof the data available to enterprises is structured data, the other 80 percent \nis unstructured. Unstructured data is really most of the data that you will \nencounter. Until recently, however, the technology didn\u2019t really support \ndoing much with it except storing it or analyzing it manually.\nExploring sources of unstructured data\nUnstructured data is everywhere. In fact, most individuals and organizations \nconduct their lives around unstructured data. Just as with structured data, \nunstructured data is either machine generated or human generated.\nHere are some examples of machine-generated unstructured data:\n \u2713 Satellite images:  This includes weather data or the data that the gov -\nernment captures in its satellite surveillance imagery. Just think about \nGoogle Earth, and you get the picture (pun intended).\n \u2713 Scientific data:  This includes seismic imagery, atmospheric data, and \nhigh energy physics.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2233, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dfd7f519-1ec6-419d-b84e-85eddd64770c": {"__data__": {"id_": "dfd7f519-1ec6-419d-b84e-85eddd64770c", "embedding": null, "metadata": {"page_label": "30", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1909214c-21c4-4888-9bda-6690844f028a", "node_type": "4", "metadata": {"page_label": "30", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "7865bfbc0571bd442545d060da23a29e818dfbaaf6584c6bbca5d3f9498e8330", "class_name": "RelatedNodeInfo"}}, "text": "30 Part I: Getting Started with Big Data \n \u2713 Photographs and video:  This includes security, surveillance, and traffic \nvideo.\n \u2713 Radar or sonar data:  This includes vehicular, meteorological, and \noceanographic seismic profiles.\nThe following list shows a few examples of human-generated unstructured data:\n \u2713 Text internal to your company:  Think of all the text within documents, \nlogs, survey results, and e-mails. Enterprise information actually repre -\nsents a large percent of the text information in the world today.\n \u2713 Social media data:  This data is generated from the social media plat -\nforms such as YouTube, Facebook, Twitter, LinkedIn, and Flickr.\n \u2713 Mobile data:  This includes data such as text messages and location \ninformation.\n \u2713 Website content:  This comes from any site delivering unstructured  \ncontent, like YouTube, Flickr, or Instagram.\nAnd the list goes on.\n Some people believe that the term unstructured data  is misleading because \neach document may contain its own specific structure or formatting based on \nthe software that created it. However, what is internal to the document is truly \nunstructured.\nBy far, unstructured data is the largest piece of the data equation, and the \nuse cases for unstructured data are rapidly expanding. On the text side alone, \ntext analytics (a technology that we discuss in Chapter 13) can be used to \nanalyze unstructured text and to extract relevant data and transform that data \ninto structured information that can be used in various ways. For example, a \npopular big data use case is social media analytics for use with high-volume \ncustomer conversations. In addition, unstructured data from call center notes, \ne-mails, written comments in a survey, and other documents is analyzed to \nunderstand customer behavior. This can be combined with social media from \ntens of millions of sources to understand the customer experience.\nLooking at semi-structured data\nSemi-structured data  is a kind of data that \nfalls between structured and unstructured \ndata. Semi-structured data does not nec -\nessarily conform to a fixed schema (that \nis, structure) but may be self-describing \nand may have simple label/value pairs. For example, label/value pairs might include: \n<family>=Jones , <mother>=Jane , and \n<daughter>=Sarah . Examples of semi-\nstructured data include EDI, SWIFT, and XML. \nYou can think of them as sort of payloads for \nprocessing complex events.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2452, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f2743124-a7bd-4731-969b-800724abb3f8": {"__data__": {"id_": "f2743124-a7bd-4731-969b-800724abb3f8", "embedding": null, "metadata": {"page_label": "31", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cc067170-9481-4d84-8161-f23f85ade5fe", "node_type": "4", "metadata": {"page_label": "31", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "02177b666f30164b1018e07a572c0f2c8854812046a094521f740ffa2b7d0d41", "class_name": "RelatedNodeInfo"}}, "text": "31  Chapter 2: Examining Big Data Types\nUnderstanding the role of a CMS  \nin big data management\nOrganizations store some unstructured data in databases. However, they also \nutilize enterprise content management systems (CMSs) that can manage the \ncomplete life cycle of content. This can include web content, document con -\ntent, and other forms media.\nAccording to the Association for Information and Image Management (AIIM; \nwww.aiim.org ;), a nonprofit organization that provides education, research, \nand best practices, Enterprise Content Management (ECM) comprises the \n\u201cstrategies, methods, and tools used to capture, manage, store, preserve, \nand deliver content and documents related to organizational processes.\u201d \nThe technologies included in ECM include document management, records \nmanagement, imaging, workflow management, web content management, and \ncollaboration.\nA whole industry has grown up around managing content, and many content \nmanagement vendors are scaling out their solutions to handle large volumes \nof unstructured data. However, new technologies are also evolving to help \nsupport unstructured data and the analysis of unstructured data. Some of \nthese support both structured and unstructured data. Some support real-\ntime streams. These include technologies like Hadoop, MapReduce, and \nstreaming. These technologies each require chapters of their own, and we \ndevote Chapters 8, 9, and 10 to them, respectively.\nSystems that are designed to store content in the form of content manage -\nment systems are no longer stand-alone solutions. Rather, they are likely to \nbe part of an overall data management solution. For example, your organiza -\ntion may monitor Twitter feeds that can then programmatically trigger a CMS \nsearch. Now, the person who triggered the tweet (maybe looking for a solu -\ntion to a problem) gets an answer back that offers a location where the indi -\nvidual can find the product that he or she might be looking for. The greatest \nbenefit is when this type of interaction can happen in real time. It also illus -\ntrates the value of leveraging real-time unstructured, structured (customer \ndata about the person who tweeted), and semi-structured (the actual content \nin the CMS) data.\n The reality is that you will probably use a hybrid approach to solve your big \ndata problems. For example, it doesn\u2019t make sense to move all your news \ncontent, for example, into Hadoop on your premises because it is supposed to \nhelp manage unstructured data.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2523, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "04eddde6-058f-4932-b0cb-2d2d3b1f5f82": {"__data__": {"id_": "04eddde6-058f-4932-b0cb-2d2d3b1f5f82", "embedding": null, "metadata": {"page_label": "32", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0b8ca2ee-09fb-472f-a47e-efb41df0646b", "node_type": "4", "metadata": {"page_label": "32", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "67b4ca7c042f125be9051798977cd9eadaaae51b5db2ba20a91a96570f67f5e2", "class_name": "RelatedNodeInfo"}}, "text": "32 Part I: Getting Started with Big Data \nLooking at Real-Time and Non-Real-Time \nRequirements\nAs we discuss in previous sections of this chapter, big data is often about \ndoing things that weren\u2019t widely possible because the technology was not \nadvanced enough or the cost of doing so was prohibitive. The big change \nthat we are encountering with big data is the capability to leverage massive \namounts of data without all the complex programming that was required in \nthe past. Many organizations are at a tipping-point in terms of managing large \nvolumes of complex data. Big data approaches will help keep things in bal -\nance so we don\u2019t go over the edge as the volume, variety, and velocity of data \nchanges. Companies have had a difficult time managing increasing amounts \nof data that needs to be managed at high speeds. Organizations had to settle \nfor analyzing small subsets of data which often lacked critical information to \nget a full picture that the data could reveal. As big data technologies evolve \nand get deployed, we will be able to more easily analyze the data and use it \nto make decisions or take actions. \nThe real-time aspects of big data can be revolutionary when companies need \nto solve significant problems. What is the impact when an organization can \nhandle data that is streaming in real time? In general, this real-time approach \nis most relevant when the answer to a problem is time sensitive and business \ncritical. This may be related to a threat to something important like detecting \nthe performance of hospital equipment or anticipating a potential intrusion \nrisk. The following list shows examples of when a company wants to leverage \nthis real-time data to gain a quick advantage:\n \u2713 Monitoring for an exception with a new piece of information, like fraud/\nintelligence\n \u2713 Monitoring news feeds and social media to determine events that may \nimpact financial markets, such as a customer reaction to a new product \nannouncement\n \u2713 Changing your ad placement during a big sporting event based on real-\ntime Twitter streams\n \u2713 Providing a coupon to a customer based on what he bought at the point \nof sale\nSometimes streaming data is coming in really fast and does not include a \nwide variety of sources, sometimes a wide variety exists, and sometimes it \nis a combination of the two. The question you need to ask yourself if you\u2019re \nmoving to real time is this: Could this (problem) be solved with traditional \ninformation management capabilities or do we need newer capabilities? Is \nthe sheer volume or velocity going to overwhelm our systems? Oftentimes it \nis a combination of the two. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2652, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5a367bc0-214a-4e17-8fdd-d03f9493ca1b": {"__data__": {"id_": "5a367bc0-214a-4e17-8fdd-d03f9493ca1b", "embedding": null, "metadata": {"page_label": "33", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3c2ec10b-1923-4ad3-9fbb-0d652108f56b", "node_type": "4", "metadata": {"page_label": "33", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b04e4f73820505852f9b8f003fd8329a9e30bf4e0e6310586f24f47df2157d45", "class_name": "RelatedNodeInfo"}}, "text": "33  Chapter 2: Examining Big Data Types\nSo, if you need real-time capabilities, what are the requirements of the infra -\nstructure to support this? We talk more about this in Chapter 3 when we \ndiscuss distributed computing. However, the following list highlights a few \nthings you need to consider regarding a system\u2019s capability to ingest data, \nprocess it, and analyze it in real time:\n \u2713 Low latency:  Latency is the amount of time lag that enables a service \nto execute in an environment. Some applications require less latency, \nwhich means that they need to respond in real time. A real-time stream \nis going to require low latency. So you need to be thinking about com -\npute power as well as network constraints.\n \u2713 Scalability:  Scalability is the capability to sustain a certain level of per -\nformance even under increasing loads.\n \u2713 Versatility: The system must support both structured and unstructured \ndata streams.\n \u2713 Native format:  Use the data in its native form. Transformation takes \ntime and money. The capability to use the idea of processing complex \ninteractions in the data that trigger events may be transformational.\n The need to process continually increasing amounts of disparate data is one \nof the key factors driving the adoption of cloud services. The cloud model is \nlarge-scale and distributed. We talk more about the cloud in Chapter 6.\nPutting Big Data Together\nWhat you want to do with your structured and unstructured data indicates \nwhy you might choose one piece of technology over another one. It also \ndetermines the need to understand inbound data structures to put this data \nin the right place.\nManaging different data types\nFigure 2-2 shows a helpful table that outlines some of the characteristics of \nbig data and the types of data management systems you might want to use to \naddress each one. We don\u2019t expect you to know what these are yet; they are \ndescribed in the chapters that follow.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1960, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b7fb92d5-6add-4256-adfd-54dc952d4c63": {"__data__": {"id_": "b7fb92d5-6add-4256-adfd-54dc952d4c63", "embedding": null, "metadata": {"page_label": "34", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "762f1898-543d-42ee-be6c-c3b7b90defd3", "node_type": "4", "metadata": {"page_label": "34", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "94f154f236354393f0ceb3ee75bb75d4032b4f0ff7fce446655c984030d83686", "class_name": "RelatedNodeInfo"}}, "text": "34 Part I: Getting Started with Big Data \n Figure 2-2:  \nThe char-\nacteristics \nof different \ndata types.\n \nIntegrating data types into  \na big data environment\nAnother important aspect of big data is that you often don\u2019t need to own all \nthe data that you will use. Many examples make the point. You may be lever -\naging social media data, data coming from third-party industry statistics, or \neven data coming from satellites. Just think about social media and you\u2019ll \nunderstand what we mean. Oftentimes, it becomes necessary to integrate dif -\nferent sources. This data may be coming from all internal systems, from both \ninternal and external sources, or from entirely external sources. Much of this \ndata may have been siloed before.\nData need not be coming to you in real time. You just may have a lot of it \nand it is disparate in nature. This could still qualify as a big data problem. Of \ncourse, you could also be faced with a scenario where you\u2019re seeing huge vol -\numes of data, at high velocities, and it is disparate in nature. The point is that \nyou won\u2019t get the business value if you deal with a variety of data sources as \na set of disconnected silos of information.\nComponents you need include connectors and metadata, which we discuss \nnext.\nConnectors\nYou want to have some connectors that enable you to pull data in from vari -\nous big data sources. Maybe you want a Twitter connector or a Facebook \none. Maybe you need to integrate from your data warehouse with a big data \nsource that\u2019s off your premises so that you can analyze both of these sources \nof data together. We discuss connectors in more detail in Chapter 15.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1665, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "502d0435-d232-4e3c-aeca-66c6b2c71ecd": {"__data__": {"id_": "502d0435-d232-4e3c-aeca-66c6b2c71ecd", "embedding": null, "metadata": {"page_label": "35", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5c26ff28-7c69-43d7-9c40-25dc6211b963", "node_type": "4", "metadata": {"page_label": "35", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f908cecacbcc0f569f3ed47121ea37bfc82772a22dbc4cd6be86050ed7560591", "class_name": "RelatedNodeInfo"}}, "text": "35  Chapter 2: Examining Big Data Types\nMetadata\nA critical component to integrating all this data is the metadata. Metadata  is \nthe definitions, mappings, and other characteristics used to describe how \nto find, access, and use a company\u2019s data (and software) components. One \nexample of metadata is data about an account number. This might include \nthe number, description, data type, name, address, phone number, and pri -\nvacy level.\nMetadata can be used to help you organize your data stores and deal with \nnew and changing sources of data. Although the idea of metadata is not new, \nit is changing and evolving in the context of big data. In the traditional meta -\ndata world, it is important to have a catalog that provides a single view of all \ndata sources. But this catalog will have to be different when you don\u2019t con -\ntrol all these data sources. You may need an analytic tool that will help you \nunderstand the underlying metadata.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 965, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bc98d551-60fb-43ec-ba2e-cdb19241d1fc": {"__data__": {"id_": "bc98d551-60fb-43ec-ba2e-cdb19241d1fc", "embedding": null, "metadata": {"page_label": "36", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6e0023b3-5f56-4b61-a6f4-50b2662c018b", "node_type": "4", "metadata": {"page_label": "36", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b9fe2c135ff392abdac61dd179bf9b8b72ab96376bb2ecf73eea2f51a76c1812", "class_name": "RelatedNodeInfo"}}, "text": "36 Part I: Getting Started with Big Data \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 60, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b50a1121-caf0-436e-8467-33958573a814": {"__data__": {"id_": "b50a1121-caf0-436e-8467-33958573a814", "embedding": null, "metadata": {"page_label": "37", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3df96586-7106-476d-996c-012bfd1592f6", "node_type": "4", "metadata": {"page_label": "37", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e4b6dc915d210ea0d3ca930438b892e14901f6ef791ec02c8d5edccab5833e39", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 3\nOld Meets New:  \nDistributed Computing\nIn This Chapter\n\u25b6 Taking a look at distributed computing through the years\n\u25b6 Exploring the elements of distributed computing\n\u25b6 Putting distributed computing together with hardware and software advancements\nD \nistributed computing is not a new technology concept. It has been \naround for almost 50 years. Initially, the technology was used in com -\nputer science research as a way to scale computing tasks and attack complex \nproblems without the expense of massive computing systems. One of the \nmost successful early endeavors into distributed computing was a project \nfunded by the U.S. Defense Advanced Research Project Agency (DARPA). The \nresult of the organization\u2019s research was the development of the Internet, the \nfirst distributed computing network. You might say that it initiated a revolu -\ntion that has led to a transformation of everything from commerce to health -\ncare, to transportation, and to human-to-human and machine-to-machine \ncommunications. In this chapter, we explain what distributed computing is \nand describe why it is the foundation for big data.\nA Brief History of Distributed Computing\nBehind all the most important trends over the past decade, including service \norientation, cloud computing, virtualization, and big data, is a foundational \ntechnology called distributed computing.  Simply put, without distributing com -\nputing, none of these advancements would be possible. Distributed comput -\ning is a technique that allows individual computers to be networked together \nacross geographical areas as though they were a single environment, as \nshown in Figure 3-1. You find many different implementations of distributed \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1728, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6309e7f6-f92e-454d-95a5-4a731837255e": {"__data__": {"id_": "6309e7f6-f92e-454d-95a5-4a731837255e", "embedding": null, "metadata": {"page_label": "38", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "303f05e2-b71d-41b1-9d97-28f005575751", "node_type": "4", "metadata": {"page_label": "38", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "c9b8627ec168bdaecaca2d17a963cba27bbedc712e3627181382390f5463573a", "class_name": "RelatedNodeInfo"}}, "text": "38 Part I: Getting Started with Big Data \ncomputing. In some topologies, individual computing entities simply pass \nmessages to each other. In other situations, a distributed computing environ -\nment may share resources ranging from memory to networks and storage. All \ndistributed computing models have a common attribute: They are a group of \nnetworked computers that work together to execute a workload or process.\nGiving thanks to DARPA\nThe most well-known distributed computing model, the Internet, is the foun -\ndation for everything from e-commerce to cloud computing to service man -\nagement and virtualization. The Internet was conceived as a research project \nfunded by the U.S. DARPA. It was designed to create an interconnecting \nnetworking system that would support noncommercial, collaborate research \namong scientists. In the early days of the Internet, these computers were \noften connected by telephone lines (see Figure 3-1)! Unless you experienced \nthat frustration, you can only imagine how slow and fragile those connec -\ntions were.\n Figure 3-1:  \nThe early \nInternet \nconnectivity \nmodel.\n \nAs the technology matured over the next decade, common protocols such \nas Transmission Control Protocol (TCP) helped to proliferate the technol -\nogy and the network. When the Internet Protocol (IP) was added, the project \nmoved from a closed network for a collection of scientists to a potentially \ncommercial platform to transfer e-mail across the globe. Throughout the \n1980s, new Internet-based services began to spring up in the market as a \ncommercial alternative to the DARPA network. In 1992, the U.S. Congress \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1652, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a9b56321-12a6-44fc-8fa0-676d49e9d4fe": {"__data__": {"id_": "a9b56321-12a6-44fc-8fa0-676d49e9d4fe", "embedding": null, "metadata": {"page_label": "39", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "088e07f9-527f-436d-8c73-67a0dd9afc08", "node_type": "4", "metadata": {"page_label": "39", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e1564aba857f0b48a11d233ad247c4f9236627bb01660c3b82bb681d1a27ae78", "class_name": "RelatedNodeInfo"}}, "text": "39  Chapter 3: Old Meets New: Distributed Computing\npassed the Scientific and Advanced-Technology Act that for the first time, \nallowed commercial use of this powerful networking technology. With its \ncontinued explosive growth, the Internet is truly a global distributed network \nand remains the best example of the power of distributed computing.\nThe value of a consistent model\nWhat difference did this DARPA-led effort make in the movement to distrib -\nuted computing? Before the commercialization of the Internet, there were \nhundreds of companies and organizations creating a software infrastructure \nintended to provide a common platform to support a highly distributed com -\nputing environment. However, each vendor or standards organization came \nup with its own remote procedures calls (RPCs) that all customers, com -\nmercial software developers, and partners would have to adopt and support. \nRPC is a primitive mechanism used to send work to a remote computer and \nusually requires waiting for the remote work to complete before other work \ncan continue.\nWith vendors implementing proprietary RPCs, it became impractical to imag -\nine that any one company would be able to create a universal standard for \ndistributed computing. By the mid-1990s, the Internet protocols replaced \nthese primitive approaches and became the foundation for what is distrib -\nuted computing today. After this was settled, the uses of this approach to \nnetworked computing began to flourish. Today, we take it for granted that \nwe can create a network of loosely coupled computers that can exchange \ninformation and communicate at the right speed at the right time, as shown \nin Figure 3-2.\n Figure 3-2:  \nAn example \nof how a \nRemote \nProcedure \nCall has \nbeen used \nin early \ndistributed \ncomputing \ntechniques.\n \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1825, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7776f955-0cfe-44e9-ba7d-876bbe43b324": {"__data__": {"id_": "7776f955-0cfe-44e9-ba7d-876bbe43b324", "embedding": null, "metadata": {"page_label": "40", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e7a6ce7c-c408-4304-ab3e-7718c3e93b9c", "node_type": "4", "metadata": {"page_label": "40", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ba1662236d81d3bf6301dc8981d77e735bd6fc059186edc34c606c68b1ec213c", "class_name": "RelatedNodeInfo"}}, "text": "40 Part I: Getting Started with Big Data \nUnderstanding the Basics of  \nDistributed Computing\nThere isn\u2019t a single distributed computing model because computing \nresources can be distributed in many ways. For example, you can distribute \na set of programs on the same physical server and use messaging services to \nenable them to communicate and pass information. It is also possible to have \nmany different systems or servers, each with its own memory, that can work \ntogether to solve one problem.\nWhy we need distributed  \ncomputing for big data\nNot all problems require distributed computing. If a big time constraint \ndoesn\u2019t exist, complex processing can done via a specialized service remotely. \nWhen companies needed to do complex data analysis, IT would move data \nto an external service or entity where lots of spare resources were available \nfor processing. It wasn\u2019t that companies wanted to wait to get the results \nthey needed; it just wasn\u2019t economically feasible to buy enough computing \nresources to handle these emerging requirements. In many situations, organi -\nzations would capture only selections of data rather than try to capture all the \ndata because of costs. Analysts wanted all the data but had to settle for snap -\nshots, hoping that they captured the right data at the right time.\nKey hardware and software breakthroughs revolutionized the data man -\nagement industry. First, innovation and demand increased the power and \ndecreased the price of hardware. New software emerged that understood \nhow to take advantage of this hardware by automating processes like load \nbalancing and optimization across a huge cluster of nodes. The software \nincluded built-in rules that understood that certain workloads required a \ncertain performance level. The software treated all the nodes as though they \nwere simply one big pool of computing, storage, and networking assets, and \nmoved processes to another node without interruption if a node failed, using \nthe technology of virtualization. Chapter 5 covers virtualization and big data \nin more detail.\nThe changing economics of computing\nFast-forward and a lot has changed. Over the last several years, the cost to \npurchase computing and storage resources has decreased dramatically. Aided \nby virtualization, commodity servers that could be clustered and blades that \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2361, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c7658495-35b6-45c2-b355-e76c894149e6": {"__data__": {"id_": "c7658495-35b6-45c2-b355-e76c894149e6", "embedding": null, "metadata": {"page_label": "41", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "072532b4-2f84-44c4-8cef-569391b26b73", "node_type": "4", "metadata": {"page_label": "41", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b446d4ee210a2fc62eefe4f1a0b6d7d0ef16dffb928407d51354c6b2a81ede89", "class_name": "RelatedNodeInfo"}}, "text": "41  Chapter 3: Old Meets New: Distributed Computing\ncould be networked in a rack changed the economics of computing. This \nchange coincided with innovation in software automation solutions that \ndramatically improved the manageability of these systems. The capability to \nleverage distributed computing and parallel processing techniques dramati -\ncally transformed the landscape and dramatically reduce latency. There are \nspecial cases, such as High Frequency Trading (HFT), in which low latency \ncan only be achieved by physically locating servers in a single location.\nThe problem with latency\nOne of the perennial problems with managing data \u2014 especially large quanti -\nties of data \u2014 has been the impact of latency. Latency  is the delay within a \nsystem based on delays in execution of a task. Latency is an issue in every \naspect of computing, including communications, data management, system \nperformance, and more. If you have ever used a wireless phone, you have \nexperienced latency firsthand. It is the delay in the transmissions between \nyou and your caller. At times, latency has little impact on customer satisfac -\ntion, such as if companies need to analyze results behind the scenes to plan \nfor a new product release. This probably doesn\u2019t require instant response \nor access. However, the closer that response is to a customer at the time of \ndecision, the more that latency matters.\nDistributed computing and parallel processing techniques can make a signifi -\ncant difference in the latency experienced by customers, suppliers, and part -\nners. Many big data applications are dependent on low latency because of \nthe big data requirements for speed and the volume and variety of the data. \nIt may not be possible to construct a big data application in a high latency \nenvironment if high performance is needed. The need to verify the data in \nnear real time can also be impacted by latency. In Chapter 16, we address the \nissue of real-time data streaming and complex event processing, which are \ncritical to applications of big data. When you are dealing with real-time data, \na high level of latency means the difference between success and failure.\nDemand meets solutions\nThe growth of the Internet as a platform for everything from commerce to \nmedicine transformed the demand for a new generation of data management. \nIn the late 1990s, engine and Internet companies like Google, Yahoo!, and \nAmazon.com were able to expand their business models, leveraging inexpen -\nsive hardware for computing and storage. Next, these companies needed a \nnew generation of software technologies that would allow them to monetize \nthe huge amounts of data they were capturing from customers. These compa -\nnies could not wait for results of analytic processing. They needed the capa -\nbility to process and analyze this data in near real time.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2875, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1e11589e-23ec-48c8-af3d-b465df560fda": {"__data__": {"id_": "1e11589e-23ec-48c8-af3d-b465df560fda", "embedding": null, "metadata": {"page_label": "42", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "789c9478-0b05-45cb-935d-f9f7b9d87cb8", "node_type": "4", "metadata": {"page_label": "42", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "133a2ab7e6503d2aa3c4e868e7e725ecfb0cfbb71ba7bbaf6fca974e12fb0a32", "class_name": "RelatedNodeInfo"}}, "text": "42 Part I: Getting Started with Big Data \nGetting Performance Right\nJust having a faster computer isn\u2019t enough to ensure the right level of perfor -\nmance to handle big data. You need to be able to distribute components of \nyour big data service across a series of nodes. See Figure 3-3. In distributed \ncomputing, a node  is an element contained within a cluster of systems or \nwithin a rack. A node typically includes CPU, memory, and some kind of disk. \nHowever, a node can also be a blade CPU and memory that rely on nearby \nstorage within a rack.\n Figure 3-3:  \nAn evolu-\ntion of \ndistributed \ncomputing \nrelies on \njobs being \ndivided for \ndistributed \nexecution of \ntasks.\n \nWithin a big data environment, these nodes are typically clustered together \nto provide scale. For example, you might start out with a big data analysis \nand continue to add more data sources. To accommodate the growth, an \norganization simply adds more nodes into a cluster so that it can scale out \nto accommodate growing requirements. However, it isn\u2019t enough to simply \nexpand the number of nodes in the cluster. Rather, it is important to be able \nto send part of the big data analysis to different physical environments. \nWhere you send these tasks and how you manage them makes the difference \nbetween success and failure.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1330, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9990a41c-7e4c-40c5-96d8-29eeb007ca68": {"__data__": {"id_": "9990a41c-7e4c-40c5-96d8-29eeb007ca68", "embedding": null, "metadata": {"page_label": "43", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7db26a35-d98b-4751-838a-8933cac6676b", "node_type": "4", "metadata": {"page_label": "43", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "df213b4ffdf188871087c677cf4275917151e9b1a4d85d09a6d141dfdc83ce4c", "class_name": "RelatedNodeInfo"}}, "text": "43  Chapter 3: Old Meets New: Distributed Computing\nIn some complex situations, you may want to execute many different algo -\nrithms in parallel, even within the same cluster, to achieve the speed of \nanalysis required. Why would you execute different big data algorithms in \nparallel within the same rack? The closer together the distributions of func -\ntions are, the faster they can execute. Although it is possible to distribute big \ndata analysis across networks to take advantage of available capacity, you \nmust do this type of distribution based on requirements for performance. In \nsome situations, the speed of processing takes a back seat. However, in other \nsituations, getting results fast is the requirement. In this situation, you want \nto make sure that the networking functions are in close proximity to each \nother. In general, the big data environment has to be optimized for the type \nof analytics task.\nTherefore, scalability is the lynchpin of making big data operate successfully. \nAlthough it would be theoretically possible to operate a big data environ -\nment within a single large environment, it is not practical. To understand the \nneeds for scalability in big data, one only has to look at cloud scalability and \nunderstand both the requirements and the approach. Like cloud computing, \nbig data requires the inclusion of fast networks and inexpensive clusters of \nhardware that can be combined in racks to increase performance. These \nclusters are supported by software automation that enables dynamic scaling \nand load balancing. \nThe design and implementations of MapReduce are excellent examples of \nhow distributed computing can make big data operationally visible and \naffordable. For more information on MapReduce, refer to Chapter 8. In \nessence, we are at one of the unique turning points in computing where tech -\nnology concepts come together at the right time to solve the right problems. \nCombining distributed computing, improved hardware systems, and practi -\ncal solutions such as MapReduce and Hadoop is changing data management \nin profound ways.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2113, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "960bd5b6-4b6c-4bb0-98fe-f06926fd2aa2": {"__data__": {"id_": "960bd5b6-4b6c-4bb0-98fe-f06926fd2aa2", "embedding": null, "metadata": {"page_label": "44", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "76cc42c2-df4f-4bad-aa4f-14b325a6474e", "node_type": "4", "metadata": {"page_label": "44", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "c8e3c4230ee294b5da5047d6634138e57a40dcf721a0a347ecd7d009d06cab8d", "class_name": "RelatedNodeInfo"}}, "text": "44 Part I: Getting Started with Big Data \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 60, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "41ca92cc-eb5f-4f66-b141-ca1721a17825": {"__data__": {"id_": "41ca92cc-eb5f-4f66-b141-ca1721a17825", "embedding": null, "metadata": {"page_label": "45", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5363b295-01e7-403c-b0b5-d29f3934f425", "node_type": "4", "metadata": {"page_label": "45", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d26c941e6c936039b7a9b3b4e3e0103821812ce449997f276da5bfb1aef988d3", "class_name": "RelatedNodeInfo"}}, "text": "Part II\nTechnology Foundations  \nfor Big Data\n Explore the big data stack online at www.dummies.com/extras/bigdata .\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 135, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9d2aa456-fc45-463e-8247-7fc7fcd0210b": {"__data__": {"id_": "9d2aa456-fc45-463e-8247-7fc7fcd0210b", "embedding": null, "metadata": {"page_label": "46", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "47acf3aa-98be-465d-9ed4-3cdf86aaba5a", "node_type": "4", "metadata": {"page_label": "46", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e2d3a2995c81bbbd85411cb4fc690be7fe4f90d10fc7d78fbac6bd797d532e0f", "class_name": "RelatedNodeInfo"}}, "text": "In this part . . .\n \u2713 Explain the various elements of the big data stack.\n \u2713 Integrate analytics and applications with big data.\n \u2713 Define virtualization.\n \u2713 Explain how virtualization impacts big data.\n \u2713 Add abstraction to the mix.\n \u2713 Understand the cloud and its role in big data.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 302, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c76dd16f-008e-4de5-9e1f-c406e8b5eb49": {"__data__": {"id_": "c76dd16f-008e-4de5-9e1f-c406e8b5eb49", "embedding": null, "metadata": {"page_label": "47", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b80b644c-5dda-4322-a136-3db5f90ccf26", "node_type": "4", "metadata": {"page_label": "47", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "5e259e60c2fad89a3fcbca2d5ce5e9a320189333541c23a2a5b74de468ec5f8d", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 4\nDigging into Big Data Technology \nComponents\nIn This Chapter\n\u25b6 Introducing the big data stack\n\u25b6 Redundant physical infrastructure\n\u25b6 Security infrastructure\n\u25b6 Interfaces and feeds to and from applications\n\u25b6 Operational databases\n\u25b6 Organizing data services and tools\n\u25b6 Analytical data warehouses\n\u25b6 Introduction to big analytics\n\u25b6 Introduction to big data applications\nA \ns discussed in the first few chapters, big data is about high-volume and \noften high-velocity data streams with highly diverse data types. Many \nseasoned software architects and developers know how to address one or \neven two of these situations quite readily. For example, if you are faced with \nhigh-volume transactional data with fault tolerance requirements, you might \nchoose to deploy redundant relational database clusters in a data center \nwith a very fast network infrastructure. Similarly, if the requirements are to \nintegrate different data types from many known and anonymous sources, the \nchoice might be to construct an extensible meta-model driving a customized \ndata warehouse.\nHowever, you may not have had the luxury of creating specific deployments \nin a much more dynamic big data world. When you move out of the world \nwhere you own and tightly control your data, you need to create an architec -\ntural model for addressing this type of hybrid environment. This new envi -\nronment requires an architecture that understands both the dynamic nature \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1467, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "caf662cd-0c3d-40a0-b885-146aa789d234": {"__data__": {"id_": "caf662cd-0c3d-40a0-b885-146aa789d234", "embedding": null, "metadata": {"page_label": "48", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f1ff4e11-dcdb-4d7e-a025-db7809aab15c", "node_type": "4", "metadata": {"page_label": "48", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "5259e0a68e660231b237accee2cfb36fcc0493ac4ba823fff821dd894b72aac9", "class_name": "RelatedNodeInfo"}}, "text": "48 Part II: Technology Foundations for Big Data \nof big data and the requirement to apply the knowledge to a business solu -\ntion. In this chapter, we examine the architectural considerations associated \nwith big data. We also dig a bit deeper into the big data technology stack we \nintroduce in Chapter 1.\nExploring the Big Data Stack\nLike any important data architecture, you should design a model that takes \na holistic look at how all the elements need to come together. Although this \nwill take some time in the beginning, it will save many hours of development \nand lots of frustration during the subsequent implementations. You need to \nthink about big data as a strategy, not a project.\nGood design principles are critical when creating (or evolving) an envi -\nronment to support big data \u2014 whether dealing with storage, analytics, \nreporting, or applications. The environment must include considerations \nfor hardware, infrastructure software, operational software, management \nsoftware, well-defined application programming interfaces (APIs), and even \nsoftware developer tools. Your architecture will have to be able to address \nall the foundational requirements that we discuss in Chapter 1:\n \u2713 Capture\n \u2713 Integrate\n \u2713 Organize\n \u2713 Analyze\n \u2713 Act\nFigure 4-1 presents the layered reference architecture we introduce in \nChapter 1. It can be used as a framework for how to think about big data \ntechnologies that can address functional requirements for your big data  \nprojects.\nThis is a comprehensive stack, and you may focus on certain aspects initially \nbased on the specific problem you are addressing. However, it is important \nto understand the entire stack so that you are prepared for the future. You\u2019ll \nno doubt use different elements of the stack depending on the problem \nyou\u2019re addressing.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1831, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7cee21fa-d803-4944-b75d-33b15171618f": {"__data__": {"id_": "7cee21fa-d803-4944-b75d-33b15171618f", "embedding": null, "metadata": {"page_label": "49", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8935afab-06b2-41a1-b0e5-4029f432f945", "node_type": "4", "metadata": {"page_label": "49", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "297961a4d22127cd044060bd932fb7d8f9575c196cbec7260bd6f78f7526d223", "class_name": "RelatedNodeInfo"}}, "text": "49  Chapter 4: Digging into Big Data Technology Components\n Figure 4-1:  \nThe big data \ntechnology \nstack.\n \nLayer 0: Redundant Physical \nInfrastructure\nAt the lowest level of the stack is the physical infrastructure \u2014 the hard -\nware, network, and so on. Your company might already have a data center \nor made investments in physical infrastructures, so you\u2019re going to want to \nfind a way to use the existing assets. Big data implementations have very \nspecific requirements on all elements in the reference architecture, so you \nneed to examine these requirements on a layer-by-layer basis to ensure that \nyour implementation will perform and scale according to the demands of \nyour business. As you start to think about your big data implementation, it \nis important to have some overarching principles that you can apply to the \napproach. A prioritized list of these principles should include statements \nabout the following:\n \u2713 Performance:  How responsive do you need the system to be? \nPerformance, also called latency,  is often measured end to end, based on \na single transaction or query request. Very fast (high-performance, low-\nlatency) infrastructures tend to be very expensive.\n \u2713 Availability:  Do you need a 100 percent uptime guarantee of service? \nHow long can your business wait in the case of a service interruption or \nfailure? Highly available infrastructures are also very expensive.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1427, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2276c69c-564d-4470-b324-be564794219d": {"__data__": {"id_": "2276c69c-564d-4470-b324-be564794219d", "embedding": null, "metadata": {"page_label": "50", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "33aae2a5-2d40-40c3-8832-6532e2371a06", "node_type": "4", "metadata": {"page_label": "50", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "58c7aa189a3fe2829c88c58092198b1a1c7adace79233c6fd9fbeb92f6224a4e", "class_name": "RelatedNodeInfo"}}, "text": "50 Part II: Technology Foundations for Big Data \n \u2713 Scalability:  How big does your infrastructure need to be? How much \ndisk space is needed today and in the future? How much computing \npower do you need? Typically, you need to decide what you need and \nthen add a little more scale for unexpected challenges.\n \u2713 Flexibility:  How quickly can you add more resources to the infrastruc -\nture? How quickly can your infrastructure recover from failures? The \nmost flexible infrastructures can be costly, but you can control the costs \nwith cloud services, where you only pay for what you actually use (see \nChapter 6 for more on cloud computing).\n \u2713 Cost:  What can you afford? Because the infrastructure is a set of com -\nponents, you might be able to buy the \u201cbest\u201d networking and decide to \nsave money on storage (or vice versa). You need to establish require -\nments for each of these areas in the context of an overall budget and \nthen make trade-offs where necessary.\nAs big data is all about high-velocity, high-volume, and high-data variety, \nthe physical infrastructure will literally \u201cmake or break\u201d the implementa -\ntion. Most big data implementations need to be highly available, so the net -\nworks, servers, and physical storage must be both resilient and redundant. \nResiliency and redundancy are interrelated. An infrastructure, or a system, \nis resilient to failure or changes when sufficient redundant resources are in \nplace, ready to jump into action. In essence, there are always reasons why \neven the most sophisticated and resilient network could fail, such as a hard -\nware malfunction. Therefore, redundancy ensures that such a malfunction \nwon\u2019t cause an outage. \nResiliency helps to eliminate single points of failure in your infrastructure. \nFor example, if only one network connection exists between your business \nand the Internet, no network redundancy exists, and the infrastructure is not \nresilient with respect to a network outage. In large data centers with business \ncontinuity requirements, most of the redundancy is in place and can be lever -\naged to create a big data environment. In new implementations, the designers \nhave the responsibility to map the deployment to the needs of the business \nbased on costs and performance.\n As more vendors provide cloud-based platform offerings, the design responsi -\nbility for the hardware infrastructure often falls to those service providers.\nThis means that the technical and operational complexity is masked behind a \ncollection of services, each with specific terms for performance, availability, \nrecovery, and so on. These terms are described in service-level agreements \n(SLAs) and are usually negotiated between the service provider and the cus -\ntomer, with penalties for noncompliance.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2794, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bd4f6ce9-d856-48f5-ad5d-be1a99e77b1f": {"__data__": {"id_": "bd4f6ce9-d856-48f5-ad5d-be1a99e77b1f", "embedding": null, "metadata": {"page_label": "51", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8cba6683-5b9b-44a1-8faa-7e06016af901", "node_type": "4", "metadata": {"page_label": "51", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "2a0339035ceaead2ce77dae69c1dc94c4c40b728d2fe32f2b7d95cea895deddc", "class_name": "RelatedNodeInfo"}}, "text": "51  Chapter 4: Digging into Big Data Technology Components\nFor example, if you contract with a managed service provider, you are theo -\nretically absolved from the worry associated with the specifics of the physi -\ncal environment and the core components of the data center. The networks, \nservers, operating systems, virtualization fabric, requisite management tools, \nand day-to-day operations are inclusive in your service agreements. In effect, \nthis creates a virtual data center. Even with this approach, you should still \nknow what is needed to build and run a big data deployment so that you can \nmake the most appropriate selections from the available service offerings. \nDespite having an SLA, your organization still has the ultimate responsibility \nfor performance.\nPhysical redundant networks\nNetworks should be redundant and must have enough capacity to accommo -\ndate the anticipated volume and velocity of the inbound and outbound data \nin addition to the \u201cnormal\u201d network traffic experienced by the business. As \nyou begin making big data an integral part of your computing strategy, it is \nreasonable to expect volume and velocity to increase.\nInfrastructure designers should plan for these expected increases and try to \ncreate physical implementations that are \u201celastic.\u201d As network traffic ebbs \nand flows, so too does the set of physical assets associated with the imple -\nmentation. Your infrastructure should offer monitoring capabilities so that \noperators can react when more resources are required to address changes in \nworkloads.\nManaging hardware: Storage and servers\nLikewise, the hardware (storage and server) assets must have sufficient \nspeed and capacity to handle all expected big data capabilities. It\u2019s of little \nuse to have a high-speed network with slow servers because the servers will \nmost likely become a bottleneck. However, a very fast set of storage and com -\npute servers can overcome variable network performance. Of course, nothing \nwill work properly if network performance is poor or unreliable.\nInfrastructure operations\nAnother important design consideration is infrastructure operations manage -\nment. The greatest levels of performance and flexibility will be present only \nin a well-managed environment. Data center managers need to be able to \nanticipate and prevent catastrophic failures so that the integrity of the data, \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2402, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ebfc7bda-02ed-465a-b48a-90466196fc53": {"__data__": {"id_": "ebfc7bda-02ed-465a-b48a-90466196fc53", "embedding": null, "metadata": {"page_label": "52", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "76391841-6341-4597-af7a-4aee02407493", "node_type": "4", "metadata": {"page_label": "52", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ee3e3f9282f19f278a352c66d88f92704e05f801086079baca4046391097953f", "class_name": "RelatedNodeInfo"}}, "text": "52 Part II: Technology Foundations for Big Data \nand by extension the business processes, is maintained. IT organizations \noften overlook and therefore underinvest in this area. We talk more about \nwhat\u2019s involved with operationalizing big data in Chapter 17.\nLayer 1: Security Infrastructure\nSecurity and privacy requirements for big data are similar to the require -\nments for conventional data environments. The security requirements have \nto be closely aligned to specific business needs. Some unique challenges \narise when big data becomes part of the strategy, which we briefly describe \nin this list:\n \u2713 Data access:  User access to raw or computed big data has about the \nsame level of technical requirements as non-big data implementations. \nThe data should be available only to those who have a legitimate busi -\nness need for examining or interacting with it. Most core data storage \nplatforms have rigorous security schemes and are often augmented with \na federated identity capability, providing appropriate access across the \nmany layers of the architecture.\n \u2713 Application access:  Application access to data is also relatively straight -\nforward from a technical perspective. Most application programming \ninterfaces (APIs) offer protection from unauthorized usage or access. \nThis level of protection is probably adequate for most big data  \nimplementations.\n \u2713 Data encryption:  Data encryption is the most challenging aspect of \nsecurity in a big data environment. In traditional environments, encrypt -\ning and decrypting data really stresses the systems\u2019 resources. With \nthe volume, velocity, and varieties associated with big data, this prob -\nlem is exacerbated. The simplest (brute-force) approach is to provide \nmore and faster computational capability. However, this comes with a \nsteep price tag \u2014 especially when you have to accommodate resiliency \nrequirements. A more temperate approach is to identify the data ele -\nments requiring this level of security and to encrypt only the necessary \nitems.\n \u2713 Threat detection:  The inclusion of mobile devices and social networks \nexponentially increases both the amount of data and the opportunities \nfor security threats. It is therefore important that organizations take a \nmultiperimeter approach to security.\nWe talk more about big data security and governance in Chapter 19. We also \ndiscuss how big data is being used to  help  detect threats and other security \nissues.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2469, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "85a7a65b-447b-4cf3-af73-dab1117fac79": {"__data__": {"id_": "85a7a65b-447b-4cf3-af73-dab1117fac79", "embedding": null, "metadata": {"page_label": "53", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "19087e09-d00a-4d9c-8c64-4315a80e911b", "node_type": "4", "metadata": {"page_label": "53", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d938feffc089439851e7278ece56bf3e8e79622d319a2ce2dee1dfc4774ddd08", "class_name": "RelatedNodeInfo"}}, "text": "53  Chapter 4: Digging into Big Data Technology Components\nInterfaces and Feeds to and from \nApplications and the Internet\nSo, physical infrastructure enables everything and security infrastructure \nprotects all the elements in your big data environment. The next level in \nthe stack is the interfaces that provide bidirectional access to all the com -\nponents of the stack \u2014 from corporate applications to data feeds from the \nInternet. An important part of the design of these interfaces is the creation of \na consistent structure that is shareable both inside and perhaps outside the \ncompany as well as with technology partners and business partners.\nFor decades, programmers have used APIs to provide access to and from \nsoftware implementations. Tool and technology providers will go to great \nlengths to ensure that it is a relatively straightforward task to create new \napplications using their products. Although very helpful, it is sometimes nec -\nessary for IT professionals to create custom or proprietary APIs exclusive to \nthe company. You might need to do this for competitive advantage, a need \nunique to your organization, or some other business demand, and it is not \na simple task. APIs need to be well documented and maintained to preserve \nthe value to the business. For this reason, some companies choose to use API \ntoolkits to get a jump-start on this important activity.\nAPI toolkits have a couple of advantages over internally developed APIs. \nThe first is that the API toolkits are products that are created, managed, \nand maintained by an independent third party. Second, they are designed to \nsolve a specific technical requirement. If you need APIs for web applications \nor mobile applications, you have several alternatives to get you started.\nTake a REST\nNo discussion of big data APIs would be com -\nplete without examining a technology called \nRepresentational State Transfer (REST). REST \nwas designed specifically for the Internet and \nis the most commonly used mechanism for con -\nnecting one web resource (a server) to another \nweb resource (a client). A RESTful API provides \na standardized way to create a temporary rela -\ntionship (also called loose coupling ) between \nand among web resources. As the name \nimplies, loosely coupled resources are not rig -\nidly connected and are resilient to changes in the networks and other infrastructure compo -\nnents. For example, if your refrigerator breaks \nin the middle of the night, you need to buy a \nnew one. You might have to wait until a retail \nstore opens before you can do so. In addition, \nyou may need to wait longer for delivery. This \nis very similar to web resources using RESTful \nAPIs. Your request may not be answered until \nthe service is available to address it. Many, if \nnot all, big data technologies support REST, as \nyou see in subsequent chapters.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2874, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "62ff0e38-0e10-489a-8345-d9f6f675d966": {"__data__": {"id_": "62ff0e38-0e10-489a-8345-d9f6f675d966", "embedding": null, "metadata": {"page_label": "54", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b1cd56ba-e4f5-4fca-9775-de169ba162fd", "node_type": "4", "metadata": {"page_label": "54", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "953c1de3d914b5f0b44d27c0b7784d217a0ea57b70e7d59a7b72c834043922bb", "class_name": "RelatedNodeInfo"}}, "text": "54 Part II: Technology Foundations for Big Data \nBig data challenges require a slightly different approach to API develop -\nment or adoption. Because much of the data is unstructured and is gener -\nated outside of the control of your business, a new technique, called Natural \nLanguage Processing (NLP), is emerging as the preferred method for inter -\nfacing between big data and your application programs. NLP allows you to \nformulate queries with natural language syntax instead of a formal query \nlanguage like SQL. For most big data users, it will be much easier to ask \u201cList \nall married male consumers between 30 and 40 years old who reside in the \nsoutheastern United States and are fans of NASCAR\u201d than to write a 30-line \nSQL query for the answer.\n One way to deal with interfaces is to implement a \u201cconnector\u201d factory. This  \nconnector factory adds a layer of abstraction and predictability to the pro -\ncess, and it leverages many of the lessons and techniques used in Service \nOriented Architecture (SOA). For more information on SOA, check out Service \nOriented Architecture (SOA) For Dummies,  2nd Edition (written by our team \nand published by John Wiley & Sons, Inc.).\nBecause most data gathering and movement have very similar characteris -\ntics, you can design a set of services to gather, cleanse, transform, normal -\nize, and store big data items in the storage system of your choice. To create \nas much flexibility as necessary, the factory could be driven with interface \ndescriptions written in Extensible Markup Language (XML). This level of \nabstraction allows specific interfaces to be created easily and quickly with -\nout the need to build specific services for each data source.\nIn practice, you could create a description of SAP or Oracle application inter -\nfaces using something like XML. Each interface would use the same under -\nlying software to migrate data between the big data environment and the \nproduction application environment independent of the specifics of SAP or \nOracle. If you need to gather data from social sites on the Internet (such as \nFacebook, Google+, and so on), the practice would be identical. Describe the \ninterfaces to the sites in XML, and then engage the services to move the data \nback and forth. Typically, these interfaces are documented for use by inter -\nnal and external technologists.\nLayer 2: Operational Databases\nAt the core of any big data environment are the database engines containing \nthe collections of data elements relevant to your business. These engines \nneed to be fast, scalable, and rock solid. They are not all created equal, and \ncertain big data environments will fare better with one engine than another, \nor more likely with a mix of database engines. For example, although it is \npossible to use relational database management systems (RDBMSs) for all \nyour big data implementations, it is not practical to do so because of perfor -\nmance, scale, or even cost. A number of different database technologies are \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3022, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dda11bf1-21cb-4f7f-bdf9-52db52f9f714": {"__data__": {"id_": "dda11bf1-21cb-4f7f-bdf9-52db52f9f714", "embedding": null, "metadata": {"page_label": "55", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1fe1f4fa-8305-4991-aabe-0a0127461246", "node_type": "4", "metadata": {"page_label": "55", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b98bf631d037bd8dff18a954469935fde8a582e205e8515090b022bf0d4b3f4d", "class_name": "RelatedNodeInfo"}}, "text": "55  Chapter 4: Digging into Big Data Technology Components\navailable, and you must take care to choose wisely. We talk more about these \nchoices in Chapter 7.\nNo single right choice exists regarding database languages. Although SQL is \nthe most prevalent database query language in use today, other languages \nmay provide a more effective or efficient way of solving your big data chal -\nlenges. It is useful to think of the engines and languages as tools in an \u201cimple -\nmenter\u2019s toolbox.\u201d Your job is to choose the right tool.\nFor example, if you use a relational model, you will probably use SQL to \nquery it. However, you can also use alternative languages like Python or Java. \nIt is very important to understand what types of data can be manipulated by \nthe database and whether it supports true transactional behavior. Database \ndesigners describe this behavior with the acronym ACID.  It stands for\n \u2713 Atomicity:  A transaction is \u201call or nothing\u201d when it is atomic. If any part of \nthe transaction or the underlying system fails, the entire transaction fails.\n \u2713 Consistency:  Only transactions with valid data will be performed on \nthe database. If the data is corrupt or improper, the transaction will not \ncomplete and the data will not be written to the database.\n \u2713 Isolation:  Multiple, simultaneous transactions will not interfere with \neach other. All valid transactions will execute until completed and in the \norder they were submitted for processing.\n \u2713 Durability:  After the data from the transaction is written to the data -\nbase, it stays there \u201cforever.\u201d\nTable 4-1 offers a comparison of these characteristics of SQL and NoSQL \ndatabases.\nTable 4-1 Important Characteristics of SQL and NoSQL Databases\nEngine Query \nLanguageMapReduce Data Types Transactions Examples\nRelational SQL, \nPython, CNo Typed ACID PostgreSQL, \nOracle, DB/2\nColumnar Ruby Hadoop Predefined \nand typedYes, if \nenabledHBase\nGraph Walking, \nSearch, \nCypherNo Untyped ACID Neo4J\nDocument Commands JavaScript Typed No MongoDB, \nCouchDB\nKey-value Lucene, \nCommandsJavaScript BLOB, \nsemitypedNo Riak, Redis\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2117, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e30c08ed-ee03-405a-8aeb-1d04c0e66263": {"__data__": {"id_": "e30c08ed-ee03-405a-8aeb-1d04c0e66263", "embedding": null, "metadata": {"page_label": "56", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "633a5fb3-f11e-49fc-826e-91286aea444c", "node_type": "4", "metadata": {"page_label": "56", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "66b8236fdf0c147857231059e986bbba482d6ec73ad0be79a3ae7cd4d89ab463", "class_name": "RelatedNodeInfo"}}, "text": "56 Part II: Technology Foundations for Big Data \nAfter you understand your requirements and understand what data you\u2019re \ngathering, where to put it, and what to do with it, you need to organize it so \nthat it can be consumed for analytics, reporting, or specific applications.\nLayer 3: Organizing Data  \nServices and Tools\nOrganizing data services and tools  capture, validate, and assemble various big \ndata elements into contextually relevant collections. Because big data is mas -\nsive, techniques have evolved to process the data efficiently and seamlessly. \nMapReduce, covered in Chapter 8, is one heavily used technique. Suffice it to \nsay here that many of these organizing data services are MapReduce engines, \nspecifically designed to optimize the organization of big data streams.\nOrganizing data services are, in reality, an ecosystem of tools and technolo -\ngies that can be used to gather and assemble data in preparation for further \nprocessing. As such, the tools need to provide integration, translation, nor -\nmalization, and scale. Technologies in this layer include the following:\n \u2713 A distributed file system:  Necessary to accommodate the decomposi -\ntion of data streams and to provide scale and storage capacity\n \u2713 Serialization services:  Necessary for persistent data storage and multi -\nlanguage remote procedure calls (RPCs)\n \u2713 Coordination services:  Necessary for building distributed applications \n(locking and so on)\n \u2713 Extract, transform, and load (ETL) tools:  Necessary for the loading and \nconversion of structured and unstructured data into Hadoop\n \u2713 Workflow services:  Necessary for scheduling jobs and providing a struc -\nture for synchronizing process elements across layers\nIn Chapters 9 and 10, we examine Hadoop, the most widely used set of prod -\nucts for organizing big data. It is an open source initiative maintained by the \nApache Foundation.\nLayer 4: Analytical Data Warehouses\nThe data warehouse , and its companion the data mart, have long been the \nprimary techniques that organizations use to optimize data to help decision \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2096, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4aa43e2b-e3ae-4c9e-aebc-ac5b1af341b5": {"__data__": {"id_": "4aa43e2b-e3ae-4c9e-aebc-ac5b1af341b5", "embedding": null, "metadata": {"page_label": "57", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9e9b96d5-141b-4a8c-968f-e486b32a9b31", "node_type": "4", "metadata": {"page_label": "57", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "dfbcecf87f3e450557a408181596b17a06e3604c7c83e7ff51f1004df5e6602b", "class_name": "RelatedNodeInfo"}}, "text": "57  Chapter 4: Digging into Big Data Technology Components\nmakers. Typically, data warehouses and marts contain normalized data \ngathered from a variety of sources and assembled to facilitate analysis of the \nbusiness. Data warehouses and marts simplify the creation of reports and  \nthe visualization of disparate data items. They are generally created from \nrelational databases, multidimensional databases, flat files, and object  \ndatabases \u2014 essentially any storage architecture. In a traditional environ -\nment, where performance may not be the highest priority, the choice of the \nunderlying technology is driven by the requirements for the analysis, report -\ning, and visualization of the company data.\nAs the organization of the data and its readiness for analysis are key, most \ndata warehouse implementations are kept current via batch processing. The \nproblem is that batch-loaded data warehouses and data marts may be insuf -\nficient for many big data applications. The stress imposed by high-velocity \ndata streams will likely require a more real-time approach to big data ware -\nhouses. This doesn\u2019t mean that you won\u2019t be creating and feeding an analyti -\ncal data warehouse or a data mart with batch processes. Rather, you may end \nup having multiple data warehouses or data marts, and the performance and \nscale will reflect the time requirements of the analysts and decision makers.\nBecause many data warehouses and data marts are comprised of data gath -\nered from various sources within a company, the costs associated with the \ncleansing and normalizing of the data must also be addressed. With big data, \nyou find some key differences:\n \u2713 Traditional data streams (from transactions, applications, and so on) \ncan produce a lot of disparate data.\n \u2713 Dozens of new data sources also exist, each of them needing some \ndegree of manipulation before it can be timely and useful to the  \nbusiness.\n \u2713 Content sources will also need to be cleansed, and these may require \ndifferent techniques than you might use with structured data.\nHistorically, the contents of data warehouses and data marts were organized \nand delivered to business leaders in charge of strategy and planning. With \nbig data, we are seeing a new set of teams that are leveraging data for deci -\nsion making. Many big data implementations provide real-time capabilities, \nso businesses should be able to deliver content to enable individuals with \noperational roles to address issues such as customer support, sales opportu -\nnities, and service outages in near real time. In this way, big data helps move \naction from the back office to the front office.\nIn Chapter 11, we examine several technology approaches for big data ware -\nhousing, with recommendations for using them effectively and efficiently.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2811, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bf33f898-0d9e-4f80-8bba-b5de0bf0e42c": {"__data__": {"id_": "bf33f898-0d9e-4f80-8bba-b5de0bf0e42c", "embedding": null, "metadata": {"page_label": "58", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e456140c-c4a7-4997-b815-afc82a507e96", "node_type": "4", "metadata": {"page_label": "58", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "97633eb2606b1c9a7998338aee37120fbd5a1a3ab17dc5cabf6aae879c9c8428", "class_name": "RelatedNodeInfo"}}, "text": "58 Part II: Technology Foundations for Big Data \nBig Data Analytics\nExisting analytics tools and techniques will be very helpful in making sense \nof big data. However, there is a catch. The algorithms that are part of these \ntools have to be able to work with large amounts of potentially real-time and \ndisparate data. The infrastructure that we cover earlier in the chapter will \nneed to be in place to support this. And, vendors providing analytics tools \nwill also need to ensure that their algorithms work across distributed imple -\nmentations. Because of these complexities, we also expect a new class of \ntools to help make sense of big data.\nWe list three classes of tools in this layer of our reference architecture. They \ncan be used independently or collectively by decision makers to help steer \nthe business. The three classes of tools are as follows:\n \u2713 Reporting and dashboards:  These tools provide a \u201cuser-friendly\u201d repre -\nsentation of the information from various sources. Although a mainstay \nin the traditional data world, this area is still evolving for big data. Some \nof the tools that are being used are traditional ones that can now access \nthe new kinds of databases collectively called NoSQL (Not Only SQL). \nWe explore NoSQL databases in Chapter 7. \n \u2713 Visualization:  These tools are the next step in the evolution of report -\ning. The output tends to be highly interactive and dynamic in nature. \nAnother important distinction between reports and visualized output \nis animation. Business users can watch the changes in the data utiliz -\ning a variety of different visualization techniques, including mind maps, \nheat maps, infographics, and connection diagrams. Often, reporting and \nvisualization occur at the end of the business activity. Although the data \nmay be imported into another tool for further computation or examina -\ntion, this is the final step.\n \u2713 Analytics and advanced analytics:  These tools reach into the data ware -\nhouse and process the data for human consumption. Advanced analyt -\nics should explicate trends or events that are transformative, unique, \nor revolutionary to existing business practice. Predictive analytics and \nsentiment analytics are good examples of this science. Issues relating to \nanalytics are covered in greater detail in Part IV, including Chapters 12, \n13, and 14. \nBig Data Applications\nCustom and third-party applications offer an alternative method of shar -\ning and examining big data sources. Although all the layers of the reference \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2540, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b7d470a0-0207-4ffb-85ae-08907cbdff90": {"__data__": {"id_": "b7d470a0-0207-4ffb-85ae-08907cbdff90", "embedding": null, "metadata": {"page_label": "59", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "412e1c50-ae5f-4a0c-a918-4cf8c9b848de", "node_type": "4", "metadata": {"page_label": "59", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "25d467f3c2d77c7762dac2a05ce9253e7c2f7a9766de6498e02ca8d9f91ca6ed", "class_name": "RelatedNodeInfo"}}, "text": "59  Chapter 4: Digging into Big Data Technology Components\narchitecture are important in their own right, this layer is where most of the \ninnovation and creativity is evident.\nThese applications are either horizontal, in that they address problems that \nare common across industries, or vertical, in that they are intended to help \nsolve an industry-specific problem. Needless to say, you have many applica -\ntions to choose from, and many more coming. We expect categories of com -\nmercially available big data applications to grow as fast or faster than the \nadoption rate of the underlying technology. The most prevalent categories as \nof this writing are log data applications (Splunk, Loggly), ad/media applica -\ntions (Bluefin, DataXu), and marketing applications (Bloomreach, Myrrix). \nSolutions are also being developed for the healthcare industry, manufactur -\ning, and transportation management, to name a few.\nLike any other custom application development initiative, the creation of big \ndata applications will require structure, standards, rigor, and well-defined \nAPIs. Most business applications wanting to leverage big data will need to \nsubscribe to APIs across the entire stack. It may be necessary to process raw \ndata from the low-level data stores and combine the raw data with synthe -\nsized output from the warehouses. As you might expect, the operative term \nis custom,  and it creates a different type of pressure on the big data imple -\nmentation.\nBig data moves fast and changes in the blink of an eye, so software develop -\nment teams need to be able to rapidly create applications germane to solving \nthe business challenge of the moment. Companies may need to think about \ncreating development \u201ctiger teams,\u201d which rapidly respond to changes in the \nbusiness environment by creating and deploying applications on demand. In \nfact, it may be more appropriate to think of these applications as \u201csemicus -\ntom\u201d because they involve more assembly than actual low-level coding.\n Over time, we expect certain types of applications will be created, in context, \nby the end user, who can assemble the solution from a palette of components. \nNeedless to say, this is where the structure and standardization are most nec -\nessary. Software developers need to create consistent, standardized develop -\nment environments and devise new development practices for rapid rollout of \nbig data applications.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2440, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f06c7da4-ef89-4e2c-a5c3-addc83b3f5ff": {"__data__": {"id_": "f06c7da4-ef89-4e2c-a5c3-addc83b3f5ff", "embedding": null, "metadata": {"page_label": "60", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1f689f58-d141-45e7-9cb9-fb05deebe3b7", "node_type": "4", "metadata": {"page_label": "60", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e5cf30da2812d1d2780448a1469462b0437fe43a85c90bef7f3c9cabde5764c8", "class_name": "RelatedNodeInfo"}}, "text": "60 Part II: Technology Foundations for Big Data \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 67, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b29b117b-4ea0-4501-a217-53ff442e269c": {"__data__": {"id_": "b29b117b-4ea0-4501-a217-53ff442e269c", "embedding": null, "metadata": {"page_label": "61", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f664c88d-2230-4779-812e-628fa91613d9", "node_type": "4", "metadata": {"page_label": "61", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "92be80b2aaef114edf8d79c63b3946e5ea9139500e22f0077ca3adce687cd058", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 5\nVirtualization and How It Supports \nDistributed Computing\nIn This Chapter\n\u25b6 Defining virtualization\n\u25b6 Understanding the hypervisor\n\u25b6 Exploring abstraction and virtualization\n\u25b6 Implementing virtualization to work with big data\nV \nirtualization is a foundational technology applicable to the implemen -\ntation of both cloud computing and big data. It provides the basis \nfor many of the platform attributes required to access, store, analyze, and \nmanage the distributed computing components in big data environments. \nVirtualization \u2014 the process of using computer resources to imitate other \nresources \u2014 is valued for its capability to increase IT resource utilization, \nefficiency, and scalability. One primary application of virtualization is server \nconsolidation, which helps organizations increase the utilization of physical \nservers and potentially save on infrastructure costs. However, you find many \nbenefits to virtualization. Companies that initially focused solely on server \nvirtualization are now recognizing that it can be applied across the entire IT \ninfrastructure, including software, storage, and networks.\nIn this chapter, we define virtualization and provide insight into the benefits \nand challenges of virtualized environments. Our primary focus is on the role \nof virtualization in big data.\nUnderstanding the Basics  \nof Virtualization\nVirtualization separates resources and services from the underlying physical \ndelivery environment, enabling you to create many virtual systems within a \nsingle physical system. Figure 5-1 shows a typical virtualization environment. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1625, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "68984963-ea1c-4802-b377-c491dbe52d90": {"__data__": {"id_": "68984963-ea1c-4802-b377-c491dbe52d90", "embedding": null, "metadata": {"page_label": "62", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "54e22b93-1866-49b1-8741-72f3dde3e9ba", "node_type": "4", "metadata": {"page_label": "62", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e85e041cc058342b628b791647fd8d4569473b058fa785e1c1c1f84215ff73b6", "class_name": "RelatedNodeInfo"}}, "text": "62 Part II: Technology Foundations for Big Data \nOne of the primary reasons that companies have implemented virtualization \nis to improve the performance and efficiency of processing of a diverse mix \nof workloads. Rather than assigning a dedicated set of physical resources to \neach set of tasks, a pooled set of virtual resources can be quickly allocated as \nneeded across all workloads. Reliance on the pool of virtual resources allows \ncompanies to improve latency. This increase in service delivery speed and \nefficiency is a function of the distributed nature of virtualized environments \nand helps to improve overall time-to-value. \n Figure 5-1:  \nUsing  \nvirtualization \nsoftware to \ncreate  \nseveral  \nvirtual  \nsystems \nwithin a \nsingle  \nphysical \nsystem. \nUsing a distributed set of physical resources, such as servers, in a more flex -\nible and efficient way delivers significant benefits in terms of cost savings and \nimprovements in productivity. The practice has several benefits, including \nthe following:\n \u2713 Virtualization of physical resources (such as servers, storage, and \nnetworks) enables substantial improvement in the utilization of these \nresources.\n \u2713 Virtualization enables improved control over the usage and performance \nof your IT resources.\n \u2713 Virtualization can provide a level of automation and standardization to \noptimize your computing environment.\n \u2713 Virtualization provides a foundation for cloud computing.\nAlthough being able to virtualize resources adds a huge amount of efficiency, \nit doesn\u2019t come without a cost. Virtual resources have to be managed so \nthat they are secure. An image can become a technique for an intruder to get \ndirect access to critical systems. In addition, if companies do not have a pro -\ncess for deleting unused images, systems will no longer behave efficiently.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1853, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ddf4f988-2163-4b79-8a1f-51b587ba0c2d": {"__data__": {"id_": "ddf4f988-2163-4b79-8a1f-51b587ba0c2d", "embedding": null, "metadata": {"page_label": "63", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d76bf612-b91e-4cb5-b167-319e6b4124de", "node_type": "4", "metadata": {"page_label": "63", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "204fceeaeeead9d4ae3cb869745a227a277d9126970a9c6ecf49ba50e09c38ae", "class_name": "RelatedNodeInfo"}}, "text": "63  Chapter 5: Virtualization and How It Supports Distributed Computing\nThe importance of virtualization  \nto big data\nSolving big data challenges typically requires the management of large vol -\numes of highly distributed data stores along with the use of compute- and \ndata-intensive applications. Therefore, you need a highly efficient IT environ -\nment to support big data. Virtualization provides the added level of efficiency \nto make big data platforms a reality. Although virtualization is technically \nnot a requirement for big data analysis, software frameworks such as \nMapReduce, which are used in big data environments, are more efficient in a \nvirtualized environment. Chapter 8 covers MapReduce in more detail. If you \nneed your big data environment to scale \u2014 almost without bounds \u2014 you \nshould virtualize elements of your environment.\nVirtualization has three characteristics that support the scalability and oper -\nating efficiency required for big data environments:\n \u2713 Partitioning:  In virtualization, many applications and operating systems \nare supported in a single physical system by partitioning (separating) \nthe available resources.\n \u2713 Isolation:  Each virtual machine is isolated from its host physical system \nand other virtualized machines. Because of this isolation, if one virtual \ninstance crashes, the other virtual machines and the host system aren\u2019t \naffected. In addition, data isn\u2019t shared between one virtual instance and \nanother.\n \u2713 Encapsulation:  A virtual machine can be represented (and even stored) \nas a single file, so you can identify it easily based on the services it pro -\nvides. For example, the file containing the encapsulated process could \nbe a complete business service. This encapsulated virtual machine \ncould be presented to an application as a complete entity. Thus, encap -\nsulation could protect each application so that it doesn\u2019t interfere with \nanother application.\nOne of the most important requirements for success with big data is having \nthe right level of performance to support the analysis of large volumes and \nvaried types of data. As you begin to leverage environments such as Hadoop \nand MapReduce, it is critical that you have a supporting infrastructure that \ncan scale. Virtualization adds efficiency at every layer of the IT infrastructure. \nApplying virtualization across your environment will help to achieve the scal -\nability required for big data analysis.\nImplementing virtualization by following an end-to-end approach will deliver \nbenefits for big data and other types of workloads in your environment. An \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2618, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d37c0e91-f60c-4aec-8497-39047c9184ea": {"__data__": {"id_": "d37c0e91-f60c-4aec-8497-39047c9184ea", "embedding": null, "metadata": {"page_label": "64", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "78896c01-86dc-462c-8d8d-c63c69bf06a9", "node_type": "4", "metadata": {"page_label": "64", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "467edbebd85bf0e2ca1cb22ca37d52f7f17f78afaecb99990c629df1a65fe634", "class_name": "RelatedNodeInfo"}}, "text": "64 Part II: Technology Foundations for Big Data \nend-to-end approach will mean that errors can be corrected more quickly \u2014 \na requirement in a big data environment. When working with big data, your \ninfrastructure needs to be prepared to manage data that is potentially very \nlarge (volume), very fast (velocity), and highly unstructured (variety).\nAs a result, your entire IT environment needs to be optimized at every layer, \nfrom the network to the databases, storage, and servers. If you only virtual -\nize your servers, you may experience bottlenecks from other infrastructure \nelements such as storage and networks. If you only focus on virtualizing one \nelement of your infrastructure, you are less likely to achieve the latency and \nefficiency you need and more likely to expose your company to higher costs \nand security risks.\nThe reality is that most organizations do not attempt to virtualize all ele -\nments of their infrastructures at one time. Many organizations begin with \nserver virtualization and achieve a certain level of efficiency improvements. \nRealistically, other elements may be virtualized as needed to continue to \nimprove overall system performance and efficiency. The following describes \nhow virtualization of each element across the IT environment \u2014 servers, \nstorage, applications, data, networks, processors, memory, and services \u2014 \ncan have a positive impact on big data analysis.\nServer virtualization\nIn server virtualization, one physical server is partitioned into multiple \nvirtual servers. The hardware and resources of a machine \u2014 including the \nrandom access memory (RAM), CPU, hard drive, and network controller \u2014 \ncan be virtualized (logically split) into a series of virtual machines that each \nruns its own applications and operating system. A virtual machine (VM) is a \nsoftware representation of a physical machine that can execute or perform \nthe same functions as the physical machine. A thin layer of software is actu -\nally inserted into the hardware that contains a virtual machine monitor, or \nhypervisor.  The hypervisor can be thought of as the technology that manages \ntraffic between the VMs and the physical machine.\nServer virtualization uses the hypervisor to provide efficiency in the use of \nphysical resources. Of course, installation, configuration, and administrative \ntasks are associated with setting up these virtual machines. This includes \nlicense management, network management, and workload administration, as \nwell as capacity planning.\nServer virtualization helps to ensure that your platform can scale as needed \nto handle the large volumes and varied types of data included in your big \ndata analysis. You may not know the extent of the volume or variety of struc -\ntured and unstructured data needed before you begin your analysis. This \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2836, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ab073368-dd14-459d-99cc-af03886c3d5e": {"__data__": {"id_": "ab073368-dd14-459d-99cc-af03886c3d5e", "embedding": null, "metadata": {"page_label": "65", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d08cc022-e77d-4013-8578-624a3b43eede", "node_type": "4", "metadata": {"page_label": "65", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "2b54a80710d4463ece14e597a48c1d370720f7a41d29d7f50146c29f021e8317", "class_name": "RelatedNodeInfo"}}, "text": "65  Chapter 5: Virtualization and How It Supports Distributed Computing\nuncertainty makes the need for server virtualization even greater, providing \nyour environment with the capability to meet the unanticipated demand for \nprocessing very large data sets.\nIn addition, server virtualization provides the foundation that enables \nmany of the cloud services used as data sources in a big data analysis. \nVirtualization increases the efficiency of the cloud that makes many com -\nplex systems easier to optimize. As a result, organizations have the perfor -\nmance and optimization to be able to access data that was previously either \nunavailable or very hard to collect. Big data platforms are increasingly used \nas sources of enormous amounts of data about customer preferences, senti -\nment, and behaviors. Companies can integrate this information with internal \nsales and product data to gain insight into customer preferences to make \nmore targeted and personalized offers.\nApplication virtualization\nApplication infrastructure virtualization provides an efficient way to manage \napplications in context with customer demand. The application is encapsu -\nlated in a way that removes its dependencies from the underlying physical \ncomputer system. This helps to improve the overall manageability and por -\ntability of the application. In addition, the application infrastructure virtual -\nization software typically allows for codifying business and technical usage \npolicies to make sure that each of your applications leverages virtual and \nphysical resources in a predictable way. Efficiencies are gained because you \ncan more easily distribute IT resources according to the relative business \nvalue of your applications. In other words, your most critical applications \ncan receive top priority to draw from pools of available computing and stor -\nage capacity as needed.\nApplication infrastructure virtualization used in combination with server vir -\ntualization can help to ensure that business service-level agreements (SLAs) \nare met. Server virtualization monitors CPU and memory usage, but does not \naccount for variations in business priority when allocating resources. For \nexample, you might require that all applications are treated with the same \nbusiness-level priority. By implementing application infrastructure virtualiza -\ntion in addition to server virtualization, you can ensure that the most high-\npriority applications have top-priority access to resources.\nYour big data applications may have significant IT resource requirements, \ndue to the large volumes of data or the speed at which that data is generated. \nYour big data environment needs to have the right level of predictability and \nrepeatability to make sure that the applications have access to the required \nresources. Application infrastructure virtualization can ensure that each \napplication deployed for a big data analysis has access to the compute power \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2968, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7be23bdb-4de7-41b3-bae7-37388f301f18": {"__data__": {"id_": "7be23bdb-4de7-41b3-bae7-37388f301f18", "embedding": null, "metadata": {"page_label": "66", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "44970fc6-30f1-4d13-b461-959a2ad61167", "node_type": "4", "metadata": {"page_label": "66", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "83bc33cdcbfa34c614a69a1326df55d59ad6c11ba7c873961c94124f6021bde7", "class_name": "RelatedNodeInfo"}}, "text": "66 Part II: Technology Foundations for Big Data \nrequired at the right time based on its relative priority. In addition, applica -\ntion infrastructure virtualization makes it easier to run applications on dif -\nferent computers, and previously incompatible or legacy applications can \nbe run together on the same physical machine. You will not need to create \nmultiple versions such as Windows or Linux.\nBig data platforms designed to support highly distributed, data-intensive \napplications will run better and faster in a virtual environment. This does not \nmean that you will want to virtualize all big data\u2013related applications. For \nexample, a text analytics application may run best in a self-contained envi -\nronment and virtualization would not add any benefit.\nNetwork virtualization\nNetwork virtualization \u2014 software-defined networking \u2014 provides an effi -\ncient way to use networking as a pool of connection resources. Networks are \nvirtualized in a similar fashion to other physical technologies. Instead of rely -\ning on the physical network for managing traffic between connections, you \ncan create multiple virtual networks all utilizing the same physical implemen -\ntation. This can be useful if you need to define a network for data gathering \nwith a certain set of performance characteristics and capacity and another \nnetwork for applications with different performance and capacity. Limitations \nin the network layer can lead to bottlenecks that lead to unacceptable laten -\ncies in big data environments. Virtualizing the network helps reduce these \nbottlenecks and improve the capability to manage the large distributed data \nrequired for big data analysis.\nProcessor and memory virtualization\nProcessor virtualization helps to optimize the processor and maximize per -\nformance. Memory virtualization decouples memory from the servers.\nIn big data analysis, you may have repeated queries of large data sets and \nthe creation of advanced analytic algorithms, all designed to look for pat -\nterns and trends that are not yet understood. These advanced analytics \ncan require lots of processing power (CPU) and memory (RAM). For some \nof these computations, it can take a long time without sufficient CPU and \nmemory resources. Processor and memory virtualization can help speed the \nprocessing and get your analysis results sooner.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2371, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "29218d44-dac3-405d-9b58-466b9ef8c329": {"__data__": {"id_": "29218d44-dac3-405d-9b58-466b9ef8c329", "embedding": null, "metadata": {"page_label": "67", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6da3cef6-fdad-450e-ad0d-208b2ff8c5ff", "node_type": "4", "metadata": {"page_label": "67", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "3575323e0adf9f947dded87be35bf185264266f4a9fa9c55bf0a3ce711015ec1", "class_name": "RelatedNodeInfo"}}, "text": "67  Chapter 5: Virtualization and How It Supports Distributed Computing\nData and storage virtualization\nData virtualization can be used to create a platform for dynamic linked data \nservices. This allows data to be easily searched and linked through a unified \nreference source. As a result, data virtualization provides an abstract service \nthat delivers data in a consistent form regardless of the underlying physical \ndatabase. In addition, data virtualization exposes cached data to all applica -\ntions to improve performance.\nStorage virtualization combines physical storage resources so that they are \nmore effectively shared. This reduces the cost of storage and makes it easier \nto manage data stores required for big data analysis.\nData and storage virtualization play a significant role in making it easier and \nless costly to store, retrieve, and analyze the large volumes of fast and vary -\ning types of data. Remember that some big data may be unstructured and \nnot easily stored using traditional methods. Storage virtualization makes it \neasier to store large and unstructured data types. In a big data environment, \nit is advantageous to have access to a variety of operational data stores on \ndemand. For example, you may only need access to a columnar database \ninfrequently. With virtualization, the database can be stored as a virtual \nimage and invoked whenever it is needed without consuming valuable data \ncenter resources or capacity.\nManagement and security challenges  \nwith virtualization\nVirtualized environments need to be adequately \nmanaged and governed to realize cost savings \nand efficiency benefits. If you rely on big data \nservices to solve your analytics challenges, you \nneed to be assured that the virtual environment \nis as well managed and secure as the physical \nenvironment. Some of the benefits of virtualiza -\ntion, including ease of provisioning, can easily \nlead to management and security problems \nwithout proper oversight. Virtualization makes it \neasy for developers to create a virtual image, or \na copy, of a resource. As a result, many compa -\nnies have implemented virtualization only to find \nthat the number of virtual images spirals out of \ncontrol. Problems to watch out for include the \nfollowing: \u2713 Too many virtual images are created, lead -\ning to a sharp drop in server and memory \nperformance.\n \u2713 Lack of control over the life cycle of virtual \nimages leads to the introduction of security \nvulnerabilities.\n \u2713 An overabundance of virtual images \nincreases storage costs and reduces cost \nsavings.\n \u2713 Administrators may increase security risks \nthrough either malicious or uninformed \nmanagement of virtual images.\n \u2713 Compliance requirements may be com -\npromised if you are not able to accurately \nmonitor virtual infrastructure logs.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2820, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "74540af3-2d2d-4898-a9fa-3d4537aa1c8c": {"__data__": {"id_": "74540af3-2d2d-4898-a9fa-3d4537aa1c8c", "embedding": null, "metadata": {"page_label": "68", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "986f52c2-566a-48bc-a216-8b5872a16c09", "node_type": "4", "metadata": {"page_label": "68", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "9ba328c35a6ddf94724d07f70dafbb92523105f1f626d2afe43b729800006e3b", "class_name": "RelatedNodeInfo"}}, "text": "68 Part II: Technology Foundations for Big Data \nManaging Virtualization  \nwith the Hypervisor\nIn an ideal world, you don\u2019t want to worry about the underlying operating \nsystem and the physical hardware. A hypervisor  is the technology responsible \nfor ensuring that resource sharing takes place in an orderly and repeatable \nway. It is the traffic cop that allows multiple operating systems to share a \nsingle host. It creates and runs virtual machines. The hypervisor sits at the \nlowest levels of the hardware environment and uses a thin layer of code (often \ncalled a fabric ) to enable dynamic resource sharing. The hypervisor makes it \nseem like each operating system has the physical resources all to itself.\nIn the world of big data, you may need to support many different operating \nenvironments. The hypervisor becomes an ideal delivery mechanism for the \ntechnology components of the big data stack. The hypervisor lets you show \nthe same application on lots of systems without having to physically copy \nthat application onto each system. As an added benefit, because of the hyper -\nvisor architecture, it can load any (or many) different operating systems as \nthough they were just another application. So, the hypervisor is a very practi -\ncal way of getting things virtualized quickly and efficiently.\n You need to understand the nature of the hypervisor. It\u2019s designed like a \nserver OS rather than like the Windows OS. Each virtual machine running \non a physical machine is called a guest machine. The hypervisor, therefore, \nschedules the access that guest operating systems have to everything, includ -\ning the CPU, memory, disk I/O, and other I/O mechanisms. The guest operat -\ning systems are the operating systems running on the virtual machines. With \nvirtualization technology, you can set up the hypervisor to split the physical \ncomputer\u2019s resources. Resources can be split 50/50 or 80/20 between two \nguest operating systems, for example.\nThe beauty of this arrangement is that the hypervisor does all the heavy lift -\ning. The guest operating system doesn\u2019t care (or have any idea) that it\u2019s run -\nning in a virtual partition; it thinks it has a computer all to itself.\nYou find basically two types of hypervisors:\n \u2713 Type 1 hypervisors run directly on the hardware platform. They achieve \nhigher efficiency because they\u2019re running directly on the platform.\n \u2713 Type 2 hypervisors run on the host operating system. They are often \nused when a need exists to support a broad range of I/O devices.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2541, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a9fa857d-3ffa-46a8-8ba7-5c60d84183f6": {"__data__": {"id_": "a9fa857d-3ffa-46a8-8ba7-5c60d84183f6", "embedding": null, "metadata": {"page_label": "69", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3394eadc-6c2f-441f-8359-0198d175d268", "node_type": "4", "metadata": {"page_label": "69", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d2080ee3ff2cf89073b7f83b926f7248a5812411e334d296ce8e42769d6d66c4", "class_name": "RelatedNodeInfo"}}, "text": "69  Chapter 5: Virtualization and How It Supports Distributed Computing\nAbstraction and Virtualization\nFor IT resources and services to be virtualized, they are separated from the \nunderlying physical delivery environment. The technical term for this act \nof separation  is called  abstraction.  Abstraction is a key concept in big data. \nMapReduce and Hadoop are distributed computing environments where \neverything is abstracted. The detail is abstracted out so that the developer \nor analyst does not need to be concerned with where the data elements are \nactually located. \nAbstraction minimizes the complexity of something by hiding the details and \nproviding only the relevant information. For example, if you were going to \npick up someone whom you\u2019ve never met before, he might tell you the loca -\ntion to meet him, how tall he is, his hair color, and what he will be wearing. \nHe doesn\u2019t need to tell you where he was born, how much money he has in \nthe bank, his birth date, and so on. That\u2019s the idea with abstraction \u2014 it\u2019s \nabout providing a high-level specification rather than going into lots of detail \nabout how something works. In the cloud, for instance, in an Infrastructure as \na Service (IaaS) delivery model, the details of the physical and virtual infra -\nstructure are abstracted from the user.\nImplementing Virtualization  \nto Work with Big Data\nVirtualization helps makes your IT environment smart enough to handle big \ndata analysis. By optimizing all elements of your infrastructure, including \nhardware, software, and storage, you gain the efficiency needed to process \nand manage large volumes of structured and unstructured data. With big \ndata, you need to access, manage, and analyze structured and unstructured \ndata in a distributed environment.\nBig data assumes distribution. In practice, any kind of MapReduce will work \nbetter in a virtualized environment. You need the capability to move work -\nloads around based on requirements for compute power and storage.\nVirtualization will enable you to tackle larger problems that have not yet been \nscoped. You may not know in advance how quickly you will need to scale.\nVirtualization will enable you to support a variety of operational big data \nstores. For example, a graph database can be spun up as an image.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2315, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5314a636-f37a-43bf-8718-a246afa4ae9e": {"__data__": {"id_": "5314a636-f37a-43bf-8718-a246afa4ae9e", "embedding": null, "metadata": {"page_label": "70", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "de99e74a-2c30-4f13-957f-8a25b3bede74", "node_type": "4", "metadata": {"page_label": "70", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "7d32d48d3cd2845a41ee084eb715910ee5402e127472b15fa4139375f80f1cf4", "class_name": "RelatedNodeInfo"}}, "text": "70 Part II: Technology Foundations for Big Data \nThe most direct benefit from virtualization is to ensure that MapReduce \nengines work better. Virtualization will result in better scale and performance \nfor MapReduce. Each one of the Map and Reduce tasks needs to be executed \nindependently. If the MapReduce engine is parallelized and configured to run \nin a virtual environment, you can reduce management overhead and allow \nfor expansions and contractions in the task workloads. MapReduce itself is \ninherently parallel and distributed. By encapsulating the MapReduce engine \nin a virtual container, you can run what you need whenever you need it. With \nvirtualization, you increase your utilization of the assets you have already \npaid for by turning them into generic pools of resources.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 811, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7d045b72-b4cc-407b-b64a-b3de06aede07": {"__data__": {"id_": "7d045b72-b4cc-407b-b64a-b3de06aede07", "embedding": null, "metadata": {"page_label": "71", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fb8fccac-e91c-4977-a1f9-5fbf1b34cf4f", "node_type": "4", "metadata": {"page_label": "71", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "10dc32de48fb613c8b080603cf04b7a033f93fbe3e5a9d648911317ab10a402f", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 6\nExamining the Cloud and Big Data\nIn This Chapter\n\u25b6 Defining the cloud\n\u25b6 Examining cloud deployment and delivery models\n\u25b6 Understanding why the cloud is an imperative for big data\n\u25b6 Looking at how the cloud can be used with big data deployments\nT \nhe power of the cloud is that users can access needed computing and \nstorage resources with little or no IT support or the need to purchase \nmore hardware or software. One of the key characteristics of the cloud is \nelastic scalability: Users can add or subtract resources in almost real time \nbased on changing requirements. The cloud plays an important role within \nthe big data world. Dramatic changes happen when these infrastructure com -\nponents are combined with the advances in data management. Horizontally \nexpandable and optimized infrastructure supports the practical implementa -\ntion of big data.\nIn this chapter, we review the fundamentals of the cloud in the context of \nwhat it means for big data. Then we discuss how and why the cloud is often \nso ideal for various use cases for big data.\nDefining the Cloud in the  \nContext of Big Data\nCloud computing  is a method of providing a set of shared computing \nresources that include applications, computing, storage, networking, devel -\nopment, and deployment platforms, as well as business processes. Cloud \ncomputing turns traditional siloed computing assets into shared pools of \nresources based on an underlying Internet foundation. In cloud computing, \neverything, from compute power to computing infrastructure and from  \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1568, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1dfc56be-d193-452f-9c34-20a80657fe04": {"__data__": {"id_": "1dfc56be-d193-452f-9c34-20a80657fe04", "embedding": null, "metadata": {"page_label": "72", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ae516bc4-5ccf-4779-9c39-d9acc60c3f64", "node_type": "4", "metadata": {"page_label": "72", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "cf35e4d58dc84d02d967cef366f19493c90ea280e3f28c0d8e0f4276c7ea4ef7", "class_name": "RelatedNodeInfo"}}, "text": "72 Part II: Technology Foundations for Big Data \napplications and business processes to data and analytics, can be delivered \nto you as a service. To be operational in the real world, the cloud must be \nimplemented with common standardized processes and automation.\n If you want to find out a lot more about the cloud, we recommend that you \nread another book we have written, Hybrid Cloud For Dummies  (published by \nJohn Wiley & Sons, Inc.).\nMany businesses leverage cloud services for everything from backup to \nSoftware as a Service (SaaS) options such as customer relationship manage -\nment (CRM) services. With the growth of mobile computing, more consum -\ners, professionals, and corporations are creating and accessing data with \ncloud-based services. The average consumer may be sent an online coupon \nfor a favorite store; a quality control manager in a manufacturing plant might \ncollect sensor data from a variety of machines to determine whether a qual -\nity problem exists. These scenarios are predicated on the cloud-based data \nservices infrastructure.\nA popular example of the benefits of cloud supporting big data can be noted \nat both Google and Amazon.com. Both companies depend on the capability \nto manage massive amounts of data to move their businesses forward. These \nproviders needed to come up with infrastructures and technologies that \ncould support applications at a massive scale. Consider Gmail and the mil -\nlions upon millions of messages that Google processes per day as part of this \nservice. Google has been able to optimize the Linux operating system and its \nsoftware environment to support e-mail in the most efficient manner; there -\nfore, it can easily support hundreds of millions of users. Even more impor -\ntantly, Google is able to capture and leverage the massive amount of data \nabout both its mail users and its search engine users to drive the business.\nLikewise, Amazon.com, with its IaaS data centers, is optimized to support \nthese workloads so that Amazon can continue to offer new services and sup -\nport a growing number of customers without breaking the bank. To grow its \nretail business, Amazon must be able to manage data about its merchandise, \nits buyers, and its channel of partner merchants. Targeted advertising based \non customer buying patterns is critical to the company\u2019s success. These \ncompanies now offer a range of cloud-based services for big data that we talk \nabout later in this chapter. \nUnderstanding Cloud Deployment  \nand Delivery Models\nTwo key cloud models are important in the discussion of big data \u2014 public \nclouds and private clouds. For those organizations that adopt cloud deploy -\nment and delivery models, most will use a combination of private computing \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2765, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a47226cf-5a76-448e-bb32-450c147a5998": {"__data__": {"id_": "a47226cf-5a76-448e-bb32-450c147a5998", "embedding": null, "metadata": {"page_label": "73", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "03d2c4f7-df57-4bb9-87d3-b55a57ca5d21", "node_type": "4", "metadata": {"page_label": "73", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "3d509e970d299a9b16de00f91685172d8061bd396a643418e4c396e9ef7b60e5", "class_name": "RelatedNodeInfo"}}, "text": "73  Chapter 6: Examining the Cloud and Big Data\nresources (data centers and private clouds) and public services (operated \nby an external company for the shared use of a variety of customers who pay \na per-usage fee). How these companies balance public and private provid -\ners depends on a number of issues, including privacy, latency, and purpose. \nIt is important to understand these environments and what they mean for a \npotential big data deployment. In that way, you can determine whether you \nmight want to use a public cloud IaaS (described later) \u2014 for example, for \nyour big data projects \u2014 or if you want to continue to keep all your data on \npremises. Or, you might want to use a combination of both. So, we outline \nthese deployment and delivery models first and then talk more about what \nthey mean to big data.\nCloud deployment models\nThe two types of deployment models for cloud computing are public and \nprivate. These are offered for general purpose computing needs as opposed \nto specific types of cloud delivery models. We examine the delivery models \nlater in the chapter. In the meantime, take a look at the differences between \npublic and private cloud models and how you might use them.\nThe public cloud\nThe public cloud is a set of hardware, networking, storage, services, applica -\ntions, and interfaces owned and operated by a third party for use by other \ncompanies and individuals. These commercial providers create a highly scal -\nable data center that hides the details of the underlying infrastructure from \nthe consumer. Public clouds are viable because they typically manage rela -\ntively repetitive or straightforward workloads. For example, electronic mail \nis a very simple application. Therefore, a cloud provider can optimize the \nenvironment so that it is best suited to support a large number of customers, \neven if it saves many messages.\nLikewise, public cloud providers offering storage or computing services opti -\nmize their computing hardware and software to support these specific types \nof workloads.\nIn contrast, the typical data center supports so many different applications \nand workloads that it cannot be easily optimized. A public cloud can be very \neffective when an organization is executing a complex data analysis project \nand needs extra computing cycles to handle the task. In addition, companies \nmay choose to store data in a public cloud where the cost per gigabyte is \nrelatively inexpensive when compared to purchased storage. The overriding \nissues with public clouds for big data are the security requirements and the \namount of latency that is acceptable.\nAll public clouds are not the same. Some public clouds are scalable managed \nservices with a high level of security and a high level of service management. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2802, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0a1ef699-6293-4029-beec-37d44eeb1968": {"__data__": {"id_": "0a1ef699-6293-4029-beec-37d44eeb1968", "embedding": null, "metadata": {"page_label": "74", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cda25f40-70c8-486d-a777-93bfa479f9c2", "node_type": "4", "metadata": {"page_label": "74", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b9e17cabeb7834571cf5c6996e20315ce7b29da0b1b6ac20ba250eb446b5ff07", "class_name": "RelatedNodeInfo"}}, "text": "74 Part II: Technology Foundations for Big Data \nOther public clouds are less robust and less secure, but they are much less \nexpensive to use. Your choice will depend on the nature of your big data \nprojects and the amount of risk you can assume.\nThe private cloud\nA private cloud is a set of hardware, networking, storage, services, applica -\ntion, and interfaces owned and operated by an organization for the use of \nits employees, partners, and customers. A private cloud can be created \nand managed by a third party for the exclusive use of one enterprise. The \nprivate cloud is a highly controlled environment not open for public con -\nsumption. Thus, the private cloud sits behind a firewall. The private cloud \nis highly automated with a focus on governance, security, and compliance. \nAutomation replaces more manual processes of managing IT service to \nsupport customers. In this way, business rules and processes can be imple -\nmented inside software so that the environment becomes more predict -\nable and manageable. If organizations are managing a big data project that \ndemands processing massive amounts of data, the private cloud might be the \nbest choice in terms of latency and security.\n A hybrid  cloud is a combination of a private cloud combined with the use of \npublic cloud services with one or several touch points between the environ -\nments. The goal is to create a well-managed cloud environment that can \ncombine services and data from a variety of cloud models to create a unified, \nautomated, and well-managed computing environment.\nCloud delivery models\nIn addition to the cloud deployment models discussed previously, a number \nof cloud delivery models also exist. Four of the most popular are described in \nthe following sections.\nInfrastructure as a Service\nInfrastructure as a Service (IaaS) is one of the most straightforward of the \ncloud computing services. IaaS is the delivery of computing services includ -\ning hardware, networking, storage, and data center space based on a rental \nmodel. The consumer of the service acquires a resource and is charged for \nthat resource based on amount used and the duration of that usage. You find \nboth public and private versions of IaaS. In the public IaaS, the user utilizes \na credit card to acquire these resources. When the user stops paying, the \nresource disappears. In a private IaaS service, it is usually the IT organiza -\ntion or an integrator who creates the infrastructure designed to provide \nresources on demand for internal users and sometimes business partners.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2578, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "23556950-35ac-459d-a3ab-d434064db509": {"__data__": {"id_": "23556950-35ac-459d-a3ab-d434064db509", "embedding": null, "metadata": {"page_label": "75", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9c3444f2-48ef-4e90-9211-d05861dfaae9", "node_type": "4", "metadata": {"page_label": "75", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "20e2054b29950f32995fb2be3d23af6236c437d8d71d597c2f5fe0ecc54548ea", "class_name": "RelatedNodeInfo"}}, "text": "75  Chapter 6: Examining the Cloud and Big Data\nPlatform as a Service\nPlatform as a Service (PaaS) is a mechanism for combining IaaS with an \nabstracted set of middleware services, software development, and deploy -\nment tools that allow the organization to have a consistent way to create and \ndeploy applications on a cloud or on premises. A PaaS offers a consistent set \nof programming or middleware services that ensure that developers have a \nwell-tested and well-integrated way to create applications in a cloud environ -\nment. A PaaS environment brings development and deployment together to \ncreate a more manageable way to build, deploy, and scale applications. A \nPaaS requires an IaaS.\nSoftware as a Service\nSoftware as a Service (SaaS) is a business application created and hosted \nby a provider in a multitenant model. Multitenancy  refers to the situation \nwhere a single instance of an application runs in a cloud environment, but \nserves multiple client organizations (tenants), keeping all their data sepa -\nrate. Customers pay for the service per user either on a monthly or yearly \ncontract model. The SaaS model sits on top of both the PaaS and the founda -\ntional IaaS.\nData as a Service\nBecause this is a book about big data, we also want you to know about \nanother delivery model called Data as a Service (DaaS). DaaS is closely \nrelated to SaaS. DaaS is a platform-independent service that would let you \nconnect to the cloud to store and retrieve your data. In addition, you find \na number of specialized data services that are of great benefit in a big data \nenvironment. For example, Google offers a service that can process a query \nwith 5 terabytes of data in only 15 seconds. This type of query would typi -\ncally take ten times as long with a typical data center. Hundreds of special -\nized analytic services have been developed by companies like IBM and \nothers.\nThe Cloud as an Imperative for Big Data\nClearly, numerous combinations of deployment and delivery models exist for \nbig data in the cloud. For example, you can utilize a public cloud IaaS or a pri -\nvate cloud IaaS. So, what does this mean for big data and why is the cloud a \ngood fit for it? Well, big data requires distributed clusters of compute power, \nwhich is how the cloud is architected. For more on distributed computing, \nsee Chapter 3.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2361, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ff7f3970-740a-43e4-aa8f-3f9dc9af42d0": {"__data__": {"id_": "ff7f3970-740a-43e4-aa8f-3f9dc9af42d0", "embedding": null, "metadata": {"page_label": "76", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a739f3b5-bf8f-4b6a-9ece-7abacfa5a660", "node_type": "4", "metadata": {"page_label": "76", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f8ca52114874a54b1f9a1b0ca98fe64b9776951e68b8624709bf9cd55e28d8a5", "class_name": "RelatedNodeInfo"}}, "text": "76 Part II: Technology Foundations for Big Data \nIn fact, a number of cloud characteristics make it an important part of the big \ndata ecosystem:\n \u2713 Scalability:  Scalability with regard to hardware refers to the capability \nto go from small to large amounts of processing power with the same \narchitecture. With regard to software, it refers to the consistency of per -\nformance per unit of power as hardware resources increase. The cloud \ncan scale to large data volumes. Distributed computing, an integral part \nof the cloud model, really works on a \u201cdivide and conquer\u201d plan. So if \nyou have huge volumes of data, they can be partitioned across cloud \nservers. An important characteristic of IaaS is that it can dynamically \nscale. This means that if you wind up needing more resources than \nexpected, you can get them. This ties into the concept of elasticity.\n \u2713 Elasticity:  Elasticity refers to the capability to expand or shrink comput -\ning resource demand in real time, based on need. One of the benefits of \nthe cloud is that customers have the potential to access as much of a \nservice as they need when they need it. This can be helpful for big data \nprojects where you might need to expand the amount of computing \nresources you need to deal with the volume and velocity of the data. \nOf course, this very feature of the cloud that makes it attractive to end \nusers means that the service provider needs to design a platform archi -\ntecture that is optimized for this kind of service.\n \u2713 Resource pooling:  Cloud architectures enable the efficient creation of \ngroups of shared resources that make the cloud economically viable.\n \u2713 Self-service:  With self-service, the user of a cloud resource is able to use \na browser or a portal interface to acquire the resources needed, say, \nto run a huge predictive model. This is dramatically different than how \nyou might gain resources from a data center, where you would have to \nrequest the resources from IT operations.\n \u2713 Often low up-front costs:  If you use a cloud provider, up-front costs can \noften be reduced because you are not buying huge amounts of hardware \nor leasing out new space for dealing with your big data. By taking advan -\ntage of the economies of scale associated with cloud environments, the \ncloud can look attractive. Of course, you will need to do your own calcu -\nlation to evaluate whether you are interested in a public cloud, private \ncloud, hybrid cloud, or no cloud. We cover this in the section \u201cWhere to \nbe careful when using cloud services,\u201d later in this chapter.\n \u2713 Pay as you go:  A typical billing option for a cloud provider is Pay as You \nGo (PAYG), which means that you are billed for resources used based \non instance pricing. This can be useful if you\u2019re not sure what resources \nyou need for your big data project (as long as you don\u2019t underbudget).\n \u2713 Fault tolerance:  Cloud service providers should have fault tolerance \nbuilt into their architecture, providing uninterrupted services despite \nthe failure of one or more of the system\u2019s components.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3078, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a3e21b2a-6c7a-4f34-bedd-b141ef208024": {"__data__": {"id_": "a3e21b2a-6c7a-4f34-bedd-b141ef208024", "embedding": null, "metadata": {"page_label": "77", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a41d8a6b-be4c-4a89-a872-3f358da6b866", "node_type": "4", "metadata": {"page_label": "77", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "16d7a7b588e7c14ac487f235081a523cdbb2d745b91bba1548b22400d5fdd425", "class_name": "RelatedNodeInfo"}}, "text": "77  Chapter 6: Examining the Cloud and Big Data\n In some situations, a service provider can\u2019t anticipate the needs of a cus -\ntomer. Therefore, it is common for a service provider to add additional capac -\nity from a third-party service provider. Typically, the consumer is unaware \nthat he is dealing with an additional cloud service provider.\nMaking Use of the Cloud for Big Data\nClearly, the very nature of the cloud makes it an ideal computing environ -\nment for big data. So how might you use big data together with the cloud? \nHere are some examples:\n \u2713 IaaS in a public cloud:  In this scenario, you would be using a public \ncloud provider\u2019s infrastructure for your big data services because you \ndon\u2019t want to use your own physical infrastructure. IaaS can provide the \ncreation of virtual machines with almost limitless storage and compute \npower. You can pick the operating system that you want, and you have \nthe flexibility to dynamically scale the environment to meet your needs. \nAn example might be using the Amazon Elastic Compute Cloud (Amazon \nEC2) service, detailed later in the chapter, to run a real-time predic -\ntive model that requires data to be processed using massively parallel \nprocessing. It might be a service that processes big-box retail data. You \nmight want to process billions of pieces of click-stream data for target -\ning customers with the right ad in real time.\n \u2713 PaaS in a private cloud:  PaaS is an entire infrastructure packaged so \nthat it can be used to design, implement, and deploy applications and \nservices in a public or private cloud environment. PaaS enables an orga -\nnization to leverage key middleware services without having to deal \nwith the complexities of managing individual hardware and software ele -\nments. PaaS vendors are beginning to incorporate big data technologies \nsuch as Hadoop and MapReduce into their PaaS offerings. For example, \nyou might want to build a specialized application to analyze vast \namounts of medical data. The application would make use of real-time as \nwell as non-real-time data. It\u2019s going to require Hadoop and MapReduce \nfor storage and processing. What\u2019s great about PaaS in this scenario is \nhow quickly the application can be deployed. You won\u2019t have to wait for \ninternal IT teams to get up to speed on the new technologies and you \ncan experiment more liberally. Once you have identified a solid solution, \nyou can bring it in house when IT is ready to support it.\n \u2713 SaaS in a hybrid cloud:  Here you might want to analyze \u201cvoice of the \ncustomer\u201d data from multiple channels. Many companies have come \nto realize that one of the most important data sources is what the cus -\ntomer thinks and says about their company, their products, and their \nservices. Getting access to voice of the customer data can provide \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2836, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8a31455f-da85-4e18-b8ee-0a69f5d824e7": {"__data__": {"id_": "8a31455f-da85-4e18-b8ee-0a69f5d824e7", "embedding": null, "metadata": {"page_label": "78", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d8799478-d6bf-4e85-9097-4b0b675635f0", "node_type": "4", "metadata": {"page_label": "78", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ba306aa0cfe664fad56580e71547f062c6ea75ac864eca6eb0cc5165a90ddc71", "class_name": "RelatedNodeInfo"}}, "text": "78 Part II: Technology Foundations for Big Data \ninvaluable insights into behaviors and actions. Increasingly, custom -\ners are \u201cvocalizing\u201d on public sites across the Internet. The value of the \ncustomers\u2019 input can be greatly enhanced by incorporating this public \ndata into your analysis. Your SaaS vendor provides the platform for the \nanalysis as well as the social media data. In addition, you might utilize \nyour enterprise CRM data in your private cloud environment for inclu -\nsion in the analysis.\n Some industry insiders are using the term big data applications  when describ -\ning applications that run in the cloud that use big data. Examples of this \ninclude Amazon.com and LinkedIn. Now some people might argue (and have) \nthat these are really SaaS applications that solve a particular business prob -\nlem. It\u2019s often a matter of semantics in an emerging space.\nProviders in the Big Data Cloud Market\nCloud players come in all shapes and sizes and offer many different prod -\nucts. Some are household names while others are recently emerging. Some \nof the cloud providers that offer IaaS services that can be used for big data \ninclude Amazon.com, AT&T, GoGrid, Joyent, Rackspace, IBM, and Verizon/\nTerremark.\nHowever, cloud companies and cloud service providers are also offering soft -\nware targeted specifically for big data. These are described in the following \nsections.\nAmazon\u2019s Public Elastic Compute Cloud\nCurrently, one of the most high-profile IaaS service providers is Amazon Web \nServices with its Elastic Compute Cloud (Amazon EC2). Amazon didn\u2019t start \nout with a vision to build a big infrastructure services business. Instead, the \ncompany built a massive infrastructure to support its own retail business and \ndiscovered that its resources were underused. Instead of allowing this asset \nto sit idle, it decided to leverage this resource while adding to the bottom \nline. Amazon\u2019s EC2 service was launched in 2006 and continues to evolve.\nAmazon EC2 offers scalability under the user\u2019s control, with the user paying \nfor resources by the hour. The use of the term elastic  in the naming of \nAmazon\u2019s EC2 is significant. Here, elasticity refers to the capability that the \nEC2 users have to increase or decrease the infrastructure resources assigned \nto meet their needs.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2323, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "177b540d-6dae-4cc6-98e9-71f82acc42e7": {"__data__": {"id_": "177b540d-6dae-4cc6-98e9-71f82acc42e7", "embedding": null, "metadata": {"page_label": "79", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e75d13be-0ea3-42a3-b1bb-3a9b9b9939cb", "node_type": "4", "metadata": {"page_label": "79", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1c91834b652e8c7e702f674e5c42c35320dd0f3c49569e1bf65f4077e2cdfc6c", "class_name": "RelatedNodeInfo"}}, "text": "79  Chapter 6: Examining the Cloud and Big Data\nAmazon also offers other big data services to customers of its Amazon Web \nServices portfolio. These include the following:\n \u2713 Amazon Elastic MapReduce:  Targeted for processing huge volumes \nof data. Elastic MapReduce utilizes a hosted Hadoop framework (see \nChapter 9 for more on Hadoop) running on EC2 and Amazon Simple \nStorage Service (Amazon S3). Users can now run HBase (a distributed, \ncolumn-oriented data store).\n \u2713 Amazon DynamoDB:  A fully managed not only SQL (NoSQL) database \nservice. DynamoDB is a fault tolerant, highly available data storage \nservice offering self-provisioning, transparent scalability, and simple \nadministration. It is implemented on SSDs (solid state disks) for greater \nreliability and high performance. We talk more about NoSQL in Chapter 7.\n \u2713 Amazon Simple Storage Service (S3):  A web-scale service designed to \nstore any amount of data. The strength of its design center is perfor -\nmance and scalability, so it is not as feature laden as other data stores. \nData is stored in \u201cbuckets\u201d and you can select one or more global \nregions for physical storage to address latency or regulatory needs.\n \u2713 Amazon High Performance Computing:  Tuned for specialized tasks, \nthis service provides low-latency tuned high performance computing \nclusters. Most often used by scientists and academics, HPC is entering \nthe mainstream because of the offering of Amazon and other HPC pro -\nviders. Amazon HPC clusters are purpose built for specific workloads \nand can be reconfigured easily for new tasks.\n \u2713 Amazon RedShift:  Available in limited preview, RedShift is a petabyte-\nscale data warehousing service built on a scalable MPP architecture. \nManaged by Amazon, it offers a secure, reliable alternative to in-house \ndata warehouses and is compatible with several popular business intel -\nligence tools. \nGoogle big data services\nGoogle, the Internet search giant, also offers a number of cloud services tar -\ngeted for big data. These include the following:\n \u2713 Google Compute Engine:  A cloud-based capability for virtual machine \ncomputing, Google Compute Engine offers a secure, flexible computing \nenvironment from energy efficient data centers. Google also offers work -\nload management solutions from several technology partners who have \noptimized their products for Google Compute Engine.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2397, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c0e5fe3b-2145-4ad8-b20d-5469d0f5f00d": {"__data__": {"id_": "c0e5fe3b-2145-4ad8-b20d-5469d0f5f00d", "embedding": null, "metadata": {"page_label": "80", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dca8bc72-a99e-48f3-90c8-0245b68c6c1f", "node_type": "4", "metadata": {"page_label": "80", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ed4b05e1c459e71c9c13f45a04960483f316f7f329a0bd3765675e47d6a8ced8", "class_name": "RelatedNodeInfo"}}, "text": "80 Part II: Technology Foundations for Big Data \n \u2713 Google Big Query:  Allows you to run SQL-like queries at a high speed \nagainst large data sets of potentially billions of rows. Although it is good \nfor querying data, data cannot be modified after it is in it. Consider \nGoogle Big Query a sort of Online Analytical Processing (OLAP) system \nfor big data. It is good for ad hoc reporting or exploratory analysis.\n \u2713 Google Prediction API:  A cloud-based, machine learning tool for vast \namounts of data, Prediction is capable of identifying patterns in data and \nthen remembering them. It can learn more about a pattern each time it \nis used. The patterns can be analyzed for a variety of purposes, includ -\ning fraud detection, churn analysis, and customer sentiment. Prediction \nis covered in more depth in Chapter 12.\nMicrosoft Azure\nBased on Windows and SQL abstractions, Microsoft has productized a set \nof development tools, virtual machine support, management and media ser -\nvices, and mobile device services in a PaaS offering. For customers with deep \nexpertise in .Net, SQLServer, and Windows, the adoption of the Azure-based \nPaaS is straightforward.\nTo address the emerging requirements to integrate big data into Windows \nAzure solutions, Microsoft has also added Windows Azure HDInsight. Built on \nHortonworks Data Platform (HDP), which according to Microsoft, offers 100 \npercent compatibility with Apache Hadoop, HDInsight supports connection \nwith Microsoft Excel and other business intelligence (BI) tools. In addition to \nAzure HDInsight can also be deployed on Windows Server.\nOpenStack\nInitiated by Rackspace and NASA, OpenStack ( www.openstack.org ) is \nimplementing an open-cloud platform aimed at either public or private \nclouds. While the organization is tightly managed by Rackspace, it moved \nto a separate OpenStack foundation. Although companies can leverage \nOpenStack to create proprietary implementations, the OpenStack designation \nrequires conformance to a standard implementation of services.\nOpenStack\u2019s goal is to provide a massively scaled, multitenant cloud speci -\nfication that can run on any hardware. OpenStack is building a large ecosys -\ntem of partners interested in adopting its cloud platform, including Dell, HP, \nIntel, Cisco, Red Hat, and IBM, along with at least 100 others that are using \nOpenStack as the foundation for their cloud offerings. In essence, OpenStack \nis an open source IaaS initiative built on Ubuntu, an operating system based \non the Debian Linux distribution. It can also run on Red Hat\u2019s version of \nLinux.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2602, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7a2124bb-0138-40a5-9fe4-76b05b1c1bc3": {"__data__": {"id_": "7a2124bb-0138-40a5-9fe4-76b05b1c1bc3", "embedding": null, "metadata": {"page_label": "81", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "15931bbb-acee-45d5-90d2-0a11f8fc0dc7", "node_type": "4", "metadata": {"page_label": "81", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "fb89807cc6a60256c7a39d572bb19dcd0e1057a9e3d14baa265c35e3e3d0f548", "class_name": "RelatedNodeInfo"}}, "text": "81  Chapter 6: Examining the Cloud and Big Data\nOpenStack offers a range of services, including compute, object storage, cata -\nlog and repository, dashboarding, identity, and networking. In terms of big \ndata, Rackspace and Hortonworks (a provider of an open source data man -\nagement platform based on Apache Hadoop) announced that Rackspace will \nrelease an OpenStack public cloud-based Hadoop service, which will be vali -\ndated and supported by Hortonworks and will enable customers to quickly \ncreate a big data environment.\nWhere to be careful when  \nusing cloud services\nCloud-based services can provide an economical solution to your big data \nneeds, but the cloud has its issues. It\u2019s important to do your homework \nbefore moving your big data there. Here are some issues to consider:\n \u2713 Data integrity:  You need to make sure that your provider has the right \ncontrols in place to ensure that the integrity of your data is maintained.\n \u2713 Compliance:  Make sure that your provider can comply with any compli -\nance issues particular to your company or industry.\n \u2713 Costs:  Little costs can add up. Be careful to read the fine print of any \ncontract, and make sure that you know what you want to do in the \ncloud.\n \u2713 Data transport:  Be sure to figure out how you get your data into the \ncloud in the first place. For example, some providers will let you mail it \nto them on media. Others insist on uploading it over the network. This \ncan get expensive, so be careful.\n \u2713 Performance:  Because you\u2019re interested in getting performance from \nyour service provider, make sure that explicit definitions of service-level \nagreements exist for availability, support, and performance. For exam -\nple, your provider may tell you that you will be able to access your data \n99.999 percent of the time; however, read the contract. Does this uptime \ninclude scheduled maintenance?\n \u2713 Data access:  What controls are in place to make sure that you and only \nyou can access your data? In other words, what forms of secure access \ncontrol are in place? This might include identity management, where the \nprimary goal is protecting personal identity information so that access \nto computer resources, applications, data, and services is controlled \nproperly.\n \u2713 Location:  Where will your data be located? In some companies and \ncountries, regulatory issues prevent data from being stored or pro -\ncessed on machines in a different country.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2454, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "131564d1-950b-49c8-9ae6-3ca3b86e146f": {"__data__": {"id_": "131564d1-950b-49c8-9ae6-3ca3b86e146f", "embedding": null, "metadata": {"page_label": "82", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "30c0cb4f-6dae-4b23-b289-5734fa1cf420", "node_type": "4", "metadata": {"page_label": "82", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "a8281ecc46764299db60448405dcb5a3dce7ca7f680f8883e8d7049d9f15f62f", "class_name": "RelatedNodeInfo"}}, "text": "82 Part II: Technology Foundations for Big Data \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 67, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "53a00819-b6ff-4ea4-9867-b50bcbcbfedd": {"__data__": {"id_": "53a00819-b6ff-4ea4-9867-b50bcbcbfedd", "embedding": null, "metadata": {"page_label": "83", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bf4ef3aa-1181-4fe7-833d-7a68debe7970", "node_type": "4", "metadata": {"page_label": "83", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "90c9d7bc86a256da6e0b87e160e1b3fcb0b984808bc7c04ac7f6e9e117acfec6", "class_name": "RelatedNodeInfo"}}, "text": "Part III\nBig Data Management\n Read about integrating the data warehouse and the big data environment online at \nwww.dummies.com/extras/bigdata .\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 163, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "12b31851-6d68-4be0-b653-52c2ec71c4ab": {"__data__": {"id_": "12b31851-6d68-4be0-b653-52c2ec71c4ab", "embedding": null, "metadata": {"page_label": "84", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "42954911-3ae9-4797-acae-34d650a3f095", "node_type": "4", "metadata": {"page_label": "84", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e47d7f0177c738ad3d05ef094e052c518c0ca7b74850e551ac25d025563fe520", "class_name": "RelatedNodeInfo"}}, "text": "In this part . . .\n \u2713 Differentiate databases in the big data world.\n \u2713 Use MapReduce for data analysis.\n \u2713 Understand Hadoop.\n \u2713 Enhance your Hadoop Distributed File System with program -\nming languages and tools.\n \u2713 Develop applications for big data in analytics.\n \u2713 Use appliances in big data management.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 326, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "08c54504-5425-4a62-9ea8-5ca85eb22b12": {"__data__": {"id_": "08c54504-5425-4a62-9ea8-5ca85eb22b12", "embedding": null, "metadata": {"page_label": "85", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4e574ffe-6153-42e5-9101-3e19b510d963", "node_type": "4", "metadata": {"page_label": "85", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d8e872367393a3d5911c431eee7e2696670b778228dd3a4b695a3ee798513519", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 7\nOperational Databases\nIn This Chapter\n\u25b6 Taking a look at the relational database\n\u25b6 Examining nonrelational and key-value pair databases \n\u25b6 Exploring document and columnar databases\n\u25b6 Getting to know graph and spatial databases\n\u25b6 Pursuing the polyglot\nB \nig data is becoming an important element in the way organizations \nare leveraging high-volume data at the right speed to solve specific \ndata problems. However, big data does not live in isolation. To be effective, \ncompanies often need to be able to combine the results of big data analysis \nwith the data that exists within the business. In other words, you can\u2019t think \nabout big data in isolation from operational data sources. There are a variety \nof important operational data services. In this chapter, we provide an expla -\nnation of what these sources are so that you can understand how the data \ninevitably will be used in conjunction with big data solutions.\nOne of the most important services provided by operational databases (also \ncalled data stores ) is persistence. Persistence guarantees that the data stored \nin a database won\u2019t be changed without permissions and that it will avail -\nable as long as it is important to the business. What good is a database if it \ncannot be trusted to protect the data you put in it? Given this most important \nrequirement, you must then think about what kind of data you want to per -\nsist, how can you access and update it, and how can you use it to make busi -\nness decisions. At this most fundamental level, the choice of your database \nengines is critical to your overall success with your big data implementation.\nThe forefather of persistent data stores is the relational database manage -\nment system, or RDBMS. In its infancy, the computing industry used what are \nnow considered primitive techniques for data persistence. In essence, these \nare the systems of record and are foundational to how companies store data \nabout everything from customer transactions to the details of the operating \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2039, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7043b65a-8750-4091-b134-582ec10c469a": {"__data__": {"id_": "7043b65a-8750-4091-b134-582ec10c469a", "embedding": null, "metadata": {"page_label": "86", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a727e92c-2721-44fb-8086-5dc21b8d475f", "node_type": "4", "metadata": {"page_label": "86", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "5e66daa999537ef0e58c4cbb4077f95a3a1ff040b7bb4238abe750604a4dc1c0", "class_name": "RelatedNodeInfo"}}, "text": "86 Part III: Big Data Management \nthe business. Even though the underlying technology has been around for \nquite some time, many of these systems are in operation today because the \nbusinesses they support are highly dependent on the data. To replace them \nwould be akin to changing the engines of an airplane on a transoceanic flight. \nYou may recall the \u201cflat files\u201d or \u201cnetwork\u201d data stores that were prevalent \nbefore 1980 or so. Although these mechanisms were useful, they were very \ndifficult to master and always required system programmers to write custom \nprograms to manipulate the data. The relational model is still in wide usage \ntoday and has an important role to play in the evolution of big data.\nRelational databases are built on one or more relations and are represented \nby tables. These tables are defined by their columns, and the data is stored \nin the rows. The primary key is often the first column in the table. The con -\nsistency of the database and much of its value are achieved by \u201cnormalizing\u201d \nthe data. As the name implies, normalized data has been converted from \nnative format into a shared, agreed upon format. For example in one data -\nbase you might have \u201ctelephone\u201d as XXX-XXX-XXXX while in another it might \nbe XXXXXXXXX. To achieve a consistent view of the information, the field \nwill need to be normalized to one form or the other. Five levels of standards \nexist for normalization. The choice of normal form is often relegated to the \ndatabase designer and is mostly invisible to the end users. The collection of \ntables, keys, elements, and so on is referred to as the database schema.\nOver the years, the structured query language (SQL) has evolved in lock step \nwith RDBMS technology and is the most widely used mechanism for creating, \nquerying, maintaining, and operating relational databases. These tasks are \nreferred to as CRUD: Create, retrieve, update, and delete are common, related \noperations you can use directly on a database or through an application pro -\ngramming interface (API). Although originally devised for use with RDBMS, \nthe popularity of SQL has also made it prevalent among nonrelational data -\nbases, as we cover later in this chapter.\nHow the relational database evolved\nThroughout the history of the relational data -\nbase, many specialty database technologies \nappeared specifically to address shortcomings \nin early RDBMS products. We witnessed the \nemergence of object databases, content data -\nbases, data warehouses, data marts, and others. \nFor companies that needed these new capa -\nbilities, they created independent solutions and \nintegrated these new solutions with the existing \nRDBMS applications. This was tedious, clumsy, \nand costly. Over time, RDBMSs embraced these new technologies and embedded them in their \ncore product offerings, eliminating the necessity \nto include additional, now redundant, solutions. \nWe suspect this will occur with big data as well. \nGiven the fundamental differences between big \ndata and traditional data solutions, the encap -\nsulation of big data technologies into RDBMSs \nwill take a few years. In contrast, we are already \nbeginning to see the big data technologies \nembrace SQL and other traditional RDBMS fea -\ntures as peers to MapReduce.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3286, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f8bbb83a-88ba-45c7-b905-2e07809b89d9": {"__data__": {"id_": "f8bbb83a-88ba-45c7-b905-2e07809b89d9", "embedding": null, "metadata": {"page_label": "87", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "50121ec2-bf5d-4276-91b0-b8279ce0b6a5", "node_type": "4", "metadata": {"page_label": "87", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f484188ddc5a3be5534ad29baa87da4acda853ad12a374c18fecf2c2ab6fd12f", "class_name": "RelatedNodeInfo"}}, "text": "87  Chapter 7: Operational Databases\nRDBMSs Are Important in  \na Big Data Environment\nIn companies both small and large, most of their important operational \ninformation is probably stored in RDBMSs. Many companies have different \nRDBMSs for different areas of their business. Transactional data might be \nstored in one vendor\u2019s database, while customer information could be stored \nin another. Knowing what data is stored and where it is stored are critical \nbuilding blocks in your big data implementation. It is not likely you will use \nRDBMSs for the core of the implementation, but you will need to rely on the \ndata stored in RDBMSs to create the highest level of value to the business \nwith big data. Although many different commercial relational databases are \navailable from companies like Oracle, IBM, and Microsoft, you need to under -\nstand an open source relational database called PostgreSQL.\nPostgreSQL relational database\nPostgreSQL ( www.postgresql.org ) is the most widely used open source \nrelational database. It was originally developed at the University of California \nat Berkeley and has been under active development as an open source proj -\nect for more than 15 years. Several factors contribute to the popularity of \nPostgreSQL. As an RDBMS with support for the SQL standard, it does all the \nthings expected in a database product, plus its longevity and wide usage \nhave made it \u201cbattle tested.\u201d It is also available on just about every variety of \noperating system, from PCs to mainframes.\nProviding the basics and doing so reliably are only part of the story. \nPostgreSQL also supports many features only found in expensive proprietary \nRDBMSs, including the following:\n \u2713 Capability to directly handle \u201cobjects\u201d within the relational schema\n \u2713 Foreign keys (referencing keys from one table in another)\n \u2713 Triggers (events used to automatically start a stored procedure)\n \u2713 Complex queries (subqueries and joins across discrete tables)\n \u2713 Transactional integrity\n \u2713 Multiversion concurrency control\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2046, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a008c3d5-6b50-45c8-b0ba-5ebccc740031": {"__data__": {"id_": "a008c3d5-6b50-45c8-b0ba-5ebccc740031", "embedding": null, "metadata": {"page_label": "88", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "11562404-ee4c-4378-a6c9-38873abf84bc", "node_type": "4", "metadata": {"page_label": "88", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "edf74b2b40a9133ed37290cf577634f427bfb9e4119f2860a740adaa9a680864", "class_name": "RelatedNodeInfo"}}, "text": "88 Part III: Big Data Management \nThe real power of PostgreSQL is its extensibility. Users and database pro -\ngrammers can add new capabilities without affecting the fundamental opera -\ntion or reliability of the database. Possible extensions include\n \u2713 Data types\n \u2713 Operators\n \u2713 Functions\n \u2713 Indexing methods\n \u2713 Procedural languages\nThis high level of customization makes PostgreSQL desirable when rigid, pro -\nprietary products won\u2019t get the job done. It is infinitely extensible.\nFinally, the PostgreSQL license permits modification and distribution in any \nform, open or closed source. Any modifications can be kept private or shared \nwith the community as you wish.\nAlthough relational databases (including PostgreSQL) play a key role in the \nbig data \u201centerprise,\u201d you also have some alternative approaches.\nNonrelational Databases\nNonrelational databases do not rely on the table/key model endemic to \nRDBMSs. A number of nonrelational database technologies are covered \nthroughout this chapter, each with its own set of unique capabilities focused \non specific problems outside the scope of traditional RDBMSs. In short, \nspecialty data in the big data world requires specialty persistence and data \nmanipulation techniques. Although these new styles of databases offer some \nanswers to your big data challenges, they are not an express ticket to the \nfinish line.\nOne emerging, popular class of nonrelational database is called not only SQL \n(NoSQL). Originally the originators envisioned databases that did not require \nthe relational model and SQL. As these products were introduced into the \nmarket, the definition softened a bit and now they are thought of as \u201cnot only \nSQL,\u201d again bowing to the ubiquity of SQL. The other class is databases that \ndo not support the relational model, but rely on SQL as a primary means of \nmanipulating the data within. Even though relational and nonrelational data -\nbases have similar fundamentals, how the fundamentals are accomplished \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2007, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "49afd5db-5f93-410e-a0d5-cf86b2b5300d": {"__data__": {"id_": "49afd5db-5f93-410e-a0d5-cf86b2b5300d", "embedding": null, "metadata": {"page_label": "89", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5a1de1e8-e4cc-44be-a79d-7bec9639a418", "node_type": "4", "metadata": {"page_label": "89", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b369e3fb62693adebb8afbfbfb0a055654eec60b30a939f3a6c5f6aef13b8369", "class_name": "RelatedNodeInfo"}}, "text": "89  Chapter 7: Operational Databases\ncreates the differentiation. Nonrelational database technologies have the fol -\nlowing characteristics in common:\n \u2713 Scalability:  In this instance, we are referring to the capability to write \ndata across multiple data stores simultaneously without regard to \nphysical limitations of the underlying infrastructure. Another important \ndimension is seamlessness. The databases must be able to expand and \ncontract in response to data flows and do so invisibly to the end users.\n \u2713 Data and Query model:  Instead of the row, column, key structure, non -\nrelational databases use specialty frameworks to store data with a requi -\nsite set of specialty query APIs to intelligently access the data.\n \u2713 Persistence design:  Persistence is still a critical element in nonrelational \ndatabases. Due to the high velocity, variety, and volume of big data, \nthese databases use difference mechanisms for persisting the data. The \nhighest performance option is \u201cin memory,\u201d where the entire database is \nkept in the very fast memory system of your servers.\n \u2713 Interface diversity:  Although most of these technologies support \nRESTful APIs as their \u201cgo to\u201d interface, they also offer a wide variety \nof connection mechanisms for programmers and database managers, \nincluding analysis tools and reporting/visualization.\n \u2713 Eventual Consistency:  While RDBMS uses ACID (Atomicity, Consistency, \nIsolation, Durability) as a mechanism for ensuring the consistency of \ndata, non-relational DBMS use BASE. BASE stands for Basically Available, \nSoft state, and Eventual Consistency. Of these, eventual consistency is \nmost important because it is responsible for conflict resolution when \ndata is in motion between nodes in a distributed implementation. The \ndata state is maintained by the software and the access model relies on \nbasic availability.\nNext we examine some of the most popular styles and the open source imple -\nmentations of nonrelational databases.\nKey-Value Pair Databases\nBy far, the simplest of the NoSQL databases are those employing the key-\nvalue pair (KVP) model. KVP databases do not require a schema (like \nRDBMSs) and offer great flexibility and scalability. KVP databases do not \noffer ACID (Atomicity, Consistency, Isolation, Durability) capability, and \nrequire implementers to think about data placement, replication, and fault \ntolerance as they are not expressly controlled by the technology itself. KVP \ndatabases are not typed. As a result, most of the data is stored as strings. \nTable 7-1 lists some sample key-value pairs.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2598, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "226f359a-074b-436b-85ef-fa4d40c17b19": {"__data__": {"id_": "226f359a-074b-436b-85ef-fa4d40c17b19", "embedding": null, "metadata": {"page_label": "90", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fc95085a-b367-4450-acc3-39991f245592", "node_type": "4", "metadata": {"page_label": "90", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "19591e36d75825c8375a4d7685783aef46214c12e421b4cf9221a4a11f14f857", "class_name": "RelatedNodeInfo"}}, "text": "90 Part III: Big Data Management \nTable 7-1 Sample Key-Value Pairs\nKey Value\nColor Blue\nLibation Beer\nHero Soldier\nThis is a very simplified set of keys and values. In a big data implementation, \nmany individuals will have differing ideas about colors, libations, and heroes, \nas presented in Table 7-2.\nTable 7-2 Big Data Key-Value Pairs\nKey Value\nFacebookUser12345_Color Red\nTwitterUser67890_Color Brownish\nFoursquareUser45678_Libation \u201cWhite wine\u201d\nGoogle+User24356_Libation \u201cDry martini with a twist\u201d\nLinkedInUser87654_Hero \u201cTop sales performer\u201d\nAs the number of users increases, keeping track of precise keys and related \nvalues can be challenging. If you need to keep track of the opinions of mil -\nlions of users, the number of key-value pairs associated with them can \nincrease exponentially. If you do not want to constrain choices for the values, \nthe generic string representation of KVP provides flexibility and readability.\nYou might need some additional help organizing data in a key-value database. \nMost offer the capability to aggregate keys (and their related values) into a \ncollection. Collections can consist of any number of key-value pairs and do \nnot require exclusive control of the individual KVP elements.\nRiak key-value database\nOne widely used open source key-value pair database is called Riak \n(http://wiki.basho.com ). It is developed and supported by a company \ncalled Basho Technologies ( www.basho.com ) and is made available under \nthe Apache Software License v2.0.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1519, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9c2afb38-f3ba-4405-9a2b-83ca8a81347c": {"__data__": {"id_": "9c2afb38-f3ba-4405-9a2b-83ca8a81347c", "embedding": null, "metadata": {"page_label": "91", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2fed310c-d99f-4914-af00-9cfd1edf5c8d", "node_type": "4", "metadata": {"page_label": "91", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "a298642cc9c056a542cca0f6fd4e509becbc1d8e8cf2f5523fec733c36e8fee4", "class_name": "RelatedNodeInfo"}}, "text": "91  Chapter 7: Operational Databases\nRiak is a very fast and scalable implementation of a key-value database. It \nsupports a high-volume environment with fast-changing data because it is \nlightweight. Riak is particularly effective at real-time analysis of trading in \nfinancial services. It uses \u201cbuckets\u201d as an organizing mechanism for collec -\ntions of keys and values. Riak implementations are clusters of physical or vir -\ntual nodes arranged in a peer-to-peer fashion. No master node exists, so the \ncluster is resilient and highly scalable. All data and operations are distributed \nacross the cluster. Riak clusters have an interesting performance profile. \nLarger clusters (with more nodes) perform better and faster than clusters \nwith fewer nodes. Communication in the cluster is implemented via a special \nprotocol called Gossip. Gossip stores status information about the cluster \nand shares information about buckets.\nRiak has many features and is part of an ecosystem consisting of the following:\n \u2713 Parallel processing:  Using MapReduce, Riak supports a capability to \ndecompose and recompose queries across the cluster for real-time anal -\nysis and computation.\n \u2713 Links and link walking:  Riak can be constructed to mimic a graph \ndatabase using links. A link can be thought of as a one-way connection \nbetween key-value pairs. Walking (following) the links will provide a map \nof relationships between key-value pairs.\n \u2713 Search:  Riak Search has a fault-tolerant, distributed full-text searching \ncapability. Buckets can be indexed for rapid resolution of value to keys.\n \u2713 Secondary indexes:  Developers can tag values with one or more key \nfield values. The application can then query the index and return a list \nof matching keys. This can be very useful in big data implementations \nbecause the operation is atomic and will support real-time behaviors.\nRiak implementations are best suited for\n \u2713 User data for social networks, communities, or gaming\n \u2713 High-volume, media-rich data gathering and storage\n \u2713 Caching layers for connecting RDBMS and NoSQL databases\n \u2713 Mobile applications requiring flexibility and dependability\nDocument Databases\nYou find two kinds of document databases. One is often described as a repos -\nitory for full document-style content (Word files, complete web pages, and so \non). The other is a database for storing document components for permanent \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2420, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c501d914-3063-4c0b-ba96-1497a7c3f9e3": {"__data__": {"id_": "c501d914-3063-4c0b-ba96-1497a7c3f9e3", "embedding": null, "metadata": {"page_label": "92", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "985c4003-99ea-46af-87c6-f23d3920fb49", "node_type": "4", "metadata": {"page_label": "92", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "17da5b47d82f6858353ae60ebaba5c88915acdbfc6937e2bc8c4366e06ffaae8", "class_name": "RelatedNodeInfo"}}, "text": "92 Part III: Big Data Management \nstorage as a static entity or for dynamic assembly of the parts of a document. \nThe structure of the documents and their parts is provided by JavaScript \nObject Notation (JSON) and/or Binary JSON (BSON). Document databases \nare most useful when you have to produce a lot of reports and they need \nto be dynamically assembled from elements that change frequently. A good \nexample is document fulfillment in healthcare, where content composition \nwill vary based on member profile (age, residency, income level), healthcare \nplan, and government program eligibility. For big data implementations, both \nstyles are important, so you should understand the details of each.\nAt its core, JSON is a data-interchange format, based on a subset of the \nJavaScript programming language. Although part of a programming language, \nit is textual in nature and very easy to read and write. It also has the advan -\ntage of being easy for computers to handle. Two basic structures exist in \nJSON, and they are supported by many, if not all, modern programming lan -\nguages. The first basic structure is a collection of name/value pairs, and they \nare represented programmatically as objects, records, keyed lists, and so  \non. The second basic structure is an ordered list of values, and they are  \nrepresented programmatically as arrays, lists, or sequences. BSON is a  \nbinary serialization of JSON structures designed to increase performance  \nand scalability.\nDocument databases are becoming a gold standard for big data adoption, so \nwe examine two of the most popular implementations.\nMongoDB\nMongoDB ( www.mongodb.com ) is the project name for the \u201chu(mongo)us \ndatabase\u201d system. It is maintained by a company called 10gen as open source \nand is freely available under the GNU AGPL v3.0 license. Commercial licenses \nwith full support are available from 10gen ( www.10gen.com ).\nMongoDB is growing in popularity and may be a good choice for the data \nstore supporting your big data implementation. MongoDB is composed of \ndatabases containing \u201ccollections.\u201d A collection is composed of \u201cdocuments,\u201d \nand each document is composed of fields. Just as in relational databases, you \ncan index a collection. Doing so increases the performance of data lookup. \nUnlike other databases, however, MongoDB returns something called a \n\u201ccursor,\u201d which serves as a pointer to the data. This is a very useful capabil -\nity because it offers the option of counting or classifying the data without \nextracting it. Natively, MongoDB supports BSON, the binary implementation \nof JSON documents.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2619, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b7ca40e3-9714-4e7f-8070-d82575fd2548": {"__data__": {"id_": "b7ca40e3-9714-4e7f-8070-d82575fd2548", "embedding": null, "metadata": {"page_label": "93", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "84388be3-b343-45dc-a1be-89fbc616966b", "node_type": "4", "metadata": {"page_label": "93", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "8df9cd50feb43afb823e80968f40696c53ceab5a6d821a16bd9a3a3b80a77567", "class_name": "RelatedNodeInfo"}}, "text": "93  Chapter 7: Operational Databases\nMongoDB is also an ecosystem consisting of the following elements:\n \u2713 High-availability and replication services for scaling across local and \nwide-area networks.\n \u2713 A grid-based file system (GridFS), enabling the storage of large objects \nby dividing them among multiple documents.\n \u2713 MapReduce to support analytics and aggregation of different collec -\ntions/documents.\n \u2713 A sharding service that distributes a single database across a cluster of \nservers in a single or in multiple data centers. The service is driven by \na shard key. The shard key is used to distribute documents intelligently \nacross multiple instances.\n \u2713 A querying service that supports ad hoc queries, distributed queries, \nand full-text search.\nEffective MongoDB implementations include\n \u2713 High-volume content management\n \u2713 Social networking\n \u2713 Archiving\n \u2713 Real-time analytics\nCouchDB\nAnother very popular nonrelational database is CouchDB ( http://\ncouchdb.apache.org ). Like MongoDB, CouchDB is open source. It is main -\ntained by the Apache Software Foundation ( www.apache.org ) and is made \navailable under the Apache License v2.0. Unlike MongoDB, CouchDB was \ndesigned to mimic the web in all respects. For example, CouchDB is resilient \nto network dropouts and will continue to operate beautifully in areas where \nnetwork connectivity is spotty. It is also at home on a smartphone or in a \ndata center. This all comes with a few trade-offs. Because of the underlying \nweb mimicry, CouchDB is high latency resulting in a preference for local data \nstorage. Although capable of working in a non-distributed manner, CouchDB \nis not well suited to smaller implementations. You must determine whether \nthese trade-offs can be ignored as you begin your big data implementation.\nCouchDB databases are composed of documents consisting of fields and \nattachments as well as a \u201cdescription\u201d of the document in the form of meta -\ndata that is automatically maintained by the system. The underlying technol -\nogy features all ACID capabilities that you are familiar with from the RDBMS \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2115, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "582dfdf5-d75c-4f10-86ec-866eb0d1490c": {"__data__": {"id_": "582dfdf5-d75c-4f10-86ec-866eb0d1490c", "embedding": null, "metadata": {"page_label": "94", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e2ca1895-345f-43b6-b3cb-6b7d7b6cec42", "node_type": "4", "metadata": {"page_label": "94", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b5fa6900b3591cc8bbcd78ca08f3885556320f7946f523b67cf8f3610189ce70", "class_name": "RelatedNodeInfo"}}, "text": "94 Part III: Big Data Management \nworld. The advantage in CouchDB over relational is that the data is packaged \nand ready for manipulation or storage rather than scattered across rows and \ntables.\nCouchDB is also an ecosystem with the following capabilities:\n \u2713 Compaction:  The databases are compressed to eliminate wasted space \nwhen a certain level of emptiness is reached. This helps performance \nand efficiency for persistence.\n \u2713 View model:  A mechanism for filtering, organizing, and reporting on \ndata utilizing a set of definitions that are stored as documents in the \ndatabase. You find a one-to-many relationship of databases to views, so \nyou can create many different ways of representing the data you have \n\u201csliced and diced.\u201d\n \u2713 Replication and distributed services:  Document storage is designed to \nprovide bidirectional replication. Partial replicas can be maintained to \nsupport criteria-based distribution or migration to devices with limited \nconnectivity. Native replication is peer based, but you can implement \nMaster/Slave, Master/Master, and other types of replication modalities.\nEffective CouchDB implementations include\n \u2713 High-volume content management\n \u2713 Scaling from smartphone to data center\n \u2713 Applications with limited or slow network connectivity\nColumnar Databases\nRelational databases are row oriented,  as the data in each row of a table is \nstored together. In a columnar, or column-oriented database, the data is \nstored across rows. Although this may seem like a trivial distinction, it is the \nmost important underlying characteristic of columnar databases. It is very \neasy to add columns, and they may be added row by row, offering great flex -\nibility, performance, and scalability. When you have volume and variety of \ndata, you might want to use a columnar database. It is very adaptable; you \nsimply continue to add columns.\nHBase columnar database\nOne of the most popular columnar databases is HBase ( http://hbase.\napache.org ). It, too, is a project in the Apache Software Foundation distrib -\nuted under the Apache Software License v2.0. HBase uses the Hadoop file \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2138, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8c17afb1-a5e9-45f1-846b-3b30162ae0ee": {"__data__": {"id_": "8c17afb1-a5e9-45f1-846b-3b30162ae0ee", "embedding": null, "metadata": {"page_label": "95", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3bfc1ed3-75e5-461b-87d5-d5e80fe20dfb", "node_type": "4", "metadata": {"page_label": "95", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "705f8acb7e936148f7a3b52686165d1a5d29de887fa43cd79ac4c20e0ac5bd44", "class_name": "RelatedNodeInfo"}}, "text": "95  Chapter 7: Operational Databases\nsystem and MapReduce engine for its core data storage needs. For more on \nMapReduce, refer to Chapter 8; for more on Hadoop, check out Chapter 9.\nThe design of HBase is modeled on Google\u2019s BigTable (an efficient form of \nstoring nonrelational data). Therefore, implementations of HBase are highly \nscalable, sparse, distributed, persistent multidimensional sorted maps. The \nmap is indexed by a row key, column key, and a timestamp; each value in the \nmap is an uninterpreted array of bytes. When your big data implementation \nrequires random, real-time read/write data access, HBase is a very good solu -\ntion. It is often used to store results for later analytical processing.\nImportant characteristics of HBase include the following:\n \u2713 Consistency:  Although not an \u201cACID\u201d implementation, HBase offers \nstrongly consistent reads and writes and is not based on an eventually \nconsistent model. This means you can use it for high-speed require -\nments as long as you do not need the \u201cextra features\u201d offered by RDBMS \nlike full transaction support or typed columns.\n \u2713 Sharding:  Because the data is distributed by the supporting file system, \nHBase offers transparent, automatic splitting and redistribution of its \ncontent.\n \u2713 High availability:  Through the implementation of region servers, HBase \nsupports LAN and WAN failover and recovery. At the core, there is a \nmaster server responsible for monitoring the region servers and all \nmetadata for the cluster.\n \u2713 Client API:  HBase offers programmatic access through a Java API.\n \u2713 Support for IT operations:  Implementers can expose performance and \nother metrics through a set of built-in web pages.\nHBase implementations are best suited for\n \u2713 High-volume, incremental data gathering and processing\n \u2713 Real-time information exchange (for example, messaging)\n \u2713 Frequently changing content serving\nGraph Databases\nThe fundamental structure for graph databases is called \u201cnode-relationship.\u201d \nThis structure is most useful when you must deal with highly interconnected \ndata. Nodes and relationships support properties,  a key-value pair where the \ndata is stored. These databases are navigated by following the relationships. \nThis kind of storage and navigation is not possible in RDBMSs due to the rigid \ntable structures and the inability to follow connections between the data \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2397, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "40a39e11-487a-4915-8029-502b34edf3b6": {"__data__": {"id_": "40a39e11-487a-4915-8029-502b34edf3b6", "embedding": null, "metadata": {"page_label": "96", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "60762a95-36a3-4f99-b922-0a96833e579b", "node_type": "4", "metadata": {"page_label": "96", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "41ac3be94c23116faa072014b13c31f9e5dc1da3fc1839ca7b25f6df71bb4b97", "class_name": "RelatedNodeInfo"}}, "text": "96 Part III: Big Data Management \nwherever they might lead us. A graph database might be used to manage geo -\ngraphic data for oil exploration or to model and optimize a telecommunica -\ntions provider\u2019s networks.\nNeo4J graph database\nOne of the most widely used graph databases is Neo4J ( www.neo4j.org ). It \nis an open source project licensed under the GNU public license v3.0. A sup -\nported, commercial version is provided by Neo Technology under the GNU \nAGPL v3.0 and commercial licensing. Neo4J is an ACID transaction database \noffering high availability through clustering. It is a trustworthy and scalable \ndatabase that is easy to model because of the node-relationship properties\u2019 \nfundamental structure and how naturally it maps to our own human relation -\nships. It does not require a schema, nor does it require data typing, so it is \ninherently very flexible.\nWith this flexibility comes a few limitations. Nodes cannot reference them -\nselves directly. For example, you (as a node) cannot also be your own  father \nor mother (as relationships), but you can be a father or mother. There might \nbe real world cases where self-reference is required. If so, a graph data -\nbase is not the best solution since the rules about self-reference are strictly \nenforced. While the replication capability is very good, Neo4J can only rep -\nlicate entire graphs, placing a limit on the overall size of the graph (approxi -\nmately 34 billion of nodes and 34 billion relationships).\nImportant characteristics of Neo4J include the following:\n \u2713 Integration with other databases:  Neo4J supports transaction manage -\nment with rollback to allow seamless interoperability with nongraphing \ndata stores.\n \u2713 Synchronization services:  Neo4J supports event-driven behaviors via \nan event bus, periodic synchronization using itself, or an RDBMS as the \nmaster, and traditional batch synchronization.\n \u2713 Resiliency:  Neo4J supports cold (that is, when database is not running) \nand hot (when it is running) backups, as well as a high-availability clus -\ntering mode. Standard alerts are available for integration with existing \noperations management systems.\n \u2713 Query language:  Neo4J supports a declarative language called Cypher, \ndesigned specifically to query graphs and their components. Cypher \ncommands are loosely based on SQL syntax and are targeted at ad hoc \nqueries of the graph data.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2408, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bc6884ea-e205-4298-8b41-797205be4142": {"__data__": {"id_": "bc6884ea-e205-4298-8b41-797205be4142", "embedding": null, "metadata": {"page_label": "97", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ecfd3451-e53d-493d-a5b1-b0a47a24fd94", "node_type": "4", "metadata": {"page_label": "97", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e31071ae93c9c600d5926841aef36370e100002a08804998ba7b0fe513b10e31", "class_name": "RelatedNodeInfo"}}, "text": "97  Chapter 7: Operational Databases\nNeo4J implementations are best suited for\n \u2713 Social networking\n \u2713 Classification of biological or medical domains\n \u2713 Creating dynamic communities of practice or interest\nSpatial Databases\nWhether you know it or not, you may interact with spatial data every day. If \nyou use a smartphone or Global Positioning System (GPS) for directions to \na particular place, or if you ask a search engine for the locations of seafood \nrestaurants near a physical address or landmark, you are using applications \nrelying on spatial data. Spatial data itself is standardized through the efforts \nof the Open Geospatial Consortium (OGC; www.opengeospatial.org ), \nwhich establishes OpenGIS (Geographic Information System) and a number \nof other standards for spatial data.\nThis is important because spatial databases are implementations of the OGC \nstandards, and your company might have specific needs met (or not met) \nby the standards. A spatial database becomes important when organizations \nbegin to leverage several different dimensions of data to help make a deci -\nsion. For example, a meteorologist doing research might want to store and \nevaluate data related to a hurricane, including temperature, wind speed, and \nhumidity, and model those results in three dimensions.\nIn their simplest form, spatial databases store data about 2-dimensional, \n2.5-dimensional, and 3-dimensional objects. You are probably familiar with \n2D and 3D objects as we interact with them all the time. A 2D object has \nlength and width. A 3D object adds depth to the length and width. A page \nfrom this book is a 2D object, while the entire book is a 3D object. What \nabout 2.5D? 2.5D objects are a special type of spatial data. They are 2D \nobjects with elevation as the extra \u201chalf\u201d dimension. Most 2.5D spatial data -\nbases contain mapping information and are often referred to as Geographic \nInformation Systems (GISs).\nThe atomic elements of spatial databases are lines, points, and polygons. \nThey can be combined in any fashion to represent any object constrained \nby 2, 2.5, or 3 dimensions. Due to the special nature of spatial data objects, \ndesigners created indexing mechanisms (spatial indices) designed to support \nad hoc queries and visual representations of the contents of the database. \nFor example, a spatial index would answer the query \u201cWhat is the distance \nbetween one point and another point?\u201d or \u201cDoes a specific line intersect \nwith a particular set of polygons?\u201d If this seems like a huge problem, that\u2019s \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2558, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bae3b027-7b2c-4921-9f63-2efbc47233f7": {"__data__": {"id_": "bae3b027-7b2c-4921-9f63-2efbc47233f7", "embedding": null, "metadata": {"page_label": "98", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "04782910-5c75-4a27-b415-9423f2fb07c3", "node_type": "4", "metadata": {"page_label": "98", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "144ff083d06baf5265880d0c79b27a30bc4974ae2a5fd7f3ad82cd8822f92557", "class_name": "RelatedNodeInfo"}}, "text": "98 Part III: Big Data Management \nbecause it is. Spatial data may well represent the biggest big data challenge \nof all.\nPostGIS/OpenGEO Suite\nPostGIS (www.postgis.org ) is an open source project maintained by \nRefractions Research ( www.refractions.net ) and is licensed under the \nGNU General Public License (GPL). PostGIS is also supplied as part of the \nOpenGeo Suite community edition and is offered and supported by OpenGeo \n(www.opengeo.org ) under an enterprise license.\nPostGIS is a little different than some of the other databases discussed in this \nchapter. It is a specialized, layered implementation running on the workhorse \nRDBMS PostgreSQL. This approach offers the best of both worlds. You get all \nthe benefits of an SQL RDBMS (such as transactional integrity and ACID) and \nsupport for the specialized operations needed for spatial applications (repro -\njection, geodetic support, geometry conversion, and so on).\nAlthough the database itself is very important, you will also require \nother pieces of technology to address spatial application requirements. \nFortunately, PostGIS is part of an ecosystem of components designed to work \ntogether to address these needs. In addition to PostGIS, the OpenGEO Suite \nconsists of the following:\n \u2713 GeoServer:  Implemented in Java, the GeoServer can publish spatial \ninformation from several of the major sources of spatial data on the \nweb. It can integrate with Google Earth and also has an excellent web-\nbased administrative front end.\n \u2713 OpenLayers:  A library for JavaScript that is useful for displaying maps \nand other representations of spatial data in a web browser. It can manip -\nulate images from most of the mapping sources on the web, including \nBing Maps, Google Maps, Yahoo! Maps, OpenStreetMap, and so on.\n \u2713 GeoExt:  Designed to make the map information from OpenLayers  \nreadily available to the web application developer. GeoExt widgets  \ncan be used to create editing, viewing, styling, and other interactive  \nweb experiences.\n \u2713 GeoWebCache:  After you have the data in a server and can display it \nin a browser, you need to find a way to make it fast. GeoWebCache is \nthe accelerator. It caches chunks of image data (called tiles) and makes \nthem available for rapid delivery to the display device.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2304, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "090199fe-f9b7-436b-9e83-fc79914a9296": {"__data__": {"id_": "090199fe-f9b7-436b-9e83-fc79914a9296", "embedding": null, "metadata": {"page_label": "99", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ef38ed6c-d8ad-414d-b869-128da4daddc1", "node_type": "4", "metadata": {"page_label": "99", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "97e3ccdd6a47be01a115760b58d78afa91490bfb3824992a6175f599cda9140c", "class_name": "RelatedNodeInfo"}}, "text": "99  Chapter 7: Operational Databases\nWhile many of the uses of spatial data involve maps and locations, spatial \ndata has many other contemporary and future applications, including\n \u2713 Precise 3D modeling of the human body, buildings, the atmosphere, and \nso on\n \u2713 Gathering and analysis of data from sensor networks\n \u2713 Integration with historical data to examine 3D space/objects over time\nPolyglot Persistence\nThe official definition of polyglot  is \u201csomeone who speaks or writes several \nlanguages.\u201d The term is borrowed in this context and redefined as a set of \napplications that use several core database technologies, and this is the most \nlikely outcome of your big data implementation planning. It is going to be dif -\nficult to choose one persistence style no matter how narrow your approach \nto big data might be. A polyglot persistence database is used when it is nec -\nessary to solve a complex problem by breaking that problem into segments \nand applying different database models. It is then necessary to aggregate the \nresults into a hybrid data storage and analysis solution. A number of factors \naffect this decision:\n \u2713 You are already using polyglot persistence in your existing workplace. If \nyour enterprise or organization is large, you are probably using multiple \nRDBMSs, data warehouses, data marts, flat files, content management \nservers, and so on. This hybrid environment is common, and you need \nto understand it so that you can make the right decisions about integra -\ntion, analytics, timeliness of data, data visibility, and so on. You need to \nunderstand all of that because you need to figure out how it is going to \nfit into your big data implementation.\n \u2713 The most ideal of environments, where you have only one persistence \ntechnology, is probably not suited to big data problem solving. At the \nvery least, you will need to introduce another style of database and \nother supporting technologies for your new implementation.\n \u2713 Depending on the variety and velocity of your big data gathering, you \nmay need to consider different databases to support one implementa -\ntion. You should also consider your requirements for transactional \nintegrity. Do you need to support ACID compliance or will BASE compli -\nance be sufficient? \nAs an example, suppose that you need to identify all the customers for your \nconsumer hard goods product who have purchased in the last 12 months and \nhave commented on social websites about their experience \u2014 AND whether \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2509, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1353ea0b-94a0-4fc4-a4a5-297eb0e60691": {"__data__": {"id_": "1353ea0b-94a0-4fc4-a4a5-297eb0e60691", "embedding": null, "metadata": {"page_label": "100", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f3834d20-5606-44b2-b911-7935bf1d292c", "node_type": "4", "metadata": {"page_label": "100", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "68c504119fcce44f8eeb06fc9feefe96c111aec2cdb3761f3b2e7d609787ff69", "class_name": "RelatedNodeInfo"}}, "text": "100 Part III: Big Data Management \nthey have had any support cases (when, how many, how resolved), where \nthey acquired the product, how it was delivered (and was the delivery rout -\ning cost efficient with respect to energy consumption?), what they paid, how \nthey paid, whether they have been to the company website, how many times, \nwhat they did on the site, and so on. Then suppose that you want to offer \nthem a promotional discount to their smartphone when they are entering one \nof your (or one of your partners\u2019) retail stores.\nThis is a big data challenge at its best. Multiple sources of data with very dif -\nferent structures need to be collected and analyzed so that you can get the \nanswers to these questions. Then you need determine whether the custom -\ners qualify for the promotion and, in real time, push them a coupon offering \nthem something new and interesting.\nThis type of problem cannot be solved easily or cost-effectively with one type \nof database technology. Even though some of the basic information is trans -\nactional and probably in an RDBMS, the other information is nonrelational \nand will require at least two types of persistence engines (spatial and graph). \nYou now have polyglot persistence.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1250, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c057261c-a501-45dc-a099-7cdeb22feb36": {"__data__": {"id_": "c057261c-a501-45dc-a099-7cdeb22feb36", "embedding": null, "metadata": {"page_label": "101", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b70e0913-30c3-41f1-ac0a-2dd402b83f51", "node_type": "4", "metadata": {"page_label": "101", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "98b1302e521e7f72f54068c8f7b1326da6c72077ec33f25e4d9203890063ce0a", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 8\nMapReduce Fundamentals\nIn This Chapter\n\u25b6 The origins of MapReduce\n\u25b6 Looking at the map function\n\u25b6 Exploring the reduce function\n\u25b6 Putting map and reduce together\n\u25b6 Optimizing MapReduce tasks\nW \nhile big data has dominated the headlines over the past year, large \ncomputing problems have existed since the beginning of the com -\nputer era. Each time a newer, faster, higher-capacity computer system was \nintroduced, people found problems that were too big for the system to \nhandle. Along came local-area networks, and the industry turned to combin -\ning the compute and storage capacities of systems on the network toward \nsolving bigger and bigger problems. The distribution of compute- and data-\nintensive applications is at the heart of a solution to big data challenges. To \nbest achieve reliable distribution at scale, new technology approaches were \nneeded. MapReduce is one of those new approaches. MapReduce is a soft -\nware framework that enables developers to write programs that can process \nmassive amounts of unstructured data in parallel across a distributed group \nof processors.\nTracing the Origins of MapReduce\nIn the early 2000s, some engineers at Google looked into the future and \ndetermined that while their current solutions for applications such as \nweb crawling, query frequency, and so on were adequate for most existing \nrequirements, they were inadequate for the complexity they anticipated as \nthe web scaled to more and more users. These engineers determined that if \nwork could be distributed across inexpensive computers and then connected \non the network in the form of a \u201ccluster,\u201d they could solve the problem. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1674, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9268b3d7-ff2d-4d8f-9f15-43a72703093a": {"__data__": {"id_": "9268b3d7-ff2d-4d8f-9f15-43a72703093a", "embedding": null, "metadata": {"page_label": "102", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "21adf69b-fc47-4828-8c6f-fbae2db02fa9", "node_type": "4", "metadata": {"page_label": "102", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "3512f03bc46af740dfb45cc7de53a398e3199d15413cc2dffeeeff303a3c4df2", "class_name": "RelatedNodeInfo"}}, "text": "102 Part III: Big Data Management \nDistribution alone was not a sufficient answer. This distribution of work must \nbe performed in parallel for the following three reasons:\n \u2713 The processing must be able to expand and contract automatically.\n \u2713 The processing must be able to proceed regardless of failures in the net -\nwork or the individual systems.\n \u2713 Developers leveraging this approach must be able to create services \nthat are easy to leverage by other developers. Therefore, this approach \nmust be independent of where the data and computations have executed.\nMapReduce was designed as a generic programming model. Some of the initial \nimplementations provided all the key requirements of parallel execution, fault \ntolerance, load balancing, and data manipulation. The engineers in charge of \nthe project named the initiative MapReduce because it combines two capabili -\nties from existing functional computer languages: map and reduce.\nGoogle engineers designed MapReduce to solve a specific practical problem. \nTherefore, it was designed as a programming model combined with the imple -\nmentation of that model \u2014 in essence, a reference implementation. The refer -\nence implementation was used to demonstrate the practicality and effectiveness \nof the concept and to help ensure that this model would be widely adopted by the \ncomputer industry. Over the years, other implementations of MapReduce have \nbeen created and are available as both open source and commercial products.\nFunctional versus procedural programming models\nWhen we talk of map and reduce, we do so as \noperations within a functional programming \nmodel. Functional programming is one of the two \nways that software developers create programs \nto address business problems. The other model \nis procedural programming. We take a quick look \nto understand the differences and to see when \nit\u2019s best to use one or the other model.\nProcedural programs are highly structured and \nprovide step-by-step instructions on what to do \nwith input data. The order of the execution is \nimportant, and the input data is changed as it \nprogresses through each step of the program. \nExamples of procedural languages include \nFORTRAN, COBOL, C, and C++. The best uses \nfor procedural programs are those where it is \nokay to change the values of the input data or \nwhere you need to compare computed values \nin one of the steps to determine whether you need to continue processing or exit the pro -\ngram and deliver the result.\nIn contrast, functional programs do not change \nthe input data. They look at all the data for spe -\ncific patterns and then apply rules to identify the \nimportant elements and then assemble them into \nlists. The order of the processing is not impor -\ntant because each operation is independent \nof another. Examples of functional languages \ninclude LISP, Scheme, Prolog, and R. Functional \nprograms do not change the input data and are \nmost often used when it is necessary to look at \nthe data again and again for different patterns. \nFor example, you could look through a list of \nall the counties in the United States that voted \nRepublican in the last election and then go \nthrough the list for all Democratic counties. This \nwill produce two distinct output lists.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3275, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d4a55e6b-8522-485d-89b8-9465eeb3b9a1": {"__data__": {"id_": "d4a55e6b-8522-485d-89b8-9465eeb3b9a1", "embedding": null, "metadata": {"page_label": "103", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9ce19be9-61f5-4d69-b481-617b1922f5c0", "node_type": "4", "metadata": {"page_label": "103", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "6bb1c9a2f8f82336e0dc823be7e79d6e16280aa4fa573aa31734c023039ce7a8", "class_name": "RelatedNodeInfo"}}, "text": "103  Chapter 8: MapReduce Fundamentals\nUnderstanding the map Function\nThe map  function has been a part of many functional programming languages \nfor years, first gaining popularity with an artificial intelligence language called \nLISP. Good software developers understand the value of reuse, so map has \nbeen reinvigorated as a core technology for processing lists of data elements \n(keys and values). To further your understanding of why the map function is \na good choice for big data (and the reduce function is as well), it\u2019s important \nto understand a little bit about functional programming.\nOperators in functional languages do not modify the structure of the data; \nthey create new data structures as their output. More importantly, the origi -\nnal data itself is unmodified as well. So you can use the map function with \nimpunity because it will not harm your precious stored data. Another advan -\ntage to functional programming is not having to expressly manage the move -\nment or flow of the data. This is helpful because it absolves the programmer \nfrom explicitly managing the data output and placement. Because you are \noperating in a distributed environment, dealing with where the data is stored \ncan be a nightmare. The map function takes care of that. Finally, in the world \nof functional programming, the order of the operations on the data is not pre -\nscribed. Again, this is a great advantage in a computing cluster where tasks \nare being performed in parallel.\nSo what exactly can you expect from the map function? It applies a function \nto each element (defined as a key-value pair) of a list and produces a new \nlist. Suppose that you wanted to create a program that counts the number of \ncharacters in a series or list of words. The following is not official program -\nming code; it\u2019s just a way to represent how to construct a solution to the \nproblem.\nOne way to accomplish the solution is to identify the input data and create a \nlist:\nmylist = (\u201call counties in the US that participated in the \nmost recent general election\u201d)\nCreate the function howManyPeople  using the map function . This selects \nonly the counties with more than 50,000 people:\nmap howManyPeople (mylist) = [ howManyPeople \u201ccounty 1\u201d; \nhowManyPeople \u201ccounty 2\u201d; howManyPeople \u201ccounty \n3\u201d; howManyPeople \u201ccounty 4\u201d; . . . ]\nNow produce a new output list of all the counties with populations greater \nthan 50,000:\n(no, county 1; yes, county 2; no, county 3; yes, county 4; \n?, county nnn)\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2506, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "71342e00-1109-422e-9fe8-c757f48741b4": {"__data__": {"id_": "71342e00-1109-422e-9fe8-c757f48741b4", "embedding": null, "metadata": {"page_label": "104", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c0d0a84f-e771-4b13-b06f-ca6e2041cab2", "node_type": "4", "metadata": {"page_label": "104", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "257a9f8a28b6ec7c780f7816712fc252e48da0b15d66437811f75c7e4c8316ce", "class_name": "RelatedNodeInfo"}}, "text": "104 Part III: Big Data Management \nThe function executes without making any changes to the original list. In \naddition, you can see that each element of the output list maps to a corre -\nsponding element of the input list, with a yes or no attached. If the county \nhas met the requirement of more than 50,000 people, the map function identi -\nfies it with a yes. If not, a no is indicated. This is an important feature, as you \nshall soon see when you look at the reduce  function.\nAdding the reduce Function\nLike the map function, reduce  has been a feature of functional programming \nlanguages for many years. In some languages, it is called fold, but the behav -\nior is exactly the same. The reduce function takes the output of a map func -\ntion and \u201creduces\u201d the list in whatever fashion the programmer desires. The \nfirst step that the reduce function requires is to place a value in something \ncalled an accumulator,  which holds an initial value. After storing a starting \nvalue in the accumulator, the reduce function then processes each element \nof the list and performs the operation you need across the list. At the end \nof the list, the reduce function returns a value based on what operation you \nwanted to perform on the output list. Revisit the map function example now \nto see what the reduce function is capable of doing.\nSuppose that you need to identify the counties where the majority of the \nvotes were for the Democratic candidate. Remember that your howMany-\nPeople  map function looked at each element of the input list and created an \noutput list of the counties with more than 50,000 people ( yes) and the coun -\nties with less than 50,000 people ( no).\nAfter invoking the howManyPeople  map function, you are left with the fol -\nlowing output list:\n(no, county 1; yes, county 2; no, county 3; yes, county 4; \n?, county nnn)\nThis is now the input for your reduce function. Here is what it looks like:\ncountylist = (no, county 1; yes, county 2; no, county 3; \nyes, county 4; ?, county nnn)\nreduce isDemocrat (countylist)\nThe reduce function processes each element of the list and returns a list of \nall the counties with a population greater than 50,000, where the majority \nvoted Democratic.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2236, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4c164064-3a09-4208-89ed-92fd83736a51": {"__data__": {"id_": "4c164064-3a09-4208-89ed-92fd83736a51", "embedding": null, "metadata": {"page_label": "105", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c524f821-32eb-417b-bcb8-6cd8f0ca9f16", "node_type": "4", "metadata": {"page_label": "105", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "94df5ac5a3373fe882de8d4e5e97f1c53a8f4bd82ff47ea620bf0d20fe297b90", "class_name": "RelatedNodeInfo"}}, "text": "105  Chapter 8: MapReduce Fundamentals\nNow imagine that you would like to know in which counties with a popula -\ntion greater than 50,000 the majority voted Republican. All you need to do \nis invoke the reduce function again, but you will change the operator from \nisDemocrat  to isRepublican :\nreduce isRepublican (countylist)\nThis returns a list of all the counties where the majority of voters supported \nRepublican candidates. Because you did not change the elements of county \nlist , you can continue to perform the reduce  functions on the input until \nyou get the results you require. For example, you could look for independent \nmajorities or refine the results to specific geographic regions.\nPutting map and reduce Together\nSometimes producing an output list is just enough. Likewise, sometimes per -\nforming operations on each element of a list is enough. Most often, you want \nto look through large amounts of input data, select certain elements from the \ndata, and then compute something of value from the relevant pieces of data. \nYou don\u2019t always control the input data, so you need to do this work nonde -\nstructively \u2014 you don\u2019t want to change that input list so you can use it in dif -\nferent ways with new assumptions and new data.\nSoftware developers design applications based on algorithms. An algorithm  is \nnothing more than a series of steps that need to occur in service to an over -\nall goal. It is very much like a cooking recipe. You start with the individual \nelements (flour, sugar, eggs, and so on) and follow step-by-step instructions \n(combine, knead, and bake) to produce the desired result (a loaf of bread). \nPutting the map and reduce functions to work efficiently requires an algo -\nrithm too. It might look a little like this:\n 1. Start with a large number or data or records.\n 2. Iterate over the data.\n 3. Use the map function to extract something of interest and create an \noutput list.\n 4. Organize the output list to optimize for further processing.\n 5. Use the reduce function to compute a set of results.\n 6. Produce the final output.\nProgrammers can implement all kinds of applications using this approach, \nbut the examples to this point have been very simple, so the real value of \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2249, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "de4c71be-a561-4016-9616-8b4c985a151c": {"__data__": {"id_": "de4c71be-a561-4016-9616-8b4c985a151c", "embedding": null, "metadata": {"page_label": "106", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3261e380-3a91-4b3e-a136-971526a18607", "node_type": "4", "metadata": {"page_label": "106", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "09914582d083d5621c448598107681edc7e20492a29eaf91a65c3bc219f9c51e", "class_name": "RelatedNodeInfo"}}, "text": "106 Part III: Big Data Management \nMapReduce may not be apparent. What happens when you have extremely \nlarge input data? Can you use the same algorithm on terabytes of data? The \ngood news is yes.\nAs illustrated in Figure 8-1, all of the operations seem independent. That\u2019s \nbecause they are. The real power of MapReduce is the capability to divide \nand conquer. Take a very large problem and break it into smaller, more \nmanageable chunks, operate on each chunk independently, and then pull it \nall together at the end. Furthermore, the map function is commutative \u2014 in \nother words, the order that a function is executed doesn\u2019t matter. \n Figure 8-1:  \nData flow in \nMapReduce.\n \nIf you remember algebra at all, you may recall that when something is com -\nmutative, the result is the same, regardless of the order of the elements. For \nexample:\n5 + 7 = 7 + 5 \nor \n3 * 4 = 4 * 3\nSo MapReduce can perform its work on different machines in a network and \nget the same result as if all the work was done on a single machine. It can \nalso draw from multiple data sources, internal or external. MapReduce keeps \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1127, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "60421461-3fd4-48ea-8b42-22271ba8cae3": {"__data__": {"id_": "60421461-3fd4-48ea-8b42-22271ba8cae3", "embedding": null, "metadata": {"page_label": "107", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c6dd19ed-61cf-44d3-baf0-87fc43508e1f", "node_type": "4", "metadata": {"page_label": "107", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "550481a64eea829fad8c8135684fafe24a8027ddca509f71877e88b91ccd6ec6", "class_name": "RelatedNodeInfo"}}, "text": "107  Chapter 8: MapReduce Fundamentals\ntrack of its work by creating a unique key to ensure that all the processing \nis related to solving the same problem. This key is also used to pull all the \noutput together at the end of all the distributed tasks.\nWhen the map and reduce functions are used in this fashion, they work col -\nlectively to run as a single job within the cluster. All the dividing and con -\nquering is done transparently by the execution framework of the MapReduce \nengine, and all the work is distributed to one or many nodes in the network.\nYou need to understand some characteristics of the execution framework so \nthat you may get a better understanding of why things work the way they do. \nThis can help you design better applications and also to optimize the execu -\ntion for performance or efficiency. The following are the foundational behav -\niors of MapReduce:\n \u2713 Scheduling:  MapReduce jobs get broken down into individual tasks for \nthe map and the reduce portions of the application. Because the map -\nping must be concluded before reducing can take place, those tasks \nare prioritized according to the number of nodes in the cluster. If you \nhave more tasks than nodes, the execution framework will manage the \nmap tasks until all are complete. Then the reduce tasks will run with \nthe same behaviors. The entire process is complete only when all the \nreduce tasks have run successfully.\n \u2713 Synchronization: When multiple processes execute concurrently \nin a cluster, you need a way to keep things running smoothly. \nSynchronization mechanisms do this automatically. Because the execu -\ntion framework knows that the program is mapping and reducing, it \nkeeps track of what has run and when. When all the mapping is com -\nplete, the reducing begins. Intermediate data is copied over the network \nas it is produced using a mechanism called \u201cshuffle and sort.\u201d This gath -\ners and prepares all the mapped data for reduction.\n \u2713 Code/data colocation:  The most effective processing occurs when the \nmapping functions (the code) is colocated on the same machine with \nthe data it needs to process. The process scheduler is very clever and \ncan place the code and its related data on the same node prior to execu -\ntion (or vice versa).\n \u2713 Fault/error handling:  What happens when a failure occurs? Hopefully, \nnothing. Most MapReduce engines have very robust error handling and \nfault tolerance. With all the nodes in a MapReduce cluster and all the \nparts in each node, something is going to fail at some point. The engine \nmust recognize that something is wrong and make the necessary correc -\ntion. For example, if some of the mapping tasks do not return as com -\nplete, the engine could assign the tasks to a different node to finish the \njob. The engine is designed so that it recognizes when a job is incom -\nplete and will automatically assign the task to a different node.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2927, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1b17192b-9e01-4cea-b6dc-9529a1414002": {"__data__": {"id_": "1b17192b-9e01-4cea-b6dc-9529a1414002", "embedding": null, "metadata": {"page_label": "108", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3a73dffe-4e6a-4495-95a3-0348c8664854", "node_type": "4", "metadata": {"page_label": "108", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "46e217c7089710b83f9b030221e91cb2e1044c3e055137f5d3dc9054dd976dad", "class_name": "RelatedNodeInfo"}}, "text": "108 Part III: Big Data Management \nOptimizing MapReduce Tasks\nAside from optimizing the actual application code, you can use some opti -\nmization techniques to improve the reliability and performance of your \nMapReduce jobs. They fall into three categories: hardware/network topology, \nsynchronization, and file system.\nHardware/network topology\nIndependent of application, the fastest hardware and networks will likely \nyield the fastest run times for your software. A distinct advantage of \nMapReduce is the capability to run on inexpensive clusters of commodity \nhardware and standard networks. If you don\u2019t pay attention to where your \nservers are physically organized, you won\u2019t get the best performance and \nhigh degree of fault tolerance necessary to support big data tasks.\nCommodity hardware is often stored in racks in the data center. The prox -\nimity of the hardware within the rack offers a performance advantage as \nopposed to moving data and/or code from rack to rack. During implemen -\ntation, you can configure your MapReduce engine to be aware of and take \nadvantage of this proximity. Keeping the data and the code together is one \nof the best optimizations for MapReduce performance. In essence, the closer \nthe hardware processing elements are to each other, the less latency you will \nhave to deal with.\nSynchronization\nBecause it is inefficient to hold all the results of your mapping within the \nnode, the synchronization mechanisms copy the mapping results to the \nreducing nodes immediately after they have completed so that the process -\ning can begin right away. All values from the same key are sent to the same \nreducer, again ensuring higher performance and better efficiency. The reduc -\ntion outputs are written directly to the file system, so it must be designed \nand tuned for best results.\nFile system\nYour MapReduce implementation is supported by a distributed file system. \nThe major difference between local and distributed file systems is capacity. \nTo handle the huge amounts of information in a big data world, file  \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2078, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "63c69f18-3b24-47b0-8fff-2c47db5da3be": {"__data__": {"id_": "63c69f18-3b24-47b0-8fff-2c47db5da3be", "embedding": null, "metadata": {"page_label": "109", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e40c7a69-06d6-4bb2-8d33-26e0bf054ff0", "node_type": "4", "metadata": {"page_label": "109", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "48b559103627dd94943019ba455fc8babb7b806058c14e17067e6c37fb7781e3", "class_name": "RelatedNodeInfo"}}, "text": "109  Chapter 8: MapReduce Fundamentals\nsystems need to be spread across multiple machines or nodes in a network. \nMapReduce implementations rely on a master-slave style of distribution, \nwhere the master node stores all the metadata, access rights, mapping and \nlocation of files and blocks, and so on. The slaves are nodes where the actual \ndata is stored. All the requests go to the master and then are handled by the \nappropriate slave node. As you contemplate the design of the file system  \nyou need to support a MapReduce implementation, you should consider the \nfollowing:\n \u2713 Keep it warm:  As you might expect, the master node could get over -\nworked because everything begins there. Additionally, if the master \nnode fails, the entire file system is inaccessible until the master is \nrestored. A very important optimization is to create a \u201cwarm standby\u201d \nmaster node that can jump into service if a problem occurs with the \nonline master.\n \u2713 The bigger the better:  File size is also an important consideration. \nLots of small files (less than 100MB) should be avoided. Distributed file \nsystems supporting MapReduce engines work best when they are popu -\nlated with a modest number of large files.\n \u2713 The long view: Because workloads are managed in batches, highly sus -\ntained network bandwidth is more important than quick execution times \nof the mappers or reducers. The optimal approach is for the code to \nstream lots of data when it is reading and again when it is time to write \nto the file system.\n \u2713 Keep it secure: But not overly so. Adding layers of security on the dis -\ntributed file system will degrade its performance. The file permissions \nare there to guard against unintended consequences, not malicious \nbehavior. The best approach is to ensure that only authorized users \nhave access to the data center environment and to keep the distributed \nfile system protected from the outside.\nNow that you understand a bit about this powerful capability, we take a deep \ndive into the most widely used MapReduce engine and its ecosystem.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2077, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5a0550ad-c6b0-4ccd-9c4d-9f35c50bf449": {"__data__": {"id_": "5a0550ad-c6b0-4ccd-9c4d-9f35c50bf449", "embedding": null, "metadata": {"page_label": "110", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e5dcb41e-2d51-4278-a6a8-7e5e2e3dca5d", "node_type": "4", "metadata": {"page_label": "110", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "57d7250033474b0dd3159d2d8c3774f3a66266a00faf44de437f8ab0971210b1", "class_name": "RelatedNodeInfo"}}, "text": "110 Part III: Big Data Management \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 53, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d3e18d7e-8032-4712-a630-dd0fdfbf2523": {"__data__": {"id_": "d3e18d7e-8032-4712-a630-dd0fdfbf2523", "embedding": null, "metadata": {"page_label": "111", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "109cfe8d-fd10-4a0e-ab6c-c2f639183f2f", "node_type": "4", "metadata": {"page_label": "111", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "61e6b4bbbb795ac7419a2eb82fb53c96ecb75bfdd52a820c6b7015b2ec4567ab", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 9\nExploring the World of Hadoop\nIn This Chapter\n\u25b6 Discovering Hadoop and why it\u2019s so important\n\u25b6 Exploring the Hadoop Distributed File System\n\u25b6 Digging into Hadoop MapReduce\n\u25b6 Putting Hadoop to work\nW \nhen you need to process big data sources, traditional approaches \nfall short. The volume, velocity, and variety of big data will bring \nmost technologies to their knees, so new technologies had to be created to \naddress this new challenge. MapReduce is one of those new technologies, but \nit is just an algorithm, a recipe for how to make sense of all the data. To get \nthe most from MapReduce , you need more than just an algorithm. You need \na collection of products and technologies designed to handle the challenges \npresented by big data.\nExplaining Hadoop\nSearch engine innovators like Yahoo! and Google needed to find a way to \nmake sense of the massive amounts of data that their engines were collect -\ning. These companies needed to both understand what information they \nwere gathering and how they could monetize that data to support their \nbusiness model. Hadoop was developed because it represented the most \npragmatic way to allow companies to manage huge volumes of data easily. \nHadoop allowed big problems to be broken down into smaller elements so \nthat analysis could be done quickly and cost-effectively.\nBy breaking the big data problem into small pieces that could be processed \nin parallel, you can process the information and regroup the small pieces to \npresent results.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1524, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "22d41dc1-f3bd-4328-83d6-25a6bde1a943": {"__data__": {"id_": "22d41dc1-f3bd-4328-83d6-25a6bde1a943", "embedding": null, "metadata": {"page_label": "112", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dff7fa52-7736-4ae4-9f0d-380d53c73877", "node_type": "4", "metadata": {"page_label": "112", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "53dd473b61e3bce96d3ed8f99037fd3cf1093bf8466bfcc09f1cc78267542f1a", "class_name": "RelatedNodeInfo"}}, "text": "112 Part III: Big Data Management \nHadoop (http://hadoop.apache.org ) was originally built by a Yahoo! \nengineer named Doug Cutting and is now an open source project managed \nby the Apache Software Foundation. It is made available under the Apache \nLicense v2.0. Along with other projects that we examine in Chapter 10, \nHadoop is a fundamental building block in our desire to capture and process \nbig data. Hadoop is designed to parallelize data processing across computing \nnodes to speed computations and hide latency. At its core, Hadoop has two \nprimary components:\n \u2713 Hadoop Distributed File System:  A reliable, high-bandwidth, low-cost, \ndata storage cluster that facilitates the management of related files \nacross machines.\n \u2713 MapReduce engine:  A high-performance parallel/distributed data-  \nprocessing implementation of the MapReduce algorithm.\nHadoop is designed to process huge amounts of structured and unstructured \ndata (terabytes to petabytes) and is implemented on racks of commodity \nservers as a Hadoop cluster. Servers can be added or removed from the \ncluster dynamically because Hadoop is designed to be \u201cself-healing.\u201d In other \nwords, Hadoop is able to detect changes, including failures, and adjust to \nthose changes and continue to operate without interruption.\nWe now take a closer look at the Hadoop Distributed File System (HDFS) and \nMapReduce as implemented in Hadoop.\nUnderstanding the Hadoop Distributed \nFile System (HDFS)\nThe Hadoop Distributed File System is a versatile, resilient, clustered \napproach to managing files in a big data environment. HDFS is not the final \ndestination for files. Rather, it is a data service that offers a unique set of \ncapabilities needed when data volumes and velocity are high. Because the \ndata is written once and then read many times thereafter, rather than the \nconstant read-writes of other file systems, HDFS is an excellent choice for \nsupporting big data analysis. The service includes a \u201cNameNode\u201d and multi -\nple \u201cdata nodes\u201d running on a commodity hardware cluster and provides the \nhighest levels of performance when the entire cluster is in the same physical \nrack in the data center. In essence, the NameNode keeps track of where data \nis physically stored. Figure 9-1 depicts the basic architecture of HDFS.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2315, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1d8f6226-57b3-466c-8a5f-84f8a565a36d": {"__data__": {"id_": "1d8f6226-57b3-466c-8a5f-84f8a565a36d", "embedding": null, "metadata": {"page_label": "113", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "27260ff1-70de-48b1-b837-9a9510ac9bb1", "node_type": "4", "metadata": {"page_label": "113", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "048411000d6f6b25fc5f884c2d7e8d07c2cc51e9b0efd7ed87ee686a55874c3a", "class_name": "RelatedNodeInfo"}}, "text": "113  Chapter 9: Exploring the World of Hadoop\n Figure 9-1:   \nHow a \nHadoop \ncluster is \nmapped to \nhardware.\n \nNameNodes\nHDFS works by breaking large files into smaller pieces called blocks.  The \nblocks are stored on data nodes, and it is the responsibility of the NameNode \nto know what blocks on which data nodes make up the complete file. The \nNameNode also acts as a \u201ctraffic cop,\u201d managing all access to the files, includ -\ning reads, writes, creates, deletes, and replication of data blocks on the data \nnodes. The complete collection of all the files in the cluster is sometimes \nreferred to as the file system namespace.  It is the NameNode\u2019s job to manage \nthis namespace.\nEven though a strong relationship exists between the NameNode and the \ndata nodes, they operate in a \u201cloosely coupled\u201d fashion. This allows the \ncluster elements to behave dynamically, adding (or subtracting) servers as \nthe demand increases (or decreases). In a typical configuration, you find one \nNameNode and possibly a data node running on one physical server in the \nrack. Other servers run data nodes only.\nData nodes are not very smart, but the NameNode is. The data nodes con -\nstantly ask the NameNode whether there is anything for them to do. This \ncontinuous behavior also tells the NameNode what data nodes are out there \nand how busy they are. The data nodes also communicate among themselves \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1410, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1e99d6ff-b880-4834-a578-9a108e5f46b5": {"__data__": {"id_": "1e99d6ff-b880-4834-a578-9a108e5f46b5", "embedding": null, "metadata": {"page_label": "114", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "992b8d06-7416-448b-bbb3-7c206d4f1a8e", "node_type": "4", "metadata": {"page_label": "114", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "7a098093b33e4ee4370892d5fa03ac4871349f6dbb7b3cd152d0f88848850e60", "class_name": "RelatedNodeInfo"}}, "text": "114 Part III: Big Data Management \nso that they can cooperate during normal file system operations. This is \nnecessary because blocks for one file are likely to be stored on multiple data \nnodes. Since the NameNode is so critical for correct operation of the cluster, \nit can and should be replicated to guard against a single point failure.\nData nodes\nData nodes are not smart, but they are resilient. Within the HDFS cluster, \ndata blocks are replicated across multiple data nodes and access is man -\naged by the NameNode. The replication mechanism is designed for optimal \nefficiency when all the nodes of the cluster are collected into a rack. In fact, \nthe NameNode uses a \u201crack ID\u201d to keep track of the data nodes in the clus -\nter. HDFS clusters are sometimes referred to as being \u201crack-aware.\u201d Data \nnodes also provide \u201cheartbeat\u201d messages to detect and ensure connectivity \nbetween the NameNode and the data nodes. When a heartbeat is no longer \npresent, the NameNode unmaps the data node from the cluster and keeps \non operating as though nothing happened. When the heartbeat returns (or a \nnew heartbeat appears), it is added to the cluster transparently with respect \nto the user or application.\nAs with all file systems, data integrity is a key feature. HDFS supports a \nnumber of capabilities designed to provide data integrity. As you might \nexpect, when files are broken into blocks and then distributed across differ -\nent servers in the cluster, any variation in the operation of any element could \naffect data integrity. HDFS uses transaction logs and checksum validation to \nensure integrity across the cluster.\nTransaction logs are a very common practice in file system and database \ndesign. They keep track of every operation and are effective in auditing or \nrebuilding of the file system should something untoward occur.\nChecksum validations are used to guarantee the contents of files in HDFS. \nWhen a client requests a file, it can verify the contents by examining its \nchecksum. If the checksum matches, the file operation can continue. If not, \nan error is reported. Checksum files are hidden to help avoid tampering.\nData nodes use local disks in the commodity server for persistence. All \nthe data blocks are stored locally, primarily for performance reasons. Data \nblocks are replicated across several data nodes, so the failure of one server \nmay not necessarily corrupt a file. The degree of replication, the number \nof data nodes, and the HDFS namespace are established when the cluster \nis implemented. Because HDFS is dynamic, all parameters can be adjusted \nduring the operation of the cluster.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2650, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4ee70a80-f6d8-440b-959a-fb64052f299f": {"__data__": {"id_": "4ee70a80-f6d8-440b-959a-fb64052f299f", "embedding": null, "metadata": {"page_label": "115", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6978a3c3-da68-4d33-85c5-6cb0538b2b7d", "node_type": "4", "metadata": {"page_label": "115", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d8c6ac8fb3cb9a1654629699d2f15eece794be5fa89df1ed7229e16470777cb7", "class_name": "RelatedNodeInfo"}}, "text": "115  Chapter 9: Exploring the World of Hadoop\nUnder the covers of HDFS\nBig data brings the big challenges of volume, velocity, and variety. As cov -\nered in the previous sections, HDFS addresses these challenges by breaking \nfiles into a related collection of smaller blocks. These blocks are distrib -\nuted among the data nodes in the HDFS cluster and are managed by the \nNameNode. Block sizes are configurable and are usually 128 megabytes (MB) \nor 256MB, meaning that a 1GB file consumes eight 128MB blocks for its basic \nstorage needs. HDFS is resilient, so these blocks are replicated throughout \nthe cluster in case of a server failure. How does HDFS keep track of all these \npieces? The short answer is file system metadata.\nMetadata is defined as \u201cdata about data.\u201d Software designers have been using \nmetadata for decades under several names like data dictionary, metadata \ndirectory, and more recently, tags. Think of HDFS metadata as a template for \nproviding a detailed description of the following:\n \u2713 When the file was created, accessed, modified, deleted, and so on\n \u2713 Where the blocks of the file are stored in the cluster\n \u2713 Who has the rights to view or modify the file\n \u2713 How many files are stored on the cluster\n \u2713 How many data nodes exist in the cluster\n \u2713 The location of the transaction log for the cluster\nHDFS metadata is stored in the NameNode, and while the cluster is operating, \nall the metadata is loaded into the physical memory of the NameNode server. \nAs you might expect, the larger the cluster, the larger the metadata footprint. \nFor best performance, the NameNode server should have lots of physical \nmemory and, ideally, lots of solid-state disks. The more the merrier, from a \nperformance point of view.\nAs we cover earlier in the chapter, the data nodes are very simplistic. They \nare servers that contain the blocks for a given set of files. It is reasonable to \nthink of data nodes as \u201cblock servers\u201d because that is their primary function. \nWhat exactly does a block server do? Check out the following list:\n \u2713 Stores (and retrieves) the data blocks in the local file system of the \nserver. HDFS is available on many different operating systems and \nbehaves the same whether on Windows, Mac OS, or Linux.\n \u2713 Stores the metadata of a block in the local file system based on the meta -\ndata template in the NameNode.\n \u2713 Performs periodic validations of file checksums.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2429, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "addf5725-5d60-4777-bad3-006193e06936": {"__data__": {"id_": "addf5725-5d60-4777-bad3-006193e06936", "embedding": null, "metadata": {"page_label": "116", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7e04fb56-d42d-4807-a128-efaffb57ee50", "node_type": "4", "metadata": {"page_label": "116", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1f62bdfff2ff175a882ea2e9f0f1669f10fc259929cf0b9beb5c9296af6e515b", "class_name": "RelatedNodeInfo"}}, "text": "116 Part III: Big Data Management \n \u2713 Sends regular reports to the NameNode about what blocks are available \nfor file operations.\n \u2713 Provides metadata and data to clients on demand. HDFS supports direct \naccess to the data nodes from client application programs.\n \u2713 Forwards data to other data nodes based on a \u201cpipelining\u201d model.\nBlock placement on the data nodes is critical to data replication and support \nfor data pipelining. HDFS keeps one replica of every block locally. It then \nplaces a second replica on a different rack to guard against a complete rack \nfailure. It also sends a third replica to the same remote rack, but to a different \nserver in the rack. Finally, it can send additional replicas to random locations \nin local or remote clusters. HDFS is serious about data replication and resil -\niency. Fortunately, client applications do not need to worry about where all \nthe blocks are located. In fact, clients are directed to the nearest replica to \nensure highest performance.\nHDFS supports the capability to create data pipelines. A pipeline  is a con -\nnection between multiple data nodes that exists to support the movement of \ndata across the servers. A client application writes a block to the first data \nnode in the pipeline. The data node takes over and forwards the data to the \nnext node in the pipeline; this continues until all the data, and all the data \nreplicas, are written to disk. At this point, the client repeats the process by \nwriting the next block in the file. As you see later in this chapter, this is an \nimportant feature for Hadoop MapReduce.\nWith all these files and blocks and servers, you might wonder how things are \nkept in balance. Without any intervention, it is possible for one data node to \nbecome congested while another might be nearly empty. HDFS has a \u201crebal -\nancer\u201d service that\u2019s designed to address these possibilities. The goal is to \nbalance the data nodes based on how full each set of local disks might be. \nThe rebalancer runs while the cluster is active and can be throttled to avoid \ncongestion of network traffic. After all, HDFS needs to manage the files and \nblocks first and then worry about how balanced the cluster needs to be.\nThe rebalancer is effective, but it does not have a great deal of built-in intel -\nligence. For example, you can\u2019t create access or load patterns and have the \nrebalancer optimize for those conditions. Nor will it identify data \u201chot spots\u201d \nand correct for them. Perhaps these features will be offered in future ver -\nsions of HDFS.\nHadoop MapReduce\nTo fully understand the capabilities of Hadoop MapReduce, we need to dif -\nferentiate between MapReduce (the algorithm) and an implementation of \nMapReduce. Hadoop MapReduce is an implementation of the algorithm \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2789, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e88e0e0d-2bba-4733-8422-25e1e585e8a9": {"__data__": {"id_": "e88e0e0d-2bba-4733-8422-25e1e585e8a9", "embedding": null, "metadata": {"page_label": "117", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4b42ac66-4176-405c-909f-74cd1bf7e951", "node_type": "4", "metadata": {"page_label": "117", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "fb7e75368bf757cce20c13721267a436b0c32fdf5e658a3c5a36608c3a667f99", "class_name": "RelatedNodeInfo"}}, "text": "117  Chapter 9: Exploring the World of Hadoop\ndeveloped and maintained by the Apache Hadoop project. It is helpful to \nthink about this implementation as a MapReduce engine, because that is \nexactly how it works. You provide input (fuel), the engine converts the input \ninto output quickly and efficiently, and you get the answers you need. You \nare using Hadoop to solve business problems, so it is necessary for you to \nunderstand how and why it works. So, we take a look at the Hadoop imple -\nmentation of MapReduce in more detail.\nHadoop MapReduce includes several stages, each with an important set of \noperations helping to get to your goal of getting the answers you need from \nbig data. The process starts with a user request to run a MapReduce program \nand continues until the results are written back to the HDFS. Figure 9-2 illus -\ntrates how MapReduce performs its tasks.\n Figure 9-2:  \nWorkflow \nand data \nmovement \nin a small \nHadoop \ncluster.\n \nHDFS and MapReduce perform their work on nodes in a cluster hosted on \nracks of commodity servers. To simplify the discussion, the diagram shows \nonly two nodes.\nGetting the data ready\nWhen a client requests a MapReduce program to run, the first step is to \nlocate and read the input file containing the raw data. The file format is com -\npletely arbitrary, but the data must be converted to something the program \ncan process. This is the function of InputFormat and RecordReader (RR). \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1466, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "75617170-eaba-4b5b-a6bd-0b56238e1bfd": {"__data__": {"id_": "75617170-eaba-4b5b-a6bd-0b56238e1bfd", "embedding": null, "metadata": {"page_label": "118", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0d1577cb-cc8d-4395-b748-5e5f797fe3a2", "node_type": "4", "metadata": {"page_label": "118", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "464c14009b075cec69a9fa570245be39ae31b9b701f11db894ea78129ef64d87", "class_name": "RelatedNodeInfo"}}, "text": "118 Part III: Big Data Management \nInputFormat decides how the file is going to be broken into smaller pieces for \nprocessing using a function called InputSplit. It then assigns a RecordReader \nto transform the raw data for processing by the map. If you read the discus -\nsion of map in Chapter 8, you know it requires two inputs: a key and a value. \nSeveral types of RecordReaders are supplied with Hadoop, offering a wide \nvariety of conversion options. This feature is one of the ways that Hadoop \nmanages the huge variety of data types found in big data problems.\nLet the mapping begin\nYour data is now in a form acceptable to map. For each input pair, a distinct \ninstance of map is called to process the data. But what does it do with the pro -\ncessed output, and how can you keep track of them? Map has two additional \ncapabilities to address the questions. Because map and reduce need to work \ntogether to process your data, the program needs to collect the output from \nthe independent mappers and pass it to the reducers. This task is performed \nby an OutputCollector. A Reporter function also provides information gathered \nfrom map tasks so that you know when or if the map tasks are complete.\nAll this work is being performed on multiple nodes in the Hadoop cluster \nsimultaneously. You may have cases where the output from certain map -\nping processes needs to be accumulated before the reducers can begin. Or, \nsome of the intermediate results may need to be processed before reduc -\ntion. In addition, some of this output may be on a node different from the \nnode where the reducers for that specific output will run. The gathering and \nshuffling of intermediate results are performed by a partitioner and a sort. \nThe map tasks will deliver the results to a specific partition as inputs to the \nreduce tasks. After all the map tasks are complete, the intermediate results \nare gathered in the partition and a shuffling occurs, sorting the output for \noptimal processing by reduce.\nReduce and combine\nFor each output pair, reduce is called to perform its task. In similar fash -\nion to map, reduce gathers its output while all the tasks are processing. \nReduce can\u2019t begin until all the mapping is done, and it isn\u2019t finished until all \ninstances are complete. The output of reduce is also a key and a value. While \nthis is necessary for reduce to do its work, it may not be the most effec -\ntive output format for your application. Hadoop provides an OutputFormat \nfeature, and it works very much like InputFormat. OutputFormat takes the \nkey-value pair and organizes the output for writing to HDFS. The last task \nis to actually write the data to HDFS. This is performed by RecordWriter, \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2725, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e8fe5931-a1c5-4f0c-8b31-78058795fbae": {"__data__": {"id_": "e8fe5931-a1c5-4f0c-8b31-78058795fbae", "embedding": null, "metadata": {"page_label": "119", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bf737236-2d14-4c86-bb36-e03124d8abdf", "node_type": "4", "metadata": {"page_label": "119", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b7e9a5e8cbc4e64dbada09274bc268b71712f629174649aa4d0028b9881416bc", "class_name": "RelatedNodeInfo"}}, "text": "119  Chapter 9: Exploring the World of Hadoop\nand it performs similarly to RecordReader except in reverse. It takes the \nOutputFormat data and writes it to HDFS in the form necessary for the \nrequirements of the application program.\nThe coordination of all these activities was managed in earlier versions of \nHadoop by a job scheduler. This scheduler was rudimentary, and as the mix \nof jobs changed and grew, it was clear that a different approach was neces -\nsary. The primary deficiency in the old scheduler was the lack of resource \nmanagement. The latest version of Hadoop has this new capability, and we \nlook at it more closely in Chapter 10.\nHadoop MapReduce is the heart of the Hadoop system. It provides all the \ncapabilities you need to break big data into manageable chunks, process the \ndata in parallel on your distributed cluster, and then make the data available \nfor user consumption or additional processing. And it does all this work in a \nhighly resilient, fault-tolerant manner. This is just the beginning. The Hadoop \necosystem is a large, growing set of tools and technologies designed specifi -\ncally for cutting your big data problems down to size.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1193, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "166ef137-449c-41f0-92b1-b97259a7efc4": {"__data__": {"id_": "166ef137-449c-41f0-92b1-b97259a7efc4", "embedding": null, "metadata": {"page_label": "120", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8145bcb0-7836-46a3-9b16-85913dd17f20", "node_type": "4", "metadata": {"page_label": "120", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "386e3b4a70b16b5528ba33fd8bf34ad5b0b4d1c993ddc84a436e241ff724ed6c", "class_name": "RelatedNodeInfo"}}, "text": "120 Part III: Big Data Management \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 53, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b22e1372-451f-458a-8553-beed2e233b8d": {"__data__": {"id_": "b22e1372-451f-458a-8553-beed2e233b8d", "embedding": null, "metadata": {"page_label": "121", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1f0cdad7-dd8c-4e4d-8d5a-a891c00b9da0", "node_type": "4", "metadata": {"page_label": "121", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "0a7d737189f38c9084d2b760cca30983184fe6e3442c762fe772fb14ebac643f", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 10\nThe Hadoop Foundation and \nEcosystem\nIn This Chapter\n\u25b6 Why the Hadoop ecosystem is foundational for big data\n\u25b6 Managing resources and applications with Hadoop YARN\n\u25b6 Storing big data with HBase\n\u25b6 Mining big data with Hive\n\u25b6 Interacting with the Hadoop ecosystem\nA \ns Chapter 9 explains, Hadoop MapReduce and Hadoop Distributed \nFile System (HDFS) are powerful technologies designed to address big \ndata challenges. That\u2019s the good news. The bad news is that you really need \nto be a programmer or data scientist to be able to get the most out of these \nelemental components. Enter the Hadoop ecosystem. For several years and \nfor the foreseeable future, open source as well as commercial developers all \nover the world have been building and testing tools to increase the adop -\ntion and usability of Hadoop. Many are working on bits of the ecosystem and \noffering their enhancements back to the Apache project. This constant flow \nof fixes and improvements helps to drive the entire ecosystem forward in a \ncontrolled and secure manner.\nIn this chapter, you take a look at the various technologies that make up the \nHadoop ecosystem.\nBuilding a Big Data Foundation  \nwith the Hadoop Ecosystem\nTrying to tackle big data challenges without a toolbox filled with technology \nand services is like trying to empty the ocean with a spoon. As core com -\nponents, Hadoop MapReduce and HDFS are constantly being improved and \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1447, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "69f1bf57-1b50-4a29-b2ed-04b32aae71cd": {"__data__": {"id_": "69f1bf57-1b50-4a29-b2ed-04b32aae71cd", "embedding": null, "metadata": {"page_label": "122", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3aa657a6-1ef2-4af6-b934-fb39d4108f9a", "node_type": "4", "metadata": {"page_label": "122", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "c155c72c6751ed519c71fe556bc14a92fc72723413ca42b885960aa23ffdffe8", "class_name": "RelatedNodeInfo"}}, "text": "122 Part III: Big Data Management \nprovide great starting points, but you need something more. The Hadoop \necosystem provides an ever-expanding collection of tools and technologies \nspecifically created to smooth the development, deployment, and support of \nbig data solutions. Before we look at the key components of the ecosystem, \nlet\u2019s take a moment to discuss the Hadoop ecosystem and the role it plays on \nthe big data stage.\nNo building is stable without a foundation. While important, stability is not \nthe only important criterion in a building. Each part of the building must \nsupport its overall purpose. The walls, floors, stairs, electrical, plumbing, \nand roof need to complement each other while relying on the foundation for \nsupport and integration. It is the same with the Hadoop ecosystem. The foun -\ndation is MapReduce and HDFS. They provide the basic structure and integra -\ntion services needed to support the core requirements of big data solutions. \nThe remainder of the ecosystem provides the components you need to build \nand manage purpose-driven big data applications for the real world.\nIn the absence of the ecosystem it would be incumbent on developers, data -\nbase administrators, system and network managers, and others to identify \nand agree on a set of technologies to build and deploy big data solutions. \nThis is often the case when businesses want to adapt new and emerging tech -\nnology trends. The chore of cobbling together technologies in a new market \nis daunting. That is why the Hadoop ecosystem is so fundamental to the suc -\ncess of big data. It is the most comprehensive collection of tools and technol -\nogies available today to target big data challenges. The ecosystem facilitate \nthe creation of new opportunities for the widespread adoption of big data by \nbusinesses and organizations. \nManaging Resources and Applications \nwith Hadoop YARN\nJob scheduling and tracking are integral parts of Hadoop MapReduce. The \nearly versions of Hadoop supported a rudimentary job and task tracking \nsystem, but as the mix of work supported by Hadoop changed, the scheduler \ncould not keep up. In particular, the old scheduler could not manage non-\nMapReduce jobs, and it was incapable of optimizing cluster utilization. So a \nnew capability was designed to address these shortcomings and offer more \nflexibility, efficiency, and performance.\nYet Another Resource Negotiator (YARN) is a core Hadoop service providing \ntwo major services:\n \u2713 Global resource management (ResourceManager)\n \u2713 Per-application management (ApplicationMaster)\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2595, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3ffe51f6-d3f7-489e-8469-049c1d8f248d": {"__data__": {"id_": "3ffe51f6-d3f7-489e-8469-049c1d8f248d", "embedding": null, "metadata": {"page_label": "123", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8967fb6e-efa6-441a-9f77-7281f80d40c7", "node_type": "4", "metadata": {"page_label": "123", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "632e85d4318e8531e339830ae03ec88ff9b2343a507cbf408f5e493f103cbaec", "class_name": "RelatedNodeInfo"}}, "text": "123  Chapter 10: The Hadoop Foundation and Ecosystem\nThe ResourceManager is a master service and control NodeManager in \neach of the nodes of a Hadoop cluster. Included in the ResourceManager is \nScheduler, whose sole task is to allocate system resources to specific running \napplications (tasks), but it does not monitor or track the application\u2019s status. \nAll the required system information is stored in a Resource Container. It con -\ntains detailed CPU, disk, network, and other important resource attributes \nnecessary for running applications on the node and in the cluster.\nEach node has a NodeManager slaved to the global ResourceManager in the \ncluster. The NodeManager monitors the application\u2019s usage of CPU, disk, \nnetwork, and memory and reports back to the ResourceManager. For each \napplication running on the node there is a corresponding ApplicationMaster. \nIf more resources are necessary to support the running application, the \nApplicationMaster notifies the NodeManager and the NodeManager negoti -\nates with the ResourceManager (Scheduler) for the additional capacity on \nbehalf of the application. The NodeManager is also responsible for tracking \njob status and progress within its node.\nStoring Big Data with HBase\nHBase is a distributed, nonrelational (columnar) database that utilizes HDFS \nas its persistence store. It is modeled after Google BigTable and is capable of \nhosting very large tables (billions of columns/rows) because it is layered on \nHadoop clusters of commodity hardware. HBase provides random, real-time \nread/write access to big data. HBase is highly configurable, providing a great \ndeal of flexibility to address huge amounts of data efficiently. Now take a look \nat how HBase can help address your big data challenges.\nHBase is a columnar database, so all data is stored into tables with rows \nand columns similar to relational database management systems (RDBMSs). \nThe intersection of a row and a column is called a cell. One important dif -\nference between HBase tables and RDBMS tables is versioning. Each cell \nvalue includes a \u201cversion\u201d attribute, which is nothing more than a timestamp \nuniquely identifying the cell. Versioning tracks changes in the cell and makes \nit possible to retrieve any version of the contents should it become neces -\nsary. HBase stores the data in cells in decreasing order (using the time -\nstamp), so a read will always find the most recent values first.\nColumns in HBase belong to a column family. The column family name is used \nas a prefix to identify members of its family. For example, fruits:apple  and \nfruits:banana  are members of the fruits  column family. HBase implementations \nare tuned at the column family level, so it is important to be mindful of how \nyou are going to access the data and how big you expect the columns to be.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2848, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2b42510c-2015-43d1-954e-606425171f02": {"__data__": {"id_": "2b42510c-2015-43d1-954e-606425171f02", "embedding": null, "metadata": {"page_label": "124", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "aff292cf-2942-4648-bfed-6c1b96a5f9cb", "node_type": "4", "metadata": {"page_label": "124", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "67e935dc23ed2ecbbfee8dc1737082384581da66b45bedf7d29a0d3906efc14d", "class_name": "RelatedNodeInfo"}}, "text": "124 Part III: Big Data Management \nThe rows in HBase tables also have a key associated with them. The struc -\nture of the key is very flexible. It can be a computed value, a string, or even \nanother data structure. The key is used to control access to the cells in the \nrow, and they are stored in order from low value to high value.\nAll of these features together make up the schema. The schema is defined \nand created before any data can be stored. Even so, tables can be altered \nand new column families can be added after the database is up and running. \nThis extensibility is extremely useful when dealing with big data because you \ndon\u2019t always know about the variety of your data streams.\nMining Big Data with Hive\nHive is a batch-oriented, data-warehousing layer built on the core elements \nof Hadoop (HDFS and MapReduce). It provides users who know SQL with \na simple SQL-lite implementation called HiveQL without sacrificing access \nvia mappers and reducers. With Hive, you can get the best of both worlds: \nSQL-like access to structured data and sophisticated big data analysis with \nMapReduce.\nUnlike most data warehouses, Hive is not designed for quick responses to \nqueries. In fact, queries can take several minutes or even hours depending \non the complexity. As a result, Hive is best used for data mining and deeper \nanalytics that do not require real-time behaviors. Because it relies on the \nHadoop foundation, it is very extensible, scalable, and resilient, something \nthat the average data warehouse is not.\nHive uses three mechanisms for data organization:\n \u2713 Tables:  Hive tables are the same as RDBMS tables consisting of rows \nand columns. Because Hive is layered on the Hadoop HDFS, tables are \nmapped to directories in the file system. In addition, Hive supports \ntables stored in other native file systems.\n \u2713 Partitions:  A Hive table can support one or more partitions. These par -\ntitions are mapped to subdirectories in the underlying file system and \nrepresent the distribution of data throughout the table. For example, if \na table is called autos,  with a key value of 12345  and a maker value Ford,  \nthe path to the partition would be /hivewh/autos/kv=12345/Ford .\n \u2713 Buckets:  In turn, data may be divided into buckets. Buckets are stored \nas files in the partition directory in the underlying file system. The \nbuckets are based on the hash of a column in the table. In the preceding \nexample, you might have a bucket called Focus,  containing all the attri -\nbutes of a Ford Focus auto.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2545, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0ac2e938-eaed-4b2a-8c9d-db62ff6eca76": {"__data__": {"id_": "0ac2e938-eaed-4b2a-8c9d-db62ff6eca76", "embedding": null, "metadata": {"page_label": "125", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2c657f58-c861-4e4d-8727-f421c3aa745a", "node_type": "4", "metadata": {"page_label": "125", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "40c50736ccfeb701ce8e510aca312b7d5b79b4da54f926d138fd78d3af109481", "class_name": "RelatedNodeInfo"}}, "text": "125  Chapter 10: The Hadoop Foundation and Ecosystem\nHive metadata is stored externally in the \u201cmetastore.\u201d The metastore is a \nrelational database containing the detailed descriptions of the Hive schema, \nincluding column types, owners, key and value data, table statistics, and so \non. The metastore is capable of syncing catalog data with other metadata  \nservices in the Hadoop ecosystem. \nHive supports an SQL-like language called HiveQL. HiveQL supports many \nof the SQL primitives, such as select, join, aggregate, union all, and so on. It \nalso supports multitable queries and inserts by sharing the input data within \na single HiveQL statement. HiveQL can be extended to support user-defined \naggregation, column transformation, and embedded MapReduce scripts.\nInteracting with the Hadoop Ecosystem\nWriting programs or using specialty query languages are not the only ways \nyou interact with the Hadoop ecosystem. IT teams that manage infrastruc -\ntures need to control Hadoop and the big data applications created for it. As \nbig data becomes mainstream, non-technical professionals will want to try \nto solve business problems with big data. Look at some examples from the \nHadoop ecosystem that help these constituencies.\nPig and Pig Latin\nThe power and flexibility of Hadoop are immediately visible to software \ndevelopers primarily because the Hadoop ecosystem was built by develop -\ners, for developers. However, not everyone is a software developer. Pig was \ndesigned to make Hadoop more approachable and usable by nondevelopers. \nPig is an interactive, or script-based, execution environment supporting Pig \nLatin, a language used to express data flows. The Pig Latin language supports \nthe loading and processing of input data with a series of operators that trans -\nform the input data and produce the desired output.\nThe Pig execution environment has two modes:\n \u2713 Local mode:  All scripts are run on a single machine. Hadoop MapReduce \nand HDFS are not required.\n \u2713 Hadoop:  Also called MapReduce mode, all scripts are run on a given \nHadoop cluster.\nUnder the covers, Pig creates a set of map  and reduce  jobs. The user is \nabsolved from the concerns of writing code, compiling, packaging, submit -\nting, and retrieving the results. In many respects, Pig is analogous to SQL in \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2320, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6381b36e-1635-4380-b063-c85e902910df": {"__data__": {"id_": "6381b36e-1635-4380-b063-c85e902910df", "embedding": null, "metadata": {"page_label": "126", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7795691c-4c99-49fa-aa90-fac43a60a560", "node_type": "4", "metadata": {"page_label": "126", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d4c3d5b46b2a0a391c544dab59bbb0a4c8426c3c7252d52b19eebe77bdc76def", "class_name": "RelatedNodeInfo"}}, "text": "126 Part III: Big Data Management \nthe RDBMS world. The Pig Latin language provides an abstract way to get \nanswers from big data by focusing on the data and not the structure of a \ncustom software program. Pig makes prototyping very simple. For example, \nyou can run a Pig script on a small representation of your big data environ -\nment to ensure that you are getting the desired results before you commit to \nprocessing all the data.\nPig programs can be run in three different ways, all of them compatible with \nlocal and Hadoop mode:\n \u2713 Script:  Simply a file containing Pig Latin commands, identified by the \n.pig  suffix (for example, file.pig  or myscript.pig ). The commands \nare interpreted by Pig and executed in sequential order.\n \u2713 Grunt:  Grunt is a command interpreter. You can type Pig Latin on the \ngrunt command line and Grunt will execute the command on your \nbehalf. This is very useful for prototyping and \u201cwhat if\u201d scenarios.\n \u2713 Embedded:  Pig programs can be executed as part of a Java program.\nPig Latin has a very rich syntax. It supports operators for the following  \noperations:\n \u2713 Loading and storing of data\n \u2713 Streaming data\n \u2713 Filtering data\n \u2713 Grouping and joining data\n \u2713 Sorting data\n \u2713 Combining and splitting data\nPig Latin also supports a wide variety of types, expressions, functions, diag -\nnostic operators, macros, and file system commands.\nTo get more examples, visit the Pig website within Apache.com. It is a rich \nresource that will provide you with all the details: http://pig.apache.org .\nSqoop\nMany businesses store information in RDBMSs and other data stores, so they \nneed a way to move data back and forth from these data stores to Hadoop. \nWhile it is sometimes necessary to move the data in real time, it is most \noften necessary to load or unload data in bulk. Sqoop (SQL-to-Hadoop) is a \ntool that offers the capability to extract data from non-Hadoop data stores, \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1938, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "030b8e7f-96bf-46ec-8c76-89f822f226eb": {"__data__": {"id_": "030b8e7f-96bf-46ec-8c76-89f822f226eb", "embedding": null, "metadata": {"page_label": "127", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "caa8dacf-1d1b-4319-8ca9-81254b3e522b", "node_type": "4", "metadata": {"page_label": "127", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "599477af82a512571c0ff674af735912767ba73f8738457282b50cfce3b0be82", "class_name": "RelatedNodeInfo"}}, "text": "127  Chapter 10: The Hadoop Foundation and Ecosystem\ntransform the data into a form usable by Hadoop, and then load the data into \nHDFS. This process is called ETL, for Extract, Transform, and Load. While \ngetting data into Hadoop is critical for processing using MapReduce, it is also \ncritical to get data out of Hadoop and into an external data source for use in \nother kinds of application. Sqoop is able to do this as well.\nLike Pig, Sqoop is a command-line interpreter. You type Sqoop commands \ninto the interpreter and they are executed one at a time. Four key features \nare found in Sqoop:\n \u2713 Bulk import:  Sqoop can import individual tables or entire databases \ninto HDFS. The data is stored in the native directories and files in the \nHDFS file system.\n \u2713 Direct input:  Sqoop can import and map SQL (relational) databases \ndirectly into Hive and HBase.\n \u2713 Data interaction:  Sqoop can generate Java classes so that you can inter -\nact with the data programmatically.\n \u2713 Data export:  Sqoop can export data directly from HDFS into a relational \ndatabase using a target table definition based on the specifics of the \ntarget database.\nSqoop works by looking at the database you want to import and selecting an \nappropriate import function for the source data. After it recognizes the input, \nit then reads the metadata for the table (or database) and creates a class def -\ninition of your input requirements. You can force Sqoop to be very selective \nso that you get just the columns you are looking for before input rather than \ndoing an entire input and then looking for your data. This can save consider -\nable time. The actual import from the external database to HDFS is performed \nby a MapReduce job created behind the scenes by Sqoop.\nSqoop is another effective tool for nonprogrammers. The other impor -\ntant item to note is the reliance on underlying technologies like HDFS and \nMapReduce. You see this repeatedly throughout the element of the Hadoop \necosystem.\nZookeeper\nHadoop\u2019s greatest technique for addressing big data challenges is its capabil -\nity to divide and conquer. After the problem has been divided, the conquer -\ning relies on the capability to employ distributed and parallel processing \ntechniques across the Hadoop cluster. For some big data problems, the \ninteractive tools are unable to provide the insights or timeliness required \nto make business decisions. In those cases, you need to create distributed \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2466, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f2d74d87-78a1-4a12-91a0-ec4a422bded8": {"__data__": {"id_": "f2d74d87-78a1-4a12-91a0-ec4a422bded8", "embedding": null, "metadata": {"page_label": "128", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "30a98276-5886-49a6-b612-20184c4cad60", "node_type": "4", "metadata": {"page_label": "128", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "3d7194f45db77f5ae34df501668933a6c6f3fd1fc8676900c5d5552b02a5455c", "class_name": "RelatedNodeInfo"}}, "text": "128 Part III: Big Data Management \napplications to solve those big data problems. Zookeeper is Hadoop\u2019s way of \ncoordinating all the elements of these distributed applications.\nZookeeper as a technology is actually simple, but its features are powerful. \nArguably, it would be difficult, if not impossible, to create resilient, fault-\ntolerant distributed Hadoop applications without it. Some of the capabilities \nof Zookeeper are as follows:\n \u2713 Process synchronization:  Zookeeper coordinates the starting and stop -\nping of multiple nodes in the cluster. This ensures that all processing \noccurs in the intended order. When an entire process group is complete, \nthen and only then can subsequent processing occur.\n \u2713 Configuration management: Zookeeper can be used to send configura -\ntion attributes to any or all nodes in the cluster. When processing is \ndependent on particular resources being available on all the nodes, \nZookeeper ensures the consistency of the configurations.\n \u2713 Self-election:  Zookeeper understands the makeup of the cluster and can \nassign a \u201cleader\u201d role to one of the nodes. This leader/master handles \nall client requests on behalf of the cluster. Should the leader node fail, \nanother leader will be elected from the remaining nodes.\n \u2713 Reliable messaging:  Even though workloads in Zookeeper are loosely \ncoupled, you still have a need for communication between and \namong the nodes in the cluster specific to the distributed application. \nZookeeper offers a publish/subscribe capability that allows the creation \nof a queue. This queue guarantees message delivery even in the case of \na node failure.\nBecause Zookeeper is managing groups of nodes in service to a single distrib -\nuted application, it is best implemented across  racks. This is very different \nthan the requirements for the cluster itself (within racks). The underlying \nreason is simple: Zookeeper needs to perform, be resilient, and be fault tol -\nerant at a level above the cluster itself. Remember that a Hadoop cluster is \nalready fault tolerant, so it will heal itself. Zookeeper just needs to worry \nabout its own fault tolerance.\nThe Hadoop ecosystem and the supported commercial distributions are \never-changing. New tools and technologies are introduced, existing technolo -\ngies are improved, and some technologies are retired by a (hopefully better) \nreplacement. This one of the greatest advantages of open source. Another is \nthe adoption of open source technologies by commercial companies. These \ncompanies enhance the products, making them better for everyone by offer -\ning support and services at a modest cost. This is how the Hadoop ecosys -\ntem has evolved and why it is a good choice for helping to solve your big \ndata challenges.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2773, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0b3ab66c-50a7-4f39-81b1-88e0a98253e7": {"__data__": {"id_": "0b3ab66c-50a7-4f39-81b1-88e0a98253e7", "embedding": null, "metadata": {"page_label": "129", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "266377b4-5118-4b88-83aa-7f26007c0abb", "node_type": "4", "metadata": {"page_label": "129", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "760eb6891e5e218de57e63d6429eee1f3027dbebda80b36b0c5c94cba76fe9a0", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 11\nAppliances and Big Data \nWarehouses\nIn This Chapter\n\u25b6 Defining the big data warehouse\n\u25b6 Creating a new model to support changing requirements\n\u25b6 The data warehouse big data hybrid system\n\u25b6 Evaluating deployment models for big data warehousing\nT \nhe concept of the data warehouse originated almost 30 years ago. The \ndata warehouse was intended to solve a big problem for customers that \nhad many operational systems that were siloed. Increasingly, management \nwanted to replace inefficient decision-support systems with a more stream -\nlined model. Companies wanted to be able to have a single architectural \nmodel that would make it much easier to make business decisions. This \napproach, whether in the form of a full data warehouse or a more limited \ndata mart, has been the norm. However, with the advent of big data, the data \nwarehouse concept is now changing so that it can be applied to new use \ncases. The traditional data warehouse will continue to survive and thrive \nbecause it is very useful in analyzing historical operational data for decision \nmaking. However, new types of data warehouses will be optimized for the big \ndata world. In this chapter, we give you a perspective on how the data ware -\nhouse has evolved to support the characteristics of big data.\nIntegrating Big Data with the  \nTraditional Data Warehouse\nUnlike traditional operational database systems and applications, the data \nwarehouse was used by business line and financial analysts to help make \ndecisions about the direction of a business strategy. Data had to be gathered \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1592, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "acfa7a96-04c4-4cf0-a234-f7c847e458ef": {"__data__": {"id_": "acfa7a96-04c4-4cf0-a234-f7c847e458ef", "embedding": null, "metadata": {"page_label": "130", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a9496ea4-471a-4d69-9a8e-3f902f475cf7", "node_type": "4", "metadata": {"page_label": "130", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "351fe42e78afd69a14402a47756aa7d3020b9ff91d2ace826615d4af1c3456c8", "class_name": "RelatedNodeInfo"}}, "text": "130 Part III: Big Data Management \nfrom a variety of relational database sources and then ensured that the \nmetadata was consistent, and that the data itself was clean and then well \nintegrated. Bill Inmon, considered the father of the modern data warehouse, \nestablished a set of principles of the data warehouse, which included the fol -\nlowing characteristics:\n \u2713 It should be subject oriented.\n \u2713 It should be organized so that related events are linked together.\n \u2713 The information should be nonvolatile so that it cannot be inadvertently \nchanged.\n \u2713 Information in the warehouse should include all the applicable opera -\ntional sources. The information should be stored in a way that has con -\nsistent definitions and the most up-to-date values.\nOptimizing the data warehouse\nData warehouses have traditionally supported structured data and have been \nclosely tied to the operational and transactional systems of the enterprise. \nThese carefully constructed systems are now in the midst of significant \nchanges as organizations try to expand and modify the data warehouse so \nthat it can remain relevant in the new world of big data. While the worlds of \nbig data and the data warehouse will intersect, they are unlikely to merge \nanytime soon. You can think of the traditional data warehouse as a system \nof record for business intelligence, much like a customer relationship man -\nagement (CRM) system or an accounting system. These systems are highly \nstructured and optimized for specific purposes. In addition, these systems of \nrecord tend to be highly centralized. Figure 11-1 shows a typical approach to \ndata flows with warehouses and marts.\nDifferentiating big data structures  \nfrom data warehouse data\nOrganizations will inevitably continue to use data warehouses to manage the \ntype of structured and operational data that characterizes systems of record. \nThese data warehouses will still provide business analysts with the capabil -\nity to analyze key data, trends, and so on. However, the advent of big data \nis both challenging the role of the data warehouse and providing a comple -\nmentary approach. You might want to think about the relationship between \nthe data warehouse and big data as merging to become a hybrid structure. In \nthis hybrid model, the highly structured optimized operational data remains \nin the tightly controlled data warehouse, while the data that is highly distrib -\nuted and subject to change in real time is controlled by a Hadoop-based (or \nsimilar NoSQL) infrastructure.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2544, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2ba884d1-9545-490c-b8f3-f6453bd16751": {"__data__": {"id_": "2ba884d1-9545-490c-b8f3-f6453bd16751", "embedding": null, "metadata": {"page_label": "131", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "864d3b95-7691-449a-a756-aa000aeaa200", "node_type": "4", "metadata": {"page_label": "131", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "932973158d937f0de5069e32ff73082e16cb2dd3d466b07d1b3d42158c163d98", "class_name": "RelatedNodeInfo"}}, "text": "131  Chapter 11: Appliances and Big Data Warehouses\n Figure 11-1:  \nData flows \nfor tradi-\ntional data \nwarehouses \nand data \nmarts.\n \nIt is inevitable that operational and structured data will have to interact in \nthe world of big data, where the information sources have not (necessarily) \nbeen cleansed or profiled. Increasingly, organizations are understanding \nthat they have a business requirement to be able to combine traditional data \nwarehouses with their historical business data sources with less structured \nand vetted big data sources. A hybrid approach supporting traditional and \nbig data sources can help to accomplish these business goals.\nExamining a hybrid process case study\nImagine that you are in charge of data management for an online travel site. \nYour company offers a wide range of services, including air travel, cruises, \nhotels, resorts, and more. The company offers these services in many differ -\nent ways. For example, a public website is available that includes reviews \nof various trips, hotels, and so on. This website has relationships with vari -\nous related companies that offer services such as trip insurance and local \ntour services. Specialized sites exist for different countries. In addition, a \ncorporate travel service is customized for large companies. Needless to say, \nthis travel company has to manage a huge volume of data and be able to \npresent it differently depending on who is interacting with it. A data ware -\nhouse is used by the company to track its transactions and operational data. \nHowever, the data warehouse does not keep track of web traffic. Therefore, \nthe company used web analytics solutions to capture customer interactions. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1718, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9f6e0f27-d4fe-4e34-b8de-37387c99d503": {"__data__": {"id_": "9f6e0f27-d4fe-4e34-b8de-37387c99d503", "embedding": null, "metadata": {"page_label": "132", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "504e2291-c837-4391-8d6b-39a18181cd54", "node_type": "4", "metadata": {"page_label": "132", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "4e3be7ab43125fe63ac81a87a9615c4ebf6a19e70f01289af8b3af1a8e4ce19e", "class_name": "RelatedNodeInfo"}}, "text": "132 Part III: Big Data Management \nFor example, what did the customer click on? What offers were made avail -\nable to different customers, and which ones did they select? Was price the \nmost important factor? Did customers like to be able to design their own \ntravel packages, or were they more likely to purchase predesigned tours? \nWere some locations attracting more customers while other geographies \nwere less popular? Which partners were attracting the most revenue?\nWhile much of this data could be incredibly valuable for those planning for \nthe future, it was not practical for the company to store all or most of this \ndata in the data warehouse. As a result, most of this data was thrown away \nafter it was examined. Soon the company realized that it would be valuable \nto keep as much of this data as possible to understand the changes and \nnuances of the business.\nThe information management team decided that rather than building a \ncustomized data warehouse to store this data, it would leverage a Hadoop \ndistributed computing approach based on commodity servers. Now the \ncompany is able to keep all the data from the web interactions. This data is \nnow stored across a vast array of servers running Hadoop and MapReduce. \nLeveraging tools such as Flume and Sqoop, the team is able to move data into \nand out of Hadoop and push it into a relational model so that it can be que -\nried with familiar SQL tools.\nNow the company is able to change its business offerings quickly when it is \napparent that a demographic group of customers wants certain new services. \nThe company can also predict changes in airfare that will impact how pack -\nages are priced. Some of this data remains in the Hadoop framework environ -\nment and is updated in near real time. Other data elements are cleansed and \nthen are moved into the data warehouse so that the data is used to compare \nthe historical information about customers and partners to the new data. \nThe existing warehouse provides the context for the business while the \nHadoop environment tracks what is happening on a minute-to-minute basis. \nThe combination of the system-of-record approach with the data warehouse \nwith the dynamic big data system provides a tremendous opportunity for the \ncompany to continue to evolve its business based on analyzing the massive \namount of data generated by its web environments. Figure 11-2 depicts an \nexample approach to hybridizing traditional and big data warehousing.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2492, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "164d8055-4a46-4db4-bdee-b0c84438027a": {"__data__": {"id_": "164d8055-4a46-4db4-bdee-b0c84438027a", "embedding": null, "metadata": {"page_label": "133", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a6a98b1a-3756-40bd-9e8e-0e61a6b87226", "node_type": "4", "metadata": {"page_label": "133", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "09cbe664e5f42b111caac4941d7eff65cf0d76e01e4b67396fdd7fee2c5d3f92", "class_name": "RelatedNodeInfo"}}, "text": "133  Chapter 11: Appliances and Big Data Warehouses\n Figure 11-2:  \nData flows \nfor big data \nwarehouses \nand data \nmarts.\n \nBig Data Analysis and  \nthe Data Warehouse\nFrom the preceding examples, you find value in bringing the capabilities \nof the data warehouse and the big data environment together. You need to \ncreate a hybrid environment where big data can work hand in hand with the \ndata warehouse. First it is important to recognize that the data warehouse as \nit is designed today will not change in the short term. Therefore, it is more \npragmatic to use the data warehouse for what it has been designed to do \u2014 \nprovide a well-vetted version of the truth about a topic that the business \nwants to analyze. The warehouse might include information about a particu -\nlar company\u2019s product line, its customers, its suppliers, and the details of \na year\u2019s worth of transactions. The information managed in the data ware -\nhouse or a departmental data mart has been carefully constructed so that \nmetadata is accurate. With the growth of new web-based information, it is \npractical and often necessary to analyze this massive amount of data in con -\ntext with historical data. This is where the hybrid model comes in.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1242, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2dcea841-c1ec-44a7-85d0-f2e3a109b8ac": {"__data__": {"id_": "2dcea841-c1ec-44a7-85d0-f2e3a109b8ac", "embedding": null, "metadata": {"page_label": "134", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dd7072d0-368a-4fb7-8e63-dbc240774852", "node_type": "4", "metadata": {"page_label": "134", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "6a0eba1de908c52f23dcc5902c52c8fdb77949991a096866717342dd36935928", "class_name": "RelatedNodeInfo"}}, "text": "134 Part III: Big Data Management \nCertain aspects of marrying the data warehouse with big data can be rela -\ntively easy. For example, many of the big data sources come from sources \nthat include their own well-designed metadata. Complex e-commerce sites \ninclude well-defined data elements (customer, price, and so on). Therefore, \nwhen conducting analysis between the warehouse and the big data source, \nthe information management organization is working with two data sets with \ncarefully designed metadata models that have to be rationalized.\nOf course, in some situations, the information sources lack explicit meta -\ndata. Before an analyst can combine the historical transactional data with \nthe less structured big data, work has to be done. Typically, initial analysis \nof petabytes of data will reveal interesting patterns that can help predict \nsubtle changes in business or potential solutions to a patient\u2019s diagnosis. \nThe initial analysis can be completed leveraging tools like MapReduce with \nthe Hadoop distributed file system framework. At this point, you can begin to \nunderstand whether it is able to help evaluate the problem being addressed. \nIn the process of analysis, it is just as important to eliminate unnecessary \ndata as it is to identify data relevant to the business context. When this phase \nis complete, the remaining data needs to be transformed so that metadata \ndefinitions are precise. In this way, when the big data is combined with tra -\nditional, historical data from the warehouse, the results will be accurate and \nmeaningful.\nThe integration lynchpin\nTo make the process we describe practical requires a well-defined data inte -\ngration strategy. We cover the issue of data integration in detail in Chapter 15.  \nWhile data integration is a critical element of managing big data, it is equally \nimportant when creating a hybrid analysis with the data warehouse. In fact, \nthe process of extracting data and transforming it in a hybrid environment \nis very similar to how this process is executed within a traditional data \nwarehouse. In the data warehouse, data is extracted from traditional source \nsystems such as CRM or ERP systems. It is critical that elements from these \nvarious systems be correctly matched.\nRethinking extraction, transformation,  \nand loading\nIn the data warehouse, you often find a combination of relational database \ntables, flat files, and nonrelational sources. A well-constructed data ware -\nhouse will be architected so that the data is converted into a common \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2556, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b0b060d3-d29d-4938-9313-6d4de3d707fc": {"__data__": {"id_": "b0b060d3-d29d-4938-9313-6d4de3d707fc", "embedding": null, "metadata": {"page_label": "135", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "73978b02-9659-4555-b940-72d26889017c", "node_type": "4", "metadata": {"page_label": "135", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "91d71297b08f8d4a34e486ab6db3f754b6947a5b152b29e38e045622b96becf8", "class_name": "RelatedNodeInfo"}}, "text": "135  Chapter 11: Appliances and Big Data Warehouses\nformat, allowing queries to be processed accurately and consistently. The \nextracted files must be transformed to match the business rules and pro -\ncesses of the subject area that the data warehouse is designed to analyze. \nFor example, it is common to have the concept of a purchase price as a calcu -\nlated field in a data warehouse because it will be used in many of the queries \nused by management. Processes may exist within the warehouse to validate \nthat the calculations are accurate based on business rules. While these ideas \nare foundational to the data warehouse, it is also a key principle of marrying \nthe warehouse to big data. In other words, the data has to be extracted from \nthe big data sources so that these sources can safely work together and pro -\nduce meaningful results. In addition, the sources have to be transformed so \nthat they are helpful in analyzing the relationship between the historical data \nand the more dynamic and real-time data that comes from big data sources.\nLoading information in the big data model will be different than what you \nwould expect in a traditional data warehousing model. In the data warehouse, \nafter data has been codified, it is never changed. A typical data warehouse \nwill provide the business with a snapshot of data based on the need to ana -\nlyze a particular business issue that requires monitoring, such as inventory \nor sales quotas. Loading information can be dramatically different with big \ndata. The distributed structure of big data will often lead organizations to \nfirst load data into a series of nodes and then perform the extraction and \ntransformation. When creating a hybrid of the traditional data warehouse \nand the big data environment, the distributed nature of the big data environ -\nment can dramatically change the capability of organizations to analyze huge \nvolumes of data in context with the business.\nChanging the Role of  \nthe Data Warehouse\nIt is useful to think about the similarities and differences between the way \ndata is managed in the traditional data warehouse and when the warehouse \nis combined with big data.\nSimilarities between the two data management methods include\n \u2713 Requirements for common data definitions\n \u2713 Requirements to extract and transform key data sources\n \u2713 The need to conform to required business processes and rules\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2416, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d326c348-d64e-4d8b-b4d8-dce37accd50a": {"__data__": {"id_": "d326c348-d64e-4d8b-b4d8-dce37accd50a", "embedding": null, "metadata": {"page_label": "136", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5fdeeac9-d706-4ff6-a0ed-6f33685dd04d", "node_type": "4", "metadata": {"page_label": "136", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "4b24e9b9622a284377e41f0579a302ea8360fb255a71ee2168a0b003284b337e", "class_name": "RelatedNodeInfo"}}, "text": "136 Part III: Big Data Management \nDifferences between the traditional data warehouse and big data include\n \u2713 The distributed computing model of big data will be essential to allow -\ning the hybrid model to be operational.\n \u2713 The big data analysis will be the primary focus of the efforts, while the \ntraditional data warehouse will be used to add historical and transac -\ntional business context.\nChanging Deployment Models  \nin the Big Data Era\nWith the advent of big data, the deployment models for managing data are \nchanging. The traditional data warehouse is typically implemented on a \nsingle, large system within the data center. The costs of this model have led \norganizations to optimize these warehouses and limit the scope and size of \nthe data being managed. However, when organizations want to leverage the \nmassive amount of information generated by big data sources, the limitations \nof the traditional models no longer work. Therefore, the data warehouse \nappliance has become a practical method of creating an optimized environ -\nment to support the transition to new information management.\nThe appliance model\nWhen companies need to combine their data warehouse structure with \nbig data, the appliance model can be one answer to the problem of scaling. \nTypically, the appliance is an integrated system that incorporates hardware \n(typically in a rack) that is optimized for data storage and management. \nBecause they are self-contained, appliances can be relatively easy and quick to \nimplement, as well as offer lower costs to operation and maintain, Therefore, \nthe system will be preloaded with a relational database, the Hadoop frame -\nwork, MapReduce, and many of the tools that help ingest and organize data \nfrom a variety of sources. It also incorporates analytical engines and tools to \nsimplify the process of analyzing data from multiple sources. The appliance is \ntherefore a single-purpose system that typically includes interfaces to make it \neasier to connect to an existing data warehouse.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2045, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6d4ae1c7-5e42-4a90-87e6-69bd4110d68a": {"__data__": {"id_": "6d4ae1c7-5e42-4a90-87e6-69bd4110d68a", "embedding": null, "metadata": {"page_label": "137", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7064b587-22ce-4b9a-9a0a-5c384351c6ea", "node_type": "4", "metadata": {"page_label": "137", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e9cb2e4c15f72c6b25c0db3c450a321c9a8eba2ae5de9404b5e0970699e64fbf", "class_name": "RelatedNodeInfo"}}, "text": "137  Chapter 11: Appliances and Big Data Warehouses\nThe cloud model\nThe cloud is becoming a compelling platform to manage big data and can be \nused in a hybrid environment with on-premises environments. Some of the new \ninnovations in loading and transferring data are already changing the potential \nviability of the cloud as a big data warehousing platform. For example, Aspera, \na company that specializes in fast data transferring between networks, is part -\nnering with Amazon.com to offer cloud data management services. Other ven -\ndors such as FileCatalyst and Data Expedition are also focused on this market. \nIn essence, this technology category leverages the network and optimizes it for \nthe purpose of moving files with reduced latency. As this problem of latency in \ndata transfer continues to evolve, it will be the norm to store big data systems \nin the cloud that can interact with a data warehouse that is also cloud based or \na warehouse that sits in the data center.\nExamining the Future  \nof Data Warehouses\nThe data warehouse market has indeed begun to change and evolve with \nthe advent of big data. In the past, it was simply not economical for compa -\nnies to store the massive amount of data from a large number of systems of \nrecord. The lack of cost-effective and practical distributed computing archi -\ntectures meant that a data warehouse had to be designed so that it could be \noptimized to operate on a single unified system. Therefore, data warehouses \nwere purpose-built to address a single topic. In addition, the warehouse had \nto be carefully vetted so that data was precisely defined and managed. This \napproach has made data warehouses accurate and useful for the business \nto query these data sources. However, this same level of control and preci -\nsion has made it difficult to provide the business with an environment that \ncan leverage much more dynamic big data sources. The data warehouse will \nevolve slowly.\nData warehouses and data marts will continue to be optimized for business \nanalysis. However, a new generation of offerings will combine historical and \nhighly structured data stores with different stages of big data stores. First, \nbig data stores will provide the capability to analyze huge volumes of data in \nnear real time. Second, a big data store will take the results of an analysis and \nprovide a mechanism to match the metadata of the big data analysis to the \nrequirements of the data warehouse.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2481, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e6aca770-0b4c-4436-98f7-3fcb07bbbd92": {"__data__": {"id_": "e6aca770-0b4c-4436-98f7-3fcb07bbbd92", "embedding": null, "metadata": {"page_label": "138", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0567cb2-fb8d-4934-8e8b-5613f6e1db5c", "node_type": "4", "metadata": {"page_label": "138", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b687aa2aabbc6e26147110c044be67f2cd25287203977fe95f0ece20065acfee", "class_name": "RelatedNodeInfo"}}, "text": "138 Part III: Big Data Management \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 53, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d4243450-9b40-44cf-b13a-62abc6bca613": {"__data__": {"id_": "d4243450-9b40-44cf-b13a-62abc6bca613", "embedding": null, "metadata": {"page_label": "139", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6a577882-8b30-4af5-a55e-a0c320479633", "node_type": "4", "metadata": {"page_label": "139", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "cb1f7d6ff6fc05d462406ca400ed5b6332a1d515952a3818ff9989f52671ad3c", "class_name": "RelatedNodeInfo"}}, "text": "Part IV\nAnalytics and Big Data\nBig Data Analysis\nAnalysis Type Description\nBasic analytics for insightSlicing and dicing of data, reporting, simple \nvisualizations, basic monitoring.\nAdvanced analytics for insightMore complex analysis such as predictive mod -\neling and other pattern-matching techniques.\nOperationalized analytics Analytics become part of the business process.\nMonetized analytics Analytics are utilized to directly drive revenue.\n Read how to get results with big data at www.dummies.com/extras/bigdata .\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 541, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1554ed40-a15e-4479-9d13-019eb88eb67f": {"__data__": {"id_": "1554ed40-a15e-4479-9d13-019eb88eb67f", "embedding": null, "metadata": {"page_label": "140", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b62fe408-28b8-47e1-9663-3d4f5598c72a", "node_type": "4", "metadata": {"page_label": "140", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "9095e66678ee24f7430b644567c9b7a8315ecf02e5d52b21b1c30bd5220beef9", "class_name": "RelatedNodeInfo"}}, "text": "In this part . . .\n \u2713 Use big data in reporting, visualization, and predictive \nanalysis.\n \u2713 Study structured analytics case studies.\n \u2713 Explore unstructured data.\n \u2713 Define and demonstrate text analytics.\n \u2713 Integrate unstructured and structured data.\n \u2713 Understand models for leveraging big data.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 317, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "82dffe9d-624b-46e1-bd0a-d926071b468d": {"__data__": {"id_": "82dffe9d-624b-46e1-bd0a-d926071b468d", "embedding": null, "metadata": {"page_label": "141", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0411dbb5-a5da-406d-822e-ec7df5ee4fe7", "node_type": "4", "metadata": {"page_label": "141", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f0358c94c46bc9712f1ce9744ce906afc8efc51ffae860ce368f71b085606529", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 12\nDefining Big Data Analytics\nIn This Chapter\n\u25b6 Using big data to get results\n\u25b6 Finding what\u2019s different with big data\n\u25b6 Exploring the challenges of analyzing big data\n\u25b6 Examining analytics tools for big data\nU \np until this point, we\u2019ve been spending a lot of time describing the \ninfrastructure you need to support your big data initiatives. However, \nbecause big data is most useful if you can do something with it, the question \nbecomes, how do you analyze it?\nCompanies like Amazon and Google are masters at analyzing big data. And \nthey use the resulting knowledge to gain a competitive advantage. Just think \nabout Amazon\u2019s recommendation engine. The company takes all your buying \nhistory together with what it knows about you, your buying patterns, and the \nbuying patterns of people like you to come up with some pretty good sugges -\ntions. It is a marketing machine, and its big data analytics capabilities have \nmade it extremely successful.\nThe capability to analyze big data provides unique opportunities for your \norganization as well. You\u2019ll be able to expand the kind of analysis you can do. \nInstead of being limited to sampling large data sets, you can now utilize much \nmore detailed and complete data to do your analysis. However, analyzing big \ndata can also be challenging. Changing algorithms and technology, even for \nbasic data analysis, often has to be addressed with big data.\nSo, in this chapter, we introduce big data analytics. We focus on the kinds of \nanalysis you can do with big data. We also discuss some of the differences \nyou need to think about between big data analytics and traditional analyt -\nics. In this chapter, we focus primarily on structured data analysis, although \nunstructured data is a very important part of the big data picture. We \ndescribe that in the next chapter.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1851, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dee7bf8c-0af3-4a61-aebc-1ba057a68cec": {"__data__": {"id_": "dee7bf8c-0af3-4a61-aebc-1ba057a68cec", "embedding": null, "metadata": {"page_label": "142", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3ecd962d-7655-4729-bb2e-61346c76fdda", "node_type": "4", "metadata": {"page_label": "142", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "44871bc343867147a3d49521b6580824d749a942b1cc3385079433adc973f3f1", "class_name": "RelatedNodeInfo"}}, "text": "142 Part IV: Analytics and Big Data \nUsing Big Data to Get Results\nThe first question that you need to ask yourself before you dive into big data \nanalysis is what problem are you trying to solve? You may not even be sure \nof what you are looking for. You know you have lots of data that you think \nyou can get valuable insight from. And certainly, patterns can emerge from \nthat data before you understand why they are there.\nIf you think about it though, you\u2019re sure to have an idea of what you\u2019re \ninterested in. For instance, are you interested in predicting customer behav -\nior to prevent churn? Do you want to analyze the driving patterns of your \ncustomers for insurance premium purposes? Are you interested in looking \nat your system log data to ultimately predict when problems might occur? \nThe kind of high-level problem is going to drive the analytics you decide to \nuse. Alternately, if you\u2019re not exactly sure of the business problem you\u2019re \ntrying to solve, maybe you need to look at areas in your business that need \nimprovement. Even an analytics-driven strategy \u2014 targeted at the right  \narea \u2014 can provide useful results with big data.\nWhen it comes to analytics, you might consider a range of possible kinds, \nwhich are outlined in Table 12-1.\nTable 12-1 Big Data Analysis\nAnalysis Type Description\nBasic analytics for insight Slicing and dicing of data, reporting, simple visualiza -\ntions, basic monitoring.\nAdvanced analytics for \ninsightMore complex analysis such as predictive modeling \nand other pattern-matching techniques.\nOperationalized analytics Analytics become part of the business process.\nMonetized analytics Analytics are utilized to directly drive revenue.\n Before you start analyzing your data, make sure that you\u2019ve dealt with all pre -\nprocessing issues. These are covered in detail in Chapter 15.\nBasic analytics\nBasic analytics can be used to explore your data, if you\u2019re not sure what  \nyou have, but you think something is of value. This might include simple \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2023, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4fdcd4cb-bcef-48e2-bb66-e33a3871724e": {"__data__": {"id_": "4fdcd4cb-bcef-48e2-bb66-e33a3871724e", "embedding": null, "metadata": {"page_label": "143", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "45f2b2e7-91a1-4c6b-b6b7-4cf29cb7c730", "node_type": "4", "metadata": {"page_label": "143", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "8bcb763f401d0c6776d2b4923e57bcd374fd7ebd19b7e5c0fdf4ded9a1f35b7a", "class_name": "RelatedNodeInfo"}}, "text": "143  Chapter 12: Defining Big Data Analysis\nvisualizations or simple statistics. Basic analysis is often used when you have \nlarge amounts of disparate data. Here are some examples:\n \u2713 Slicing and dicing:  Slicing and dicing  refers to breaking down your data \ninto smaller sets of data that are easier to explore. For example, you \nmight have a scientific data set of water column data from many differ -\nent locations that contains numerous variables captured from multiple \nsensors. Attributes might include temperature, pressure, transparency, \ndissolved oxygen, pH, salinity, and so on, collected over time. You might \nwant some simple graphs or plots that let you explore your data across \ndifferent dimensions, such as temperature versus pH or transparency \nversus salinity. You might want some basic statistics such as average or \nrange for each attribute, from each height, for the time period. The point \nis that you might use this basic type of exploration of the variables to \nask specific questions in your problem space. The difference between \nthis kind of analysis and what happens in a basic business intelligence \nsystem is that you\u2019re dealing with huge volumes of data where you \nmight not know how much query space you\u2019ll need to examine it and \nyou\u2019re probably going to want to run computations in real time.\n \u2713 Basic monitoring:  You might also want to monitor large volumes of data \nin real time. For example, you might want to monitor the water column \nattributes in the preceding example every second for an extended period \nof time from hundreds of locations and at varying heights in the water \ncolumn. This would produce a huge data set. Or, you might be interested \nin monitoring the buzz associated with your product every minute when \nyou launch an ad campaign. Whereas the water column data set might \nproduce a large amount of relatively structured time-sensitive data, the \nsocial media campaign is going to produce large amounts of disparate \nkinds of data from multiple sources across the Internet.\n \u2713 Anomaly identification:  You might want to identify anomalies, such as \nan event where the actual observation differs from what you expected, \nin your data because that may clue you in that something is going wrong \nwith your organization, manufacturing process, and so on. For example, \nyou might want to analyze the records for your manufacturing operation \nto determine whether one kind of machine, or one operator, has a higher \nincidence of a certain kind of problem. This might involve some simple \nstatistics like moving averages triggered by an alert from the problem -\natic machine.\nAdvanced analytics\nAdvanced analytics provides algorithms for complex analysis of either \nstructured or unstructured data. It includes sophisticated statistical models, \nmachine learning, neural networks, text analytics (described in detail in \nChapter 13), and other advanced data-mining techniques. (See the sidebar \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2967, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8171fd5d-7c56-41ce-82c9-d6f1533b04d9": {"__data__": {"id_": "8171fd5d-7c56-41ce-82c9-d6f1533b04d9", "embedding": null, "metadata": {"page_label": "144", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d9f9d2d6-bb91-4f4a-b4df-704c2c4b0413", "node_type": "4", "metadata": {"page_label": "144", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "11bda90d560a0f828b6a021bec2adf26c7f3e30eacb9db3ca503baa5490f84f6", "class_name": "RelatedNodeInfo"}}, "text": "144 Part IV: Analytics and Big Data \n\u201cWhat is data mining?\u201d later in this chapter, for more detail on data mining.) \nAmong its many use cases, advanced analytics can be deployed to find pat -\nterns in data, prediction, forecasting, and complex event processing.\nWhile advanced analytics has been used by statisticians and mathematicians \nfor decades, it was not as big a part of the analytics landscape as it is today. \nConsider that 20 years ago, statisticians at companies were able to predict who \nmight drop a service using advanced survival analysis or machine learning tech -\nniques. However, it was difficult to persuade other people in the organization \nto understand exactly what this meant and how it could be used to provide a \ncompetitive advantage. For one thing, it was difficult to obtain the computational \npower needed to interpret data that kept changing through time.\nToday, advanced analytics is becoming more mainstream. With increases in \ncomputational power, improved data infrastructure, new algorithm develop -\nment, and the need to obtain better insight from increasingly vast amounts \nof data, companies are pushing toward utilizing advanced analytics as part \nof their decision-making process. Businesses realize that better insights can \nprovide a superior competitive position.\nHere are a few examples of advanced analytics for big data:\n \u2713 Predictive modeling:  Predictive modeling is one of the most popular big \ndata advanced analytics use cases. A predictive model is a statistical or \ndata-mining solution consisting of algorithms and techniques that can be \nused on both structured and unstructured data (together or individually) \nto determine future outcomes. For example, a telecommunications com -\npany might use a predictive model to predict customers who might drop \nits service. In the big data world, you might have large numbers of predic -\ntive attributes across huge amounts of observations. Whereas in the past, \nit might have taken hours (or longer) to run a predictive model, with a \nlarge amount of data on your desktop, you might be able to now run it \niteratively hundreds of times if you have a big data infrastructure in place.\n \u2713 Text analytics:  Unstructured data is such a big part of big data, so text \nanalytics \u2014 the process of analyzing unstructured text, extracting rel -\nevant information, and transforming it into structured information that \ncan then be leveraged in various ways \u2014 has become an important com -\nponent of the big data ecosystem. The analysis and extraction processes \nused in text analytics take advantage of techniques that originated in com -\nputational linguistics, statistics, and other computer science disciplines. \nText analytics is being used in all sorts of analysis, from predicting churn, \nto fraud, and to social media analytics. It is so important that we devote a \nconsiderable part of Chapter 13 to this issue of text analytics.\n \u2713 Other statistical and data-mining algorithms:  This may include \nadvanced forecasting, optimization, cluster analysis for segmentation or \neven microsegmentation, or affinity analysis.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3133, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c4116b72-c129-455e-a6c7-f7b1715eebe0": {"__data__": {"id_": "c4116b72-c129-455e-a6c7-f7b1715eebe0", "embedding": null, "metadata": {"page_label": "145", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2a9f80df-3a9b-4472-8ec6-a3e3cb111f45", "node_type": "4", "metadata": {"page_label": "145", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "36c0dade2a57afd3116b2288974aaa95501092f354684ed3dab1ecf160e68ca8", "class_name": "RelatedNodeInfo"}}, "text": "145  Chapter 12: Defining Big Data Analysis\nWhat is data mining?\nData mining involves exploring and analyzing \nlarge amounts of data to find patterns in that \ndata. The techniques came out of the fields of \nstatistics and artificial intelligence (AI), with a bit \nof database management thrown into the mix. \nGenerally, the goal of the data mining is either \nclassification or prediction. In classification, the \nidea is to sort data into groups. For example, a \nmarketer might be interested in the character -\nistics of those who responded versus who didn\u2019t \nrespond to a promotion. These are two classes. \nIn prediction, the idea is to predict the value of \na continuous (that is, nondiscrete) variable. For \nexample, a marketer might be interested in pre -\ndicting those who will respond to a promotion. \nTypical algorithms used in data mining include \nthe following:\n \u2713 Classification trees:  A popular data-  \nmining technique that is used to classify a \ndependent categorical variable based on \nmeasurements of one or more predictor \nvariables. The result is a tree with nodes \nand links between the nodes that can be \nread to form if-then rules.\n \u2713 Logistic regression: A statistical technique \nthat is a variant of standard regression but \nextends the concept to deal with classifica -\ntion. It produces a formula that predicts the \nprobability of the occurrence as a function \nof the independent variables.\n \u2713 Neural networks: A software algorithm \nthat is modeled after the parallel architec -\nture of animal brains. The network consists \nof input nodes, hidden layers, and output \nnodes. Each of the units is assigned a \nweight. Data is given to the input node, and \nby a system of trial and error, the algorithm \nadjusts the weights until it meets a certain \nstopping criteria. Some people have likened this to a black\u2013box (you don\u2019t necessarily \nknow what is going on inside) approach.\n \u2713 Clustering techniques like K-nearest \nneighbors: A technique that identifies \ngroups of similar records. The K-nearest \nneighbor technique calculates the dis -\ntances between the record and points in \nthe historical (training) data. It then assigns \nthis record to the class of its nearest neigh -\nbor in a data set.\nHere\u2019s a classification tree example. Consider \nthe situation where a telephone company wants \nto determine which residential customers are \nlikely to disconnect their service. The telephone \ncompany has information consisting of the fol -\nlowing attributes: how long the person has had \nthe service, how much he spends on the service, \nwhether he has had problems with the service, \nwhether he has the best calling plan for his \nneeds, where he lives, how old he is, whether \nhe has other services bundled together with his \ncalling plan, competitive information concern -\ning other carriers plans, and whether he still has \nthe service or has disconnected the service. Of \ncourse, you can find many more attributes than \nthis. The last attribute is the outcome variable; \nthis is what the software will use to classify the \ncustomers into one of the two groups \u2014 perhaps \ncalled stayers and flight risks.\nThe data set is broken into training data and \na test data set. The training data consists of \nobservations (called attributes) and an outcome \nvariable (binary in the case of a classification \nmodel) \u2014 in this case, the stayers or the flight \nrisks. The algorithm is run over the training data \nand comes up with a tree that can be read like \na series of rules. For example, if the customers \nhave been with the company for more than ten \nyears and they are over 55 years old, they are \nlikely to remain as loyal customers.\n(continued)\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3681, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2178cb5a-4876-4d51-bac1-2bc9eb50ce5f": {"__data__": {"id_": "2178cb5a-4876-4d51-bac1-2bc9eb50ce5f", "embedding": null, "metadata": {"page_label": "146", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d7346a3c-606e-40a2-b703-19e9536b77f1", "node_type": "4", "metadata": {"page_label": "146", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "6272571c090a180ef529498c5e647a3a4fd55d3bf6ce11f34f4085ef3cc20f0c", "class_name": "RelatedNodeInfo"}}, "text": "146 Part IV: Analytics and Big Data \n Advanced analytics doesn\u2019t require big data. However, being able to apply \nadvanced analytics with big data can provide some important results.\nOperationalized analytics\nWhen you operationalize analytics, you make them part of a business pro -\ncess. For example, statisticians at an insurance company might build a model \nthat predicts the likelihood of a claim being fraudulent. The model, along \nwith some decision rules, could be included in the company\u2019s claims-processing \nsystem to flag claims with a high probability of fraud. These claims would be \nsent to an investigation unit for further review. In other cases, the model \nitself might not be as apparent to the end user. For example, a model could \nbe built to predict customers who are good targets for upselling when they \ncall into a call center. The call center agent, while on the phone with the  \ncustomer, would receive a message on specific additional products to sell to \nthis customer. The agent might not even know that a predictive model was \nworking behind the scenes to make this recommendation.\nMonetizing analytics\nAnalytics can be used to optimize your business to create better decisions \nand drive bottom- and top-line revenue. However, big data analytics can also \nbe used to derive revenue above and beyond the insights it provides just for \nyour own department or company. You might be able to assemble a unique \ndata set that is valuable to other companies, as well. For example, credit card \nproviders take the data they assemble to offer value-added analytics prod -\nucts. Likewise, with financial institutions. Telecommunications companies \nare beginning to sell location-based insights to retailers. The idea is that vari -\nous sources of data, such as billing data, location data, text-messaging data, \nor web-browsing data can be used together or separately to make inferences \nabout customer behavior patterns that retailers would find useful. As a regu -\nlated industry, they must do so in compliance with legislation and privacy \npolicies.These rules are then run over the test data set \nto determine how good this model is on \u201cnew \ndata.\u201d Accuracy measures are provided for the \nmodel. For example, a popular technique is the \nconfusion matrix. This matrix is a table that pro -\nvides information about how many cases were \ncorrectly versus incorrectly classified. If the model looks good, it can be deployed on other \ndata, as it is available (that is, using it to predict \nnew cases of flight risk). Based on the model, \nthe company might decide, for example, to send \nout special offers to those customers whom it \nthinks are flight risks.(continued)\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2705, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "432f18a0-5579-4d97-8412-4ec94d454970": {"__data__": {"id_": "432f18a0-5579-4d97-8412-4ec94d454970", "embedding": null, "metadata": {"page_label": "147", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bfbfb084-58ea-4f60-aed8-9e3fa2d7eb79", "node_type": "4", "metadata": {"page_label": "147", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "8dbb74196077fbeccc2c66f5a3ac205a0fa2fb7c099eab3f4dc214da49beb020", "class_name": "RelatedNodeInfo"}}, "text": "147  Chapter 12: Defining Big Data Analysis\nModifying Business Intelligence  \nProducts to Handle Big Data\nTraditional business intelligence products weren\u2019t really designed to handle \nbig data. They were designed to work with highly structured, well-understood \ndata, often stored in a relational data repository and displayed on your desktop \nor laptop computer. This traditional business intelligence analysis is typically \napplied to snapshots of data rather than the entire amount of data available. \nSo what\u2019s different when you start to analyze big data?\nData\nAs we discuss in Chapter 2, big data consists of structured, semi-structured, \nand unstructured data. You often have a lot of it, and it can be quite complex. \nWhen you think about analyzing it, you need to be aware of the potential \ncharacteristics of your data:\n \u2713 It can come from untrusted sources.  Big data analysis often involves \naggregating data from various sources. These may include both internal \nand external data sources. How trustworthy are these external sources \nof information? For example, how trustworthy is social media data like \na tweet? The information may be coming from an unverified source. The \nintegrity of this data needs to be considered in the analysis. We talk \nmore about big data security and governance in Chapter 19.\n \u2713 It can be dirty.  Dirty data refers to inaccurate, incomplete, or erroneous \ndata. This may include the misspelling of words; a sensor that is broken, \nnot properly calibrated, or corrupted in some way; or even duplicated \ndata. Data scientists debate about where to clean the data \u2014 either \nclose to the source or in real time. Of course, one school of thought says \nthat the dirty data should not be cleaned at all because it may contain \ninteresting outliers. The cleansing strategy will probably depend on the \nsource and type of data and the goal of your analysis. For example, if \nyou\u2019re developing a spam filter, the goal is to detect the bad elements in \nthe data, so you would not want to clean it.\n \u2713 The signal-to-noise ratio can be low.  In other words, the signal (usable \ninformation) may only be a tiny percent of the data; the noise is the rest. \nBeing able to extract a tiny signal from noisy data is part of the benefit of \nbig data analytics, but you need to be aware that the signal may indeed \nbe small.\n \u2713 It can be real-time.  In many cases, you\u2019ll be trying to analyze real-time \ndata streams. We cover a whole set of complexities about how to ana -\nlyze this data in Chapter 16.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2546, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bea3172b-04c3-4fe3-9c67-28eb70412558": {"__data__": {"id_": "bea3172b-04c3-4fe3-9c67-28eb70412558", "embedding": null, "metadata": {"page_label": "148", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f3f1c77b-86f8-4f9e-8a52-8c1e123a7870", "node_type": "4", "metadata": {"page_label": "148", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e872719d3b328b2945f052608176e8883cb03ead054281d293c36fabfe36f96b", "class_name": "RelatedNodeInfo"}}, "text": "148 Part IV: Analytics and Big Data \n Big data governance is going to be an important part of the analytics equation. \nUnderneath business analytics, enhancements will need to be made to gover -\nnance solutions to ensure the veracity coming from the new data sources, \nespecially as it is being combined with existing trusted data stored in a ware -\nhouse. Data security and privacy solutions also need to be enhanced to sup -\nport managing/governing big data stored within new technologies. \nGovernance and security and so important that we devote Chapter 19 to it.\nAnalytical algorithms\nWhen you\u2019re considering big data analytics, you need to be aware that when \nyou expand beyond the desktop, the algorithms you use often need to be \nrefactored,  changing the internal code without affecting its external function -\ning. The beauty of a big data infrastructure is that you can run a model that \nused to take hours or days in minutes. This lets you iterate on the model hun -\ndreds of times over. However, if you\u2019re running a regression on a billion rows \nof data across a distributed environment, you need to consider the resource \nrequirements relating to the volume of data and its location in the cluster. \nYour algorithms need to be data aware.\nAdditionally, vendors are starting to offer a new breed of analytics designed \nto be placed close to the big data sources to analyze data in place rather than \nfirst having to store it and then analyze it. This approach of running analytics \ncloser to the data sources minimizes the amount of stored data by retaining \nonly the high-value data. It is also enables you to analyze the data sooner, \nlooking for key events, which is critical for real-time decision making. We dis -\ncuss these kinds of techniques in more detail in Chapter 14.\nOf course, analytics will continue to evolve. For example, you may need real-\ntime visualization capabilities to display real-time data that is continuously \nchanging. How do you practically plot a billion points on a graph plot? Or, \nhow do you work with the predictive algorithms so that they perform fast \nenough and deep enough analysis to utilize an ever-expanding, complex data \nset? This is an area of active research.\nInfrastructure support\nWe spend a good deal of this book talking about the infrastructure needed to \nsupport big data, so we don\u2019t go into detail about that here. You might want \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2415, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "05bb1699-dc49-44de-bb35-c4dd54446470": {"__data__": {"id_": "05bb1699-dc49-44de-bb35-c4dd54446470", "embedding": null, "metadata": {"page_label": "149", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "68afc25a-164b-4270-bd3d-4f3cca5766e8", "node_type": "4", "metadata": {"page_label": "149", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "944836635c967b3b81f707744a43c22efdb03897992b17bef6a93c81bde51694", "class_name": "RelatedNodeInfo"}}, "text": "149  Chapter 12: Defining Big Data Analysis\nto turn to Chapter 4 for more details on infrastructure issues. Suffice it to say \nthat if you\u2019re looking for a platform, it needs to achieve the following:\n \u2713 Integrate technologies:  The infrastructure needs to integrate new big \ndata technologies with traditional technologies to be able to process all \nkinds of big data and make it consumable by traditional analytics.\n \u2713 Store large amounts of disparate data:  An enterprise-hardened Hadoop \nsystem may be needed that can process/store/manage large amounts of \ndata at rest, whether it is structured, semi-structured, or unstructured.\n \u2713 Process data in motion:  A stream-computing capability may be needed \nto process data in motion that is continuously generated by sensors, \nsmart devices, video, audio, and logs to support real-time decision \nmaking.\n \u2713 Warehouse data:  You may need a solution optimized for operational or \ndeep analytical workloads to store and manage the growing amounts of \ntrusted data.\nAnd of course, you need the capability to integrate the data you already have \nin place along with the results of the big data analysis.\nStudying Big Data Analytics Examples\nBig data analytics has many different use cases. We mention examples \nthroughout this book, but we now look at a few others from Internet compa -\nnies and others.\nOrbitz\nIf you\u2019ve ever looked for deals on travel, you\u2019ve probably been to sites like \nOrbitz (www.orbitz.com ). The company was established in 1999, and its \nwebsite went live in 2001. Users of Orbitz perform over a million searches a \nday, and the company collects hundreds of gigabytes of raw data each day \nfrom these searches. Orbitz realized that it might have useful information in \nthe web log files that it was collecting from its web analytics software that \ncontained information about consumer interaction with its site. \nIn particular, it was interested to see whether it could identify consumer \npreferences to determine the best-performing hotels to display to users so \nthat it could increase conversions (bookings). It had not been utilizing this \ndata in the past because it was too expensive to store all of it. It implemented \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2214, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a27d215a-61e0-4133-aac1-7070cb9e0081": {"__data__": {"id_": "a27d215a-61e0-4133-aac1-7070cb9e0081", "embedding": null, "metadata": {"page_label": "150", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a2c7c947-01a4-4d88-b38c-66619394fef9", "node_type": "4", "metadata": {"page_label": "150", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ad365e7ac7203157ea50e20d3ad4f7a99a6b5f2da39d476b8eac851c81b2c323", "class_name": "RelatedNodeInfo"}}, "text": "150 Part IV: Analytics and Big Data \nHadoop and Hive running on commodity hardware to help. Hadoop provided \nthe distributed file system and Hive provided an SQL-type interface. It took \na series of steps to put the data into Hive. After the data was in Hive, the \ncompany used machine learning  \u2014 a data-driven (and data-mining; see the \nsidebar earlier in this chapter) approach to unearthing patterns in data and \nhelping to analyze the data. For more details about Hadoop and Hive, turn to \nChapters 9 and 10.\nNokia\nNokia provides wireless communication devices and services. The com -\npany believes that its data is a strategic asset. Its big data analytics service \nincludes a multipetabyte platform that executes over tens of thousands of \njobs each day. This includes utilizing advanced analytics over terabytes of \nstreaming data. For example, the company wants to understand how people \ninteract with its different applications on its phones. Nokia wants to under -\nstand what features customers use, how they use a feature, and how they \nmove from feature to feature and whether they get lost in the application as \nthey are using it. This level of detail helps the company lay out new features \nfor its applications and improve customer retention.\nNASA\nNASA is using predictive models to analyze safety data on aircrafts. It wants \nto understand whether the introduction of a new technology into an aircraft \nwill make a dramatic impact in safety. Needless to say, NASA is dealing with \na massive amount of data. Each airplane each day is recording a thousand  \nparameters every second for every flight. Some of this data is streaming.  \nThe company also receives text data from reports written by pilots and  \nother crew members. NASA also throws weather data (that changes in time \nand space) into the mix. The data scientists there are looking to predict  \noutcomes \u2014 for example, what pattern indicates a possible accident or  \nincident.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1972, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a37ef74e-a8ab-40f4-8fdf-6084ce42cec2": {"__data__": {"id_": "a37ef74e-a8ab-40f4-8fdf-6084ce42cec2", "embedding": null, "metadata": {"page_label": "151", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c6408129-2b9c-4f52-96cc-67bfafd23142", "node_type": "4", "metadata": {"page_label": "151", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "5b88223fc735edc9892639000c1cd9568041e74ae691241622ff0f54c4a8051c", "class_name": "RelatedNodeInfo"}}, "text": "151  Chapter 12: Defining Big Data Analysis\nBig Data Analytics Solutions\nA number of vendors on the market today support big data solutions. Here is \na listing of a few solutions that you may find interesting:\n \u2713 IBM (www.ibm.com ) is taking an enterprise approach to big data and \nintegrating across the platform including embedding/bundling its \nanalytics. Its products include a warehouse (InfoSphere warehouse) \nthat has its own built-in data-mining and cubing capability. Its new \nPureData Systems (a packaging of advanced analytics technology into \nan integrated systems platform) includes many packaged analytical \nintegrations. Its InfoSphere Streams product is tightly integrated with \nits Statistical Package for the Social Sciences (SPSS) statistical software \nto support real-time predictive analytics, including the capability to \ndynamically update models based on real-time data. It is bundling a \nlimited-use license of Cognos Business Intelligence with its key big data \nplatform capabilities (enterprise-class Hadoop, stream computing, and \nwarehouse solutions).\n \u2713 SAS (www.sas.com ) provides multiple approaches to analyze big data \nvia its high-performance analytics infrastructure and its statistical \nsoftware. SAS provides several distributed processing options. These \ninclude in-database analytics, in-memory analytics, and grid computing. \nDeployments can be on-site or in the cloud.\n \u2713 Tableau (www.tableausoftware.com ), a business analytics and data \nvisualization software company, offers its visualization capabilities to \nrun on top appliances and other infrastructure offered by a range of big \ndata partners, including Cirro, EMC Greenplum, Karmasphere, Teradata/\nAster, HP Vertica, Hortonworks, ParAccel, IBM Netezza, and a host of \nothers.\n \u2713 Oracle (www.oracle.com ) offers a range of tools to complement its big \ndata platform called Oracle Exadata. These include advanced analyt -\nics via the R programming language, as well as an in-memory database \noption with Oracle\u2019s Exalytics in-memory machine and Oracle\u2019s data \nwarehouse. Exadata is integrated with its hardware platform.\n \u2713 Pentaho (www.pentaho.com ) provides open source business analytics \nvia a community and enterprise edition. Pentaho supports the leading \nHadoop-based distributions and supports native capabilities, such as \nMapR\u2019s NFS high-performance mountable file system.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2400, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "af294b54-ca40-4efc-9069-925cf54a1cb3": {"__data__": {"id_": "af294b54-ca40-4efc-9069-925cf54a1cb3", "embedding": null, "metadata": {"page_label": "152", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "087831a0-c35a-4ee9-bf4b-571a2e9c80e4", "node_type": "4", "metadata": {"page_label": "152", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "bd0f892f7cdf6acb77bc2307fb9f20675e484b003179b3650ac8346c419b23aa", "class_name": "RelatedNodeInfo"}}, "text": "152 Part IV: Analytics and Big Data \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 55, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "3eff921e-d8c3-4bb0-bcf4-6fcb0cff3eea": {"__data__": {"id_": "3eff921e-d8c3-4bb0-bcf4-6fcb0cff3eea", "embedding": null, "metadata": {"page_label": "153", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "09dcac7c-6707-41d5-9d39-2ec35ec9c540", "node_type": "4", "metadata": {"page_label": "153", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "931a7dfbf54f14b080b37f60ecbedcb5c733ed7477ec028f9298b4cc2bdfdf25", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 13\nUnderstanding Text Analytics  \nand Big Data\nIn This Chapter\n\u25b6 Exploring the different types of unstructured data\n\u25b6 Defining text analytics\n\u25b6 Unstructured analytics use cases\n\u25b6 Putting unstructured data together with structured data\n\u25b6 Text analytics tools for big data\nM \nost data is unstructured. Unstructured data includes information \nstored internally, such as documents, e-mails, and customer cor -\nrespondence, as well as external information sources that are important to \nyour organization, such as tweets, blogs, YouTube videos, and satellite imag -\nery. The amount and variety of this data are growing rapidly. Increasingly, \ncompanies want to take advantage of this wealth of data to understand the \nimplications for their business today and in the future.\nWhile image and audio analysis are still in the early adopter stage, text ana -\nlytics is evolving into a mainstream technology. Here\u2019s an example of how \none company was able to leverage its text data to support business decision \nmaking. A large automobile manufacturer needed to improve quality prob -\nlems with its cars. It discovered that by analyzing the text from its repair \npartners, it could identify quality problems with its cars as they enter the \nmarketplace. The company views this analysis as an early warning system. \nThe earlier it can identify problems, the more changes it can make on the \nfactory floor and the fewer customers will be dissatisfied. Prior to using text \nanalytics, the company mined information from its line of business systems, \nincluding part numbers and defect codes. This worked well enough for many \nyears, but only for problems the company already knew existed. The tradi -\ntional system could not reveal hidden issues that were well known to the \npeople who were interacting with customers.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1832, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1542497e-c0ab-4a1b-a3dc-ba61c48d2a19": {"__data__": {"id_": "1542497e-c0ab-4a1b-a3dc-ba61c48d2a19", "embedding": null, "metadata": {"page_label": "154", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6e3885c4-da36-47e4-8b4c-73ca310ff2ec", "node_type": "4", "metadata": {"page_label": "154", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "254ae3c8a2978c4fecece2f275b339e394e313d0d996d4e4ef3937de55be7e56", "class_name": "RelatedNodeInfo"}}, "text": "154 Part IV: Analytics and Big Data \nSounds exciting, right? In fact, text analytics is being used in a wide variety \nof big data use cases from social media analysis to warranty analysis to \nfraud analysis. In addition, businesses are increasingly beginning to analyze \na merge view of structured and unstructured data together to get a full pic -\nture. In this chapter, we delve into this technology and provide an in-depth \nexample of how it works. We also provide you with some other use cases of \ntext analytics in action, including the capability to merge unstructured data \nwith structured data. We end the chapter with the names of some vendors \nthat are providing text analytics tools for big data.\nExploring Unstructured Data\nWhat sets unstructured data apart from structured data is that its structure \nis unpredictable. As we mention in Chapter 2, some people believe that the \nterm unstructured data  is misleading because each text source may contain its \nown specific structure or formatting based on the software that created it. In \nfact, it is the content of the document that is really unstructured.\nJust think about the kinds of text that are out there and the structure that \nmight be associated with each:\n \u2713 Documents:  \n  In return for a loan that I have received, I promise to pay $2,000 (this \namount is called principal ), plus interest, to the order of the lender. The \nlender is First Bank. I will make all payments under this note in the form \nof cash, check, or money order. I understand that the lender may trans -\nfer this note. The lender or anyone who takes this note by transfer and \nwho is entitled . . .\n \u2713 E-mails:\n  Hi Sam. How are you coming with the chapter on big data for the For \nDummies  book? It is due on Friday.\n  Joanne\n \u2713 Log files:\n  222.222.222.222- - [08/Oct/2012:11:11:54 -0400] \u201cGET / HTTP/1.1\u201d 200 \n10801 \u201chttp://www.google.com/search?q=log+analyzer&ie=\u2026. . .\n \u2713 Tweets:\n  #Big data is the future of data!\n \u2713 Facebook posts:\n  LOL. What are you doing later? BFF\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2037, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cc39aa99-3775-4b81-b935-c8c18d9517be": {"__data__": {"id_": "cc39aa99-3775-4b81-b935-c8c18d9517be", "embedding": null, "metadata": {"page_label": "155", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0a7572d9-3d53-44c4-a30d-e7b3e290041e", "node_type": "4", "metadata": {"page_label": "155", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "a846615130de45b72e75987936f498da1986182b3b887c8ff4e5c19db85a4471", "class_name": "RelatedNodeInfo"}}, "text": "155  Chapter 13: Understanding Text Analytics and Big Data\nClearly, some of these examples have more structure than others. For \ninstance, a bank loan note has some structure in terms of sentences and the \ntemplate it might follow. An e-mail might have little structure. A tweet or a \nFacebook message might have strange abbreviations or characters. A log file \nmight have its own structure.\nSo, the question is, how do you analyze this disparate kind of unstructured \ntext data?\nUnderstanding Text Analytics\nNumerous methods exist for analyzing unstructured data. Historically, these \ntechniques came out of technical areas such as Natural Language Processing \n(NLP), knowledge discovery, data mining, information retrieval, and statis -\ntics. Text analytics is the process of analyzing unstructured text, extracting \nrelevant information, and transforming it into structured information that \ncan then be leveraged in various ways. The analysis and extraction processes \ntake advantage of techniques that originated in computational linguistics, sta -\ntistics, and other computer science disciplines.\nSometimes an example can help to explain a complex topic.  Suppose that \nyou work for the marketing department in a wireless phone company.  You\u2019ve \njust launched two new calling plans \u2014 Plan A and Plan B \u2014  and you are not \ngetting the uptake you wanted on Plan A.  The unstructured text from the call \ncenter notes might give you some insight as to why this happened. Figure \n13-1 illustrates some of the call center notes.\n Figure 13-1:  \nSample \ncall center \nrecords.\n \nThe underlined words provide the information you might need to under -\nstand why Plan A isn\u2019t gaining rapid adoption.  For example, the entity Plan A \nappears throughout the call center notes, indicating that the reports mention \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1825, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8b7e55e5-36b7-48de-b64a-fd55f11464d0": {"__data__": {"id_": "8b7e55e5-36b7-48de-b64a-fd55f11464d0", "embedding": null, "metadata": {"page_label": "156", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "965edd30-c4db-4ecf-82de-96a1a7db8cd0", "node_type": "4", "metadata": {"page_label": "156", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "8c793521f97cbd36c7c02691c102eea294331f2a203182a10c8a496c59ee28b1", "class_name": "RelatedNodeInfo"}}, "text": "156 Part IV: Analytics and Big Data \nthe plan.  The terms roll-over minutes, 4GB data, data plan,  and expensive  are \nevidence that an issue exists with roll-over minutes, the data plan, and the \nprice.  Words like ridiculous  and stupid  provide insight into the caller senti -\nment, which in this case is negative.\nThe text analytics process uses various algorithms, such as understanding \nsentence structure,  to analyze the unstructured text and then  extract infor -\nmation, and transform that information into structured data.  The structured \ndata extracted from the unstructured text is illustrated in Table 13-1.\nTable 13-1 Making Structured Data from Unstructured Text\nIdentifier Entity Issue Sentiment\nCust XYZ Plan A Roll-over minutes Neutral\nCust ABC Plan A Roll-over minutes Negative\nXXXX Plan A Expensive Neutral\nXXXX Plan A Data plan Neutral\nCust XYT Plan A Data plan Negative\nYou may look at this and say, \u201cBut I could have figured that out by looking at \nthe call center records.\u201d However, these are just a small subset of the infor -\nmation being recorded by thousands of call center agents. Each individual \nagent cannot possibly sense a broad trend regarding the problem with each \nplan being offered by the company. Agents do not have the time or require -\nment to share this information across all the other call center agents who \nmay be getting similar numbers of calls about Plan A. However, after this \ninformation is aggregated and processed using text analytics algorithms, a \ntrend may emerge from this unstructured data. That\u2019s what makes text ana -\nlytics so powerful.\nThe difference between text  \nanalytics and search\nNotice that we are focusing on extracting text, not on keyword search. Search \nis about retrieving a document based on what end users already know they \nare looking for. Text analytics is about discovering information. While text \nanalytics differs from search, it can augment search techniques. For example, \ntext analytics combined with search can be used to provide better categori -\nzation or classification of documents and to produce abstracts or summaries \nof documents. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2150, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "345e5fc3-e46f-491b-b0d6-0913117e47c7": {"__data__": {"id_": "345e5fc3-e46f-491b-b0d6-0913117e47c7", "embedding": null, "metadata": {"page_label": "157", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b6075e6e-b7c9-4ec1-b2ba-80aa6d80c889", "node_type": "4", "metadata": {"page_label": "157", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "77c70c5345ca47addb70cca0d801e376d573c31fd12c6a9bdc8ba9c58a68965d", "class_name": "RelatedNodeInfo"}}, "text": "157  Chapter 13: Understanding Text Analytics and Big Data\nTable 13-2 illustrates four technologies: query, data mining, search, and text \nanalytics. On the left side of the table are query and search, which are both \nabout retrieval. For example, an end user could query a database to find out \nhow many customers stopped using the company\u2019s services in the past month. \nThe query would return a single number. Only by asking more and different \nqueries will the end user get the information required to determine why cus -\ntomers are leaving. Likewise, keyword search allows the end user to find the \ndocuments that contain the names of a company\u2019s competitors. The search \nwould return a group of documents. Only by reading the documents would the \nend user come up with any relevant answers to his or her questions.\nTable 13-2 Query, Data Mining, Search, and Text Analytics\nRetrieval Insight\nStructured Query: Returns data Data mining: Insight from \nstructured data\nUnstructured Search: Returns documents Text analytics: Insight from \ntext\nThe technologies on the left return pieces of information and require human \ninteraction to synthesize and analyze that information. The technologies \non the right \u2014 data mining (discussed in Chapter 12) and text analytics \u2014 \ndeliver insight much more quickly. Hopefully, the value of text analytics to \nyour organization is becoming clear.\nAnalysis and Extraction Techniques\nOkay, now it\u2019s time to get a little bit more technical. In general, text analytics \nsolutions use a combination of statistical and Natural Language Processing \n(NLP) techniques to extract information from unstructured data. NLP is a \nbroad and complex field that has developed over the last 20 years. A primary \ngoal of NLP is to derive meaning from text. Natural Language Processing gen -\nerally makes use of linguistic concepts such as grammatical structures and \nparts of speech. Often, the idea behind this type of analytics is to determine \nwho did what to whom, when, where, how, and why.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2033, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "63e5195b-9d47-4641-83c7-25f230180877": {"__data__": {"id_": "63e5195b-9d47-4641-83c7-25f230180877", "embedding": null, "metadata": {"page_label": "158", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bc97e1d5-4d52-4e0a-8986-1e7ecded7826", "node_type": "4", "metadata": {"page_label": "158", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "827c193cdc429731fca4b46ab04df0c438da074e9e0a46f922fd4a84ea7b8754", "class_name": "RelatedNodeInfo"}}, "text": "158 Part IV: Analytics and Big Data \nNLP performs analysis on text at different levels:\n \u2713 Lexical/morphological analysis examines the characteristics of an indi -\nvidual word \u2014 including prefixes, suffixes, roots, and parts of speech \n(noun, verb, adjective, and so on) \u2014 information that will contribute to \nunderstanding what the word means in the context of the text provided. \nLexical analysis depends on a dictionary, thesaurus, or any list of words \nthat provides information about those words. In the case of a wireless \ncommunication company\u2019s sales promotion, a dictionary might provide \nthe information that promotion is a noun that can mean an advancement \nin position, an advertising or publicity effort, or an effort to encourage \nsomeone\u2019s growth. Lexical analysis would also enable an application to \nrecognize that promotion,  promotions,  and promoting are all versions of \nthe same word and idea.\n \u2713 Syntactic analysis uses grammatical structure to dissect the text and \nput individual words into context. Here you are widening your gaze from \na single word to the phrase or the full sentence. This step might diagram \nthe relationship between words (the grammar) or look for sequences \nof words that form correct sentences or for sequences of numbers that \nrepresent dates or monetary values. For example, the wireless commu -\nnication company\u2019s call center records included this complaint: \u201cThe \ncustomer thought it was ridiculous that roll-over minutes were not in \nthe plan.\u201d Syntactic analysis would tag the noun phrases in addition to \nproviding the part-of-speech tags.\n \u2713 Semantic analysis determines the possible meanings of a sentence. This \ncan include examining word order and sentence structure and disam -\nbiguating words by relating the syntax found in the phrases, sentences, \nand paragraphs.\n \u2713 Discourse-level analysis attempts to determine the meaning of text \nbeyond the sentence level.\nIn practice, to extract information from various document sources, organiza -\ntions sometimes need to develop rules. These rules can be simple: \nThe name of a person must start with a capital letter.\nEvery course on the college website must follow a three-digit course \nnumber and a semicolon.\nA logo must appear in a certain location on every page.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2294, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "84f2af73-a280-4687-8fe2-7c6999ff93cc": {"__data__": {"id_": "84f2af73-a280-4687-8fe2-7c6999ff93cc", "embedding": null, "metadata": {"page_label": "159", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "23e704cb-317f-4c89-8f26-01497829db42", "node_type": "4", "metadata": {"page_label": "159", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "025708979fea134fa0f3fcbe10630e11b0c9ee3554e91f60a84855d2de0f43fc", "class_name": "RelatedNodeInfo"}}, "text": "159  Chapter 13: Understanding Text Analytics and Big Data\nOf course, the rules can be much more complex. Organizations can generate \nrules manually, automatically, or by a combination of both approaches:\n \u2713 In the manual approach, someone uses a proprietary language to build \na series of rules for extraction. This person may also build dictionaries \nand/or synonym lists. While the manual approach can be time-consuming, \nit can provide very accurate results.\n \u2713 Automated approaches may use machine learning or other statistical \ntechniques. The software generates rules based on a set of training and \ntext data. First, the system processes a set of similar documents (for \nexample, newspaper articles) to develop \u2014 that is, learn \u2014 the rules. \nThen the user runs a set of test data to test the accuracy of the rules.\nUnderstanding the extracted information\nThe techniques described earlier in the chapter are generally combined with \nother statistical or linguistic techniques to automate the tagging and markup \nof text documents to extract the following kinds of information:\n \u2713 Terms: Another name for keywords. \n \u2713 Entities:  Often called named entities,  these are specific examples of \nabstractions (tangible or intangible). Examples are names of persons, \nnames of companies, geographical locations, contact information, dates, \ntimes, currencies, titles and positions, and so on. For example, text ana -\nlytic software can extract the entity Jane Doe  as a person referred to in \nthe text being analyzed. The entity March 3, 2007  can be extracted as a \ndate, and so on. Many vendors provide entity extraction out of the box.\n \u2713 Facts:  Also called relationships,  facts indicate the who/what/where rela -\ntionships between two entities. John Smith is the CEO of Company Y and \nAspirin reduces fever are examples of facts. \n \u2713 Events:  While some experts use the terms fact, relationship,  and event \ninterchangeably, others distinguish between events and facts, stating \nthat events usually contain a time dimension and often cause facts to \nchange. Examples include a change in management within a company or \nthe status of a sales process.\n \u2713 Concepts:  These are sets of words and phrases that indicate a particu -\nlar idea or topic with which the user is concerned. This can be done \nmanually or by using statistical, rule-based, or hybrid approaches to \ncategorization. For example, the concept unhappy customer may include \nthe words angry, disappointed,  and confused  and the phrases disconnect \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2537, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "adb9d066-e0f4-48ee-9341-fe41c1dff0d7": {"__data__": {"id_": "adb9d066-e0f4-48ee-9341-fe41c1dff0d7", "embedding": null, "metadata": {"page_label": "160", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9c97f423-d185-40ce-86d1-bdc79b51bb31", "node_type": "4", "metadata": {"page_label": "160", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ca4791623e31ec3dbd4ec416680f6da18d8384ceb808c47eef9d27df6ae42566", "class_name": "RelatedNodeInfo"}}, "text": "160 Part IV: Analytics and Big Data \nservice, didn\u2019t call back,  and waste of money  \u2014 among many others. Thus \nthe concept unhappy customer can be extracted even without the words \nunhappy  or customer  appearing in the text. Concepts can be defined by \nusers to suit their particular needs.\n \u2713 Sentiments:  Sentiment analysis is used to identify viewpoints or emo -\ntions in the underlying text. Some techniques do this by classifying text \nas, for example, subjective (opinion) or objective (fact), using machine-\nlearning or NLP techniques. Sentiment analysis has become very popu -\nlar in \u201cvoice of the customer\u201d kinds of applications.\nTaxonomies\nTaxonomies are often critical to text analytics. A taxonomy  is a method \nfor organizing information into hierarchical relationships. It is sometimes \nreferred to as a way of organizing categories. Because a taxonomy defines the \nrelationships between the terms a company uses, it makes it easier to find \nand then analyze text.\nFor example, a telecommunications service provider offers both wired and \nwireless service. Within the wireless service, the company may support cel -\nlular phones and Internet access. The company may then have two or more \nways of categorizing cellular phone service, such as plans and phone types. \nThe taxonomy could reach all the way down to the parts of a phone itself.\nTaxonomies can also use synonyms and alternate expressions, recognizing \nthat cellphone, cellular phone, and mobile phone are all the same. These tax -\nonomies can be quite complex and can take a long while to develop.\n Some vendors will state that a taxonomy is not necessary when using their \nproduct and that business users can categorize already extracted informa -\ntion. This will actually depend on the subjects you\u2019re interested in. Often, the \ntopics can be very complex, nuanced, or specific to a certain industry. That\u2019s \ngoing to require a focused taxonomy.\nPutting Your Results Together  \nwith Structured Data\nAfter your unstructured data is structured, you can combine it with other \nstructured information that might exist in your data warehouse, and then \napply business intelligence or data-mining tools to gather further insight.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2221, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dc3e47d4-bc7e-4e42-a172-0e3406197ed4": {"__data__": {"id_": "dc3e47d4-bc7e-4e42-a172-0e3406197ed4", "embedding": null, "metadata": {"page_label": "161", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "80e07c50-f880-4bee-b69e-c3652f9bf262", "node_type": "4", "metadata": {"page_label": "161", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "bd5c7936663269ca635ce6bbb7365110ea04839acaf44286b399fe559aed9376", "class_name": "RelatedNodeInfo"}}, "text": "161  Chapter 13: Understanding Text Analytics and Big Data\nFor example, in Table 13-3, text analytics results are merged with structured \nbilling information. You can see that the contents of Table 13-3 are the same \nas Table 13-1, except we\u2019ve added a Segment column on the right. Essentially, \nyou can match information from your customers that live in the billing \nsystem with the information from the call center notes. Of course, when pros -\npects call in, no information is available to match; this is why \u201cXXXX\u201d appear \nin these rows.\nTable 13-3 Marrying Structured and Unstructured Data\nIdentifier Entity Issue Sentiment Segment\nCust XYZ Plan A Roll-over minutes Neutral Gold\nCust ABC Plan A Roll-over minutes Negative Silver\nXXXX Plan A Expensive Neutral XXX\nXXXX Plan A Data plan Neutral XXX\nCust XYT Plan A Data plan Negative Bronze\nIn this example, the structured data together with the unstructured data indi -\ncate that at least one of your customers is a gold customer, so it would be \nworthwhile for the company to make an extra effort to retain him or her. Of \ncourse, in reality, you will have a lot more data than this to work with.\nPutting Big Data to Use\nThe wireless promotion use case is just one example of how text analytics \ncan be used to help gain insight into data. So, what if the data is big data? A \nbig data use case would mean that the unstructured data being analyzed is \neither high volume, high velocity, or both. The following sections describe a \nfew examples.\nVoice of the customer\nOptimizing the customer experience and improving customer retention are \ndominant drivers for many service industries. Organizations concerned with \nthese issues might ask questions such as\n \u2713 What are major areas of complaints by customers and how are these \nchanging over time?\n \u2713 What is the level of satisfaction of customers with specific services?\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1894, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d8823b6e-d2a4-4dae-916c-89ecb90c4526": {"__data__": {"id_": "d8823b6e-d2a4-4dae-916c-89ecb90c4526", "embedding": null, "metadata": {"page_label": "162", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "28b09737-9e31-47fb-ab99-c6705ae39c2b", "node_type": "4", "metadata": {"page_label": "162", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "7a0509b78e1a12e2ef913e7cb687c1f9f2c3c8d113fc76c36be32a5476cbe3e4", "class_name": "RelatedNodeInfo"}}, "text": "162 Part IV: Analytics and Big Data \n \u2713 What are the most frequent issues that lead to customer churn?\n \u2713 What are some key customer segments that provide higher potential \nupsell opportunities?\nInformation, such as e-mails to the company, customer satisfaction surveys, \ncall center notes, and other internal documents, hold a lot of information \nabout customer concerns and sentiment. Text analytics can help to iden -\ntify and address causes of customer dissatisfaction in a timely manner. It \ncan help improve brand image by proactively solving problems before they \nbecome a big sticking point with customers.\nIs this a big data problem? It can be. It depends on the volume of the informa -\ntion. You may have a large volume of information that is delivered in batch \nmode. Companies may want to merge this data with structured data, as we \ndiscuss earlier in this chapter.\nSocial media analytics\nAnother form of voice of the customer or customer experience management, \nsocial media analytics, has gotten a lot of visibility recently and, in fact, is \nhelping to drive the text analytics market. In social media analytics, data \nacross the Internet is gathered together. This includes unstructured text \nfrom blogs, microblogs, news articles, text from online forums, and so on. \nThis huge stream of data is then analyzed \u2014 often using text analytics \u2014 to \nget answers to questions such as\n \u2713 What are people saying about my brand?\n \u2713 What do they like about my brand?\n \u2713 What do they dislike about my brand?\n \u2713 How does my brand compare to my competitors\u2019?\n \u2713 How loyal are my customers?\nAnd, social media isn\u2019t just being used by marketers concerned about their \nbrand. The government is using it to look for terrorist conversations. Health \nagencies are using it to identify public health threats worldwide. The list  \ngoes on.\nThis is a big data use case, especially when you can work with a service \nprovider that can assemble all the tweets from Twitter, together with all the \nother data.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2020, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "398383c4-129f-4e3a-962a-31e9697ed43d": {"__data__": {"id_": "398383c4-129f-4e3a-962a-31e9697ed43d", "embedding": null, "metadata": {"page_label": "163", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "068b52ad-ecd2-4c5c-b5d8-2fd9a52b75f5", "node_type": "4", "metadata": {"page_label": "163", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "307bfb73a680878ee5614ce7fa39a8b2550c90471db6c251969ebab07f7924e3", "class_name": "RelatedNodeInfo"}}, "text": "163  Chapter 13: Understanding Text Analytics and Big Data\nIBM Watson\nYou may have seen a machine playing and win -\nning Jeopardy!  a few years ago. That machine \nis called Watson. IBM Watson is a set of tech -\nnologies that processes and analyzes massive \namounts of both structured and unstructured \ndata in a unique way. Watson can process and \nanalyze information from 200 million books in \nthree seconds. While Watson is very advanced, \nit uses technologies that are commercially \navailable with some \u201csecret sauce\u201d technolo -\ngies that IBM Research has either enhanced or \ndeveloped. It combines software technologies \nfrom big data, content and predictive analyt -\nics, and industry-specific software to make it \nwork. IBM is working together with the medical \nindustry to develop a Watson for that industry. It \nis only the first in a series of Watsons that IBM \nwill develop with its partners.\nSo what is this secret sauce? Watson under -\nstands natural language, generates and evalu -\nates hypotheses, and adapts and learns.\nFirst, Watson uses Natural Language \nProcessing. IBM is using a set of annotators to \nextract information like symptoms, age, loca -\ntion, and so on. Watson is processing vast \namounts of this unstructured data quickly, using \nan architecture designed for this.\nSecond, Watson works by generating hypoth -\neses that are potential answers to a question. It \nis trained by feeding question-and-answer (Q/A) \ndata into the system. In other words, it is shown \nrepresentative questions and it learns from the \nsupplied answers. This is called evidence-based \nlearning . The goal is to generate a model that \ncan produce a confidence score (think logistic \nregression with a bunch of attributes). Watson \nstarts with a generic statistical model, then look \nat the first Q/A, and use that to tweak coeffi -\ncients. As it gains more evidence, it continues to tweak the coefficients until it can \u201csay\u201d that \nconfidence is high. Training Watson is key \nbecause what is really happening is that the \ntrainers are building statistical models that  \nare scored. At the end of the training, Watson \nhas a system that has feature vectors and \nmodels so that eventually it can use the model \nto probabilistically score the answers. The key \nhere is something that Jeopardy! did not show -\ncase, which is that it is not deterministic (that \nis, using rules). Watson is probabilistic and that \nmakes it dynamic.\nWhen Watson generates a hypothesis, it then \nscores the hypothesis based on the evidence. \nIts goal is to get the right answer for the right \nreason. (So, theoretically, if five symptoms \nmust be positive for a certain disease and four \nmust be negative and Watson only has four of \nthe nine pieces of information, it could ask for \nmore.) The hypothesis with the highest score is \npresented. By the end of the analysis, Watson is \nconfident when it knows the answer and when \nit doesn\u2019t know the answer.\nHere\u2019s an example. Suppose that you see \nyour doctor because you are not feeling well. \nSpecifically, you might have heart palpita -\ntions, fatigue, hair loss, and muscle weakness. \nYou decide to go see a doctor to determine \nwhether something is wrong with your thyroid \nor whether it is something else. If your doctor \nhas access to a Watson system, he could use it \nto help advise him regarding your diagnosis. In \nthis case, Watson would already have ingested \nand curated all the information in books and \njournals associated with thyroid disease. It also \nhas the diagnosis and related information from \nother patients from this hospital and other doc -\ntors in the practice from the electronic medi -\ncal records of prior cases that it has in its data \nbanks.\n(continued)\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3732, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f0cb22b2-4e6c-4e55-8e1e-15425c2a1cb3": {"__data__": {"id_": "f0cb22b2-4e6c-4e55-8e1e-15425c2a1cb3", "embedding": null, "metadata": {"page_label": "164", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1e9e7d80-5e07-4968-81f8-c0750c0d9f3d", "node_type": "4", "metadata": {"page_label": "164", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "8b3345a1b69645ffb38fb881df879615ec6a669b3e8a004b0602097c017ca221", "class_name": "RelatedNodeInfo"}}, "text": "164 Part IV: Analytics and Big Data \nText Analytics Tools for Big Data\nIn the following sections, we provide an overview of some of the players in this \nmarket. Some are small while others are household names. Some call what \nthey do big data text analytics,  while some just refer to it as text analytics.\nAttensity\nAttensity ( www.attensity.com ) is one of the original text analytics compa -\nnies that began developing and selling products more than ten years ago. At \nthis time, it has over 150 enterprise customers and one of the world\u2019s largest \nNLP development groups. Attensity offers several engines for text analyt -\nics. These include Auto-Classification, Entity Extraction, and Exhaustive \nExtraction. Exhaustive Extraction is Attensity\u2019s flagship technology that \nautomatically extracts facts from parsed text (who did what to whom, when, \nwhere, under what conditions) and organizes this information.\nThe company is focused on social and multichannel analytics and engage -\nment by analyzing text for reporting from internal and external sources \nand then routing it to business users for engagement. It recently purchased \nBiz360, a social media company that aggregates huge streams of social \nmedia. It has developed a grid computing system that provides high-\nperformance capabilities for processing massive amounts of real-time text. \nAttensity uses a Hadoop framework (MapReduce, HDFS, and HBase) to store \ndata. It also has a data-queuing system that creates an orchestration process \nthat recognizes spikes in inbound data and adjusts processing across more/\nless servers as needed.Based on the first set of symptoms you might \nreport, it would generate a hypothesis along \nwith probabilities associated with the hypoth -\nesis (for example, 60 percent hyperthyroidism, \n40 percent anxiety, and so on). It might then ask \nfor more information. As it is fed this informa -\ntion, such as patient history, Watson would \ncontinue to refine its hypothesis along with \nthe probability of the hypothesis being correct. \nAfter it is given all the information and it iterates \nthrough it and presents the diagnosis with the \nhighest confidence level, the physician would use this information to help assist him in making \nthe diagnosis and developing a treatment plan. \nIf Watson doesn\u2019t know the answer, it will state \nthat it does not have an answer or doesn\u2019t have \nenough information to provide an answer.\nIBM likens the process of training a Watson to \nteaching a child how to learn. A child can read \na book to learn. However, he can also learn by \na teacher asking questions and reinforcing the \nanswers about that text.(continued)\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2668, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1d7a692a-985c-44e5-aac6-981d93fcb829": {"__data__": {"id_": "1d7a692a-985c-44e5-aac6-981d93fcb829", "embedding": null, "metadata": {"page_label": "165", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "513f6e02-adc8-4c1c-b036-e60699f8c545", "node_type": "4", "metadata": {"page_label": "165", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "569aeed30774b9580af97af1df7c8f20820f2123ae05cfbc53b92e06460e4047", "class_name": "RelatedNodeInfo"}}, "text": "165  Chapter 13: Understanding Text Analytics and Big Data\nClarabridge\nAnother pure-play text analytics vendor, Clarabridge ( www.clarabridge.\ncom) is actually a spin-off of a business intelligence (BI) consulting firm \n(called Claraview) that realized the need to deal with unstructured data. Its \ngoal is to help companies drive measurable business value by looking at the \ncustomer holistically, pinpointing key experiences and issues, and helping \neveryone in an organization take actions and collaborate in real time. This \nincludes real-time determination of sentiment and classification of customer \nfeedback data / text and staging the verbatim for future processing into the \nClarabridge system.\nAt this time, Clarabridge is offering its customers some sophisticated and \ninteresting features, including single-click root cause analysis to identify what \nis causing a change in the volume of text feeds, sentiment, or satisfaction \nassociated with emerging issues. It also offers its solution as a Software as a \nService (SaaS).\nIBM\nSoftware giant IBM ( www.ibm.com ) offers several solutions in the text ana -\nlytics space under its Smarter Planet strategy umbrella. Aside from Watson \nand IBM SPSS (see Chapter 12 for more on SPSS), IBM also offers IBM Content \nAnalytics with Enterprise Search (ICAES). IBM Content Analytics was devel -\noped based on work done at IBM Research.\nIBM Content Analytics is used to transform content into analyzed informa -\ntion, and this is available for detailed analyses similar to the way structured \ndata would be analyzed in a BI toolset. IBM Content Analytics and Enterprise \nSearch were once two separate products. The converged solution targets \nboth enhanced enterprise search that uses text analytics, as well as stand-\nalone content analytics needs. ICAES has tight integration with the IBM \nInfoSphere BigInsights platform, enabling very large search and content ana -\nlytics collections.\nOpenText\nOpenText ( www.opentext.com ), a Canadian-based company, is probably \nbest known for its leadership in enterprise information management (EIM) \nsolutions. Its vision revolves around managing, securing, and extracting \nvalue from the unstructured data of enterprises. It provides what it terms \n\u201csemantic middleware.\u201d According to the company, its semantic technology \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2338, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9be3c6d3-5945-4e6c-b98c-638ee602bf9a": {"__data__": {"id_": "9be3c6d3-5945-4e6c-b98c-638ee602bf9a", "embedding": null, "metadata": {"page_label": "166", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fff125c2-910a-4948-9f8d-470063e1ddfd", "node_type": "4", "metadata": {"page_label": "166", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "7a398946932f91c1761b776c2d565afbcce655c1c2e0b388c11ce278ec35a6c2", "class_name": "RelatedNodeInfo"}}, "text": "166 Part IV: Analytics and Big Data \nevolution is rooted in its capability \u201cto enable real-time analytics with high \naccuracy on large data sets (that is, content) across languages, formats, and \nindustry domains.\u201d The idea behind semantic middleware is that semantics \ncan be exposed at different levels and work with different technologies (for \nexample, document management, predictive analytics, and so on) to address \nbusiness issues. In other words, the text analytics can be enabled and utilized \nwhere needed. OpenText provides this middleware as a stand-alone product \nto be used in a variety of solutions as well as embedded in its products.\n The idea of pluggable semantic enablers is starting to gain more steam, and  \nsmaller players are also looking at ways that these enablers can provide value \nto big data applications.\nSAS\nSAS (www.sas.com ) has been solving complex big data problems for a long \ntime. Several years ago, it purchased text analytics vendor Teragram to \nenhance its strategy to use both structured and unstructured data in analysis \nand to integrate this data for descriptive and predictive modeling. Now, its \ntext analytics capabilities are part of its overall analytics platform and text \ndata is viewed as simply another source of data.\nSAS continues to innovate in the area of high-performance analytics to ensure \nthat performance meets customer expectations. The goal is to take problems \nthat used to take weeks to solve and solve them in days, or problems that \nused to take days to solve and solve them in minutes instead. For example, \nthe SAS High Performance Analytics Server is an in-memory solution that \nallows you to develop analytical models using complete data, not just a \nsubset of aggregate data. SAS says that you can use thousands of variables \nand millions of documents as part of this analysis. The solution runs on EMC \nGreenplum or Teradata appliances as well as on commodity hardware using \nHadoop Distributed File System (HDFS). \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2012, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e45e8984-3536-499a-8b10-e41d432df4b9": {"__data__": {"id_": "e45e8984-3536-499a-8b10-e41d432df4b9", "embedding": null, "metadata": {"page_label": "167", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8fdcccca-be0b-42f3-891c-8ec061c62edc", "node_type": "4", "metadata": {"page_label": "167", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "093a5ed18d597c1a06a9cac81e4b91aa2648626a5739f719b7b9ac55fd3cc134", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 14\nCustomized Approaches for \nAnalysis of Big Data\nIn This Chapter\n\u25b6 New models and approaches evolving to support big data analysis\n\u25b6 Full custom versus semi-custom analysis approaches\n\u25b6 Optimal environment for big data analysis\n\u25b6 Big to small is the goal\nT \nhe beauty of big data is that, theoretically, all the data you need, both \ninside and outside of your company, can be used to drive your analysis. \nIdeally, this means that if you increase the amount or type of data you ana -\nlyze, you can derive new insights from it.\nAs we discuss in Chapters 12 and 13, many tools used to analyze big data are \nan evolution of what\u2019s already out there in the market in terms of business \nintelligence and advanced analysis. These include data-mining software, pre -\ndictive modeling, advanced statistics, and text analytics. As we also mention \nin the previous two chapters, often, vendors have had to rewrite their algo -\nrithms to run this software across new big data infrastructures.\nFigure 14-1 shows the focus of this chapter.\nAccording to some experts in the field, the mind-set around analyzing big \ndata is different than traditional analysis and is one of exploration and experi -\nmentation \u2014 going where the data takes you. While others disagree, the real -\nity is that the big data analytics ecosystem will require some new technology \nplatforms, algorithms, and skill sets to support this kind of analysis \u2014 espe -\ncially when it comes to pushing the envelope in terms of what can be done. \nBecause we are in the early stages of big data usage and adoption, a large \npercentage of the analysis will need to be delivered in the form of \u201ccustom -\nized\u201d or \u201cspecial-purpose\u201d applications. This chapter examines some of these \nchanges and describes how to address them.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1801, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f01d666d-be9b-4c5f-8688-de72965d8e04": {"__data__": {"id_": "f01d666d-be9b-4c5f-8688-de72965d8e04", "embedding": null, "metadata": {"page_label": "168", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ec1a5fb8-2b9d-4d7a-820f-41fab35a5a0c", "node_type": "4", "metadata": {"page_label": "168", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "63d91d00bc1db267ff8fd3061e53a11a3502abec82443932798dd1d1834f3c87", "class_name": "RelatedNodeInfo"}}, "text": "168 Part IV: Analytics and Big Data \n Figure 14-1:  \nLayers of \nthe big data \nreference \narchitecture \nneeded for \ncustomer \nanalysis.\n \nBuilding New Models and Approaches  \nto Support Big Data\nBig data analysis has gotten a lot of hype recently, and for good reason. \nCompanies are excited to be able to access and analyze data that they\u2019ve \nbeen collecting or want to gain insight from, but have not been able to \nmanage or analyze effectively. These companies know that something is \nout there, but until recently, have not been able to mine it. This pushing \nthe envelope on analysis is an exciting aspect of the big data analysis move -\nment. It might involve visualizing huge amounts of disparate data, or it might \ninvolve advanced analyzed streaming at you in real time. It is evolutionary in \nsome respects and revolutionary in others.\nCharacteristics of big data analysis\nSo, what\u2019s different when your company is pushing the envelope with big \ndata analysis? We talk a little bit about this in Chapter 12. We describe that \nthe infrastructure supporting big data analysis is different and algorithms \nhave been changed to be infrastructure aware.\nBig data analysis should be viewed from two perspectives:\n \u2713 Decision-oriented\n \u2713 Action-oriented\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1274, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7129647b-1cf0-487c-9e44-de2edfa1ee4b": {"__data__": {"id_": "7129647b-1cf0-487c-9e44-de2edfa1ee4b", "embedding": null, "metadata": {"page_label": "169", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6274f166-8516-4889-b0f6-c161ba6ed760", "node_type": "4", "metadata": {"page_label": "169", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "99732edc8652dce4591141bae9e0f12e0a37e3e96f44e22143abfb4d31315106", "class_name": "RelatedNodeInfo"}}, "text": "169  Chapter 14: Customized Approaches for Analysis of Big Data\nDecision-oriented analysis is more akin to traditional business intelligence. \nWe look at selective subsets and representations of larger data sources \nand try to apply the results to the process of making business decisions. \nCertainly these decisions might result in some kind of action or process \nchange, but the purpose of the analysis is to augment decision making.\nAction-oriented analysis is used for rapid response, when a pattern emerges \nor specific kinds of data are detected and action is required. We discuss these \nkinds of use cases throughout the book, but here is where the \u201crubber meets \nthe road.\u201d Taking advantage of big data through analysis and causing proactive \nor reactive behavior changes offer great potential for early adopters.\nFinding and utilizing big data by creating analysis applications can hold the \nkey to extracting value sooner rather than later. To accomplish this task, it is \nmore effective to build these custom applications from scratch or by leverag -\ning platforms and/or components. We cover this topic later in this chapter.\nFirst, we look at some of the additional characteristics of big data analysis \nthat make it different from traditional kinds of analysis aside from the three \nVs of volume, velocity, and variety:\n \u2713 It can be programmatic.  One of the biggest changes in terms of analy -\nsis is that in the past you were dealing with data sets you could manu -\nally load into an application and visualize and explore. With big data \nanalysis, you may be faced with a situation where you might start with \nthe raw data that often needs to be handled programmatically  (using \ncode) to manipulate it or to do any kind of exploration because of the \nscale of the data.\n \u2713 It can be data driven.  While many data scientists use a hypothesis-\ndriven approach to data analysis (develop a premise and collect data \nto see whether that premise is correct), you can also use the data to \ndrive the analysis \u2014 especially if you\u2019ve collected huge amounts of it. \nFor example, you can use a machine-learning algorithm (for more on \nmachine learning, see Chapter 12) to do this kind of hypothesis-free \nanalysis.\n \u2713 It can use a lot of attributes.  In the past, you might have been dealing \nwith hundreds of attributes or characteristics of that data source. Now \nyou might be dealing with hundreds of gigabytes of data that consist of \nthousands of attributes and millions of observations. Everything is now \nhappening on a larger scale.\n \u2713 It can be iterative.  More compute power means that you can iterate on \nyour models until you get them the way you want them. Here\u2019s an exam -\nple. Assume that you\u2019re building a model that is trying to find the predic -\ntors for certain customer behaviors associated with certain products. \nYou might start off extracting a reasonable sample of data or connecting \nto where the data resides. You might build a model to test a hypothesis. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3007, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "58bb0c78-54c3-4ddc-9abd-da977406c9d8": {"__data__": {"id_": "58bb0c78-54c3-4ddc-9abd-da977406c9d8", "embedding": null, "metadata": {"page_label": "170", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b5988093-3b8f-4640-8a66-97ba862d7bdb", "node_type": "4", "metadata": {"page_label": "170", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "21c2ec18d3724d874a10ddb3b785cb8697095852d4bd891bc08f98e85dedf72a", "class_name": "RelatedNodeInfo"}}, "text": "170 Part IV: Analytics and Big Data \nWhereas in the past you might not have had that much memory to \nmake your model work effectively, you will need a tremendous amount \nof physical memory to go through the necessary iterations required to \ntrain the algorithm. It may also be necessary to use advanced comput -\ning techniques like natural language processing or neural networks that \nautomatically evolve the model based on learning as more data is added.\n \u2713 It can be quick  to get the compute cycles you need by leveraging a \ncloud-based Infrastructure as a Service.  With Infrastructure as a Service \n(IaaS) platforms like Amazon Cloud Services (ACS), you can rapidly pro -\nvision a cluster of machines to ingest large data sets and analyze them \nquickly.\nNow that you have a better understanding of some of the characteristics, \nlook at some of the means at your disposal for analyzing big data.\nUnderstanding Different Approaches  \nto Big Data Analysis\nIn many cases, big data analysis will be represented to the end user through \nreports and visualizations. Because the raw data can be incomprehensively \nvaried, you will have to rely on analysis tools and techniques to help pres -\nent the data in meaningful ways. Traditionally generated reports are familiar, \nbut they may not be able to provide new insights or create the unanticipated \nfindings decision makers are searching for. Data visualization techniques will \nhelp, but they too will need to be enhanced or supported by more sophisti -\ncated tools to address big data.\nWhile traditional reporting and visualization are familiar, they are insuffi -\ncient, so it will become necessary to create new applications and approaches \nfor analysis of big data. Otherwise, you will be in a holding pattern until ven -\ndors begin to catch up with the demand. Even when they catch up, the result -\ning solution may not do what you need. Early adoption of big data requires \nthe creation of new applications designed to address analysis requirements \nand time frames. Why is this so important? It is important because a well-\nused representation from traditional data analysis will be inadequate.\nThese new applications will fall broadly into two categories: custom (coded \nfrom scratch) or semi-custom (based on frameworks or components). We \nexamine some examples to help understand why and how we can use these \napproaches to make big data more useful in our daily work lives sooner \nrather than later.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2479, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "03e75fce-8874-4085-900d-9ce4c1548e7b": {"__data__": {"id_": "03e75fce-8874-4085-900d-9ce4c1548e7b", "embedding": null, "metadata": {"page_label": "171", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "841382a7-a849-41aa-965d-1df29959ed8d", "node_type": "4", "metadata": {"page_label": "171", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1ba33a18815fa8b59c0c3c198ed39ea660ebef0cd43ae3a4617ccbcd0de03ee0", "class_name": "RelatedNodeInfo"}}, "text": "171  Chapter 14: Customized Approaches for Analysis of Big Data\nCustom applications for big data analysis\nIn general, a custom application is created for a specific purpose or a related \nset of purposes. Certain areas of a business or organization will always \nrequire a custom set of technologies to support unique activities or to pro -\nvide a competitive advantage. For example, if you are involved in financial \nservices, you want your trading applications to be faster and more accurate \nthan your competitors\u2019. In contrast, the applications that do your client bill -\ning probably do not need very much specialization, so a packaged system \ncan do the trick.\nFor big data analysis, the purpose of custom application development is to \nspeed the time to decision or the time to action. As big data evolves as a sci -\nence and a market, software vendors of traditional solutions will be slow to \nbring new technologies to market. Little value exists in a big data infrastruc -\nture if very few opportunities are available to decide or act upon because of \nthe lack of analysis capabilities germane to the business area. As we discuss \nin Chapters 12 and 13, some packages support a wide variety of analysis \ntechniques for big data. The vendors discussed in these chapters can utilize \ntheir technology components to help build solutions for their customers. \nHowever, the reality is that there is no such thing as a completely packaged \napplication that will work out of the box for a sophisticated big data solution. \nWe now examine some additional options that are available for those of us \nwho may need custom analysis applications for big data.\nR environment\nThe \u201cR\u201d environment is based on the \u201cS\u201d statistics and analysis language \ndeveloped in the 1990s by Bell Laboratories. It is maintained by the GNU proj -\nect and is available under the GNU license. Over the years, many users of S \nand R have contributed greatly to the base system, enhancing and expanding \nits capabilities. While challenging to fully comprehend, its depth and flex -\nibility make it a compelling choice for analytics application developers and \n\u201cpower users.\u201d In addition, the CRAN (Comprehensive R Archive Network) \nR project maintains a worldwide set of File Transfer Protocol (FTP) and web \nservers with the most up-to-date versions of the R environment. A commer -\ncially supported, enterprise version of R is also available from Revolution \nAnalytics in Palo Alto, California ( www.revolution-computing.com ).\nMore specifically, R is an integrated suite of software tools and technologies \ndesigned to create custom applications used to facilitate data manipulation, \ncalculation, analysis, and visual display. Among other advanced capabilities, \nit supports\n \u2713 Effective data-handling and manipulation components.\n \u2713 Operators for calculations on arrays and other types of ordered data.\n \u2713 Tools specific to a wide variety of data analyses.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2952, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8961b22d-5941-48f4-9607-020ce16e89ce": {"__data__": {"id_": "8961b22d-5941-48f4-9607-020ce16e89ce", "embedding": null, "metadata": {"page_label": "172", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9d4c54b0-b6dc-4732-837d-cc255eff7b54", "node_type": "4", "metadata": {"page_label": "172", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "097cdaf4661d97d1aaf115c3d4242148d7647732c8f7ffa2731fa8df85825ee4", "class_name": "RelatedNodeInfo"}}, "text": "172 Part IV: Analytics and Big Data \n \u2713 Advanced visualization capabilities.\n \u2713 S programming language designed by programmers, for programmers \nwith many familiar constructs, including conditionals, loops, user-\ndefined recursive functions, and a broad range of input and output facili -\nties. Most of the system-supplied functions are written in the S language.\nR is a vehicle for developing new methods of interactive big data analysis. It \nhas developed rapidly and has been extended by a large collection of pack -\nages.  It is well suited to single-use, custom applications for analysis of big \ndata sources.\nGoogle Prediction API\nThe Google Prediction API is an example of an emerging class of big data \nanalysis application tools. It is available on the Google developers website \nand is well documented and provided with several mechanisms for access \nusing different programming languages. To help you get started, it is freely \navailable (with some restrictions) for six months. Subsequent licensing is \nvery modest and project based.\nThe Prediction API is fairly simple. It looks for patterns and matches them to \nproscriptive, prescriptive, or other existing patterns. While performing its pat -\ntern matching, it also \u201clearns.\u201d In other words, the more you use it, the smarter \nit gets. What kinds of things could you \u201clearn\u201d from using the Prediction API? \nSuppose that you wanted to understand consumer behavior. You might want \nto source postings from Facebook, Twitter, Amazon, and/or foursquare social \nsites looking for specific patterns of behavior. If you are a consumer products \ncompany, you might want to suggest new or existing products based on the \ninformation on the social sites. If you are a Hollywood production company, \nyou might want to notify people of a new movie with one of their favorite stars. \nThe Prediction API gives you the opportunity to predict (or even encourage) \nfuture behaviors by analyzing habits and prior actions.\nPrediction is implemented as a RESTful API with language support for .NET, \nJava, PHP, JavaScript, Python, Ruby, and many others. Google also provides \nscripts for accessing the API as well as a client library for R.\nPredictive analysis is one of the most powerful potential capabilities of big \ndata, and the Google Prediction API is a very useful tool for creating custom \napplications.\nAs big data evolves, many new types of custom application tools will be \nintroduced to the market. Some may resemble R, and others (like Google \nPrediction API) will be introduced as APIs or libraries that programmers can \nuse to create new ways to compute and analyze big data. In the real world, \nmany people do not have software developers available to code custom \napplications. Fortunately, some other means are available and emerging that \nyou can use to address the needs of analysis users.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2874, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7e1f9f87-5da4-4c9c-a71d-cd5ac6a62938": {"__data__": {"id_": "7e1f9f87-5da4-4c9c-a71d-cd5ac6a62938", "embedding": null, "metadata": {"page_label": "173", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f090516-cc06-4f9c-81ea-01d59ede926c", "node_type": "4", "metadata": {"page_label": "173", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "588a2350c45938dc5abf33f5e95fd9fe2756a23730efa8eaca75b85d37824077", "class_name": "RelatedNodeInfo"}}, "text": "173  Chapter 14: Customized Approaches for Analysis of Big Data\nSemi-custom applications  \nfor big data analysis\nIn truth, what many people perceive as custom applications are actually \ncreated using \u201cpackaged\u201d or third-party components like libraries. It is not \nalways necessary to completely code a new application. (When it is neces -\nsary, no substitute exists.) Using packaged applications or components \nrequires developers or analysts to write code to \u201cknit together\u201d these compo -\nnents into a working custom application. The following are reasons why this \nis a sound approach:\n \u2713 Speed to deployment:  Because you don\u2019t have to write every part of the \napplication, the development time can be greatly reduced.\n \u2713 Stability:  Using well-constructed, reliable, third-party components can \nhelp to make the custom application more resilient.\n \u2713 Better quality:  Packaged components are often subject to higher qual -\nity standards because they are deployed into a wide variety of environ -\nments and domains.\n \u2713 More flexibility:  If a better component comes along, it can be swapped \ninto the application, extending the lifetime, adaptability, and usefulness \nof the custom application. \nAnother type of semi-custom application is one where the source code is \navailable and is modified for a particular purpose. This can be an efficient \napproach because there are quite a few examples of application building \nblocks available to incorporate into your semi-custom application. Some of \nthese include:\n \u2713 TA-Lib:  The Technical Analysis library is used extensively by software \ndevelopers who need to perform technical analysis of financial market \ndata. It is available as open source under the BSD license, allowing it to \nbe integrated into semi-custom applications.\n \u2713 JUNG:  The Java Universal Network Graph framework is a library that \nprovides a common framework for analysis and visualization of data that \ncan be represented by a graph or network. It is useful for social network \nanalysis, importance measures (PageRank, hits), and data mining. It is \navailable as open source under the BSD license.\n \u2713 GeoTools:  An open source geospatial toolkit for manipulating GIS data in \nmany forms, analyzing spatial and non-spatial attributes or GIS data, and \ncreating graphs and networks of the data. It is available under the GPL2 \nlicense, allowing for integration into semi-custom applications.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2431, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5737c67e-8da9-45c7-b52c-e1e481649bca": {"__data__": {"id_": "5737c67e-8da9-45c7-b52c-e1e481649bca", "embedding": null, "metadata": {"page_label": "174", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cb8673c3-84a7-4c6f-97bd-aeb3e932c3cb", "node_type": "4", "metadata": {"page_label": "174", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "9dd61aef137af6a50037fa5114aeb07b9a3cf272ac1842a9f881d33cb4c0aa04", "class_name": "RelatedNodeInfo"}}, "text": "174 Part IV: Analytics and Big Data \nThe velocity of big data, coupled with its variety, will cause a move toward \nreal-time observations, allowing better decision making or quick action. As \nthe market evolves, it is likely that most of these observations will be the \nresult of custom applications designed to augment the ability to react to \nchanges in the environment. Analysis frameworks and components will help \nto create, modify, share, and maintain these applications with greater ease \nand efficiency.\nCharacteristics of a Big Data  \nAnalysis Framework\nEven though new sets of tools continue to be available to help you manage \nand analyze big data more effectively, you may not be able to get what you \nneed from what\u2019s already out there. In addition, a range of technologies that \nwe talk about earlier in this book can support big data analysis and also sup -\nport requirements such as availability, scalability, and high performance. \nSome of these technologies include big data appliances, columnar databases, \nin-memory databases, nonrelational databases, and massively parallel pro -\ncessing engines. Chapters 1, 4, and 7 cover these topics in more detail.\nSo, what are business users looking for when it comes to big data analysis? \nThe answer to that question depends on the type of business problem they \nare trying to solve. Earlier in the chapter, we discuss decision orientation \nand action orientation as two broad types of business challenges. Many of \nthe characteristics are common to both, and because decisions often lead \nto actions, the commonality is required. Some important considerations \nyou need to take in as you select a big data application analysis framework \ninclude the following:\n \u2713 Support for multiple data types:  Many organizations are incorporat -\ning, or expect to incorporate, all types of data as part of their big data \ndeployments, including structured, semi-structured, and unstructured \ndata.Going mobile\nIt is true that many (if not all) mobile applica -\ntions are custom. Some third-party package \nproviders offer mobile access, often through a \nmobile application, but they are generally not \nuseful outside the providers\u2019 interests. As a result, many of the emerging custom compo -\nnent developers are delivering technology that \ncan help create mobile applications for big data \nmore easily.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2371, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "47370352-5441-4135-acc5-72b775e007c5": {"__data__": {"id_": "47370352-5441-4135-acc5-72b775e007c5", "embedding": null, "metadata": {"page_label": "175", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b3068d4d-5c3a-43a1-a0c0-cb6bbcf7c4f9", "node_type": "4", "metadata": {"page_label": "175", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "0c49f02544910b52514573d709afc54b4d7bd2ac8f435510a22af5627d95df38", "class_name": "RelatedNodeInfo"}}, "text": "175  Chapter 14: Customized Approaches for Analysis of Big Data\n \u2713 Handle batch processing and/or real time data streams:  Action orienta -\ntion is a product of analysis on real-time data streams, while decision \norientation can be adequately served by batch processing. Some users \nwill require both, as they evolve to include varying forms of analysis.\n \u2713 Utilize what already exists in your environment:  To get the right con -\ntext, it may be important to leverage existing data and algorithms in the \nbig data analysis framework.\n \u2713 Support NoSQL and other newer forms of accessing data:  While organi -\nzations will continue to use SQL, many are also looking at newer forms  \nof data access to support faster response times or faster times to  \ndecision.\n \u2713 Overcome low latency:  If you\u2019re going to be dealing with high data \nvelocity, you\u2019re going to need a framework that can support the require -\nments for speed and performance.\n \u2713 Provide cheap storage:  Big data means potentially lots of storage \u2014 \ndepending on how much data you want to process and/or keep. This \nmeans that storage management and the resultant storage costs are \nimportant considerations.\n \u2713 Integrate with cloud deployments:  The cloud can provide storage and \ncompute capacity on demand. More and more companies are using the \ncloud as an analysis \u201csandbox.\u201d Increasingly, the cloud is becoming an \nimportant deployment model to integrate existing systems with cloud \ndeployments (either public or private) in a hybrid model. In addition, \nbig data cloud services are beginning to emerge that will benefit custom -\ners. For more on this issue, check out Chapter 11.\nWhile all these characteristics are important, the perceived and actual value \nof creating applications from a framework is quicker time to deployment. \nWith all these capabilities in mind, we look at an example of a big data analy -\nsis application framework from a company called Continuity.\nThe Continuity AppFabric ( www.continuity.com ) is a framework support -\ning the development and deployment of big data applications. Deployment \ncan be as a single instance, private cloud, or public cloud, without any recod -\ning required for the target environment. The AppFabric itself is a set of tech -\nnologies specifically designed to abstract away the vagaries of low-level big \ndata technologies. The application builder is an Eclipse plug-in permitting the \ndeveloper to build, test, and debug locally and in familiar surroundings.\nAppFabric capabilities include the following:\n \u2713 Stream support for real-time analysis and reaction\n \u2713 Unified API, eliminating the need to write to big data infrastructures\n \u2713 Query interfaces for simple results and support for pluggable query  \nprocessors\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2763, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "26388164-d4fc-42e9-98de-70738d4e0654": {"__data__": {"id_": "26388164-d4fc-42e9-98de-70738d4e0654", "embedding": null, "metadata": {"page_label": "176", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "03d3bbfc-eef0-42d7-a04c-b3c291dc4195", "node_type": "4", "metadata": {"page_label": "176", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "762270ed700012bb2a610e8986231d0c857a3c50441852860277c67260576ef9", "class_name": "RelatedNodeInfo"}}, "text": "176 Part IV: Analytics and Big Data \n \u2713 Data sets representing queryable data and tables accessible from the \nUnified API\n \u2713 Reading and writing of data independent of input or output formats or \nunderlying component specifics (such as Hadoop data operations)\n \u2713 Transaction-based event processing\n \u2713 Multimodal deployment to a single node or the cloud\nThis approach is going to gain traction for big data application develop -\nment primarily because of the plethora of tools and technologies required to \ncreate a big data environment. If a developer can write to a higher-level API, \nrequiring that the \u201cfabric\u201d or abstraction layer manage the specifics of the \nunderlying components, you should expect high-quality, reliable applications \nthat can be easily modified and deployed.\n It is a rare company that can afford to build a big data analysis capability from \nscratch. Therefore, it is best to think about your big data deployment as an \necosystem of people, processes, and technologies. Big data analysis is not an \nisland. It is connected to many other data environments and business process \nenvironments throughout your enterprise. Even though these are the early \ndays in the big data movement and many projects are experimenting with big \ndata analysis in isolation from their overall computing environment, you need \nto think about integration as a requirement. As big data analysis becomes \nmore mainstream, it should remain isolated from the rest of the data manage -\nment environment.\nSoftware developers seldom work in isolation. Likewise, data scientists and \nanalysis experts like to share discoveries and leverage existing assets. The \nneed to collaborate and share is even more pronounced in an emerging tech -\nnology area. In fact, the lack of collaboration can be costly in many ways. \nLarge organizations can benefit from tools that drive collaborations. Very \noften people doing similar work are unaware of each other\u2019s efforts leading to \nduplicate work (or worse!). This is costly in terms of money and productivity. \nJump-starting a project with existing solutions can make a difference in qual -\nity and time-to-market. \nAnother good example of an application framework is OpenChorus ( www.\nopenchorus.org ). In addition to rapid development of big data analysis \napplications, it also supports collaboration and provides many other features \nimportant to software developers, like tool integration, version control, and \nconfiguration management.\nOpen Chorus is a project maintained by EMC Corporation and is available \nunder the Apache 2.0 license. EMC also produces and supports a commercial \nversion of Chorus. Both Open Chorus and Chorus have vibrant partner net -\nworks as well as a large set of individual and corporate contributors.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2790, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2922dbdb-578f-4fe9-bbaa-313cb221ec19": {"__data__": {"id_": "2922dbdb-578f-4fe9-bbaa-313cb221ec19", "embedding": null, "metadata": {"page_label": "177", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "317095a3-46d1-4447-b2fa-9476cde3113f", "node_type": "4", "metadata": {"page_label": "177", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "6f4def721dbf38356b69479bb0a06a7a2b20f0cdad1730a154064d5c37125efb", "class_name": "RelatedNodeInfo"}}, "text": "177  Chapter 14: Customized Approaches for Analysis of Big Data\nOpen Chorus is a generic framework. Its leading feature is the capability to \ncreate a communal \u201chub\u201d for sharing big data sources, insights, analysis tech -\nniques, and visualizations. Open Chorus provides the following:\n \u2713 Repository of analysis tools, artifacts, and techniques with complete \nversioning, change tracking, and archiving\n \u2713 Workspaces and sandboxes that are self-provisioned and easily main -\ntained by community members\n \u2713 Visualizations, including heat maps, time series, histograms, and so on\n \u2713 Federated search of any and all data assets, including Hadoop, meta -\ndata, SQL repositories, and comments\n \u2713 Collaboration through social networking\u2013like features encouraging dis -\ncovery, sharing, and brainstorming\n \u2713 Extensibility for integration of third-party components and technologies\nAs big data evolves, you will see the introduction of new kinds of application \nframeworks. Many of these will support mobile application development, \nwhile others will address vertical application areas. In any case, they are an \nimportant tool for early adopters of big data.\nBig to Small: A Big Data Paradox\nYou\u2019ll find a nuance about big data analysis. It\u2019s really about small data. \nWhile this may seem confusing and counter to the whole premise of this \nbook, small data is the product of big data analysis. This is not a new con -\ncept, nor is it unfamiliar to people who have been doing data analysis for any \nlength of time. The overall working space is larger, but the answers lie some -\nwhere in the \u201csmall.\u201d\nTraditional data analysis began with databases filled with customer informa -\ntion, product information, transactions, telemetry data, and so on. Even then, \ntoo much data was available to efficiently analyze. Systems, networks, and \nsoftware didn\u2019t have the performance or capacity to address the scale. As an \nindustry, we addressed the shortcomings by creating smaller data sets.\nThese smaller data sets were still fairly substantive, and we quickly discov -\nered other shortcomings; the most glaring was the mismatch between the \ndata and the working context. If you worked in Accounts Payable, you had to \nlook at a large amount of unrelated data to do your job. Again, the industry \nresponded by creating smaller, contextually relevant data sets \u2014 big to small \nto smaller still.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2399, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aa956ec2-3e27-4b9e-a902-6746361f27ee": {"__data__": {"id_": "aa956ec2-3e27-4b9e-a902-6746361f27ee", "embedding": null, "metadata": {"page_label": "178", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "56b692a4-4121-4598-a50b-f15ce6370fe5", "node_type": "4", "metadata": {"page_label": "178", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "835cbb53c5a8ed831305d14ab3aa6a73f4e7bc83121f15ef428730f3819df52e", "class_name": "RelatedNodeInfo"}}, "text": "178 Part IV: Analytics and Big Data \nYou may recognize this as the migration from databases to data warehouses \nto data marts. More often than not, the data for the warehouses and the \nmarts was chosen on arbitrary or experimental parameters resulting in a \ngreat deal of trial and error. We weren\u2019t getting the perspectives we needed \nor were possible because the capacity reductions weren\u2019t based on computa -\ntional fact.\nEnter big data, with all its volumes, velocities, and varieties, and the problem \nremains or perhaps worsens. We have addressed the shortcomings of the \ninfrastructure and can store and process huge amounts of additional data, \nbut we also had to introduce new technologies specifically to help us manage \nbig data.\nDespite the outward appearances, this is a wonderful thing. Today and in the \nfuture, we will have more data than we can imagine and we\u2019ll have the means \nto capture and manage it. What is more necessary than ever is the capability \nto analyze the right  data in a timely enough fashion to make decisions and \ntake actions. We will still shrink the data sets into \u201cfighting trim,\u201d but we can \ndo so computationally. We process the big data and turn it into small data so \nthat it\u2019s easier to comprehend. It\u2019s more precise and, because it was derived \nfrom a much larger starting point, it\u2019s more contextually relevant.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1378, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "684377bf-4b23-477d-9140-be0e72412887": {"__data__": {"id_": "684377bf-4b23-477d-9140-be0e72412887", "embedding": null, "metadata": {"page_label": "179", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4b4df9f8-8086-4cae-9a19-ff2b1ca4d1df", "node_type": "4", "metadata": {"page_label": "179", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "9fc0e0e5bf3edfe95f8b37d48c448b2ffc6b30bb30c61810b4d7d86e6d7104d2", "class_name": "RelatedNodeInfo"}}, "text": "Part V\nBig Data Implementation\nOutput Manager\n Bone up on the best practices of big data integration online at www.dummies.com/\nextras/bigdata .\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 163, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "54fffd8f-d07e-4f9c-810c-a35f16227ffb": {"__data__": {"id_": "54fffd8f-d07e-4f9c-810c-a35f16227ffb", "embedding": null, "metadata": {"page_label": "180", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2d77bafc-963c-4325-87bc-45f8befa7d81", "node_type": "4", "metadata": {"page_label": "180", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "cd7436deae37dabe0a18aafe3aea2cea320116926538b300c5ea57044794be4a", "class_name": "RelatedNodeInfo"}}, "text": "In this part . . .\n \u2713 Identify and integrate the right data for your big data \nimplementation.\n \u2713 Determine the accuracy of your results.\n \u2713 Use streaming data.\n \u2713 Understand complex event processing.\n \u2713 Operationalize big data.\n \u2713 Design an implementation road map for big data.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 298, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9a1306c5-7607-4931-b7b4-e0144a3892e7": {"__data__": {"id_": "9a1306c5-7607-4931-b7b4-e0144a3892e7", "embedding": null, "metadata": {"page_label": "181", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "583118d2-406f-44a0-9b3d-4596e26559fb", "node_type": "4", "metadata": {"page_label": "181", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "4c1e08ac70146e8e96229572d8849fc6389214ee755dde9079925c5bd6e56bf8", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 15\nIntegrating Data Sources\nIn This Chapter\n\u25b6 Identifying the data you need\n\u25b6 Understanding the fundamentals of big data integration\n\u25b6 Using Hadoop as ETL\n\u25b6 Knowing best practices for data integration\nT \no get the most business value from big data, it needs to be integrated \ninto your business processes. How can you take action based on your \nanalysis of big data unless you can understand the results in context with \nyour operational data? Differentiating your company as a result of making \ngood business decisions depends on many factors. One factor that is \nbecoming increasingly important is your capability to integrate internal \nand external data sources comprised of both traditional relational data and \nnewer forms of unstructured data. While this may seem like a daunting task, \nthe reality is that you probably already have a lot of experience with data \nintegration. Don\u2019t toss aside everything you have learned about delivering \ndata as a trusted source to your organization. You will want to place a high \npriority on data quality as you move to make big data analytics actionable. \nHowever, to bring your big data environments and enterprise data environ -\nments together, you will need to incorporate new methods of integration that \nsupport Hadoop and other nontraditional big data environments.\nTwo major categories of big data integration are covered in this chapter: the \nintegration of multiple big data sources in big data environments and the \nintegration of unstructured big data sources with structured enterprise data. \nWe cover the traditional forms of integration such as extract, transform, and \nload (ETL) and new solutions designed for big data platforms.\nIdentifying the Data You Need\nBefore you can begin to plan for integration of your big data, you need to \ntake stock of the type of data you are dealing with. Many organizations are \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1900, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "648ab0c4-ebff-4b59-b30c-d496d26e6fb1": {"__data__": {"id_": "648ab0c4-ebff-4b59-b30c-d496d26e6fb1", "embedding": null, "metadata": {"page_label": "182", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c234d193-a6cc-46f6-b6cc-f86604bf6462", "node_type": "4", "metadata": {"page_label": "182", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "baf2472368364ea72603d5fdd5b6cb8a626bc7703e008f2c9be641f043b4ae02", "class_name": "RelatedNodeInfo"}}, "text": "182 Part V: Big Data Implementation \nrecognizing that a lot of internally generated data has not been used to its full \npotential in the past. By leveraging new tools, organizations are gaining new \ninsight from previously untapped sources of unstructured data in e-mails, \ncustomer service records, sensor data, and security logs. In addition, much \ninterest exists in looking for new insight based on analysis of data that is  \nprimarily external to the organization, such as social media, mobile phone \nlocation, traffic, and weather.\nYour analysis may require that you bring several of these big data sources \ntogether. To complete your analysis, you need to move large amounts of data \nfrom log files, Twitter feeds, RFID tags, and weather data feeds and integrate \nall these elements across highly distributed data systems. After you complete \nyour analysis, you may need to integrate your big data with your operational \ndata. For example, healthcare researchers explore unstructured information \nfrom patient records in combination with traditional medical record patient \ndata such as test results to begin improving patient care and improving  \nquality of care. Big data sources like information from medical devices and \nclinical trials may be incorporated into the analysis as well.\nAs you begin your big data analysis, you probably do not know exactly what \nyou will find. Your analysis will go through several stages. You may begin \nwith petabytes of data, and as you look for patterns, you may narrow your \nresults. The following three stages are described in more detail:\n \u2713 Exploratory stage\n \u2713 Codifying stage\n \u2713 Integration and incorporation stage\nExploratory stage\nIn the early stages of your analysis, you will want to search for patterns in the \ndata. It is only by examining very large volumes (terabytes and petabytes) \nof data that new and unexpected relationships and correlations among ele -\nments may become apparent. These patterns can provide insight into cus -\ntomer preferences for a new product, for example. You will need a platform \nsuch as Hadoop for organizing your big data to look for these patterns.\nAs described in Chapters 9 and 10, Hadoop is widely used as an underlying \nbuilding block for capturing and processing big data. Hadoop is designed \nwith capabilities that speed the processing of big data and make it possible \nto identify patterns in huge amounts of data in a relatively short time. The \ntwo primary components of Hadoop \u2014 Hadoop Distributed File System \n(HDFS) and MapReduce \u2014 are used to manage and process your big data. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2600, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "756f9485-3d82-4ba1-8a75-040c7c21e68b": {"__data__": {"id_": "756f9485-3d82-4ba1-8a75-040c7c21e68b", "embedding": null, "metadata": {"page_label": "183", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b3027740-f03c-47f2-9d90-c6741c1cdaf3", "node_type": "4", "metadata": {"page_label": "183", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1c0b0eb4a56cfedb3cb7b4063180e017f1eb222f55e05e03df9bad7ef5497771", "class_name": "RelatedNodeInfo"}}, "text": "183  Chapter 15: Integrating Data Sources\nIn the exploratory stage, you are not so concerned about integration with \noperational data. That will come later.\nUsing FlumeNG for big data integration\nHowever, one type of integration is critical during the exploratory stage. It is \noften necessary to collect, aggregate, and move extremely large amounts of \nstreaming data to search for hidden patterns in big data. Traditional integra -\ntion tools such as ETL would not be fast enough to move the large streams of \ndata in time to deliver results for analysis such as real-time fraud detection. \nFlumeNG (a more advanced version of the original Flume) loads data in real \ntime by streaming your data into Hadoop.\nTypically, Flume is used to collect large amounts of log data from distrib -\nuted servers. It keeps track of all the physical and logical nodes in a Flume \ninstallation. Agent nodes are installed on the servers and are responsible for \nmanaging the way a single stream of data is transferred and processed from \nits beginning point to its destination point. In addition, collectors are used to \ngroup the streams of data into larger streams that can be written to a Hadoop \nfile system or other big data storage container. Flume is designed for scalabil -\nity and can continually add more resources to a system to handle extremely \nlarge amounts of data in an efficient way. Flume\u2019s output can be integrated \nwith Hadoop and Hive for analysis of the data. Flume also has transformation \nelements to use on the data and can turn your Hadoop infrastructure into a \nstreaming source of unstructured data.\nLooking for patterns in big data\nYou find many examples of companies beginning to realize competitive \nadvantages from big data analytics. For many companies, social media data \nstreams are increasingly becoming an integral component of a digital market -\ning strategy. For example, Wal-Mart analyzes customer location-based data, \ntweets, and other social media streams to make more targeted product rec -\nommendations for customers and to tailor in-store product selection to cus -\ntomer demand. Wal-Mart acquired social media company Kosmix in 2011 to \ngain access to its technology platform for searching and analyzing real-time \ndata streams. In the exploratory stage, this technology can be used to rapidly \nsearch through huge amounts of streaming data and pull out the trending \npatterns that relate to specific products or customers. The results can be \nused to optimize inventory based on the likes and dislikes of shoppers near a \nspecific geographic location.\nAs companies search for patterns in big data, the huge data volumes are nar -\nrowed down as if they are passed through a funnel. You may start with petabytes \nof data and then, as you look for data with similar characteristics or data that \nforms a particular pattern, you eliminate data that does not match up.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2914, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "08138a5e-c66a-417f-b4b5-d812f6ee4513": {"__data__": {"id_": "08138a5e-c66a-417f-b4b5-d812f6ee4513", "embedding": null, "metadata": {"page_label": "184", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9e9d71c9-1366-4ec9-a85a-ac5e85d413c0", "node_type": "4", "metadata": {"page_label": "184", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f546f1587d677cbdbb22d3f53e1b1bb3e4eb7060facce49de120a1f6914ca9f4", "class_name": "RelatedNodeInfo"}}, "text": "184 Part V: Big Data Implementation \nCodifying stage\nTo make the leap from identifying a pattern to incorporating this trend into \nyour business process needs some sort of process to follow. For example, if \na large retailer monitors social media and identifies lots of chatter about an \nupcoming college football event near one of its stores, how will the company \nmake use of this information? With hundreds of stores and many thousands of \ncustomers, you need a repeatable process to make the leap from pattern iden -\ntification to implementation of new product selection and more targeted mar -\nketing. With a process in place, the retailer can quickly take action and stock \nthe local store with clothing and accessories with the team logo. After you find \nsomething interesting in your big data analysis, you need to codify it and make \nit a part of your business process. You need to make the connection between \nyour big data analytics and your inventory and product systems.\nTo codify the relationship between your big data analytics and your opera -\ntional data, you need to integrate the data.\nIntegration and incorporation stage\nBig data is having a major impact on many aspects of data management, \nincluding data integration. Traditionally, data integration has focused on the \nmovement of data through middleware, including specifications on message \npassing and requirements for application programming interfaces (APIs). \nThese concepts of data integration are more appropriate for managing data \nat rest rather than data in motion. The move into the new world of unstruc -\ntured data and streaming data changes the conventional notion of data \nintegration. If you want to incorporate your analysis of streaming data into \nyour business process, you need advanced technology that is fast enough to \nenable you to make decisions in real time. One important goal with big data \nanalytics is to look for patterns that apply to your business and narrow down \nthe data set based on business context. Therefore, the analysis of big data \nis only one step in your implementation. After your big data analysis is com -\nplete, you need an approach that will allow you to integrate or incorporate \nthe results of your big data analysis into your business process and real-time \nbusiness actions. \nCompanies have high expectations for gaining real business value from big \ndata analysis. In fact, many companies would like to begin a deeper analysis \nof internally generated big data, such as security log data, that was not previ -\nously possible due to technology limitations. Technologies for high-speed \ntransport of very large and fast data are a requirement for integrating across \ndistributed big data sources and between big data and operational data. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2785, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "79242a63-bfdd-4135-9800-79022e60bf69": {"__data__": {"id_": "79242a63-bfdd-4135-9800-79022e60bf69", "embedding": null, "metadata": {"page_label": "185", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "17b5f466-f8b1-4e2b-8df2-563e1ccc7110", "node_type": "4", "metadata": {"page_label": "185", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "bb3daffd6efaba8dc90944771cf605aaa9d2c24c63c98ed2e5e894d69510b1b9", "class_name": "RelatedNodeInfo"}}, "text": "185  Chapter 15: Integrating Data Sources\nUnstructured data sources often need to be moved quickly over large geo -\ngraphic distances for the sharing and collaboration required in everything \nfrom major scientific research projects to development and delivery of con -\ntent for the entertainment industry.\nFor example, scientific researchers typically work with very large data sets. \nResearchers share data and collaborate more easily than in the past by \nusing a combination of big data analytics and the cloud. One example of a \nlarge data set shared by scientific researchers across the world is the 1000 \nGenomes Project. Disease researches study the human genome to identify \nand compile variations to help understand and treat diseases. The data for \nthe 1000 Genomes Project \u2014 the largest and most detailed catalog of human \ngenetic variation in the world \u2014 is maintained on Amazon Web Services \n(AWS). The data is made available to the international scientific research \ncommunity. AWS is able to support the transfer of very large files at fast \nspeeds over the Internet (700 megabytes per second) using technology by \nAspera. Aspera provides high-speed file transport technology called fasp. \nThis software transfers big data at speeds that are many times faster than \nTCP-based file transfer technologies like FTP and HTTP. This speed can be \nguaranteed with very large file sizes and long distances, and across geo -\ngraphic boundaries.\nLinking traditional sources with big data is a multistaged process after you \nhave looked at all the data from streaming big data sources and identified the \nrelevant patterns. You may not have known what you were looking for when \nyou started, but now you have some important information for your busi -\nness. As you move from the exploratory stage and get closer to the real busi -\nness problem, you need to begin thinking about metadata and rules and the \nstructure of the data. After narrowing the amount of data you need to manage \nand analyze, now you need to think about integration.\nA company that uses big data to predict customer interest in new products \nneeds to make a connection between the big data and the operational data \non customers and products to take action. If the company wants to use this \ninformation to buy new products or change pricing or manage inventory, it \nneeds to integrate its operational data with the results of its big data analy -\nsis. The retail industry is one market where companies are beginning to use \nbig data analytics to deepen its relationship with customers and create more \npersonalized and targeted offers. Integration of big data and operational data \nis key to the success of these efforts. For example, consider a customer who \nregisters on a retailer\u2019s website, providing her mobile number and e-mail \naddress. Today, the customer receives e-mails about sales and coupon incen -\ntives to make purchases in the store or online. In the future, retailers are \nplanning to use location-based services from the customer\u2019s mobile device \nto identify where the customer is located in the store and send a text mes -\nsage with a coupon for immediate use in that department. In other words, a \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3211, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "08d773ff-9bbb-4985-ac2f-afaa12f5dc74": {"__data__": {"id_": "08d773ff-9bbb-4985-ac2f-afaa12f5dc74", "embedding": null, "metadata": {"page_label": "186", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9fd6f81e-fe19-4479-9266-e57be6951284", "node_type": "4", "metadata": {"page_label": "186", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e56a325d3378c03941bab1ea048f652f86869c9aed6c6e0ff4ade97225bbe2ed", "class_name": "RelatedNodeInfo"}}, "text": "186 Part V: Big Data Implementation \ncustomer might walk into the entertainment section of the store and receive \na text message for a discount on the purchase of a Blu-ray disc player. To do \nthis, the retailer needs real-time integration of big data feeds (location-based \ninformation) with operational data on customer history and in-store inven -\ntory. The analysis needs to take place immediately, and communication with \nthe customer needs to happen at the same time. Even a delay of ten minutes \nmay be too long, and the moment of customer interaction will be lost.\nUnderstanding the Fundamentals  \nof Big Data Integration\nThe elements of the big data platform manage data in new ways as compared \nto the traditional relational database. This is because of the need to have \nthe scalability and high performance required to manage both structured \nand unstructured data. Components of the big data ecosystem ranging from \nHadoop to NoSQL DB, MongoDB, Cassandra, and HBase all have their own \napproach for extracting and loading data. As a result, your teams may need \nto develop new skills to manage the integration process across these plat -\nforms. However, many of your company\u2019s data management best practices \nwill become even more important as you move into the world of big data.\nWhile big data introduces a new level of integration complexity, the basic fun -\ndamental principles still apply. Your business objective needs to be focused \non delivering quality and trusted data to the organization at the right time \nand in the right context. To ensure this trust, you need to establish common \nrules for data quality with an emphasis on accuracy and completeness of \ndata. In addition, you need a comprehensive approach to developing enter -\nprise metadata, keeping track of data lineage and governance to support  \nintegration of your data.\nAt the same time, traditional tools for data integration are evolving to handle \nthe increasing variety of unstructured data and the growing volume and \nvelocity of big data. While traditional forms of integration take on new mean -\nings in a big data world, your integration technologies need a common plat -\nform that supports data quality and profiling.\nTo make sound business decisions based on big data analysis, this informa -\ntion needs to be trusted and understood at all levels of the organization. \nWhile it will probably not be cost or time effective to be overly concerned \nwith data quality in the exploratory stage of a big data analysis, eventu -\nally quality and trust must play a role if the results are to be incorporated \nin the business process. Information needs to be delivered to the business \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2692, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d338d7c4-e3af-4640-8944-ce147fd80895": {"__data__": {"id_": "d338d7c4-e3af-4640-8944-ce147fd80895", "embedding": null, "metadata": {"page_label": "187", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "26e6bb9d-c06b-436c-b549-13da6c371087", "node_type": "4", "metadata": {"page_label": "187", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "bb50998b00f29c06f6ac622adf7196898e274efea05df7f517b5db0746517966", "class_name": "RelatedNodeInfo"}}, "text": "187  Chapter 15: Integrating Data Sources\nin a trusted, controlled, consistent, and flexible way across the enterprise, \nregardless of the requirements specific to individual systems or applications. \nTo accomplish this goal, three basic principles apply:\n \u2713 You must create a common understanding of data definitions.  At the \ninitial stages of your big data analysis, you are not likely to have the \nsame level of control over data definitions as you do with your opera -\ntional data. However, once you have identified the patterns that are \nmost relevant to your business, you need the capability to map data ele -\nments to a common definition. That common definition is then carried \nforward into operational data, data warehouses, reporting, and business \nprocesses. \n \u2713 You must develop of a set of data services to qualify the data and \nmake it consistent and ultimately trustworthy.  When your unstructured \nand big data sources are integrated with structured operational data, \nyou need to be confident that the results will be meaningful.\n \u2713 You need a streamlined way to integrate your big data sources and \nsystems of record. In order to make good decisions based on the results \nof your big data analysis, you need to deliver information at the right \ntime and with the right context. Your big data integration process \nshould ensure consistency and reliability. \nTo integrate data across mixed application environments, you need to get \ndata from one data environment (source) to another data environment \n(target). Extract, transform, and load (ETL) technologies have been used to \naccomplish this in traditional data warehouse environments. The role of ETL \nis evolving to handle newer data management environments like Hadoop. In \na big data environment, you may need to combine tools that support batch \nintegration processes (using ETL) with real-time integration and federation \nacross multiple sources. For example, a pharmaceutical company may need \nto blend data stored in its Master Data Management (MDM) system with big \ndata sources on medical outcomes of customer drug usage. Companies use \nMDM to facilitate the collecting, aggregating, consolidating, and delivering \nof consistent and reliable data in a controlled manner across the enterprise. \nIn addition, new tools like Sqoop and Scribe are used to support integration \nof big data environments. You also find an increasing emphasis on using \nextract, load, and transform (ELT) technologies. These technologies are \ndescribed next.\nDefining Traditional ETL\nETL tools combine three important functions required to get data from one \ndata environment and put it into another data environment. Traditionally, \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2708, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "28095953-bc85-42cd-9ddb-eb96412f7e2a": {"__data__": {"id_": "28095953-bc85-42cd-9ddb-eb96412f7e2a", "embedding": null, "metadata": {"page_label": "188", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "baf650c7-2a9b-4405-a815-61c8cc71b30f", "node_type": "4", "metadata": {"page_label": "188", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d2788191214e13a0ca4d8acfab1b9808458ffd9f4e479209d68cf26b419b1f35", "class_name": "RelatedNodeInfo"}}, "text": "188 Part V: Big Data Implementation \nETL has been used with batch processing in data warehouse environments. \nData warehouses provide business users with a way to consolidate informa -\ntion across disparate sources (such as enterprise resource planning [ERP] \nand customer relationship management [CRM]) to analyze and report on \ndata relevant to their specific business focus. ETL tools are used to transform \nthe data into the format required by the data warehouse. The transforma -\ntion is actually done in an intermediate location before the data is loaded \ninto the data warehouse. Many software vendors, including IBM, Informatica, \nPervasive, Talend, and Pentaho, provide ETL software tools. \nETL provides the underlying infrastructure for integration by performing \nthree important functions:\n \u2713 Extract:  Read data from the source database.\n \u2713 Transform:  Convert the format of the extracted data so that it conforms \nto the requirements of the target database. Transformation is done by \nusing rules or merging data with other data.\n \u2713 Load:  Write data to the target database.\nHowever, ETL is evolving to support integration across much more than tra -\nditional data warehouses. ETL can support integration across transactional \nsystems, operational data stores, BI platforms, MDM hubs, the cloud, and \nHadoop platforms. ETL software vendors are extending their solutions to \nprovide big data extraction, transformation, and loading between Hadoop \nand traditional data management platforms. ETL and software tools for other \ndata integration processes like data cleansing, profiling, and auditing all work \non different aspects of the data to ensure that the data will be deemed trust -\nworthy. ETL tools integrate with data quality tools, and many incorporate \ntools for data cleansing, data mapping, and identifying data lineage. With \nETL, you only extract the data you will need for the integration.\nETL tools are needed for the loading and conversion of structured and \nunstructured data into Hadoop. Advanced ETL tools can read and write mul -\ntiple files in parallel from and to Hadoop to simplify how data is merged into \na common transformation process. Some solutions incorporate libraries of \nprebuilt ETL transformations for both the transaction and interaction data \nthat run on Hadoop or a traditional grid infrastructure.\nData transformation\nData transformation is the process of changing the format of data so that \nit can be used by different applications. This may mean a change from the \nformat the data is stored in into the format needed by the application that \nwill use the data. This process also includes mapping  instructions so that \napplications are told how to get the data they need to process.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2755, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b6fc5a84-3f11-4c5f-a512-f7b44a612276": {"__data__": {"id_": "b6fc5a84-3f11-4c5f-a512-f7b44a612276", "embedding": null, "metadata": {"page_label": "189", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b9143be8-6470-4063-ab00-a612b8a9fb98", "node_type": "4", "metadata": {"page_label": "189", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ffc99a78e961b99fc9145b8bc8c6281ceeca2f9d4450926f0ebf85e922fc69aa", "class_name": "RelatedNodeInfo"}}, "text": "189  Chapter 15: Integrating Data Sources\nThe process of data transformation is made far more complex because of the \nstaggering growth in the amount of unstructured data. A business application \nsuch as a customer relationship management or sales management system \ntypically has specific requirements for how the data it needs should be \nstored. The data is likely to be structured in the organized rows and columns \nof a relational database. Data is semi-structured or unstructured if it does not \nfollow these very rigid format requirements. The information contained in \nan e-mail message is considered unstructured, for example. Some of a com -\npany\u2019s most important information is in unstructured and semi-structured \nforms such as documents, e-mail messages, complex messaging formats, cus -\ntomer support interactions, transactions, and information coming from pack -\naged applications like ERP and CRM.\nData transformation tools are not designed to work well with unstructured \ndata. As a result, companies needing to incorporate unstructured information \ninto its business process decision making have been faced with a significant \namount of manual coding to accomplish the required data integration. Given \nthe growth and importance of unstructured data to decision making, ETL \nsolutions from major vendors are beginning to offer standardized approaches \nto transforming unstructured data so that it can be more easily integrated \nwith operational structured data.\nUnderstanding ELT \u2014 Extract,  \nLoad, and Transform\nELT stands for extract, load, and transform. It performs the same functions \nas ETL, but in a different order. Early databases did not have the technical \ncapability to transform the data. Therefore, ETL tools extracted the data to \nan intermediary location to perform the transformation before loading the \ndata to the data warehouse. However, this restriction is no longer a problem, \nthanks to technology advances such as massively parallel processing sys -\ntems and columnar databases. As a result, ELT tools can transform the data \nin the source or target database without requiring an ETL server. Why use \nELT with big data? The performance is faster and more easily scalable. ELT \nuses structured query language (SQL) to transform the data. Many traditional \nETL tools also offer ELT so that you can use both, depending on which option \nis best for your situation.\nPrioritizing Big Data Quality\nGetting the right perspective on data quality can be very challenging in the \nworld of big data. With the majority of big data sources, you need to assume \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2606, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "160d837e-0c67-4e24-b457-0284cc01b110": {"__data__": {"id_": "160d837e-0c67-4e24-b457-0284cc01b110", "embedding": null, "metadata": {"page_label": "190", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4714f68c-a079-472c-bb5f-04ab2b17924c", "node_type": "4", "metadata": {"page_label": "190", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "5f6654a8836ad445c5c0b0795bcd3daf091b28aab707d7ca3bd6515729c18a97", "class_name": "RelatedNodeInfo"}}, "text": "190 Part V: Big Data Implementation \nthat you are working with data that is not clean. In fact, the overwhelming \nabundance of seemingly random and disconnected data in streams of social \nmedia data is one of the things that make it so useful to businesses. You start \nby searching petabytes of data without knowing what you might find after \nyou start looking for patterns in the data. You need to accept the fact that a \nlot of noise will exist in the data. It is only by searching and pattern matching \nthat you will be able to find some sparks of truth in the midst of some very \ndirty data. Of course, some big data sources such as data from RFID tags or \nsensors have better-established rules than social media data. Sensor data \nshould be reasonably clean, although you may expect to find some errors. It \nis always your responsibility when analyzing massive amounts of data to plan \nfor the quality level of that data. You should follow a two-phase approach to \ndata quality:\nPhase 1:  Look for patterns in big data without concern for data quality.\nPhase 2:  After you locate your patterns and establish results that are \nimportant to the business, apply the same data quality standards that \nyou apply to your traditional data sources. You want to avoid collect -\ning and managing big data that is not important to the business and will \npotentially corrupt other data elements in Hadoop or other big data  \nplatforms.\nAs you begin to incorporate the outcomes of your big data analysis into your \nbusiness process, recognize that high-quality data is essential for a com -\npany to make sound business decisions. This is true for big data as well as \ntraditional data. The quality of data refers to characteristics about the data, \nincluding consistency, accuracy, reliability, completeness, timeliness, reason -\nableness, and validity. Data quality software makes sure that data elements \nare represented in the same way across different data stores or systems to \nincrease the consistency of the data.\nFor example, one data store may use two lines for a customer\u2019s address and \nanother data store may use one line. This difference in the way the data is \nrepresented can result in inaccurate information about customers, such as \none customer being identified as two different customers. A corporation \nmight use dozens of variations of its company name when it buys products. \nData quality software can be used to identify all the variations of the com -\npany name in your different data stores and ensure that you know everything \nthat this customer purchases from your business. This process is called \nproviding a single view of customer or product.  Data quality software matches \ndata across different systems and cleans up or removes redundant data. The \ndata quality process provides the business with information that is easier to \nuse, interpret, and understand.\nData profiling tools are used in the data quality process to help you to under -\nstand the content, structure, and condition of your data. They collect infor -\nmation on the characteristics of the data in a database or other data store to \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3142, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a519ca91-88f4-45ef-81b9-23e605effe1a": {"__data__": {"id_": "a519ca91-88f4-45ef-81b9-23e605effe1a", "embedding": null, "metadata": {"page_label": "191", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3f2bc7d5-6d4e-4313-934f-8a0736c839ae", "node_type": "4", "metadata": {"page_label": "191", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f21d47841a0e85cb5fd6727785000be05a4c83db70b22a6a8f77dbdd7fd9c623", "class_name": "RelatedNodeInfo"}}, "text": "191  Chapter 15: Integrating Data Sources\nbegin the process of turning the data into a more trusted form. The tools ana -\nlyze the data to identify errors and inconsistencies. They can make adjust -\nments for these problems and correct errors. The tools check for acceptable \nvalues, patterns, and ranges and help identify overlapping data. The data-\nprofiling process, for example, checks to see whether the data is expected to \nbe alpha or numeric. The tools also check for dependencies or to see how the \ndata relates to data from other databases.\nData-profiling tools for big data have a similar function to data-profiling tools \nfor traditional data. Data-profiling tools for Hadoop will provide you with \nimportant information about the data in Hadoop clusters. These tools can be \nused to look for matches and remove duplications on extremely large data \nsets. As a result, you can ensure that your big data is complete and consis -\ntent. Hadoop tools like HiveQL and Pig Latin can be used for the transforma -\ntion process.\nUsing Hadoop as ETL\nMany organizations with big data platforms are concerned that ETL tools \nare too slow and cumbersome to use with large volumes of data. Some have \nfound that Hadoop can be used to handle some of the transformation process \nand to otherwise improve on the ETL and data-staging processes. You can \nspeed up the data integration process by loading both unstructured data and \ntraditional operational and transactional data directly into Hadoop, regard -\nless of the initial structure of the data. After the data is loaded into Hadoop, \nit can be further integrated using traditional ETL tools. When Hadoop is used \nas an aid to the ETL process, it speeds the analytics process.\nThe use of Hadoop as an integration tool is a work in progress. Vendors with \ntraditional ETL solutions, such as IBM, Informatica, Talend, Pentaho, and \nDatameer, are incorporating Hadoop into their integration offerings. By rely -\ning on the capabilities of Hadoop as a massively parallel system, developers \ncan perform data quality and transformation functions that were not previ -\nously possible. However, Hadoop does not stand on its own as a replacement \nfor ETL.\nBest Practices for Data Integration  \nin a Big Data World\nYou find a lot of potential in using big data to look at a range of business and \nscientific problems in new ways, find answers to unanswered questions, and \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2432, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e38db428-75de-4144-aee1-38e2700aba09": {"__data__": {"id_": "e38db428-75de-4144-aee1-38e2700aba09", "embedding": null, "metadata": {"page_label": "192", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4c201736-8d6f-4591-933b-313a1c9c7351", "node_type": "4", "metadata": {"page_label": "192", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "77475bdb8bc2946b4b7e7af20bb0be47f7590ac409782bed92b1295a7bcb9b5a", "class_name": "RelatedNodeInfo"}}, "text": "192 Part V: Big Data Implementation \nbegin to take immediate action that delivers significant results. Many com -\npanies are exploring big data problems and coming up with some innovative \nsolutions. Chapters 21 and 22 present some interesting case examples. The \nfuture is exciting. However, now is the time to pay attention to some basic \nprinciples that will serve you well as you begin your big data journey.\nIn reality, big data integration fits into the overall process of integration of \ndata across your company. Therefore, you can\u2019t simply toss aside everything \nyou have learned from data integration of traditional data sources. The same \nrules apply whether you are thinking about traditional data management or \nbig data management. So keep these key issues at the top of your priority list:\n \u2713 Keep data quality in perspective. Your emphasis on data quality \ndepends on the stage of your big data analysis. Don\u2019t expect to be able \nto control data quality when you do your initial analysis on huge vol -\numes of data. However, when you narrow down your big data to identify \na subset that is most meaningful to your organization, this is when you \nneed to focus on data quality. Ultimately data quality becomes impor -\ntant if you want your results to be understood in context with your \nhistorical data. As your company relies more and more on analytics as a \nkey planning tool, data quality can mean the difference between success \nand failure.\n \u2713 Consider real-time data requirements.  Big data will bring streaming \ndata to the forefront. Therefore, you will have to have a clear under -\nstanding of how you integrate data in motion into your environment for \npredictable analysis.\n \u2713 Don\u2019t create new silos of information.  While so much of the empha -\nsis around big data is focused on Hadoop and other unstructured and \nsemi-structured sources, remember that you have to manage this data \nin context with the business. You will therefore need to integrate these \nsources with your line of business data and your data warehouse. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2068, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "81f2a4c4-6c9b-41d8-aeb7-cf19ffd8837b": {"__data__": {"id_": "81f2a4c4-6c9b-41d8-aeb7-cf19ffd8837b", "embedding": null, "metadata": {"page_label": "193", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "73dba28a-5f11-4adc-a332-cbfb0234face", "node_type": "4", "metadata": {"page_label": "193", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "714ddc2c910e7322c59b2b1868e43924ab43208294deca0fe4bc7adebcb6b6be", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 16\nDealing with Real-Time Data \nStreams and Complex Event \nProcessing\nIn This Chapter\n\u25b6 Streaming data\n\u25b6 Exploring complex event processing\n\u25b6 Understanding how streaming data and complex event processing impact big data\n\u25b6 Using streaming data and complex event processing in the real world\n\u25b6 Streaming data in action\nB \nig data is offering new and exciting approaches to providing a different \nlevel of insight and operational sophistication to data management. In \nmany of the examples discussed in the preceding chapters, big data is ana -\nlyzed in batch mode. Often the most important issues for organizations are \nthat the amount of data is huge and it needs to be processed and managed \nat the right speed to impact outcomes. But most of this analysis is related to \nlarge-scale analysis and decision making. Analyzing the massive amount of \ndata from multitudes of sources can help the organization understand the \nmeaning of data, plan for the future, and anticipate market changes and unan -\nticipated customer requirements.\nIn many situations, you may need to react to the current state of data. You \nmight need to react to sensor data that indicates a problem with a medical \nmonitoring device. You might want to send a customer a coupon at the time \nof purchase. Or you may need to adjust the placement of equipment based \non changing weather conditions. The list of possibilities goes on. But the \ncommon element is that you are analyzing data that is in motion. One execu -\ntive stated the issue clearly: \u201cWe need to be able to process and analyze \nstreaming data from sensors in real time, while that data is still moving.\u201d\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1664, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "06d4c177-f080-416a-9b7b-1004ce7de1db": {"__data__": {"id_": "06d4c177-f080-416a-9b7b-1004ce7de1db", "embedding": null, "metadata": {"page_label": "194", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "065236b5-729e-436f-8c74-f2e89c9e634b", "node_type": "4", "metadata": {"page_label": "194", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "79ff5fa56cc2347a059caef38a8f9022f27cd5c24fd944b822cda1b6f14d6c3a", "class_name": "RelatedNodeInfo"}}, "text": "194 Part V: Big Data Implementation \nIn this chapter, we combine two techniques for managing the flow of data. \nStreaming technology is closely tied to the volume of the data, while com -\nplex event processing of the volume of data is secondary to the capability \nto match data to rules. Streaming data and complex event processing are \nincreasingly important across industries. These technologies are the most \nimportant in the trenches of an organization, where reaction time to a condi -\ntion or situation will make the difference between success and failure. In this \nchapter, we look at the impact and importance of streaming data and com -\nplex event processing to big data.\nExplaining Streaming Data and  \nComplex Event Processing\nSo what is streaming data and how is that different from complex event \nprocessing? This is not a simple question to answer because a continuum of \ndata management exists. Streaming computing is designed to handle a con -\ntinuous stream of a large amount of unstructured data. In contrast, Complex \nEvent Processing (CEP) typically deals with a few variables that need to be \ncorrelated with a specific business process. In many situations, CEP is depen -\ndent on data streams. However, CEP is not required for streaming data. Like \nstreaming data, CEP relies on analyzing streams of data in motion. In fact, if \ndata is at rest, it does not fit into the category of streaming data or CEP. In \nthe next section, we discuss streaming data and its application in organiza -\ntions and industries.\nUsing Streaming Data\nSo far, we have talked about collecting massive amounts of data from many \ndifferent sources and processing that information to gain insights. In general, \nthis is considered data at rest. Before we give you an example, what is data \nthat is not at rest? This would be systems that are managing active transac -\ntions and therefore need to have persistence. In these cases, the data will \nbe stored in an operational data store. However, in other situations, those \ntransactions have been executed, and it is time to analyze that data typically \nin a data warehouse or data mart. This means that the information is being \nprocessed in batch and not in real time. When organizations are planning for \ntheir future, they need to be able to analyze all sorts of data, ranging from \ninformation about what customers are saying to what they are buying and \nwhy. It is important to understand the leading indicators of change. In other \nwords, what is changing? If customer buying preferences are changing, how \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2577, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b13f1d8e-5245-4f13-ab28-857e17ead86a": {"__data__": {"id_": "b13f1d8e-5245-4f13-ab28-857e17ead86a", "embedding": null, "metadata": {"page_label": "195", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0ad74638-7752-4dc4-b30d-23e7dc52f682", "node_type": "4", "metadata": {"page_label": "195", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "7b4a328a72875f324d781b2382ffeb2bda3c1ab6daaed50c845c7ca5b83b2e31", "class_name": "RelatedNodeInfo"}}, "text": "195  Chapter 16: Dealing with Real-Time Data Streams and Complex Event Processing\nwill that impact what products and services an organization will offer next \nyear or even in three years? Many research organizations are using this type \nof big data analytics to discover new medicines. An insurance company may \nwant to compare the patterns of traffic accidents across a broad geographic \narea with weather statistics. In these use cases, no benefit exists to manage \nthis information at real-time speed. Clearly, the analysis has to be fast enough \nto be practical. In addition, organizations will often analyze the data multiple \ntimes to see whether new patterns emerge.\nBut when a significant amount of data needs to be quickly processed in near \nreal time to gain insights, data in motion in the form of streaming data is the \nbest answer.\nData streaming\nStreaming data is an analytic computing platform that is focused on speed. \nThis is because these applications require a continuous stream of often \nunstructured data to be processed. Therefore, data is continuously analyzed \nand transformed in memory before it is stored on a disk. Processing streams \nof data works by processing \u201ctime windows\u201d of data in memory across a \ncluster of servers. This is similar to the approach when managing data at \nrest leveraging Hadoop, covered in Chapter 9. The primary difference is the \nissue of velocity. In the Hadoop cluster, data is collected in batch mode and \nthen processed. Speed matters less in Hadoop than it does in data streaming. \nSome key principles define when using streams is most appropriate:\n \u2713 When it is necessary to determine a retail buying opportunity at the \npoint of engagement, either via social media or via permission-based \nmessaging\n \u2713 Collecting information about the movement around a secure site\n \u2713 To be able to react to an event that needs an immediate response, such \nas a service outage or a change in a patient\u2019s medical condition\n \u2713 Real-time calculation of costs that are dependent on variables such as \nusage and available resources\nStreaming data is useful when analytics need to be done in real time while \nthe data is in motion. In fact, the value of the analysis (and often the data) \ndecreases with time. For example, if you can\u2019t analyze and act immediately, a \nsales opportunity might be lost or a threat might go undetected.\nThe following are a few examples that can help explain how this is useful.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2467, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a280161d-0cb5-4d54-b5a5-ae533994d8b6": {"__data__": {"id_": "a280161d-0cb5-4d54-b5a5-ae533994d8b6", "embedding": null, "metadata": {"page_label": "196", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f8c383cc-b035-4431-94aa-9d957e842b6d", "node_type": "4", "metadata": {"page_label": "196", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d9f3d008fb4d7171f810cd4852ecd575a43ed28ce86a9de5218ad5e9930dc518", "class_name": "RelatedNodeInfo"}}, "text": "196 Part V: Big Data Implementation \nA power plant needs to be a highly secure environment so that unauthor -\nized individuals do not interfere with the delivery of power to customers. \nCompanies often place sensors around the perimeter of a site to detect move -\nment. But a problem could exist. A huge difference exists between a rabbit \nthat scurries around the site and a car driving by quickly and deliberately. \nTherefore, the vast amount of data coming from these sensors needs to be \nanalyzed in real time so that an alarm is sounded only when an actual threat \nexists.\nA telecommunications company in a highly competitive market wants to \nmake sure that outages are carefully monitored so that a detected drop in \nservice levels can be escalated to the appropriate group. Communications \nsystems generate huge volumes of data that have to be analyzed in real time \nto take the appropriate action. A delay in detecting an error can seriously \nimpact customer satisfaction.\nAn oil exploration company drilling at sea needs to know exactly where the \nsources of oil are and what other environmental factors might impact their \noperations. Therefore, it needs to know details such as water depth, tempera -\nture, ice flows, and so on. This massive amount of data needs to be analyzed \nand computed so that mistakes are avoided.\nA medical diagnostic group was required to be able to take massive amounts \nof data from brain scans and analyze the results in real time to determine \nwhere the source of a problem is and what type of action needed to be taken \nto help the patient.\nNeedless to say, we are dealing with a lot of data that needs to be processed \nand analyzed in real time. Therefore, the physical environment that supports \nthis level of responsiveness is critical. Streaming data environments typically \nrequire a clustered hardware solution, and sometimes a massively parallel \nprocessing approach will be required to handle the analysis. One important \nfactor about streaming data analysis is the fact that it is a single-pass analysis. \nIn other words, the analyst cannot reanalyze the data after it is streamed. This \nis common in applications where you are looking for the absence of data. In \ntelecommunication networks, the loss of a heartbeat needs to be addressed \nas soon as possible. If several passes are required, the data will have to be put \ninto some sort of warehouse where additional analysis can be performed. For \nexample, it is often necessary to establish context. How does this streaming \ndata compare to historical data? This correlation can tell you a lot about what \nhas changed and what that change might mean to your business.\nThe need for metadata in streams\nMost data management professionals are familiar with the need to manage \nmetadata in structured database management environments. These data \nsources are strongly typed (for example, the first ten characters are the \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2940, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a7d3c3bc-1788-49b8-8ff7-bce2be469e25": {"__data__": {"id_": "a7d3c3bc-1788-49b8-8ff7-bce2be469e25", "embedding": null, "metadata": {"page_label": "197", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c4606470-21dc-460f-874f-a41779700f6c", "node_type": "4", "metadata": {"page_label": "197", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "bba8afffb7f9984c405392dc2fd08fe96e03cdac5d7deb56c220fe6d116cc456", "class_name": "RelatedNodeInfo"}}, "text": "197  Chapter 16: Dealing with Real-Time Data Streams and Complex Event Processing\nfirst name) and designed to operate with metadata. You might assume that \nmetadata is nonexistent in unstructured data, but that is not true. Typically \nyou find structure in any kind of data. Take the example of video. Although \nyou might not be able to know exactly the content of a specific video, a lot \nof structure exists in the format of that video-based data. If you are looking \nat unstructured text, you know that the words are written in the English lan -\nguage and that if you apply the right tools and algorithms, you can interpret \nthe text. Managing unstructured data is covered in Chapter 13.\nBecause of this implicit metadata from unstructured data, it is possible to \nparse the information using eXtensible Markup Language (XML). XML is a \ntechnique for presenting unstructured text files with meaningful tags. The \nunderlying technology is not new and was one of the foundational technolo -\ngies for implementing service orientation.\nExamples of products for streaming data include IBM\u2019s InfoSphere Streams, \nTwitter\u2019s Storm, and Yahoo\u2019s S4.\nIBM InfoSphere Streams\nInfoSphere Streams provides continuous analysis of massive data volumes. \nIt is intended to perform complex analytics of heterogeneous data types, \nincluding text, images, audio, voice, VoIP, video, web traffic, e-mail, GPS data, \nfinancial transaction data, satellite data, and sensors. Infosphere Streams can \nsupport all data types. It can perform real-time and look-ahead analysis of \nregularly generated data, using digital filtering, pattern/correlation analysis, \nand decomposition as well as geospacial analysis.\nTwitter\u2019s Storm\nTwitter\u2019s Storm is an open source real-time analytics engine developed by \na company called BackType that was acquired by Twitter in 2011 partially \nbecause Twitter uses Storm internally. It is still available as open source and \nhas been gaining significant traction among emerging companies. It can be \nused with any programming language for applications such as real-time ana -\nlytics, continuous computation, distributed remote procedure calls (RPCs), \nand integration. Storm is designed to work with existing queuing and data -\nbase technologies. Companies using Storm in their big data implementations \ninclude Groupon, RocketFuel, Navisite, and Oolgala.\nApache S4\nThe four S\u2019s in S4 stand for Simple Scalable Streaming System. Apache S4 was \ndeveloped by Yahoo! as a general-purpose, distributed, scalable, partially \nfault-tolerant, pluggable platform that allows programmers to easily develop \napplications for processing continuous streams of data. The core platform \nis written in Java and was released by Yahoo! in 2010. A year later, it was \nturned over to Apache under the Apache 2.0 license. Clients that send and \nreceive events can be written in any programming language. S4 is designed as \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2929, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "65fc3742-7feb-42bf-8fbc-2a35c46dccb6": {"__data__": {"id_": "65fc3742-7feb-42bf-8fbc-2a35c46dccb6", "embedding": null, "metadata": {"page_label": "198", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c64aa61a-ca33-4c64-8e7c-46131d3fe0d1", "node_type": "4", "metadata": {"page_label": "198", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1b02809ec1ebc0e77e53987a02e1079a79f393c5dac9279fa99abeec34656f31", "class_name": "RelatedNodeInfo"}}, "text": "198 Part V: Big Data Implementation \na highly distributed system. Throughput can be increased linearly by adding \nnodes into a cluster. The S4 design is best suited for large-scale applications \nfor data mining and machine learning in a production environment.\nUsing Complex Event Processing\nBoth streams and Complex Event Processing (CEP) are intended to manage \ndata in motion. But the uses of these two technologies are quite different. \nWhile streams are intended to analyze large volumes of data in real time, \nComplex Event Processing is a technique for tracking, analyzing, and pro -\ncessing data as an event happens. This information is then processed and \ncommunicated based on business rules and processes. The idea behind CEP \nis to be able to establish the correlation between streams of information \nand match the resulting pattern with defined behaviors such as mitigating a \nthreat or seizing an opportunity.\nCEP is an advanced approach based on simple event processing that collects \nand combines data from different relevant sources to discover events and \npatterns that can result in action.\nHere is an example. A retail chain creates a tiered loyalty program to increase \nrepeat sales \u2014 especially for customers who spend more than $1,000 a year. \nIt is important that the company creates a platform that could keep these \ncritical customers coming back and spending more. Using a CEP platform, as \nsoon as a high-valued customer uses the loyalty program, the system triggers \na process that offers the customer an extra discount on a related product. \nAnother process rule could give the customer an unexpected surprise \u2014 an \nextra discount or a sample of a new product. The company also adds a new \nprogram that links the loyalty program to a mobile application. When a loyal \ncustomer walks near a store, a text message offers the customer a discounted \nprice. At the same time, if that loyal customer writes something negative on \na social media site, the customer care department is notified and an apology \nis issued. It is quite likely that we are dealing with a huge number of custom -\ners with a significant number of interactions. But it would not be enough to \nsimply stream the data and analyze that data. To achieve the business goals \nthe retailer wanted to achieve would require executing a process to respond \nto the results of the analysis.\nMany industries take advantage of CEP. Credit card companies use CEP to \nbetter manage fraud. When a pattern of fraud emerges, the company can shut \noff the credit card before the company experiences significant losses. The \nunderlying system will correlate the incoming transactions, track the stream \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2698, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e588e2da-aaff-4647-b454-e683bff43533": {"__data__": {"id_": "e588e2da-aaff-4647-b454-e683bff43533", "embedding": null, "metadata": {"page_label": "199", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0ac6ddbf-ce29-40aa-8595-46d95b2607e7", "node_type": "4", "metadata": {"page_label": "199", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "148955dbb65e1565cd0d38d6fe6578f03365d2c1df2a29b59436edd1bfb35683", "class_name": "RelatedNodeInfo"}}, "text": "199  Chapter 16: Dealing with Real-Time Data Streams and Complex Event Processing\nof event data, and trigger a process. CEP is also implemented in financial-\ntrading applications, weather-reporting applications, and sales management \napplications, to name a few. What all these applications have in common is \nthat the applications have a predefined norm for temperature, pressure, size \nof transaction, or value of the sale. A change in state will trigger an action. If \nyou drive a late-model car, you probably have noticed that when a tire\u2019s pres -\nsure has dropped, the car will trigger a dashboard indicator that notifies the \ndriver to take action (getting the tire inflated or fixed).\nMany vendors offer CEP solutions. Many of the CEP tools on the market allow \nthe creation of real-time, event-driven applications. These applications might \ningest data from streams, but they can also ingest data from traditional data -\nbase sources. Most of the offerings include common capabilities, including \na graphical development environment that is typically Eclipse-based, con -\nnectivity to real-time data flows, as well as APIs to historical data sources. \nMost of these products include a graphical event flow language and support \nSQL. Key vendors in this space include Esper (open source vendor), IBM with \nIBM Operational Decision Manager, Informatica with RulePoint, Oracle with \nits Complex Event Processing Solution, Microsoft\u2019s StreamInsights, and SAS \nDataFlux Event Stream Processing Engine, and Streambase\u2019s CEP. Numerous \nstartups are emerging in this market.\nDifferentiating CEP from Streams\nSo, what is the difference between CEP and streaming data solutions? While \nstream computing is typically applied to analyzing vast amounts of data in \nreal time, CEP is much more focused on solving a specific use case based \non events and actions. However, a streaming data technique is often used \nas an integral part of a CEP application. As discussed earlier in the chapter, \nstreaming data applications typically manage a lot of data and process it at a \nhigh rate of speed. Because of the amount of data, it is typically managed in a \nhighly distributed clustered environment.\nCEP, on the other hand, typically will not manage as much data, so it is often \nrun on less complex hardware. In addition, the type of analysis will be differ -\nent. It is critical that CEP applications be able to connect to key systems of \nrecord such as customer relationship management (CRM) systems or trans -\naction management environments. It is not uncommon for CEP environments \nto deal with only a few variables that are applied to very complex models and \nprocesses. While relying on complex mining or statistical models, CEP sys -\ntems are designed around a rules engine so that when an event takes place, \nthe rules engine triggers an action.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2864, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b444a56b-ad3a-476d-93e2-ae26ef21f3f9": {"__data__": {"id_": "b444a56b-ad3a-476d-93e2-ae26ef21f3f9", "embedding": null, "metadata": {"page_label": "200", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0c9945ad-eabf-41cd-a7a7-38cf7ca307e9", "node_type": "4", "metadata": {"page_label": "200", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ab9fbb68001975dc4bef9e76628c56d2f6c48730367bd59d3c56c3527c3bbd03", "class_name": "RelatedNodeInfo"}}, "text": "200 Part V: Big Data Implementation \nUnderstanding the Impact of Streaming \nData and CEP on Business\nBoth streaming data and CEP have an enormous impact on how companies \ncan make strategic use of big data. With streaming data, companies are able \nto process and analyze this data in real time to gain an immediate insight. It \noften requires a two-step process to continue to analyze the key findings that \nmight have gone unnoticed in the past. With CEP approaches, companies \ncan stream data and then leverage a business process engine to apply busi -\nness rules to the results of that streaming data analysis. The opportunities to \ngain insights that lead to new innovation and new action are the foundational \nvalue of streaming data approaches.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 769, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ce638535-07aa-49d2-9b03-fdcc805c6065": {"__data__": {"id_": "ce638535-07aa-49d2-9b03-fdcc805c6065", "embedding": null, "metadata": {"page_label": "201", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "461e488f-5088-4a7e-bcf5-ca42555c2506", "node_type": "4", "metadata": {"page_label": "201", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "9d7837d0bb1b4dc41bb7e64d0d35a729e6f043585ea6c9f93c02c97883361628", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 17\nOperationalizing Big Data\nIn This Chapter\n\u25b6 Making big data a part of your business/operating processes\n\u25b6 Understanding big data workflows\n\u25b6 Ensuring the validity, veracity, and volatility of big data\nT \nhe benefits of big data to business are significant. But the real question \nis how do you make big data part of your overall business process so \nthat you can operationalize big data? What if you can combine the traditional \ndecision making process with big data analysis? How do you make big data \navailable to decision makers so that they get the benefit from the myriad data \nsources that transform business processes? To make big data a part of the \noverall data management process requires that you put together a plan. In \nthis chapter, we talk about what it takes to combine the results of big data \nanalysis with your existing operational data. The combination can be a pow -\nerful approach to transforming your business.\nMaking Big Data a Part of  \nYour Operational Process\nThe best way to start making big data a part of your business process is to \nbegin by planning an integration strategy. The data \u2014 whether it is a tradi -\ntional data source or big data \u2014 needs to be integrated as a seamless part of \nthe inner workings of the processes.\nCan big data be ancillary to the business process? The answer is yes, but \nonly if little or no dependency exists between transactional data and big \ndata. Certainly you can introduce big data to your organization as a parallel \nactivity. However, if you want to get the most from big data, it needs to be \nintegrated into your existing business operating processes. We take a look at \nhow to accomplish this task. In the next section, we discuss the importance \nof data integration in making big data operational.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1802, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b9bee75b-87ff-413c-bbde-4b6006b99e75": {"__data__": {"id_": "b9bee75b-87ff-413c-bbde-4b6006b99e75", "embedding": null, "metadata": {"page_label": "202", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b5c2c895-999a-4a96-95e7-6a3210bbef21", "node_type": "4", "metadata": {"page_label": "202", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e4e3f35ef0e7da7475a42137b77447c6e8002a9966a6a36c31cfa9adc15bd58f", "class_name": "RelatedNodeInfo"}}, "text": "202 Part V: Big Data Implementation \nIntegrating big data\nJust having access to big data sources is not enough. Soon there will be pet -\nabytes of data and hundreds of access mechanisms for you to choose from. \nBut which streams and what kinds of data do you need? The identification  \nof the \u201cright\u201d sources of data is similar to what we have done in the past:\n \u2713 Understand the problem you are trying to solve\n \u2713 Identify the processes involved\n \u2713 Identify the information required to solve the problem\n \u2713 Gather the data, process it, and analyze the results\nThis process may sound familiar because businesses have been doing a vari -\nation of this algorithm for decades. So is big data different? Yes, even though \nwe have been dealing with large amounts of operational data for years, big \ndata introduces new types  of data into people\u2019s professional and personal \nlives. Twitter streams, Facebook posts, sensor data, RFID data, security logs, \nvideo data, and many other new sources of information are emerging almost \ndaily. As these sources of big data emerge and expand, people are trying to \nfind ways to use this data to better serve customers, partners, and suppliers. \nOrganizations are looking for ways to use this data to predict the future and \nto take better actions. We look at an example to understand the importance \nof integrating big data with operating processes.\nHealthcare is one of the most important and complex areas of investment \ntoday. It is also an area that increasingly produces more data in more forms \nthan most industries. Therefore, healthcare is likely to greatly benefit by \nnew forms of big data. The healthcare providers, insurers, researchers, and \nhealthcare practitioners often make decisions about treatment options with \ndata that is incomplete or not relevant to specific illnesses. Part of the reason \nfor this disparity is that it is very difficult to effectively gather and process \ndata for individual patients. Data elements are often stored and managed in \ndifferent places by different organizations. In addition, clinical research that \nis being conducted all over the world can be helpful in determining the con -\ntext for how a specific disease or illness might be approached and managed. \nBig data can help change this problem.\nSo, we apply our algorithm to a standard data healthcare scenario:\n 1. Understand the problem we are trying to solve:\n a. Need to treat a patient with a specific type of cancer\n 2. Identify the processes involved:\n a. Diagnosis and testing\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2545, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "565c6c22-e11c-45da-ad1c-076de4da6e0b": {"__data__": {"id_": "565c6c22-e11c-45da-ad1c-076de4da6e0b", "embedding": null, "metadata": {"page_label": "203", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1181f5a1-6863-494e-9a0a-f0af64a323f7", "node_type": "4", "metadata": {"page_label": "203", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1cc2b9eb83a2c4893ac3e9fab1a4203c881699dd69d1c14ab47e55f4b1993e20", "class_name": "RelatedNodeInfo"}}, "text": "203  Chapter 17: Operationalizing Big Data\n b. Results analysis including researching treatment options\n c. Definition of treatment protocol\n d. Monitor patient and adjust treatment as needed\n 3. Identify the information required to solve the problem:\n a. Patient history\n b. Blood, tissue, test results, and so on\n c. Statistical results of treatment options\n 4. Gather the data, process it, and analyze the results:\n a. Commence treatment\n b. Monitor patient and adjust treatment as needed\nFigure 17-1 illustrates the process.\n Figure 17-1:  \nProcess \nflow of the \ntraditional \npatient \ndiagnostic \nprocess.\n \nThis is how medical practitioners work with patients today. Most of the data \nis local to a healthcare network, and physicians have little time to go outside \nthe network to find the latest information or practice.\nIncorporating big data into  \nthe diagnosis of diseases\nAcross the world, big data sources for healthcare are being created and made \navailable for integration into existing processes. Clinical trial data, genetics  \nand genetic mutation data, protein therapeutics data, and many other new \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1136, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6d3902a4-f8bf-4c23-bd4d-834640dd3755": {"__data__": {"id_": "6d3902a4-f8bf-4c23-bd4d-834640dd3755", "embedding": null, "metadata": {"page_label": "204", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cde1d9a7-ce24-406d-9b69-de336bad310e", "node_type": "4", "metadata": {"page_label": "204", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "12a5eea7a174daf500f7a44e16bfead506c259b93059a9cd0e7042bda779eac9", "class_name": "RelatedNodeInfo"}}, "text": "204 Part V: Big Data Implementation \nsources of information can be harvested to improve daily healthcare pro -\ncesses. Social media can and will be used to augment existing data and pro -\ncesses to provide more personalized views of treatment and therapies. New \nmedical devices will control treatments and transmit telemetry data for real-\ntime and other kinds of analytics. The task ahead is to understand these new \nsources of data and complement the existing data and processes with the \nnew big data types.\nSo, what would the healthcare process look like with the introduction of big \ndata into the operational process of identifying and managing patient health? \nHere is an example of what the future might look like: \n 1. Understand the problem we are trying to solve:\n a. Need to treat a patient with a specific type of cancer\n 2. Identify the processes involved:\n a. Diagnosis and testing (identify genetic mutation)\n b. Results analysis including researching treatment options, clinical \ntrial analysis, genetic analysis, and protein analysis\n c. Definition of treatment protocol, possibly including gene or protein \ntherapy\n d. Monitor patient and adjust treatment as needed using new wireless \ndevice for personalized treatment delivery and monitoring. Patient \nuses social media to document overall experience.\n 3. Identify the information required to solve the problem:\n a. Patient history\n b. Blood, tissue, test results, and so on\n c. Statistical results of treatment options\n d. Clinical trial data\n e. Genetics data\n f. Protein data\n g. Social media data\n 4. Gather the data, process it, and analyze the results:\n a. Commence treatment\n b. Monitor patient and adjust treatment as needed\nFigure 17-2 identifies the same operational process as before, but with big \ndata integrations.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1819, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "26a25a94-518d-4420-8a3c-18a529617c10": {"__data__": {"id_": "26a25a94-518d-4420-8a3c-18a529617c10", "embedding": null, "metadata": {"page_label": "205", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2ac90a08-2902-4429-83bc-9e2ec9d19168", "node_type": "4", "metadata": {"page_label": "205", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "a33153bf1d5897fcb2188c427bacec1a60b8e2dd529642fd0c584d768bd21b41", "class_name": "RelatedNodeInfo"}}, "text": "205  Chapter 17: Operationalizing Big Data\n Figure 17-2:   \nThe \nhealthcare \ndiagnostic \nprocess \nleveraging \nbig data.\n \nThis represents the optimal case where no new processes need to be created  \nto support big data integrations. While the processes are relatively unchanged, \nthe underlying technologies include the applications that will need to be \naltered to accommodate the impact of characteristics of big data, including \nthe volume of data, the variety of data sources, and the speed or velocity \nrequired to process that data.\nThe introduction of big data into the process of managing healthcare will \nmake a big difference in effectiveness to diagnosing and managing healthcare \nin the future. This same operational approach process can be applied to a \nvariety of industries, ranging from oil and gas to financial markets and retail, \nto name a few. What are the keys to successfully applying big data to opera -\ntional processes? Here are some of the most important issues to consider: \n \u2713 Fully understand the current process.\n \u2713 Fully understand where gaps exist in information. \n \u2713 Identify relevant big data sources.\n \u2713 Design a process to seamlessly integrate the data now and as it changes.\n \u2713 Modify analysis and decision-making processes to incorporate the use of \nbig data.\nUnderstanding Big Data Workflows\nTo understand big data workflows, you have to understand what a process is \nand how it relates to the workflow in data-intensive environments. Processes \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1503, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6f90733c-a74d-49d4-b4f6-4b9362b7abb2": {"__data__": {"id_": "6f90733c-a74d-49d4-b4f6-4b9362b7abb2", "embedding": null, "metadata": {"page_label": "206", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "807b8b05-0e36-405f-9e45-38fb7345b68a", "node_type": "4", "metadata": {"page_label": "206", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "5dc48dc46550b97aa6cafde96c02da5a8c9bfdde8bc4e635a235be0c70ac7830", "class_name": "RelatedNodeInfo"}}, "text": "206 Part V: Big Data Implementation \ntend to be designed as high level, end-to-end structures useful for decision \nmaking and normalizing how things get done in a company or organization. \nIn contrast, workflows are task-oriented and often require more specific data \nthan processes. Processes are comprised of one or more workflows relevant \nto the overall objective of the process.\nIn many ways, big data workflows are similar to standard workflows. In fact, \nin any workflow, data is necessary in the various phases to accomplish the \ntasks. Consider the workflow in the preceding healthcare example. One \nelementary workflow is the process of \u201cdrawing blood.\u201d Drawing blood is a \nnecessary task required to complete the overall diagnostic process. If some -\nthing happens and blood has not been drawn or the data from that blood test \nhas been lost, it will be a direct impact on the veracity or truthfulness of the \noverall activity.\nWhat happens when you introduce a workflow that depends on a big data \nsource? Although you might be able to use existing workflows with big data, \nyou cannot assume that a process or workflow will work correctly by just \nsubstituting a big data source for a standard source. This may not work \nbecause standard data-processing methods do not have the processing \napproaches or performance to handle the variety of complexity of the big \ndata.\nWorkload in context to  \nthe business problem\nThe healthcare example focuses on the need to conduct an analysis after the \nblood is drawn from the patient. In the standard data workflow, the blood is \ntyped and then certain chemical tests are performed based on the require -\nments of the healthcare practitioner. It is unlikely that this workflow under -\nstands the testing required for identifying specific biomarkers or genetic \nmutations. If you supplied big data sources for biomarkers and mutations, \nthe workflow would fail. It is not big data aware and will need to be modified \nor rewritten to support big data.\nThe best practice for understanding workflows and the effect of big data is to \ndo the following:\n \u2713 Identify the big data sources you need to use.\n \u2713 Map the big data types to your workflow data types.\n \u2713 Ensure that you have the processing speed and storage access to support \nyour workflow.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2316, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "035a58a1-e26c-422a-87ad-7892b869c5ef": {"__data__": {"id_": "035a58a1-e26c-422a-87ad-7892b869c5ef", "embedding": null, "metadata": {"page_label": "207", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "296e1811-93af-4857-8de1-d5999abd3dc7", "node_type": "4", "metadata": {"page_label": "207", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "c550a7549933299eb4b02eca0687b01cbee0cf3942665345bf89adb43265a833", "class_name": "RelatedNodeInfo"}}, "text": "207  Chapter 17: Operationalizing Big Data\n \u2713 Select the data store best suited to the data types.\n \u2713 Modify the existing workflow to accommodate big data or create new big \ndata workflow.\nAfter you have your big data workflows, it will be necessary to fine-tune these \nworkflows so that they won\u2019t overwhelm or contaminate your analysis. For \nexample, many big data source do not include well-defined data definitions \nand metadata about the elements of those sources. In some cases, these data \nsources have not been cleaned. You need to make sure that you have the \nright level of knowledge about the big data sources that you are going to use.\nEnsuring the Validity, Veracity,  \nand Volatility of Big Data\nHigh volume, high variety, and high velocity are the essential characteristics of \nbig data. These characteristics are covered in detail in Chapter 1. But other \ncharacteristics of big data are equally important, especially when you apply \nbig data to operational processes. This second set of \u201cV\u201d characteristics that \nare key to operationalizing big data includes\n \u2713 Validity:  Is the data correct and accurate for the intended usage?\n \u2713 Veracity:  Are the results meaningful for the given problem space?\n \u2713 Volatility:  How long do you need to store this data?\nData validity\nIt stands to reason that you want accurate results. But in the initial stages \nof analyzing petabytes of data, it is likely that you won\u2019t be worrying about \nhow valid each data element is. That initial stream of big data might actually \nbe quite dirty. In the initial stages, it is more important to see whether any \nrelationships exist between elements within this massive data source than to \nensure that all elements are valid.\nHowever, after an organization determines that parts of that initial data \nanalysis are important, this subset of big data needs to be validated because \nit will now be applied to an operational condition. When the data moves \nfrom exploratory to actionable, data must be validated. The validity of big \ndata sources and subsequent analysis must be accurate if you are to use the \nresults for decision making or any other reasonable purpose. Valid input \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2193, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c256693d-98ab-42f1-96c8-3f09c61b77d0": {"__data__": {"id_": "c256693d-98ab-42f1-96c8-3f09c61b77d0", "embedding": null, "metadata": {"page_label": "208", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d0896d9f-8bb1-4fcd-8922-8bd5c57607be", "node_type": "4", "metadata": {"page_label": "208", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ff84f73235f2643be12fc65bb8c1d5a1559ee80b21ba51de5d33d77e0aaeca9e", "class_name": "RelatedNodeInfo"}}, "text": "208 Part V: Big Data Implementation \ndata followed by correct processing of the data should yield accurate results. \nWith big data, you must be extra vigilant with regard to validity. For example, \nin healthcare, you may have data from a clinical trial that could be related to \na patient\u2019s disease symptoms. But a physician treating that person cannot \nsimply take the clinical trial results as though they were directly related to \nthe patient\u2019s condition without validating them.\nA considerable difference exists between a Twitter data stream and telemetry  \ndata coming from a weather satellite. Why would you want to integrate two  \nseemingly disconnected data sources? Imagine that the weather satellite \nindicates that a storm is beginning in one part of the world. How is that storm \nimpacting individuals who live in the path of that storm? With about half a  \nbillion users, it is possible to analyze Twitter streams to determine the impact \nof a storm on local populations. Therefore, using Twitter in combination with \ndata from a weather satellite could help researchers understand the veracity \nof a weather prediction.\nJust because you have data from a weather satellite, that doesn\u2019t mean the \ndata is a truthful representation of the weather on the ground in a specific \ngeography. If you want to get a truthful representation of the weather, you \nmight correlate a social media stream (like Twitter) with the satellite data \nfor a specific area. If people within the area publish observations about the \nweather and they align with the data from the satellite, you have established \nthe veracity of the current weather. While veracity and validity are related, \nthey are independent indicators of the efficacy of data and process.\nData volatility\nIf you have valid data and can prove the veracity of the results, how long does \nthe data need to \u201clive\u201d to satisfy your needs? In a standard data setting, you \ncan keep data for decades because you have, over time, built an understand -\ning of what data is important for what you do with it. You have established \nrules for data currency and availability that map to your work processes. For \nexample, some organizations might only keep the most recent year of their \ncustomer data and transactions in their business systems. This will ensure \nrapid retrieval of this information when required. If they need to look at a \nprior year, the IT team may need to restore data from offline storage to honor \nthe request. With big data, this problem is magnified.\nIf storage is limited, you must look at the big data sources to determine what \nyou need to gather and how long you need to keep it. With some big data \nsources, you might just need to gather data for a quick analysis. For example, \nif you are interested in the experiences of hybrid car owners, you might want \nto tap into Facebook and Twitter feeds to collect all the posts/tweets about \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2931, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0abcaff8-cb51-4145-ae0d-5acbc0bca447": {"__data__": {"id_": "0abcaff8-cb51-4145-ae0d-5acbc0bca447", "embedding": null, "metadata": {"page_label": "209", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "afad88eb-21a9-41df-93d9-dafa4407ad54", "node_type": "4", "metadata": {"page_label": "209", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "a6456c5df157000eb501702d7e2f141b519128ed5a6d64c2a366b595be5b5bfc", "class_name": "RelatedNodeInfo"}}, "text": "209  Chapter 17: Operationalizing Big Data\nhybrid cars. You could then store the information locally for further process -\ning. If you do not have enough storage for all this data, you could process the \ndata \u201con the fly\u201d (as you are gathering it) and only keep relevant pieces of \ninformation locally. How long you keep big data available depends on a few \nfactors:\n \u2713 How much data is kept at the source?\n \u2713 Do you need to process the data repeatedly?\n \u2713 Do you need to process the data, gather additional data, and do more \nprocessing?\n \u2713 Do you have rules or regulations requiring data storage?\n \u2713 Do your customers depend on your data for their work?\n \u2713 Does the data still have value or is it no longer relevant?\nDue to the volume, variety, and velocity of big data, you need to understand \nvolatility. For some sources, the data will always be there; for others, this is \nnot the case. Understanding what data is out there and for how long can help \nyou to define retention requirements and policies for big data.\nBig data and analytics can open the door to all kinds of new information about \nthe things that are most interesting in your day-to-day life. As a consumer, big \ndata will help to define a better profile for how and when you purchase goods \nand services. As a patient, big data will help to define a more customized \napproach to treatments and health maintenance. As a professional, big data \nwill help you to identify better ways to design and deliver your products and \nservices. This will only happen when big data is integrated into the operating \nprocesses of companies and organizations.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1633, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d34af4bd-dd6a-4a5a-856d-641c1c79a3c0": {"__data__": {"id_": "d34af4bd-dd6a-4a5a-856d-641c1c79a3c0", "embedding": null, "metadata": {"page_label": "210", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "97663dda-cd53-44bf-8b54-0d682609ac3a", "node_type": "4", "metadata": {"page_label": "210", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "da72e37094a963468a5be36c68d7cf720bddfc82cb446720331fcb571968be6f", "class_name": "RelatedNodeInfo"}}, "text": "210 Part V: Big Data Implementation \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 55, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "38f1e3d4-d9b4-45ea-9194-7dec706d42e0": {"__data__": {"id_": "38f1e3d4-d9b4-45ea-9194-7dec706d42e0", "embedding": null, "metadata": {"page_label": "211", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "289c9a0f-5208-4c5a-85b7-74e11c474114", "node_type": "4", "metadata": {"page_label": "211", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "38da6a2165c6a132a22bfdb8dd6b03a95d7492131bfaa7b9b7a6e38a6e727a0d", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 18\nApplying Big Data within  \nYour Organization\nIn This Chapter\n\u25b6 Understanding the economics of big data\n\u25b6 Integrating Enterprise Data Management and big data\n\u25b6 Designing an implementation road map\n\u25b6 Getting started\nA \nfter it is gathered and analyzed, big data will provide insights into \nexisting challenges and also open the door to solving new problems. \nWhile organizations see the potential for leveraging big data to solve many \npreviously unsolvable problems, the process comes at a cost. Operational \nprocesses, discussed in Chapter 17, will need to change to accommodate big \ndata. New types of data will need to be added into the environment. Also, new \nkinds of analysis will emerge to help understand the implications of big data \nand how it relates (or doesn\u2019t relate) to existing data. Finally, new technologies \nwill need to be employed to address the requirements of big data.\nUnderstanding some of the economics of big data, especially how to implement \nand integrate big data in your environment, will decide\n \u2713 What is the best use of big data for your organization?\n \u2713 How can you create a flexible, cost-effective big data implementation?\n \u2713 How do you get going with big data?\n \u2713 How do you minimize the disruption of a disruptive technology?\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1293, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9fdc4343-1ff5-44fd-83ca-15a427c50918": {"__data__": {"id_": "9fdc4343-1ff5-44fd-83ca-15a427c50918", "embedding": null, "metadata": {"page_label": "212", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a4454e8e-cf39-45f5-b164-eeef340d1f74", "node_type": "4", "metadata": {"page_label": "212", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b9cc677366bf1c8b8d93cacc7c7091698ea6aa49bea527dab01dace7e7038f6d", "class_name": "RelatedNodeInfo"}}, "text": "212 Part V: Big Data Implementation \nFiguring the Economics of Big Data\nThe best way to understand the economics of big data is to look at the \nvarious methods for putting big data to work for your organization. While \nspecific costs may vary due to the size of your organization, its purchasing \npower, vendor relationships, and so on, the classes of expense are fairly  \nconsistent. Big data economics should be analyzed in the following areas:\n \u2713 Identification of data types and sources\n \u2713 Business process modifications or new process creation\n \u2713 Technology changes or new technologies for big data\n \u2713 New talent acquisition and upgrades to existing talent\n \u2713 ROI potential of big data investments\nGiven the growing popularity of big data, it is best to consider the economics \nfrom two perspectives: getting started and steady-state. We look at these areas \nand try to understand the economic impacts and advantages of big data.\nIdentification of data types and sources\nAs big data matures, you will need to consider new and evolving data types \nand data sources. Some of these you may be able to control; others will con -\ntrol some of what you do. The most important decisions you need to make \nwith respect to types and sources are\n \u2713 What data will be necessary to address your business problem?\n \u2713 Where can you source the data?\n \u2713 What can you do with the data?\n \u2713 How often do you need to interact with the data?\n \u2713 Who maintains ownership of the data and the work products?\n \u2713 How long do you need to keep the data?\n \u2713 Can you trust the data and its source?\nNow look at an example to help you understand the practical aspects of \nthe related economics. If you are a brand manager in a consumer products \ncompany, you are likely to want to use big data to better understand your \ncustomers\u2019 needs, habits, buying patterns, and loyalty. Given these require -\nments, you will need to find data about sentiment, experience, usability, \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1964, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "72017dbf-147c-4d10-b1c4-ee12a34a6cc2": {"__data__": {"id_": "72017dbf-147c-4d10-b1c4-ee12a34a6cc2", "embedding": null, "metadata": {"page_label": "213", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7050e2cf-3b8a-44e1-8930-e2e15ad257ea", "node_type": "4", "metadata": {"page_label": "213", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "d9d15d30d0bf77fe48c113dfa9e680f7533ba558be5a8d32c0713bfee9a907c9", "class_name": "RelatedNodeInfo"}}, "text": "213  Chapter 18: Applying Big Data within Your Organization\ncompetitive alternatives, and so on. Some of this data will be available in \ntraditional forms like customer relationship management (CRM) systems and \nexisting data warehouses. More than likely, this brand manager is looking for \nmore than the traditional data and will need to understand where to get dif -\nferent perspectives.\nAnalyzing big data to anticipate what\u2019s next\nThe brand manager really wants to be able to go beyond asking questions. \nThat brand manager wants to be able to anticipate changes in customer \nrequirements or habits. Often hints are available within existing data. However, \nwithout enough data to analyze, these hints will be ignored because that data \nmay look like an outlier or even an error. But being able to anticipate even the \nmost subtle change could give the brand manager an early warning signal. That \nearly notification of a changing requirement could enable the brand manager \nto test new services and new packaging that could become important \u2014 before \na competitor knows that anything is changing.\nFinding the right data sources\nSourcing the data is the next step. It is not just about where to get the data, \nbut also the form or type of the data as well as the quality or trustworthiness \nof the data. Good sources of sentiment data are found in social web properties  \nlike Facebook, foursquare, Yelp, Pinterest, and Twitter. The sources you select \nmay be determined by the habits of your customers. For example, your ideal \ncustomer may be very active in social media. However, you might be a com -\npany that only does business-to-business selling. Will social media sites really \nhelp you serve your customers more proactively? You may find important \nbusiness-to-business (B2B) sites that should be part of your analysis. The \namount of data is vast and sometimes you are looking for the proverbial needle \nin the haystack: the few bits of sentiment about your product or brand hidden \nin the vastness of the social web. In addition, the structure and types of this \ndata vary from site to site, adding additional complexity and perhaps costs as  \nwell. The brand manager is going to need to understand the value of sourcing  \nand sifting through this data to get the supporting insights. Some of these \nsources can be easily and inexpensively examined, while others will require \ndeeper ROI analysis to determine the potential value of information on the site.\nWhat can you do with the data?\nAfter identifying the sources and types of data, the brand manager must \nthen understand what can be done with the data. Can it be modified? Can it \nbe stored locally for subsequent use? Is there a limit on how much data can \nbe gathered in a given time period? How often can the data be sourced? Is a \n\u201cthrottle\u201d limiting the speed of the data movement? How often does the data \nchange at the source? How long is the data stored at the source? Answering \nthese questions can help the brand manager understand the economic \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3046, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c117b427-cf16-447e-9a2c-b74939c6ca28": {"__data__": {"id_": "c117b427-cf16-447e-9a2c-b74939c6ca28", "embedding": null, "metadata": {"page_label": "214", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b5b21e9b-f5fe-4b74-b480-fc55a6e15eb8", "node_type": "4", "metadata": {"page_label": "214", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e44c5ad49cc6bd970d8c3b49ad57e642ee495771d407a0b2c764e9cbef530004", "class_name": "RelatedNodeInfo"}}, "text": "214 Part V: Big Data Implementation \nimpacts of big data usage. For example, your analysis might require unre -\nstricted access to a certain source. This level of access might be quite expen -\nsive. How important is constant access? If you use this data source every \nweek, will it impact revenue or future product direction? If the answer is yes, \nyou will need to spend the money.\nUnderstanding how often the data is used by internal systems can help to \ncontrol costs. If the requirements are to analyze customer sentiment in real \ntime across several social properties, the costs will be very high. If the analy -\nsis can be performed more leisurely or with fewer data sources, the costs can \nbe lower and more controllable (that is, only pay when you need to use the \ndata). Data usage and currency are key contributors to big data economics.\nSome big data source suppliers will want to maintain ownership of their data, \nlicensing it for specific, nondestructive uses. Others will be open with little \nor no access costs or overbearing usage requirements. The brand manager in \nthe example will need to look at each source and ensure that proper care is \ntaken with respect to who owns the data and who owns work products using \nthe data. Some data licensing will limit the usage to compute and destroy. \nYou can use the data as part of an analytics process but must then expunge \nthe data at the completion of the computations. Others may allow you to use \nthe data, but require you to \u201cgive it back\u201d when your analysis or computations \nare complete, enhancing the data source for other, future users. Care must \nbe taken to protect company information and work products as you integrate \nbig data into your work environment.\nIn the example, it is likely that the brand manager will also want to understand \nsentiment over a given time period. Has customer sentiment changed in the \npast month? Six months? A year? How about customer sentiment about com -\npetitive offerings in the same time periods? Knowing how often you need to \naccess the data can help to predict the costs associated with data capacity, \naccessibility, and currency.\nBig data economics should be understood from two dimensions: getting \nstarted and managing the steady state. Startup costs can be contained by find -\ning open data or freely accessible data sources. If more data center resources \nare required, you should consider cloud-based services where you can \u201cpay by \nthe drink.\u201d It is much easier to experiment when employing this open source \nor cloud services strategy. After you decide on the approach that will best \nhelp you achieve your business goals, you can begin to operationalize your \napproach. The capability to operationalize the approach to leveraging big data \nwill allow you to move to predictable steady-state economics. Of course, you \nmust also plan for the fact that costs may rise and new issues become impor -\ntant. However, you will start with the right foundation.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2995, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "402743a0-2d94-4e48-bc45-7350a9f47493": {"__data__": {"id_": "402743a0-2d94-4e48-bc45-7350a9f47493", "embedding": null, "metadata": {"page_label": "215", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f6d35e9a-bc55-457d-8b43-b03c5d44c65e", "node_type": "4", "metadata": {"page_label": "215", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b1f6b3b22ea4a406892dcfb4b476dd4dd36b3344bc42f7337e856b07ea7eb78f", "class_name": "RelatedNodeInfo"}}, "text": "215  Chapter 18: Applying Big Data within Your Organization\nBusiness process modifications  \nor new process creation\nAfter the brand manager in the example has vetted the data sources, she \nthen needs to understand what processes are affected. For example, identify -\ning new customers from big data sources and adding them (as prospects) to \nexisting customer databases will have a minimal impact. In other cases, you \nmay need to create new processes to understand how the big data sources \ncan be utilized to create new understandings about your brand or drive \ndeeper understandings of customer loyalty and retention. In any case, it is \nimportant to model the costs required to change existing work process or \ncreate new ones. The true economic impact of big data will need to balance \nthe costs of these changes with the potential benefit.\nThe technology impact of  \nbig data workflows\nSo far, the brand manager has identified types and sources of big data and \nhas scoped the required changes to business processes. Now she needs to \nunderstand the technology impacts of these discoveries. In an ideal world, it \nwill be possible to use a lot of existing technologies and applications when \nbig data is applied to workflows. However, it is much more likely that new \ntechnologies will need to be employed to extract maximum economic value \nfrom big data investments.\nAs discussed in Chapters 8, 9, and 10, many new and different tools are avail -\nable for big data. If a brand manager needs to gather data from several differ -\nent social sites, each with different data types, she will need to work with the \nIT teams to select what technology best fits the business and cost requirements. \nFor example, if a MapReduce engine is required, can Hadoop be used or is \na commercial implementation better suited to the tasks? Can existing data \nwarehouses be used or is it necessary to implement Apache Hive? Can an \nRDBMS store the big data or will a different data store be required? You will \ncertainly have implementations of products that will incorporate elements of \nHadoop and Hive to take advantage of this hot new trend. However, it is most \nlikely that this approach isn\u2019t going to take you far enough to solve the differ -\nent situations that you will be applying to big data.\nIt is safe to say that new technologies will be required as you introduce big \ndata into your work environments. The existing technologies are too brittle \nor because they are designed for a specific task, they are too simplistic or \nunderpowered to address the stress of big data applications. This means that \ncosts will be associated with taking your company to the next level with big \ndata. This is why your economic analysis will be so important.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2764, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ef815dba-4f17-4f92-b82c-e965a5ac7389": {"__data__": {"id_": "ef815dba-4f17-4f92-b82c-e965a5ac7389", "embedding": null, "metadata": {"page_label": "216", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b25bd757-99b1-4da2-b2b6-4e14bfb342ba", "node_type": "4", "metadata": {"page_label": "216", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "2974f2402de0814b65d2d39cb3ab9d95d03498566333bc1da44ead9884f0a436", "class_name": "RelatedNodeInfo"}}, "text": "216 Part V: Big Data Implementation \nFinding the talent to support  \nbig data projects\nIn the example, the brand manager\u2019s needs will create new processes and \ntechnologies. Each of these requirements, in turn, will drive the need for new \nskills and upgrading existing skills in many departments, but most visibly in \nthe IT and business analyst areas.\nThe business analysts will need to consider augmenting their ranks with data \nscientists. This can be accomplished with consulting relationships in the \nstartup phases, but should transition to permanent staffing as the direction \nand benefits become more clear. A single data scientist is not likely to be the \nanswer unless you are in a small- to medium-size enterprise or organization. \nThe most leverage will be realized by creating a team of data scientists who \nare charged with discovering big data sources, analytical processes, and \nbusiness process impacts.\nFor the IT team, knowledge of new big data technologies will need to be intro -\nduced to existing team members through training and mentoring. It is fair to \nassume that new talent will need to be hired as your organization approaches \nsteady state. Consulting resources can and should be employed to help your \norganization get jump-started with its big data initiatives. While you should \nlook at consulting companies as well as independent data scientists, many \nuniversities and colleges have begun to offer courses that should help fill the \ngap in the short term. In the long term, vendors providing solutions will have \nto create more usable big data solutions that abstract the complexity.\nCalculating the return on investment \n(ROI) from big data investments\nIn the example, the brand manager needs to create an ROI case for the big \ndata to better understand and predict new ways of growing the customer \nbase. All the costs discussed must be balanced with the potential outcomes \nof the investments. How long will it take to recoup an investment in a big data \ninitiative? Like many things, the answer is \u201cit depends.\u201d If the brand manager \nis building out a solution unique to her area of responsibility, the ROI may \nnot be as attractive as building a generic approach to using big data across \nmany areas of the business. If other brand managers, customer support, or \nsalespeople can leverage the enhancements, the ROI can look very attractive, \nperhaps even compelling. The most important part of building the ROI model \nis to fully bake in the economics across all the areas examined earlier in this \nchapter to ensure more complete coverage and better predictability of the \noutcomes.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2643, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c6b86ce8-3717-42fb-8aac-63eecb2144f8": {"__data__": {"id_": "c6b86ce8-3717-42fb-8aac-63eecb2144f8", "embedding": null, "metadata": {"page_label": "217", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9af2a35e-c949-4228-aeab-23f3cd733856", "node_type": "4", "metadata": {"page_label": "217", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "2aa2bc1c08945436393f187ebf62e1a5e209013b715d48e5166de220bf9475a2", "class_name": "RelatedNodeInfo"}}, "text": "217  Chapter 18: Applying Big Data within Your Organization\nNow that you have a better understanding about what  you need to do to intro -\nduce big data in your organization, consider how you might accomplish it.\nEnterprise Data Management  \nand Big Data\nEnterprise Data Management (EDM) is an important process for understand -\ning and controlling the economics of data in your enterprise or organization. \nAlthough EDM is not required for big data, the proper application of EDM will \nhelp to ensure better integration, control, and usability of big data.\nDefining Enterprise Data Management\nEDM is a comprehensive approach to defining, governing, securing, and \nmaintaining the quality of all data involved in the business processes of an \norganization. EDM establishes policy about and ownership of key data types \nand sources as well as helping to create a strategic context for the technol -\nogy underpinnings of data life cycle management. The primary object of EDM \nprocesses is to sustain a single version of the \u201ctruth.\u201d Figure 18-1 depicts the \ncore components of EDM.\n Figure 18-1:  \nPillars of \nEnterprise \nData  \nManagement.\n \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1159, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "03344cbe-ad47-43aa-b440-ca51a70768b5": {"__data__": {"id_": "03344cbe-ad47-43aa-b440-ca51a70768b5", "embedding": null, "metadata": {"page_label": "218", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4d104773-bc31-4081-8418-f9a6bb50f835", "node_type": "4", "metadata": {"page_label": "218", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "60555f0538271089aa5ca3d6efa7d79f78a96c9d54edc347b25289af4352cc1b", "class_name": "RelatedNodeInfo"}}, "text": "218 Part V: Big Data Implementation \nWhile your organization\u2019s version of EDM may vary slightly from what is \nshown in Figure 18-1, the tenets remain true: Data must be modeled, man -\naged, and secured so that you can trust the processing results as part of your \ndecision-making activities. It should also be noted that the absence of EDM in \nyour organization is not a barrier to adopting big data. While not as effective, \nEnterprise Data Management can be performed at a departmental or even \na project level. With that in mind, you need to examine where adoption of \nbig data can impact enterprise data management practices. After you begin \nthinking about using big data in combination with your systems of record, \nyou must have a good handle on the governance and stewardship of the \noverall data management environment. After all, you will be making decisions \nabout business strategy, so it is critical that the data elements that you are \ncomparing or analyzing are accurate, meaningful, and secure. We talk further \nabout governance and compliance in Chapter 19.\nCreating a Big Data Implementation \nRoad Map\nBig data implementation plans will be different depending on your business \ngoals, the maturity of your data management environment, and the amount \nof risk your organization can absorb. So, begin your planning by taking into \naccount all the issues that will allow you to determine an implementation \nroad map. Here are a few of the factors that you need to consider:\n \u2713 Business urgency\n \u2713 Projected capacity\n \u2713 Preferred software development methodology\n \u2713 Available budgets and skill sets\n \u2713 Appetite for risk\nNow look at these factors and some example road maps you can use as  \nguidelines for your big data implementations.\nUnderstanding business urgency\nMany ambitious organizations always seem to need the latest and greatest \ntechnologies immediately. In some situations, an organization can demonstrate \nthat the availability of important big data sources can lead to new strategies. \nIn these cases, it makes sense to create a strategy and plan. It is a mistake to \nassume that big data adoption and implementation are a defined project. The \nadoption of big data has broad implications for the company\u2019s overall data \nmanagement strategy. So, independent of some of the other factors involved, \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2345, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a4855dc1-a69e-476d-889d-5b9f60464611": {"__data__": {"id_": "a4855dc1-a69e-476d-889d-5b9f60464611", "embedding": null, "metadata": {"page_label": "219", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b57b3f93-aa17-4adf-af2b-21e9a5128472", "node_type": "4", "metadata": {"page_label": "219", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ae0702c1b1fe1c653bf78d88b5ebf58d3e0f9aed348d68337bb800fe7cab9d0b", "class_name": "RelatedNodeInfo"}}, "text": "219  Chapter 18: Applying Big Data within Your Organization\nthe time required to design your big data solutions should be clearly noted \non any road map. In addition, the design tasks should never be glossed over \nor eliminated. Doing so will reduce the value of any big data initiative. For \nexample, new data sources may need to be acquired. New equipment and \nsoftware may be required. In addition, you may need to sign up for cloud ser -\nvices. These services need to have the service level and security guarantees \nthat conform to your company\u2019s requirements.\nProjecting the right amount of capacity\nBecause the introduction of big data into your environment is a necessity, \nyou must be able to answer the questions \u201cHow much data do you need?\u201d \nand \u201cHow fast do you need to analyze it?\u201d The answers will provide a context \nfor the design, implementation, and testing phases of your road map. For \nexample, if you expect to need to gather 200GB of data and only keep it until \nyour analysis is complete, you should expect to set up this big data solution \nin two to four weeks. On the other hand, if you expect to require 2 petabytes \nof initial data, with a growth projection of 0.5 petabytes per month, and you \nneed to keep all the data for years, you should plan on an implementation \ntaking several months. In either case, if you need to perform the gathering \nand analysis in or near real time, you should expect your implementation \ntime to increase by 50 percent.\nSelecting the right software  \ndevelopment methodology\nMost companies and organizations have IT teams that follow prescribed devel -\nopment processes and practices. Some of these development methodologies \nare well suited to big data implementations, while others, sadly, are not.\nBig data projects are best suited for an agile and interactive development \nprocess. Iterative methodologies use short time cycles with rapid results \nand constant user involvement to incrementally deliver a business solution. \nTherefore, it is not surprising that an iterative process is the most effective \ndevelopment methodology for big data implementations.\nBalancing budgets and skill sets\nIt is always difficult to anticipate the budgetary requirements for a new type of \nproject like big data. The best practice is to clearly understand the expected \ncosts and downstream benefits of your big data implementation and then \nsecure an appropriate budget for the initiative. An iterative approach will do \nthe best job of determining the best approach to project budgeting. Therefore, \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2568, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b9bd91bc-855a-4cb3-b8a8-35f19afe278a": {"__data__": {"id_": "b9bd91bc-855a-4cb3-b8a8-35f19afe278a", "embedding": null, "metadata": {"page_label": "220", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4ccb95f3-13ba-4cc6-b2ab-26689d84b124", "node_type": "4", "metadata": {"page_label": "220", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "2d6ef1247c8e80ead670d800886bcbf23db08bcfa4ede67585322ad147dff2a3", "class_name": "RelatedNodeInfo"}}, "text": "220 Part V: Big Data Implementation \nbudget can be allocated up front and then released as milestones as the  \nprogress of the project is achieved.\nGetting the right skill sets for any project is another challenge. Often the most \nsought-after individuals are stretched thin across several initiatives. Staff aug -\nmentation is often the answer to resource challenges, but in an emerging, high-\ngrowth area, this is harder than usual. Big data skills are somewhat nascent as \nthe market evolves. Over time, you will find more training and more qualified \nprofessionals. In the meantime, the best practice is to identify and acquire \nsome data science skills for design and planning, Hadoop and NoSQL skills for \nimplementation, and parallel/cluster computing skills for operations. You can \nalso test products and build skill by conducting a pilot or proof-of-concept \nimplementation in a cloud environment. Getting these skills in-house as quickly \nas possible will help to ensure success with your big data adoption.\nDetermining your appetite for risk\nEvery organization has a culture that will determine how much risk manage -\nment it is willing to assume. If you are in a highly competitive market, you \nmay be forced to take more risks on potential market innovation than a com -\npany whose products are required by customers and where fewer competi -\ntors exist. Even companies in highly competitive markets may be cautious \nbefore assuming risk. So, you have to understand the dynamics of your orga -\nnization before you embark on a big data project. For example, you might \nwant to create a bounded pilot project that demonstrates to management \nwhat is possible. In other cases, your organization may want to establish an \nambitious plan based on predictive analytics of big data that could transform \nthe customer experience.\nIf your organization is risk averse, the best you can hope to do is watch \nthe evolution of big data and bring proposals to the table as it emerges. \nIdentifying successes in other organizations can help to reduce the anxiety of \nintroducing new technologies into your environment.\nEven organizations with an appetite for high risk must also be wary as they \nadopt big data. It is all too easy to oversell the benefits or set very high \nexpectations about working with big data. The development and accultura -\ntion of any new technology or solution can be fraught with failures. Using \nagile methodologies to help to explicate fast successes and fast failures is the \nbest practice for setting proper expectations in a trailblazing organization.\nStarting Your Big Data Road Map\nThe next two diagrams can help you to form a framework for creating road \nmaps that are best suited to your organization\u2019s capability to adopt big data. \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2787, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d6472d5f-037b-45d5-9f46-93638b4f18e0": {"__data__": {"id_": "d6472d5f-037b-45d5-9f46-93638b4f18e0", "embedding": null, "metadata": {"page_label": "221", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "97dbb027-c699-4352-ab8d-b489f5d6420d", "node_type": "4", "metadata": {"page_label": "221", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "15c159a6f17db6dbf4066d08567f86dee9eaaa14f22c9841cc971009bba309dc", "class_name": "RelatedNodeInfo"}}, "text": "221  Chapter 18: Applying Big Data within Your Organization\nThese are just examples of how other new technologies have been introduced \nsuccessfully during their early emergence into daily use. You should think of \nthese as starting points for how you can get the ball rolling with big data.\nFigure 18-2 is an example of a road map you can adopt for your first big data \ninitiative. It assumes that little or no process or technology is in place that is \ncapable of meeting the requirements of big data volume, variety, and veloc -\nity. The desire is to keep the project moving, but not at a breakneck pace. \nOne sure way to impugn big data as a key enabler for the next generation of \nyour business decision making is to rush the process.\n Figure 18-2:   \nMajor \nphases of \nan inaugural \nbig data \nimplementa-\ntion.\n \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 837, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e7ea517e-9f19-49ec-91b0-99c38bba23ba": {"__data__": {"id_": "e7ea517e-9f19-49ec-91b0-99c38bba23ba", "embedding": null, "metadata": {"page_label": "222", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4eed4177-b25d-4871-9f7c-69f38d10d948", "node_type": "4", "metadata": {"page_label": "222", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f526b8315cd4fefbc676d563f07b9502e2a98d29fb8082cf6e45dbb78439bea4", "class_name": "RelatedNodeInfo"}}, "text": "222 Part V: Big Data Implementation \nIf your organization has experience with business intelligence applica -\ntions and analytics, has relatively mature data management practices, and \nhas established a high-capacity infrastructure and operations, the task of \nadopting big data is a bit easier. This does not imply guaranteed success or \nreduced risk. The existence of these capabilities is an indicator of the overall \nmaturity of your company and its willingness to ingest new information, tech -\nnology, and skills. The road map for a more experienced approach might look \nlike what is shown in Figure 18-3.\n Figure 18-3:   \nMajor \nphases of a \nmature big \ndata imple-\nmentation.\n \nMost of the activities are the same and very often can be run in parallel, \ndepending again on organizational maturity. The good news is that everyone \ncan achieve similar results. If you are diligent with after-action analysis and \nyou incorporate improvements based on the lessons learned from the first \nor second project, you should be able to reduce the time to design, develop, \ntest, implement, and deploy big data initiatives.\nGetting started is always easier if some of the people involved have done it \nbefore. With new disruptive business and technology like big data, you won\u2019t \nfind many people who have \u201cbeen there, done that.\u201d Here are a few tips to con -\nsider as you contemplate bringing big data into your company or organization:\n \u2713 Get some help.  Don\u2019t be adverse to hiring an expert or two as consultants. \nBe sure that they know their \u201cstuff\u201d and ensure that they are capable of \nmentoring people in your organization. They should be willing to work \nthemselves out of a job.\n \u2713 Get training.  Take classes, buy and read books (like this one!), do \nresearch on the Internet, ask questions, and attend a conference or  \ntwo. Getting a better grounding can help with all the subsequent  \ndecision making.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1930, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9e461e0d-487e-4525-83ef-83fd38364240": {"__data__": {"id_": "9e461e0d-487e-4525-83ef-83fd38364240", "embedding": null, "metadata": {"page_label": "223", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "da1fd3f0-4d12-4689-aa96-7d1018484872", "node_type": "4", "metadata": {"page_label": "223", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "acd48204edef50b19f0be7f7ba077a082abe52a83ca5cfe187338f43299995a7", "class_name": "RelatedNodeInfo"}}, "text": "223  Chapter 18: Applying Big Data within Your Organization\n \u2713 Experiment.  Plan to fail. Fast failure is becoming de rigueur for contem -\nporary technology-driven organizations. The best lessons learned often \ncome from failures. Study other people\u2019s experiences as well.\n \u2713 Set proper expectations.  Some say that the key to happiness is low \nexpectations. In the business world, properly set expectations can mean \nthe difference between success and failure. A successful project may be \nviewed as a failure if the business benefits are overstated or if it takes \n50 percent longer to deliver. Big data offers huge potential to your busi -\nness, but only if you accurately represent the value, costs, and time to \nimplement.\n \u2713 Be holistic.  Try to look at all the dimensions to any given big data initia -\ntive. If the project is delivered on time and on budget, but the end users \nweren\u2019t trained or ready to use it, the project may fall into failure. Most \nsuccessful project managers understand that it\u2019s about people, process, \nand technology, at a very detailed level.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1096, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c77e6d3f-999b-4089-8a5c-a6c73c1b4165": {"__data__": {"id_": "c77e6d3f-999b-4089-8a5c-a6c73c1b4165", "embedding": null, "metadata": {"page_label": "224", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7201e3c1-d82a-4a25-bec8-eb3a436980ff", "node_type": "4", "metadata": {"page_label": "224", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "dc4027edceb145270a093128452785cfe24a4791344c71ea159a37bb6d0c8208", "class_name": "RelatedNodeInfo"}}, "text": "224 Part V: Big Data Implementation \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 55, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6c8f4143-449c-418e-8d23-2e93297d2e8b": {"__data__": {"id_": "6c8f4143-449c-418e-8d23-2e93297d2e8b", "embedding": null, "metadata": {"page_label": "225", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f186b7ff-c986-4836-bde8-9dfe98881ad7", "node_type": "4", "metadata": {"page_label": "225", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "5cd44ea139aff2ac6b5da09e583d2be3e13c284d5d1d2345d6a5b05438c608c7", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 19\nSecurity and Governance for  \nBig Data Environments\nIn This Chapter\n\u25b6 Considering security requirements for big data\n\u25b6 Governing big data\n\u25b6 Approaching a big data ecosystem\n\u25b6 Extending governance for big data analytics\n\u25b6 Developing a secure big data environment\n\u25b6 Maintaining a safe big data environment\nI \nn many areas of data management, an assumption exists that the data being \nleveraged for analysis and planning has been well vetted and secure. It \nhas typically been through a data-cleansing and -profiling process so that the \ndata can be trusted. The world of big data offers a new set of challenges and \nobstacles that make security and governance a challenge. Many individuals \nand organizations working with big data assume that they do not have to worry \nabout security or governance. Therefore, little thought or planning is done. \nThis all changes, however, when those big data sources become operational. \nIn this chapter, we present the issues that you need to think about and plan \nfor when you begin to leverage big data sources as part of your analysis and \nplanning process.\nSecurity in Context with Big Data\nWhile companies are very concerned about the security and governance of \ntheir data in general, they are unprepared for the complexities that are  \npresented by the management of big data.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1348, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "63cc13b3-659a-4560-b2e0-4d4816289844": {"__data__": {"id_": "63cc13b3-659a-4560-b2e0-4d4816289844", "embedding": null, "metadata": {"page_label": "226", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f14dc418-4cd5-4819-aa7e-77e359b7fab4", "node_type": "4", "metadata": {"page_label": "226", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "fa44f18b152820aa24e02506e72419847d464b7fdb84311167c4cbdf2630bc74", "class_name": "RelatedNodeInfo"}}, "text": "226 Part V: Big Data Implementation \n Information governance is the capability to create an information resource  \nthat can be trusted by employees, partners, and customers, as well as govern -\nment organizations.\nOften big data analysis is conducted with a vast array of data sources that \nmight come from many unvetted sources. Additionally, your organization \nneeds to be aware of the security and governance policies that apply to vari -\nous big data sources. Your organization might be looking to determine the \nimportance of large amounts of new data culled from many different unstruc -\ntured or semi-structured sources. Does your newly sourced data contain \npersonal health information (PHI) that is protected by the Health Insurance \nAccountability and Portability Act (HIPAA) or personal identifiable informa -\ntion (PII) such as names and addresses? Once you acquire the data, you will \nsubject your company to compliance issues if it is not managed securely. \nSome of this data will not be needed and must be properly disposed of. The \ndata that remains will need to be secured and governed. Therefore, what -\never your information management strategy is, you will have to have a well-\ndefined security strategy. \nSecurity is something you can never really relax about because the state of \nthe art is constantly evolving. Hand in hand with this security strategy needs \nto be a governance strategy. The combination of security and governance \nwill ensure accountability by all parties involved in your information manage -\nment deployment. Managing the security of information needs to be viewed \nas a shared responsibility across the organization. You can implement all the \nlatest technical security controls and still face security risks if your end users \ndon\u2019t have a clear understanding of their role in keeping all the data that they \nare working with secure.\nAssessing the risk for the business\nBig data is becoming critical to business executives who are trying to under -\nstand new product direction and customer requirements or understand \nthe health of their overall environment. However, if the data from a variety \nof sources introduces security risks into the company, unintended conse -\nquences can endanger the company. You have a lot to consider, and under -\nstanding security is a moving target, especially with the introduction of big \ndata into the data management landscape. Ultimately, education is key to \nensuring that everyone in the organization has an understanding of his or her \nroles and responsibilities with regard to security.\nRisks lurking inside big data\nWhile security and governance are corporate-wide issues that companies \nhave to focus on, some differences are specific to big data that you need to \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2772, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9729dc55-73cd-4032-8bc1-ceb8cd19ee42": {"__data__": {"id_": "9729dc55-73cd-4032-8bc1-ceb8cd19ee42", "embedding": null, "metadata": {"page_label": "227", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "7aabe694-f51a-45b0-96ee-da321ab0d900", "node_type": "4", "metadata": {"page_label": "227", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b67d0eaaa605a70e628e13791d7e9dd6474aa7eebc4fdd98876d0b916ff16aa3", "class_name": "RelatedNodeInfo"}}, "text": "227  Chapter 19: Security and Governance for Big Data Environments\nremember. For example, if you are collecting data from unstructured data \nsources such as social media sites, you have to make sure that viruses or \nbogus links are not buried in the content. If you take this data and make it \npart of your analytics system, you could be putting your company at risk. \nAlso, keep in mind what the original source of this data might be. An unstruc -\ntured data source that might have interesting commentary about the type of \ncustomer you are trying to understand may also include extraneous noise. \nYou need to know the nature of this data source. Has the data been verified? \nIs it secure and vetted against intrusion? The more reputable social media \nsites, for example, will watch closely for patterns of malicious behavior and \ndelete those accounts before they cause damage. This requires a level of \nsophisticated big data analysis that not all sites are capable of. Your organi -\nzation may have discovered a wonderful site, but that site has been hacked \nand you have selected that data as part of your big data platform. The con -\nsequences can be serious. Not all security threats are deliberate. You don\u2019t \nwant to incorporate a big data source that includes sensitive personally \nidentifiable information that could put your customers and your company\u2019s \nreputation at risk.\nUnderstanding Data Protection Options\nSome experts believe that different kinds of data require different forms of \nprotection and that, in some cases in a cloud environment, data encryption \nmight, in fact, be overkill. You could encrypt everything. You could encrypt \ndata, for example, when you write it to your own hard drive, when you send \nit to a cloud provider, and when you store it in a cloud provider\u2019s database. \nYou could encrypt at every layer.\nEncrypting everything in a comprehensive way reduces your exposure; how -\never, encryption poses a performance penalty. For example, many experts \nadvise managing your own keys rather than letting a cloud provider do so, \nand that can become complicated. Keeping track of too many keys can be \na nightmare. Additionally, encrypting everything can create other issues. \nFor example, if you\u2019re trying to encrypt data in a database, you will have to \nexamine the data as it\u2019s moving (point-to-point encryption) and also while it\u2019s \nbeing stored in the database. This procedure can be costly and complicated. \nAlso, even when you think you\u2019ve encrypted everything and you\u2019re safe, that \nmay not be the case.\n One of the long-standing weaknesses with encryption strategies is that your \ndata is at risk before and after it\u2019s encrypted. For example, in a major data \nbreach at Hannaford Supermarkets in 2008, the hackers hid in the network \nfor months and were able to steal payment data when customers used their \ncredit card at the point of sale. This breach took place before the data was \nencrypted.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2962, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "eee79fa8-48bb-4271-bebe-f000ad300ccb": {"__data__": {"id_": "eee79fa8-48bb-4271-bebe-f000ad300ccb", "embedding": null, "metadata": {"page_label": "228", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e9b9e98c-67e9-4d6b-8c97-d8d6532cfe1d", "node_type": "4", "metadata": {"page_label": "228", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "a1ab90a29ffb96c3ae297b1e37da75f2563512e2182abd181ce85f13a26cebd6", "class_name": "RelatedNodeInfo"}}, "text": "228 Part V: Big Data Implementation \nMaintaining a large number of keys can be impractical, and managing the \nstoring, archiving, and accessing of the keys is difficult. To alleviate this \nproblem, generate and compute encryption keys as needed to reduce  \ncomplexity and improve security.\nHere are some other available data-safeguarding techniques:\n \u2713 Data  anonymization:  When data is anonymized, you remove all data \nthat can be uniquely tied to an individual (such as a person\u2019s name, \nSocial Security number, or credit card number). Although this technique \ncan protect some personal identification, hence privacy, you need to be \nreally careful about the amount of information you strip out. If it\u2019s not \nenough, hackers can still figure out whom the data pertains to.\n \u2713 Tokenization:  This technique protects sensitive data by replacing it \nwith random tokens or alias values that mean nothing to someone who \ngains unauthorized access to this data. This technique decreases the \nchance that thieves could do anything with the data. Tokenization can \nprotect credit card information, passwords, personal information, and \nso on. Some experts argue that it\u2019s more secure than encryption.\n \u2713 Cloud database controls: In this technique, access controls are built \ninto the database to protect the whole database so that each piece of \ndata doesn\u2019t need to be encrypted.\nThe Data Governance Challenge\nData governance is important to your company no matter what your data \nsources are or how they are managed. In the traditional world of data ware -\nhouses or relational database management, it is likely that your company has \nwell-understood rules about how data needs to be protected. For example, \nin the healthcare world, it is critical to keep patient data private. You may \nbe able to store and analyze data about patients as long as names, Social \nSecurity numbers, and other personal data is masked. You have to make sure \nthat unauthorized individuals cannot access private or restricted data. What \nhappens when you flood your environment with big data sources that come \nfrom a variety of sources? Some of these sources will come from commercial \nthird-party vendors that have carefully vetted the data and masked out  \nsensitive data. \nHowever, it is quite likely that the big data sources may be insecure and \nunprotected, and include a lot of personal data. During initial processing of \nthis data, you will probably analyze lots of data that will not turn out to be \nrelevant to your organization. Therefore, you don\u2019t want to invest resources \nto protect and govern data that you do not intend to retain. However, if \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2657, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "08bad362-b5d7-46df-bd82-c53ba090cfee": {"__data__": {"id_": "08bad362-b5d7-46df-bd82-c53ba090cfee", "embedding": null, "metadata": {"page_label": "229", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d8b8baed-0785-4b0b-82f4-2866b9cf2aba", "node_type": "4", "metadata": {"page_label": "229", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "864da225dd2da78d59f71be8017fea4399b651c585d5f18523502b1800e5d54a", "class_name": "RelatedNodeInfo"}}, "text": "229  Chapter 19: Security and Governance for Big Data Environments\nsensitive personal data passes across your network, you may expose your \ncompany to unanticipated compliance requirements. For data that is truly \nexploratory, with unknown contents, it might be safer to perform the initial \nanalysis in a \u201cwalled\u201d environment that is internal but segmented, or in the \ncloud.\nFinally, after you decide that a subset of that data is going to be analyzed \nmore deeply so that results may be incorporated into your business process, \nit is important to institute a process of carefully applying governance require -\nments to that data.\nWhat issues should you consider when you incorporate these unvetted \nsources into your environment? Consider the following:\n \u2713 Determine beforehand who is allowed to access new data sources initially \nas well as after the data has been analyzed and understood.\n \u2713 Understand how this data will be segregated from other companies\u2019 data.\n \u2713 Understand what your responsibility is to leverage the data. If the data \nis privately owned, you have to make sure that you are adhering to  \ncontracts or rules of use. Some data may be linked to a usage contract \nwith a vendor.\n \u2713 Understand where your data will be physically located. You may include \ndata that is linked to customers or prospects in specific countries that \nhave strict privacy requirements. You need to be aware of the details of \nthese sources to avoid violating regulations.\n \u2713 Understand how your data needs to be treated if it is physically moved \nfrom one location to another. Are you going to store some of this data \nwith a cloud provider? What type of promises will that provider offer in \nterms of where the data will be stored, and how well it will be secured?\nJust because you have created a security and governance process for your \ntraditional data sources doesn\u2019t mean that you can assume that employees and \npartners will expand those rules to new data sources. You need to consider \ntwo key issues: visibility of the data and the trust of those working with the data.\n \u2713 Visibility:  While business analysts and partners you are working with \nmay be eager to use these new data sources, you may not be aware of \nhow this data will be used and controlled. In other words, you may not \nhave control over your visibility into your resources that are running \noutside of your control. This situation is especially troublesome if you \nneed to ensure that your provider is following compliance regulations \nor laws. This is also true when you are using a cloud provider to manage \nthat data because the storage may be very inexpensive to manage.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2669, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cef72f88-821f-41f9-8df1-f394f1ad4185": {"__data__": {"id_": "cef72f88-821f-41f9-8df1-f394f1ad4185", "embedding": null, "metadata": {"page_label": "230", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cd719117-5c20-4c7c-8489-7826ede9f7e7", "node_type": "4", "metadata": {"page_label": "230", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1ed3a3dfe8422a2cb1a63a055082dabe7c1438773745a980119c7469e9a55159", "class_name": "RelatedNodeInfo"}}, "text": "230 Part V: Big Data Implementation \n \u2713 Unvetted employees:  Although your company may go through an exten -\nsive background check on all of its employees, you\u2019re now trusting that \nno malicious insiders work in various business units outside of IT. You \nalso have to assume that your cloud provider has diligently checked its \nemployees. This concern is real because close to 50 percent of security \nbreaches are caused by insiders (or by people getting help from insid -\ners). If your company is going to use these new data sources in a highly \ndistributed manner, you need to have a plan to deal with inside as well \nas outside threats.\n You have a responsibility to make sure that your new big data sources do not \nopen your company to unanticipated threats or governance risks. It is your \nresponsibility to have good security, governance processes, and education in \nplace across your entire information management environment.\nAs with any technology life cycle, you need to have a process for assessing \nthe capability of your organization to meet the readiness of all constituents \nto follow security and governance requirements. You may already have \nprocesses for data security, privacy, and governance in place for your exist -\ning structured databases and data warehouses. These processes need to be \nextended for your big data implementation.\nFor example, is the chief security officer of the company aware of the new \ndata sources being used in the various businesses? Is it clear how you are \nallowed to use third-party data sources? If you begin to incorporate propri -\netary data into your big data environment, your company may be violating \ncopyright rules. When you create a big data environment that brings in a lot \nof new data sources, have you exposed private data that should be masked? \nAt the same time, are you adhering to the data privacy policies of the differ -\nent countries that you are operating in?\nAuditing your big data process\nAt the end of the day, you have to be able to demonstrate to internal and \nexternal auditors that you are meeting the rules necessary to support the \noperations of the business. You will need a way to show logs or other evidence \nthat the data you are using is secure and clean. You will need to explain the \nsources of that data. Will you be able to validate the results so that you mini -\nmize the risk to the company? You may have to prove that you have archived \nthe data that you are using to make decisions and run the business. This may \nbe well-managed for your traditional databases and your data warehouse, but \nyour unstructured big data sources have not been added to this process.\nAlthough external auditors may not analyze the accuracy of the data warehouse\u2013\nbased data with external big data sources, your internal process will dictate \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2835, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "40d1a7c3-9a69-45bc-a6c0-bea351c7f718": {"__data__": {"id_": "40d1a7c3-9a69-45bc-a6c0-bea351c7f718", "embedding": null, "metadata": {"page_label": "231", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0fef8586-e4c9-48c9-ab00-878fd3461a6d", "node_type": "4", "metadata": {"page_label": "231", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "fa2d4b6201e5d109d114c41d09037c119e69a534d92c2c88994ef55a7382b2a0", "class_name": "RelatedNodeInfo"}}, "text": "231  Chapter 19: Security and Governance for Big Data Environments\nthat these sources be well synchronized. For example, the data warehouse \nwill have a clear set of master data definitions, but the big data sources may \nnot have documented metadata. Therefore, it is important that external data \nsources be managed in a way that metadata definitions are codified so that \nyou can have a set of consistent metadata across these sources. Thinking \nthrough this process can make the difference between business success and \nfailure.\nIdentifying the key stakeholders\nOne of the characteristics of big data is that it is typically tied to specific \nbusiness initiatives. For example, the Marketing organization wants to be \nable to use the huge volumes of data generated by social media sites such \nas Facebook, Twitter, and so on. Operations teams will want to manage their \nsupply chain leveraging RFID data. The Human Resources department will be \neager to keep track of what employees are publishing on social media sites \nto make sure that they are not violating internal and external regulations. A \nmedical claims department will want to keep track of the regulations deter -\nmining how patient claim information within health insurance records is \nmanaged so that privacy rules are not violated. All of these constituents may \nreside within the same company, so it is critical that everyone has a common \nunderstanding of what the rules are and that the infrastructure is in place to \nkeep the company consistently safe.\nPutting the Right Organizational \nStructure in Place\nTypically, companies begin their journey to big data by starting with an \nexperiment to see whether big data can play an important role in defining \nand impacting business strategy. However, after it becomes clear that big \ndata will have a strategic role as part of the information management envi -\nronment, you have to make sure that the right structure is in place to sup -\nport and protect the organization. \nBefore you establish policies, you first have to know what you are dealing with. \nFor example, are you going to involve transactional systems, social media \ndata, or machine-generated data? Do you intend to combine information from \nthese different sources as part of your data analytics strategy? If you are \nplanning to move forward with more than an isolated experiment, you will \nneed to update your governance strategy so that you are prepared to manage \na new variety of data in ways that are safe.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2516, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2d7ae344-20d3-4a6b-87ff-44e2960816f7": {"__data__": {"id_": "2d7ae344-20d3-4a6b-87ff-44e2960816f7", "embedding": null, "metadata": {"page_label": "232", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f53e7f8d-782b-48bb-9aaf-eb025797580f", "node_type": "4", "metadata": {"page_label": "232", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "4b8f4c4d8f0eba50849ba142d04d1062358034951e09bbc9206ba09ecc33e70b", "class_name": "RelatedNodeInfo"}}, "text": "232 Part V: Big Data Implementation \nPreparing for stewardship  \nand management of risk\nNo matter what your information management strategy is, you need to make \nsure that you have the right level of oversight. This is simply a best practice \nin general and does not change when you add big data to the mix. However, \nyou may need to implement data stewardship differently with the addition of \nbig data sources. For example, you might need to have a different individual \nmonitor social media data because it has a different origin and different \nstructure than traditional relational data. This new data steward role needs \nto be carefully defined so that the individual selected can work across the \nbusiness units that find this type of data most relevant to how they are ana -\nlyzing the business. For example, the data steward needs to understand or \nhave access to the right people who understand the company\u2019s data reten -\ntion policy as well as the requirements for masking out personal data no \nmatter where that data originates.\nSetting the right governance  \nand quality policies\nThe way that an organization deals with big data is an ongoing cycle and \nnot a one-time project. The potential for causing risk to the business can be \nserious if consistent rules and processes are not applied consistently. Data \nquality should also be approached from a governance standpoint. When you \nthink about policy, here are some of the key elements that need to be codi -\nfied to protect your organization:\n \u2713 Determine best practices that your peers have implemented to have \nconsistent polices documented so that everyone has the same under -\nstanding of what is required.\n \u2713 Compare your policies with the governance requirements for your own \nbusiness and your industry. Update your policies if you find oversights.\n \u2713 Do you have a policy about the length of time that you must hold on to \ninformation? Do these policies apply to the data you are collecting from \nexternal sources, such as customer discussion groups and social media \nsites? \n \u2713 What is the importance of the data sources that you are bringing into \nthe business? Do you have quality standards in place so that a set of data \nis only used for decision making if it is proven to be clean and well docu -\nmented? It is easy to get caught up in the excitement of leveraging big \ndata to conduct the type of analysis that was never achievable before. \nBut if that analysis leads to incorrect conclusions, your business will be \nat risk. Even data coming from sensors could be impacted by extraneous \ndata that will cause an organization to come to the wrong conclusion.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2658, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "680a2335-a304-4de6-b125-c477adf81855": {"__data__": {"id_": "680a2335-a304-4de6-b125-c477adf81855", "embedding": null, "metadata": {"page_label": "233", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cdc7ccb5-4307-4ada-9404-3bcd9e030d58", "node_type": "4", "metadata": {"page_label": "233", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "18133a62c1cc567f0fee7209222538b9bc6570bd56a12a9a1b18b6cfbaa44c79", "class_name": "RelatedNodeInfo"}}, "text": "233  Chapter 19: Security and Governance for Big Data Environments\nDeveloping a Well-Governed and  \nSecure Big Data Environment\nA thoughtful approach to security can succeed in mitigating against many \nsecurity risks. You need to develop a secure big data environment. One thing \nthat you can do is to evaluate your current state.\nIn a big data environment, security starts with assessing your current state.  \nA great place to begin is by answering a set of questions that can help you \nform your approach to your data security strategy. Here are a few important \nquestions to consider:\n \u2713 Have you evaluated your own traditional data security approach?\n \u2713 How do you control access rights to the data in your applications, your \ndatabases, and your warehouse both those within your company and \nthose from third-party sources? Who has the right to access existing \ndata resources as well as the new big data sources you are introducing? \nHow do you ensure that only the right identities gain access to your \napplications and information?\n \u2713 Can you identify data vulnerabilities and risks and then correct any \nweaknesses?\n \u2713 Do you have a way of tracking your security risk over time so that you \ncan easily share updated information with those who need it?\n \u2713 Is your overall infrastructure protected at all times from external security \nthreats? If not, this could be the weak link that could seriously impact \nthe security of your data.\n \u2713 Do you maintain your own keys if you are using encryption, or do you get \nthem from a trusted, reliable provider? Do you use standard algorithms? \nHave you applied this standard to new data sources that you have deter -\nmined are critical to your business?\n \u2713 Are you able to monitor and quantify security risks in real time?\n \u2713 Can you implement security and governance policies consistently across \nall types of data sources, including ones that reside in a cloud environment?\n \u2713 Can you protect all your data no matter where it\u2019s stored?\n \u2713 Can you satisfy auditing and reporting requirements for data wherever it \nresides?\n \u2713 Can you meet the compliance requirements of your industry?\n \u2713 What are your disaster and recovery plans? How do you ensure service \ncontinuity for all your critical data sources?\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2273, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f52d4a60-60a8-4243-bbe9-244bcef3501b": {"__data__": {"id_": "f52d4a60-60a8-4243-bbe9-244bcef3501b", "embedding": null, "metadata": {"page_label": "234", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a16f95c5-8624-4e67-905f-8384714645c7", "node_type": "4", "metadata": {"page_label": "234", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "fb5134204ec32c7fc48835a8b476f881ba1ec9e2ba5c9c9173f442b795888dfb", "class_name": "RelatedNodeInfo"}}, "text": "234 Part V: Big Data Implementation \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 55, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "63c11f09-18da-4d4d-b8e1-ed641b0ef4ab": {"__data__": {"id_": "63c11f09-18da-4d4d-b8e1-ed641b0ef4ab", "embedding": null, "metadata": {"page_label": "235", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fe667dc0-9a19-4878-9a5f-0a010b3788bb", "node_type": "4", "metadata": {"page_label": "235", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "93bcea763ee95ae890a327a3c9e4b2c8d7d7aca18d850797d07d027c7ebfddd0", "class_name": "RelatedNodeInfo"}}, "text": "Part VI\nBig Data Solutions in  \nthe Real World\n Explore the big data planning stages online at www.dummies.com/extras/  \nbigdata .Use Big Data as a Business  \nPlanning Tool\n \u2713 Stage 1: Plan with Data\n \u2713 Stage 2: Do the analysis\n \u2713 Stage 3: Check the results\n \u2713 Stage 4: Act on the plan\n \u2713 Stage 5: Monitor in real time\n \u2713 Stage 6: Adjust the impact\n \u2713 Stage 7: Enable experimentation\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 402, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "002a43d7-c9ee-4df5-b1aa-dbbd49c51c63": {"__data__": {"id_": "002a43d7-c9ee-4df5-b1aa-dbbd49c51c63", "embedding": null, "metadata": {"page_label": "236", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66ad42e2-f95d-48ce-ac0f-a63e88b80d52", "node_type": "4", "metadata": {"page_label": "236", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "5122a27a8156172d8acc237fa5358c53997e5ecbaedd181b7d6f42dbb8bfd091", "class_name": "RelatedNodeInfo"}}, "text": "In this part . . .\n \u2713 Review big data utilization models.\n \u2713 Use big data in fraud detection.\n \u2713 Integrate social media feedback into corporate decision \nmaking.\n \u2713 Improve healthcare diagnoses with big data.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 227, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7542225a-3ff7-4985-853f-93747ca154bf": {"__data__": {"id_": "7542225a-3ff7-4985-853f-93747ca154bf", "embedding": null, "metadata": {"page_label": "237", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5cd65b97-c15d-4e9b-8924-b023880d55d5", "node_type": "4", "metadata": {"page_label": "237", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "66aa5ed4c001661bffb30dbbf6b5b0e10defa2e35c14d2b3f44797f3ada33161", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 20\nThe Importance of Big  \nData to Business\nIn This Chapter\n\u25b6 Using big data as a business planning tool\n\u25b6 Incorporating big data into your company\u2019s planning process\n\u25b6 Making business decisions with big data\n\u25b6 Starting your big data journey\nT \nhe idea of managing data to transform business is nothing new. As long \nas organizations have been capturing information about their business \nprocesses, their customers, their prospects, and their products, a big data \nproblem has existed. It was simply not economical or practical for compa -\nnies to be able to effectively manage all the data across their organizations. \nTherefore, for the past 30 years, companies have had to make compromises. \nEither data management professionals would have to compromise by saving \nonly snapshots of data or they would have to create separate databases to \nstore segments of data. Companies have tried complex work-arounds to try \nto integrate data together to improve business decision making. This often \nrequired programmers to develop complex programs to create the right  \nbusiness view of data.\nThe gating factors keeping businesses from being able to get the most busi -\nness value from their data were varied and complicated. These factors \nincluded\n \u2713 The expense of purchasing enough systems and storage to physically \ncontain the data\n \u2713 The problem of managing a database that was too big to be managed, \nbacked up, or queried\n \u2713 The immaturity of available technology to manage the variety of the data \nat the right speed\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1547, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d18465ff-9846-40a4-8878-de4449291098": {"__data__": {"id_": "d18465ff-9846-40a4-8878-de4449291098", "embedding": null, "metadata": {"page_label": "238", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "05e8d5a1-deff-4b52-afe1-9b15f18f425c", "node_type": "4", "metadata": {"page_label": "238", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "42ec7002f739fe4aa30136d907f07552722eb8415c6a5d485be522619abedef1", "class_name": "RelatedNodeInfo"}}, "text": "238 Part VI: Big Data Solutions in the Real World \n \u2713 The difficulty of programming to integrate data elements and then  \nmaintain that code\n \u2713 The complexity of keeping data up to date and relevant to emerging \nbusiness requirements\nIn this chapter, we explore the business imperative behind the movement \nto big data and describe how companies leverage big data to affect business \noutcomes.\nBig Data as a Business Planning Tool\nWhat does the business hope to achieve by leveraging big data? This is not \nan easy question to answer. Different companies in different industries need \nto manage their data differently. But some common business issues are at \nthe center of the way that big data is being considered as a way to both plan \nand execute for business strategy. While most businesses have mechanisms \nin place to track customer interactions, it is much more difficult to determine \nthe relationships among a lot of data sources to understand changing customer \nrequirements.\nThe greatest challenge for the business is to be able to look into the future \nand anticipate what might change and why. Companies want to be able to \nmake informed decisions in a faster and more efficient manner. The business \nwants to apply that knowledge to take action that can change business out -\ncomes. Leaders also need to understand the nuances of the business impacts \nthat are across product lines and their partner ecosystem. The best busi -\nnesses take a holistic approach to data. Four stages are part of the planning \nprocess that applies to big data: planning, doing, checking, and acting.\nStage 1: Planning with data\nWith the amount of data available to the business, dangers exist in making \nassumptions based on a single view of data. The only way to make sure that \nbusiness leaders are taking a balanced perspective on all the elements of \nthe business is to have a clear understanding of how these data sources are \nrelated. But companies typically only have a small amount of the data they \nwill need to make informed decisions. The business needs a road map for \ndetermining what data is needed to plan for new strategies and new directions.\nFor example, if your company needs to expand the type of services it can \noffer to existing customers, you need to analyze as much data as possible \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2320, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "357b9157-be6f-4823-98b1-b07ba021bc09": {"__data__": {"id_": "357b9157-be6f-4823-98b1-b07ba021bc09", "embedding": null, "metadata": {"page_label": "239", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0067d163-a186-4e00-a7bf-bf5054baa37c", "node_type": "4", "metadata": {"page_label": "239", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "25c8c76c1051823a80a6c1378ab0bccd4e84c7354c5d75034c710e05b5742e94", "class_name": "RelatedNodeInfo"}}, "text": "239  Chapter 20: The Importance of Big Data to Business\nabout what customers are buying and how that is changing. What do custom -\ners like and dislike about products? What are competitors offering? What \nnew macro trends are emerging that will change customer requirements? \nAnd how are your customers reacting to your products and those from your \ncompetitors? If you find ways to effectively manage the data, you may be able \nto have a powerful planning tool. While the data may confirm your existing \nstrategy, it might send you in new unexpected directions. Part of your plan -\nning process requires that you use a variety of data to test assumptions and \nthink differently about the business.\nStage 2: Doing the analysis\nAfter your organization understands the business objectives, it is time to \nbegin analyzing the data itself as part of the planning process. This is not a \nstand-alone process. Executing on big data analysis requires learning a set of \nnew tools and new skills. Many organizations will need to hire some big data \nscientists who can understand how to take this massive amount of disparate \ndata and begin to understand how all the data elements relate in the context \nof the business problem or opportunity.\n The big data analytics market is very immature, so you find few highly abstracted \nand easy-to-use tools to support analysis. So right now, it will be necessary to \nfind highly skilled professionals within consulting organizations who can help \nyou make progress. Big data analytics is a dynamic area that is experiencing \nvery rapid change. Combining the immaturity of the analytics with the needs \nof business to continually add new data sources that need to be added into \nthe analytics approach will put a lot of pressure on the business to push the \nboundaries of what is possible. The businesses that are able to get a handle on \napplying big data analytics to their business planning will be able to identify \nbusiness nuances and changes that can impact the bottom line. For example, \nif your company is in the e-commerce market, you will want to analyze the \nresults of new partnerships to see whether they are generating both customer \ninterest and new sales. You may want to see the reaction to the new services \non social media sites. At the same time, you want to have a clear understand -\ning of what your closest competitors are offering that could impact revenue.\nStage 3: Checking the results\nIt is easy to get caught up in the process of analyzing data and forget to do a \nreality check. Does the analysis reflect business outcomes? Is the data you \nare using accurate enough or do problems exist? Are the data sources going \nto truly help with planning? This is the time to make sure that you are not \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2775, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "34298bbb-2b4d-42c4-8e99-bd66c2b8c7ab": {"__data__": {"id_": "34298bbb-2b4d-42c4-8e99-bd66c2b8c7ab", "embedding": null, "metadata": {"page_label": "240", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a4b8d008-5d65-4242-96ff-f62ece8c6afb", "node_type": "4", "metadata": {"page_label": "240", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f92bd2ba1d40d8803869e214c35884555c75ec7baf918c153d45ac555f77f0f4", "class_name": "RelatedNodeInfo"}}, "text": "240 Part VI: Big Data Solutions in the Real World \nrelying on data sources that will take you in the wrong direction. Many com -\npanies will use third-party data sources and may not take the time to vet the \nquality of the data. When you are planning and making business decisions \nbased on analysis, you have to make sure that you are on a strong foundation.\nStage 4: Acting on the plan\nAfter this cycle of analysis is complete, it is time to put the plan into action. \nBut actions have to be part of an overall planning cycle that is repeated \u2014 \nespecially as markets become more dynamic. Each time a business initiates a \nnew strategy, it is critical to constantly create a big data business evaluation \ncycle. This approach of acting based on results of big data analytics and then \ntesting the results of executing business strategy is the key to success. Big \ndata adds the critical element of being able to leverage real results to verify \nthat a strategy is working as intended. Sometimes the results of a new strategy \ndo not match expectations. In some cases, this will mean resetting the strategy. \nIn other situations, the unintended consequences will lead a company in a \nnew direction that might have a better outcome.\nAdding New Dimensions  \nto the Planning Cycle\nWith the advent of big data, some changes can impact the way you approach \nbusiness planning. As more businesses begin to use the cloud as a way to \ndeploy new and innovative services to customers, the role of data analysis \nwill explode. You might want to therefore think about another part of your \nplanning process. After you make your initial road map and strategy, you \nmay want to add three more stages to your data cycle: monitoring, adjusting, \nand experimenting.\nStage 5: Monitoring in real time\nBig data analytics enables you to monitor data in near real time proactively. \nThis can have a profound impact on your business. If you are a pharmaceutical \ncompany conducting a clinical trial, you may be able to adjust or cancel a \ntrial to avoid a lawsuit. A manufacturing company may be able to monitor the \nresults of sensors on equipment to fix a flaw in the manufacturing process \nbefore it has a greater impact.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2222, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "40c896da-47d3-4c74-8ca0-3c09ec20ec80": {"__data__": {"id_": "40c896da-47d3-4c74-8ca0-3c09ec20ec80", "embedding": null, "metadata": {"page_label": "241", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f0b5e696-90c7-4b83-9896-bb7181c3605a", "node_type": "4", "metadata": {"page_label": "241", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "55d16f6073b0c7f6cddd0997eec7e991934aef7ecb8d2371ab85c4b3f595c5a8", "class_name": "RelatedNodeInfo"}}, "text": "241  Chapter 20: The Importance of Big Data to Business\nStage 6: Adjusting the impact\nWhen your company has the tools to monitor continuously, it is possible \nto adjust processes and strategy based on data analytics. Being able to \nmonitor quickly means that a process can be changed earlier and result in \nbetter overall quality. This type of adjustment is something new for most \ncompanies. In the past, analysts often were able to analyze the results of \nmonitoring processes, but typically after a problem had already become \napparent. Therefore, this type of analysis was used to find out why a problem \nhappened and why a product failed or why a service did not meet customer \nexpectations. While understanding the cause of failure is important, it is \nalways better to be able to avoid mistakes in the first place.\nStage 7: Enabling experimentation\nBeing able to try out new product and service offerings is important in an \nincreasingly real-time data world. But it is not without risk. Experimentation \nwithout the capability to understand the outcome quickly will only confuse \ncustomers and partners. Therefore, combining experimentation with real-time \nmonitoring and rapid adjustment can transform a business strategy. You \nhave less risk with experimentation because you can change directions and \noutcomes more easily if you are armed with the right data.\nKeeping Data Analytics in Perspective\nBig data is beginning to have an important impact on business strategy. As \ncompanies are putting a big data strategy in place, management is beginning \nto realize that they can begin leveraging data throughout the planning cycle \nrather than at the end. As the big data market begins to mature, companies \nwill be able to run their business based on a data-centric view of the world. \nPredictive analytics, for example, is making it possible for companies to \nunderstand the small and subtle changes in customer buying patterns so \nthat they can make changes in strategy earlier. For example, Walmart uses \nsocial media data to determine what new products customer are starting to \ndemand earlier in the cycle. It is difficult for a retail company to change the \nproducts already on store shelves. If a company can predict changes in cus -\ntomer buying preferences six months in advance, it can have a huge impact \non the bottom line.\nIt is easy to assume that all a company needs is to create a big data platform \nand the strategy will just happen. The reality, of course, is much more com -\nplicated. While big data will be an important business tool, a danger exists \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2599, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "34f619b5-fdba-4922-9f5a-bed2b7ee008c": {"__data__": {"id_": "34f619b5-fdba-4922-9f5a-bed2b7ee008c", "embedding": null, "metadata": {"page_label": "242", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4066711e-891c-4db3-9c78-ca0c32daaa37", "node_type": "4", "metadata": {"page_label": "242", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "274a05606be0899b2293ae91d269a6a21360d7922129475d468b5a5afa0b525c", "class_name": "RelatedNodeInfo"}}, "text": "242 Part VI: Big Data Solutions in the Real World \nin relying too much on data alone. Business leaders need to make sure that \nthey do not trust the results of big data analytics in isolation from other fac -\ntors that cannot easily be codified into an algorithm. You find subtle issues \nsuch as what strategies are practical in light of changing business conditions. \nYou\u2019ll see emerging trends or a changing competitive landscape that isn\u2019t \nshowing up in the analysis. Senior leaders also bring intuition and knowledge \nto the table. So before you assume that big data is the panacea for all busi -\nness strategy issues, make sure that you are taking a balanced approach.\nGetting Started with the  \nRight Foundation\nSo, how do you get started in your journey to creating the right environment \nso that you are ready to both experiment with big data and be prepared to \nexpand your use of big data when you are ready? Will you have to invest in \nnew technologies for your data center? Can you leverage cloud computing  \nservices? The answer to these questions is yes. You will have to make changes \nto support big data. First, you need to make sure that you understand the \nvarious types of data that are important to your organization. You also need \nto understand the new types of data management environments that are \navailable. Each of these new options could be helpful in different types of \nsituations.\nFor example, if you need to process data quickly, you might want to evaluate \nin-memory databases. If you have a lot of data that needs to be processed in \nreal time, streaming data offerings are worth evaluating. Many different prod -\nucts can handle spatial data. Chapters 1 and 4 give you a good idea of some \nof the products and architectures that will support a variety of different data \nstructures and different analytic processes. In addition, you will want to eval -\nuate the cloud-based offerings that allow you to store massive amounts of \ninformation inexpensively. Several cloud-based analytics services are chang -\ning the way that companies can access and use complicated tools that were \nnever affordable in the past.\nGetting your big data strategy started\nWhile clearly a huge amount of technology is involved in building your big \ndata strategy, you have to get started by building the right team of individuals \nwith both technical and business knowledge. You will need business leaders \nwho are involved in planning the strategy for the next generation of products \nand services. You need to understand the types of answers that they are \nlooking for and the types of questions that they are asking.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2651, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "83febfb1-20b0-4873-b2a3-8fa6af0adf64": {"__data__": {"id_": "83febfb1-20b0-4873-b2a3-8fa6af0adf64", "embedding": null, "metadata": {"page_label": "243", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bb0bce83-0c15-4816-9dab-0305e6d4bf49", "node_type": "4", "metadata": {"page_label": "243", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "40c6e5269c1225cb0970c58525e618fb6512652896ff70da963fddf949285952", "class_name": "RelatedNodeInfo"}}, "text": "243  Chapter 20: The Importance of Big Data to Business\nTherefore, the best way to get started is to build a team. You may want to \ninvolve consultants who have experience working on big data implementations  \nand can help you with best practices. You should understand that at this stage \nin the industry, you would be working with low-level tools that typically involve \na lot of programming. But as new tools emerge, you should continue to exper -\niment to take advantage of innovations. In some cases, you will discover that \nvendors and consultants have packaged best practices into product offerings \nthat can be customized for your markets and your business model.\nBut to take advantage of the emerging technologies, it is important that you \nfocus on the basics. You need to make sure that after you select the right \ndata elements for your analysis, that it all makes sense. You have to be able \nto trust the data so that you minimize the risks. Each new data source will \nhave its own structure. These sources may not be well-vetted. So, before \nthese sources are brought into an analytics framework, you will have to make \nsure that metadata is consistent.\nGetting started will mean taking things slowly. Most organizations do not jump \nin and start doing full-fledged, corporate-wide big data analytics. Rather, \nmost companies continue to progress with the analytics they have always \nbeen doing. However, they are adding pilot projects or planning to add pilots \nbased on areas where the business needs to leverage new types of data at \ngreater speed than ever before.\nPlanning for Big Data\nThe ways that big data can be applied to business problems are almost end -\nless. Virtually every industry has the capability or potential to collect and \nanalyze data to improve business outcomes. Some use cases are more obvious \nthan others. You find hundreds of examples of how companies might use \nsocial media data to improve business planning and execution. But the capa -\nbility to leverage big data touches everything from monitoring manufacturing \nprocesses to the detection of diseases. In the insurance industry, executives \nare using big data to figure out what product offerings are the best for a  \ncertain customer with the least amount of risk.\nExecutives in almost every industry want to be able to analyze patterns in all \ndifferent types of structured and unstructured data to be able to predict out -\ncomes. Companies are leveraging information from customer service notes \nand information collected from sensors and system logs to understand their \nbusinesses. Big data has the potential to help companies get a handle on \nboth risk and opportunities in the best way. Chapters 21 and 22 list how big \ndata is applied to specific industries.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2785, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6bcbc51b-0a2d-4fa6-b860-6c58a861851b": {"__data__": {"id_": "6bcbc51b-0a2d-4fa6-b860-6c58a861851b", "embedding": null, "metadata": {"page_label": "244", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b5f540bd-7311-4ee5-b8dd-17e1e284a3c4", "node_type": "4", "metadata": {"page_label": "244", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "84fd4c959ad17ed8e7d8b25f63141ff94b811ab60c95a0802805daa426c576fa", "class_name": "RelatedNodeInfo"}}, "text": "244 Part VI: Big Data Solutions in the Real World \nTransforming Business Processes  \nwith Big Data\nMore and more organizations are discovering that they can take advantage \nof lots of different types of information in new ways. The maturation of the \ntechnology will coincide with business leaders\u2019 ability to push the envelope \non business strategy. We have only touched on the potential value of big data. \nCompanies can save money by identifying fraud before money is paid out. \nCompanies can determine the next best action based on real-time access to \ncustomer actions \u2014 what they are buying and what they are asking. Healthcare \npractitioners can leverage massive amounts of best practice data to be \nbetter prepared to treat patients more quickly with better results at a lower \ncost. Needless to say, this is only an early indicator of what will be possible. \nPreparing for this new world requires your organization to gain knowledge \nabout the potential for technology to transform business processes.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1029, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f128258a-e07e-413f-94e7-d4e9baeb2c31": {"__data__": {"id_": "f128258a-e07e-413f-94e7-d4e9baeb2c31", "embedding": null, "metadata": {"page_label": "245", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f612b985-3947-432c-91ac-4f277bc3fa8d", "node_type": "4", "metadata": {"page_label": "245", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b23f23767203ba18a2dbb27fde69474a0fe2ef18fce9dd093fc66121ef45efb9", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 21\nAnalyzing Data in Motion:  \nA Real-World View\nIn This Chapter\n\u25b6 Understanding why companies need data in motion\n\u25b6 Streaming data with an environmental impact\n\u25b6 Streaming data with a public policy impact\n\u25b6 Streaming data with a health impact\n\u25b6 Streaming data with an energy impact\nI \nf you want to be successful with big data, you need to begin by thinking \nabout solving problems in new ways. Many of the previous limitations \nplaced on problem-solving techniques were due to lack of data, limitations \non storage or compute power, or high costs. The technology of big data is \nshattering some of the old concepts of what can\u2019t be done and opening new \npossibilities for innovation across many industries. The new reality is that an \nenormous amount of data is generated every day that may have some  \nrelevance to your business, if you can only tap into it.\nMost likely, you have invested lots of resources to manage and analyze the \nstructured data that you need to understand your customers, manage your \noperations, and meet your financial obligations. However, today you find \nhuge growth in a very different type of data. The type of information you get \nfrom social media, news or stock market data feeds, and log files, and spatial \ndata from sensors, medical-device data, or GPS data, is constantly in motion. \nThese newer sources of data can add new insight to some very challenging \nquestions because of the immediacy of the knowledge. Streaming data \u2014 \ndata in motion \u2014 provides a way to understand an event at the moment it \noccurs.\nIn this chapter, you learn about organizations and entire industries that are \nchanging the way they look at data that is constantly flowing across various \ninterconnected channels of communication. We show you how the technology \npresented in previous chapters can be applied to solve business problems. \nChapter 14 discusses in detail how stream computing technology is used to \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1956, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "2ca5a89b-a827-4122-b3a7-4ae861d7e031": {"__data__": {"id_": "2ca5a89b-a827-4122-b3a7-4ae861d7e031", "embedding": null, "metadata": {"page_label": "246", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "15622a6f-14b6-4d45-9d1a-a8d704eb1c39", "node_type": "4", "metadata": {"page_label": "246", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "9a18dff1bfff5814caf6d2b8c8a91069f6610bb5c87cd63306d23d2377ae3ee0", "class_name": "RelatedNodeInfo"}}, "text": "246 Part VI: Big Data Solutions in the Real World \nprocess and analyze these continuous streams of data. For information on \nhow companies approach the integration of streaming data sources with \nother data sources \u2014 both structured and unstructured \u2014 refer to Chapter 15.\nUnderstanding Companies\u2019  \nNeeds for Data in Motion\nTo complete a credit card transaction, finalize a stock market transaction, or \nsend an e-mail, data needs to be transported from one location to another. \nData is at rest when it is stored in a database in your data center or in the \ncloud. In contrast, data is in motion when it is in transit from one resting \nlocation to another. Companies that must process large amounts of data in \nnear real time to gain business insights are likely orchestrating data while it \nis in motion. You need data in motion if you must react quickly to the current \nstate of the data.\nData in motion and large volumes of data go hand in hand. Many real-world \nexamples of continuous streams of large volumes of data are in use today:\n \u2713 Sensors are connected to highly sensitive medical equipment to monitor \nperformance and alert technicians of any deviations from expected per -\nformance. The recorded data is continuously in motion to ensure that \ntechnicians receive information about potential faults with enough lead \ntime to make a correction to the equipment and avoid potential harm to \npatients.\n \u2713 Telecommunications equipment is used to monitor large volumes of \ncommunications data to ensure that service levels meet customer \nexpectations.\n \u2713 Point-of-sale data is analyzed as it is created to try to influence customer \ndecision making. Data is processed and analyzed at the point of engage -\nment \u2014 maybe in combination with location data or social media data.\n \u2713 Messages, including details about financial payments or stock trades, \nare constantly exchanged between financial organizations. To ensure \nthe security of these messages, standard protocols such as Advanced \nMessage Queuing Protocol (AMQP) or IBM\u2019s MQSeries are often used. \nBoth of these messaging approaches embed security services within \ntheir frameworks.\n \u2713 Collecting information from sensors in a security-sensitive area so that \nan organization can differentiate between the movement of a harmless \nrabbit and a car moving rapidly toward a facility.\n \u2713 Medical devices can provide huge amounts of detailed data about differ -\nent aspects of a patient\u2019s condition and match those results against  \ncritical conditions or other abnormal indicators.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2562, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f349a33-9cfb-428f-a321-1137cf2a372a": {"__data__": {"id_": "4f349a33-9cfb-428f-a321-1137cf2a372a", "embedding": null, "metadata": {"page_label": "247", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a79e89c0-84b7-4dc1-95c5-3ee03d54884f", "node_type": "4", "metadata": {"page_label": "247", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "00d79abd6f912b8768ce21a6cc41e16645e3dc367e602150614d294fca688758", "class_name": "RelatedNodeInfo"}}, "text": "247  Chapter 21: Analyzing Data in Motion: A Real-World View\nThe value of streaming data\nData in motion, often in the form of streaming data, is becoming increasingly \nimportant to companies needing to make decisions when speed is a critical \nfactor. If you need to react quickly to a situation, having the capability to ana -\nlyze data in real time may mean the difference between either being able to \nreact to change an outcome or to prevent a poor result. The challenge with \nstreaming data is to extract useful information as it is created and transported \nbefore it comes to a resting location. Streaming data can be of great value to \nyour business if you can take advantage of that data when it is created or when \nit arrives at your business.\nYou need to process and analyze the streaming data in real time so that you \ncan react to the current state of the data \u2014 while in motion and before it is \nstored. You need to have some knowledge of the context of this data and how \nit relates to historical performance. And you need to be able to integrate this \ninformation with traditional operational data. The key issue to remember is \nthat you need to have a clear understanding of the nature of that streaming \ndata and what results you are looking for. For example, if your company is \na manufacturer, it will be important to use the data coming from sensors to \nmonitor the purity of chemicals being mixed in the production process. This \nis a concrete reason to leverage the streaming data. However, in other situa -\ntions, it may be possible to capture a lot of data, but no overriding business \nrequirement exists. In other words, just because you can stream data doesn\u2019t \nmean that you always should.\nHow can you use streaming data to change your business? In the following \nsections, we look at how organizations in several industries are finding ways \nto gain value from data in motion. In some situations, these companies are \nable to take data they already have and begin to use it more effectively. In \nother situations, they are collecting data that they were not able to collect \nbefore. Sometimes organizations can collect much more of the data that they \nhad been only collecting snapshots of in the past. These organizations are \nusing streaming data to improve outcomes for customers, patients, city resi -\ndents, or perhaps for mankind. Businesses are using streaming data to influ -\nence customer decision making at the point of sale.\nStreaming Data with an  \nEnvironmental Impact\nScientists measure and monitor various attributes of lakes, rivers, oceans, \nseas, wells, and other water environments to support environmental research. \nImportant research on water conservation and sustainability depends on \ntracking and understanding underwater environments and knowing how they \nchange. Why is this work done? Changes in these natural environments can \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2901, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "fc11c467-8676-4047-8127-028ee7b354c7": {"__data__": {"id_": "fc11c467-8676-4047-8127-028ee7b354c7", "embedding": null, "metadata": {"page_label": "248", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4f01354a-ace1-437d-a796-11f63ae8ca2b", "node_type": "4", "metadata": {"page_label": "248", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "2516ad23dae221497b95d00860f5f767495ce10bd22e4c9db9f56d14a3d2850c", "class_name": "RelatedNodeInfo"}}, "text": "248 Part VI: Big Data Solutions in the Real World \nhave an enormous impact on the economic, physical, and cultural well-being \nof individuals and communities throughout the world. To improve their ability \nto predict environmental impacts, researchers at universities and environ -\nmental organizations across the globe are beginning to include the analysis \nof data in motion in their research.\nScientific research includes the collection of large volumes of time-sensitive \ninformation about water resources and weather to help protect communities \nagainst risks and respond appropriately to disasters impacting these natural \nresources. Mathematical models are used to make predictions such as the \nseverity of flooding in a particular location or the impact of an oil spill on \nsea life and the surrounding ecosystem. The type of data that can be used \nincludes everything from measuring temperature, to measuring the chemi -\ncals in the water, to measuring the current flow. In addition, it is helpful to be \nable to compare this newly acquired data with historical information about \nthe same bodies of water.\nMany sophisticated research programs are in place to improve the under -\nstanding of how to protect natural water resources. Rivers and adjacent flood -\nplains and wetlands, for example, need protection because they are important \nhabitats for fish and wildlife. Many communities depend on rivers for drinking \nwater, power generation, food, transportation, and tourism. In addition, the \nrivers are monitored to provide knowledge about flooding and to give communi -\nties advance warnings about floods. By adding a real-time component to these \nresearch projects, scientists hope to have a major impact on people\u2019s lives.\nUsing sensors to provide real-time  \ninformation about rivers and oceans\nAt one research center in the United States, sensors are used to collect physi -\ncal, chemical, and biological data from rivers. These sensors monitor spatial \nchanges in temperature, pressure, salinity, turbidity, and the chemistry of \nwater. Their goal is to create a real-time monitoring network for rivers and \nestuaries. Researchers expect that in the future, they will be able to predict \nchanges in rivers in the same way that weather predictions are made today. \nAnother research center based in Europe is using radio-equipped buoys \ncontaining sensors to collect data about the ocean, including measurements \nof wave height and wave action. This streaming data is combined with other \nenvironmental and weather data to provide real-time information on ocean \nconditions to fisherman and marine researchers.\nIn both examples, sensors are used to collect large volumes of data as events \nare taking place. Although infrastructure platforms vary, it is typical to include \na middleware layer to integrate data collected by the sensor with data in \na data warehouse. These research organizations are also using external \nsources like mapping databases and sensors coming from other locations as \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3031, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5eb7a21a-1640-46ae-b9fe-bbe56ab522df": {"__data__": {"id_": "5eb7a21a-1640-46ae-b9fe-bbe56ab522df", "embedding": null, "metadata": {"page_label": "249", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f097dc9f-5ba0-4f6d-a184-ab7e4f6d772c", "node_type": "4", "metadata": {"page_label": "249", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ec4478825932a1c30d98a1840cea208d1d3bc171b66d7aad91b1f93db00a25bd", "class_name": "RelatedNodeInfo"}}, "text": "249  Chapter 21: Analyzing Data in Motion: A Real-World View\nwell as geographical information. The data is analyzed and processed as it \nstreams in from these different sources. One organization is building an inte -\ngrated network of sensors, robotics, and mobile monitoring. It is using this \ninformation to build complicated models such as real-time, multiparameter \nmodeling systems. The models will be used to look at the dynamic interac -\ntions within local rivers and estuary ecosystems.\nThe benefits of real-time data\nBy incorporating real-time analysis of data into environmental research, \nscientists are advancing their understanding of major ecological challenges. \nStreaming technology opens new fields of research and takes the concept of \nscientific data collection and analysis in a new direction. They are looking at \ndata they may have collected in the past in a new way and are also able to \ncollect new types of data sources. Although you can learn a lot by monitoring \nchange variables such as water temperature and water chemistry at set inter -\nvals over time, you may miss out on identifying important changes or patterns.\nWhen you have the opportunity to analyze streaming data as it happens, \nit is possible to pick up on patterns you might have missed. Real-time data \non river motion and weather is used to predict and manage river changes. \nScientists are hoping to predict environmental impacts just like we report on \nand forecast weather. They are furthering research on the impact of global \nwarming. They are asking what can be learned from watching the movements \nof migrating fish. How can watching how pollutants are transported help to \nclean up from future environmental contamination?\nIf data scientists are able to take data they have already collected, they can \ncombine it with the real-time data in a much more efficient manner. They \nalso have the capability to do more in-depth analysis and do a better job of \npredicting future outcomes. Because this analysis is completed, it allows \nother groups needing the same information to be able to use the findings in \nnew ways to analyze the impact of different issues. This data could be stored \nin a data cloud environment so that researchers across the globe can have \naccess, add new data into the mix, and solve other environmental problems.\nStreaming Data with a  \nPublic Policy Impact\nAlmost every area of a city has the capability to collect data, whether in the \nform of taxes, sensors on buildings and bridges, traffic pattern monitoring, \nlocation data, and data about criminal activity. Creating workable policies \nthat make cities safer, more efficient, and more desirable places to live and \nwork requires the collection and analysis of huge amounts of data from a \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2789, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4de0ad38-8785-40d4-8859-3e90f07f0c6d": {"__data__": {"id_": "4de0ad38-8785-40d4-8859-3e90f07f0c6d", "embedding": null, "metadata": {"page_label": "250", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9e601ce1-80eb-487f-b2c6-db37a867a07f", "node_type": "4", "metadata": {"page_label": "250", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1f89912c7da7c2c6b5c7fe4949ed312fe78b6f46d9b755a90952fc6434eef253", "class_name": "RelatedNodeInfo"}}, "text": "250 Part VI: Big Data Solutions in the Real World \nvariety of sources. Much of the data that is pertinent to research on public \npolicy improvements is collected by various city agencies and has histori -\ncally taken months or years to analyze (such as annual census data, police \nrecords, and city tax records). Even within one specific agency, such as the \npolice department, data may be collected by separate districts and not easily \nshared across the city and its surrounding communities.\nAs a result, city leaders have an abundance of information about how policies \nimpacted people in their city in prior years, but it has been very challenging \nto share and leverage fast-changing data to make real-time decisions that can \nimprove city life. What makes leveraging this data even more complicated \nis the fact that data is managed and stored in separate silos. This causes \nproblems because a direct relationship can exist between different aspects \nof city operations. Policy makers are beginning to realize that change can \nonly happen if they can use the available data and data from best practices \nto transform the current state of their environment. The more complex a city, \nthe more a need exists to leverage data to change things for the better.\nThis is changing as policy makers, scientists, and technology innovators \nteam up to implement policies based on data in motion. For example, to \ndesign and implement a program to improve city traffic congestion, you \nmay need to collect data on population, employment figures, road condi -\ntions, and weather. Much of this data has been collected in the past, but it is \nstored in various silos and represents a static view of historical information. \nTo make suggestions based on current streaming information, you need a \nnew approach. Researchers at a technical university in Europe are collect -\ning real-time traffic data from a variety of sources such as Global Positioning \nSystem (GPS) data from traveling vehicles, radar sensors on the roads, and \nweather data. They integrated and analyzed the streaming data to decrease \ntraffic congestion and improve traffic flow. By analyzing both structured and \nunstructured data as events are taking place, the systems can assess current \ntravel conditions and make suggestions on alternative routes that will cut \ndown on traffic. Ultimately, the goal is to have a major impact on traffic flow \nin the city. Data in motion is evaluated in connection with historical data so \nthat the recommendations make sense in context with actual conditions.\nStreaming data can have a significant impact on lower crime rates in cities. \nFor example, a police department uses predictive analytics to identify crime \npatterns by time and location. If a sudden change is found in an identified \npattern to a new location, the police can dispatch officers to the right loca -\ntion at the right time. After the fact, this data can now be used to further  \nanalyze changes in criminal behavior patterns.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3018, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "501032c1-cec0-4513-b820-c0ae1496de60": {"__data__": {"id_": "501032c1-cec0-4513-b820-c0ae1496de60", "embedding": null, "metadata": {"page_label": "251", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1324f456-7239-4f92-bafc-c4ef27d9b1ea", "node_type": "4", "metadata": {"page_label": "251", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f0e9d079a066527be3960e873f3b3d6e0fa8fec53cde51180ee132ba730a2c87", "class_name": "RelatedNodeInfo"}}, "text": "251  Chapter 21: Analyzing Data in Motion: A Real-World View\nStreaming Data in the  \nHealthcare Industry\nBig data is of enormous significance to the healthcare industry \u2014 including \nits use in everything from genetic research to advanced medical imaging and \nresearch on improving quality of care. While conducting big data analysis \nin each of these areas is significant in furthering research, a major benefit \nis applying this information to clinical medicine. If enough data is captured, \nthis data can be applied practically and quickly at the right time to help save \nlives. Medical clinicians and researchers are using streaming data to speed \ndecision making in hospital settings and improve healthcare outcomes for \npatients.\nDoctors make use of large amounts of time-sensitive data when caring for \npatients, including results of lab tests, pathology reports, X-rays, and digital \nimaging. They also use medical devices to monitor a patient\u2019s vital signs such \nas blood pressure, heart rate, and temperature. While these devices provide \nalerts when the readings go out of normal range, in some cases, preventive \naction could take place if doctors were able to receive an early warning. Subtle \nchanges in a patient\u2019s condition are often hard to pick up with a physical \nexam, but could be picked up by monitoring devices if a way existed to have \nmore immediate access to the data.\nMonitoring devices used in intensive care units generate thousands of read -\nings every second. In the past, these readings have been summarized into \none reading every 30\u201360 minutes. These devices were monitoring very large \nvolumes of data, but because of technology limitation, much of that data was \nnot available for analysis.\nCapturing the data stream\nUsing streaming technology, a hospital university research team is able to \ncapture the data stream from bedside monitors and process it using algo -\nrithms designed to look for early warning signs of serious infections. The \ndata is used in real time to provide early warnings of changes in a patient\u2019s \ncondition. In some situations, doctors are finding that they are able to take \ncorrective action to help a patient almost 24\u201336 hours earlier than without \nthe data-streaming technology. Another benefit is the ability of doctors to \ncompare the analysis to a database of patient outcomes that could provide \nadditional insight.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2403, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "879952e4-8e9f-4e53-81fb-bf6a1b10d260": {"__data__": {"id_": "879952e4-8e9f-4e53-81fb-bf6a1b10d260", "embedding": null, "metadata": {"page_label": "252", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5ccb8656-5185-4b8d-a3de-200af453f479", "node_type": "4", "metadata": {"page_label": "252", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "c6d1b11a9ab0e90d07383c7dfc831e734ba6a7768a33b9b964194f6ee52ae56c", "class_name": "RelatedNodeInfo"}}, "text": "252 Part VI: Big Data Solutions in the Real World \nStreaming Data in the Energy Industry\nReducing energy consumption, finding new sources of renewable energy, and \nincreasing energy efficiency are all important goals for protecting the envi -\nronment and sustaining economic growth. Large volumes of data in motion \nare increasingly being monitored and analyzed in real time to help achieve \nthese goals.\nMany large organizations are using a variety of measures to ensure that they \nhave the energy resources they need now and in the future. Nontraditional \nsources of energy, such as wind turbines, solar farms, and wave energy, \nare becoming more realistic options as the price and scarcity of fossil fuels \ncontinue to be of concern. These organizations are generating and storing \ntheir own energy and need good real-time information to match the supply \nto demand. They use streaming data to measure and monitor energy demand \nand supply to improve their understanding of their energy requirements and \nto make real-time decisions about energy consumption.\nUsing streaming data to increase  \nenergy efficiency\nOrganizations are beginning to use streaming data to increase energy effi -\nciency, as highlighted by the following two examples:\n \u2713 A large university monitors streaming data on its energy consumption \nand integrates it with weather data to make real-time adjustments in \nenergy use and production.\n \u2713 Members of a business community collectively share and analyze \nstreaming energy use data. This enables the companies in this com -\nmunity to consume energy more efficiently and reduce energy costs. \nStreaming data enables them to monitor supply and demand and ensure \nthat changes in demand are anticipated and kept in balance with supply.\nUsing streaming data to advance the  \nproduction of alternative sources of energy\nOrganizations are also beginning to use streaming data to help advance \nresearch and efficient production of alternative energy sources, as demon -\nstrated by the following two examples:\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2046, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "69eafcf0-9577-4d60-be8a-c3611e11a187": {"__data__": {"id_": "69eafcf0-9577-4d60-be8a-c3611e11a187", "embedding": null, "metadata": {"page_label": "253", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e7d2d1f6-258e-4529-99b2-c46b028381ab", "node_type": "4", "metadata": {"page_label": "253", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "5316d5cef35bd281f320725f58582a60d77fe2b03e6b322d420984bc333d311b", "class_name": "RelatedNodeInfo"}}, "text": "253  Chapter 21: Analyzing Data in Motion: A Real-World View\n \u2713 A research institution is using streaming data to understand the viabil -\nity of using wave energy as source of renewable energy. Many different \nparameters, such as temperature, geospatial data, and moon and tide \ndata, need to be collected. The organization uses monitoring devices, \ncommunications technology, cloud computing, and stream analytics to \nmonitor and analyze the noise made by wave energy technology. The group \nis studying the impact of the noise levels on fish and other marine life.\n \u2713 A wind-farm company uses streaming data to create hourly and daily \npredictions about energy production. The company collects turbine \ndata, temperature, barometric pressure, humidity, precipitation, wind \ndirection, and velocity from ground level up to 300 feet. The data comes \nfor thousands of meteorological stations around the world and from its \nown company\u2019s turbines. What does the company do with the data? It \ncreates a model of wind flow to improve the understanding of wind pat -\nterns and turbulence near existing turbines. The resulting analytics are \nused to select the best location for its wind turbines and to reduce cost \nper kilowatt-hour of energy produced.\nConnecting Streaming Data to Historical \nand Other Real-Time Data Sources\nThe examples in this chapter demonstrate how companies can gain value \nfrom streaming data. The most important aspect of these types of outcomes \nrequires the ability to understand the context of the situation. A doctor might \nsee analysis that points to a particular disease. However, further analysis of \nother patients with similar symptoms and test results shows that other pos -\nsible diagnoses may exist. In a complicated world, data is valuable in taking \naction only in the context of how it is applied to a problem.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1865, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "93e83c50-5fc1-43f1-a171-41052a5823d6": {"__data__": {"id_": "93e83c50-5fc1-43f1-a171-41052a5823d6", "embedding": null, "metadata": {"page_label": "254", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9fd5da10-d98b-4e3f-a678-3578dd9e92e8", "node_type": "4", "metadata": {"page_label": "254", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "8917835bb8e3d3e7a856308c1563024178aba84e0ba88f616b5146ef7440012f", "class_name": "RelatedNodeInfo"}}, "text": "254 Part VI: Big Data Solutions in the Real World \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 69, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4a8ef1fd-ad8b-4da4-a309-9a5c75612421": {"__data__": {"id_": "4a8ef1fd-ad8b-4da4-a309-9a5c75612421", "embedding": null, "metadata": {"page_label": "255", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d1fbaf09-caca-4d6f-b7ec-f561b9de3b1e", "node_type": "4", "metadata": {"page_label": "255", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b3a8b63fe6300275d866a9607f5a2b08744a5bb561d78910cb9a0397830cfe82", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 22\nImproving Business Processes \nwith Big Data Analytics:  \nA Real-World View\nIn This Chapter\n\u25b6 Seeing why companies need big data analytics\n\u25b6 Improving customer service with text analytics\n\u25b6 Predicting the next best action with big data\n\u25b6 Preventing fraud with big data\n\u25b6 Understanding the business benefit of integrating new sources of data\nI \nt is becoming clearer every day that business decision makers need to \nbe able to interpret data differently if businesses expect to keep up with \nrapid market changes. C-level executives know that future success depends \non innovation and building more predictive, responsive, and personalized \ncustomer experiences. Success also depends on reducing risk and making \ngovernance and security a priority. Meeting these changing business require -\nments demands that the right information be available at the right time. Many \ncompanies see big data analytics as central to their business strategy to \nincrease the level of partner and customer engagement and to decrease the \ntime to decision.\nIn this chapter, you find out about organizations and entire industries that \nare changing the way they manage and analyze structured and unstructured \ndata that is increasing in volume, velocity, variety, and veracity. We show \nhow the technology presented in previous chapters can be applied to solve \nreal-world business problems.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1399, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "ad9cbca2-ff01-4569-8aa8-e11e12e018fb": {"__data__": {"id_": "ad9cbca2-ff01-4569-8aa8-e11e12e018fb", "embedding": null, "metadata": {"page_label": "256", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a04bf7f8-dde8-4990-9569-cff522891e88", "node_type": "4", "metadata": {"page_label": "256", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "2c85e4fd8d6cd6abfe9fe5062f4bee5fea0f67b2a28fc84091bb95e9731b4f6e", "class_name": "RelatedNodeInfo"}}, "text": "256 Part VI: Big Data Solutions in the Real World \nUnderstanding Companies\u2019 Needs  \nfor Big Data Analytics\nThe data that can make a difference in how companies satisfy their cus -\ntomers and partners is not necessarily in traditional databases any more. \nThe value of unstructured data from nontraditional sources has become \napparent. Business leaders have discovered that if they can quickly analyze \ninformation that is unstructured \u2014 either in the form of text from customer \nsupport systems or social media sites \u2014 they can gain important insights. \nWhen companies can analyze massive collections of data and compare those \nresults in real time to the customer decision-making process, businesses can \ngain huge revenue increases. Therefore, leveraging a combination of unstruc -\ntured and structured data as part of a business process can transform a busi -\nness\u2019s capability to be agile and nimble, and most importantly, profitable.\nImproving the Customer Experience  \nwith Text Analytics\nMany companies accumulate huge amounts of unstructured data that have \nbeen underutilized as sources of information about their customer experi -\nence. Unstructured data is the text found in e-mails, text messages, call \ncenter notes, comments in survey responses, tweets, and blogs. This type \nof data represents about 80 percent of the data available to companies, and \nit is continuing to grow. Unstructured data has typically taken many manual \nhours to review, and in many companies, it has never have been adequately \nanalyzed. Companies recognize that if this data is analyzed at the right time, \nit may help to identify patterns of customer dissatisfaction or a potential \nproduct defect so that corrective action can be taken before it is too late. The \nincreasing sophistication of text analytics is viewed by companies as a major \nbenefit, enabling the deep analysis of large volumes of unstructured data in \nreal or near real time so that the results can be used in decision making. Text \nanalytics is the process of analyzing unstructured text, extracting relevant \ninformation, and transforming it into structured information that can be lever -\naged in various ways. (Text analytics is covered in more detail in Chapter 13.)\nHow would this work in the real world? Look at an example of a car rental \ncompany that was experiencing huge pressures from emerging companies that \ndidn\u2019t have the same high overhead. How could the existing company compete? \nImproving responsiveness seemed to be the key to success. Therefore, the \ncompany was able to use text analytics to begin making significant improve -\nments in its customer service. The company encouraged its customers \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2701, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d2104e10-ef87-47c9-bce2-4b401e0dcb8a": {"__data__": {"id_": "d2104e10-ef87-47c9-bce2-4b401e0dcb8a", "embedding": null, "metadata": {"page_label": "257", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2c8988be-e73b-498c-9133-96c0e95bfd76", "node_type": "4", "metadata": {"page_label": "257", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1148f6c9df868ad51f24ae3d6d94367cb69118b748c9530606c0b543f5ebb4d4", "class_name": "RelatedNodeInfo"}}, "text": "257  Chapter 22: Improving Business Processes with Big Data Analytics: A Real-World View\nto provide feedback on its services in online surveys or by e-mail or text. \nCustomers used these communication methods to provide comments about \nservice issues such as longer-than-expected wait times, poor agent service, \nor not getting the car they ordered. However, the company\u2019s response and \ninterpretation of these comments had been inconsistent. The company was \ntaking the right approach, but the response was too slow and the analysis was \ninconsistent. Agency managers read the e-mails and comments in web surveys \nand text messages. Managers read the comments online and placed them in \ncategories for future attention. Unfortunately, this approach took a long time, \nand each manager followed a different approach to categorizing comments. It \nwas too easy to miss patterns of dissatisfaction or concern that might show up \nif you were able to look across a large number of comments at one time.\nWhat managers wanted to do was analyze feedback from customers faster so \nthat they could identify potential issues in real time and address problems \nat the outset before they become bigger problems. Managers implemented \na text analytics solution that allowed them to quickly analyze text for insight \nacross all types of sources, including structured and unstructured data. They \nalso implemented a sentiment analysis solution that enabled an automated \napproach to identifying forms of communication that might need immediate \nattention. They were able to capture large volumes of information about the \ncustomer experience in real time and quickly analyze and take action.\nThe business value to the big data  \nanalytics implementation\nThe company was able to make major improvements in customer satisfac -\ntion. It is able to keep better track of car and equipment rental performance \nlevels and find problems and fix them early. It now has a more accurate \nunderstanding of where problems are located and can recognize them much \nfaster. The new analysis provided managers with an early identification of \nproblems at one location. As a result, they were able to make changes and \nimprove customer satisfaction at this location.\nUsing Big Data Analytics to  \nDetermine Next Best Action\nToday the customer is in the driver\u2019s seat when it comes to making a choice \nabout how to interact with a service provider. This is true across many \nindustries, including telcos, insurance companies, banks, and retailers. The \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2536, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "23dd86b9-e523-42db-9f08-7b5fc30d2c0d": {"__data__": {"id_": "23dd86b9-e523-42db-9f08-7b5fc30d2c0d", "embedding": null, "metadata": {"page_label": "258", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8c402393-850d-4bcb-a7ce-fe45e06d7ec6", "node_type": "4", "metadata": {"page_label": "258", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "423fa29f34e1a24289c9dc1d30fb46f3910d6b7b699ac2a452482a8dd83bf5a9", "class_name": "RelatedNodeInfo"}}, "text": "258 Part VI: Big Data Solutions in the Real World \nbuyer has many more channel options and is increasingly researching pur -\nchase decisions and making buying decisions from a mobile device. You \nneed to manage your customer interactions armed with in-depth and custom -\nized knowledge about each individual customer to compete in a fast-paced, \nmobile-driven market. What does it take to provide the right offer to a buyer \nwhile he is making a purchasing decision? How do you ensure that your cus -\ntomer service representatives are armed with customized knowledge about \nyour customer\u2019s value to the company and her specific requirements? How \ncan you integrate and analyze multiple sources of structured and unstruc -\ntured information so that you can offer customers the most appropriate \naction at the time of engagement? How do you quickly assess the value of a \ncustomer and determine what sort of offer that customer needs so that you \ncan keep the customer satisfied and make a sale?\nCompany executives are increasingly viewing big data analytics as the secret \nweapon they need to take the next best action in highly competitive environ -\nments. Using analytics to understand customer requirements on a more per -\nsonal level is seen as an important capability when dealing with the increased \npressures of an empowered consumer. Companies are expanding their use \nof social media and mobile computing environments and want to reach their \ncustomers at the right time through their channel of choice. To deliver suc -\ncessful customer outcomes in a mobile world, offers need to be as targeted \nand personal as possible. Companies are using their analytics platform com -\nbined with big data analysis with fast processing of real-time data to achieve \ncompetitive advantage. Some of the key goals they wish to achieve include\n \u2713 Increase their understanding of each customer\u2019s unique needs. Provide \nthese in-depth customer insights at the right time to make them actionable.\n \u2713 Improve responsiveness to customers at the point of interaction.\n \u2713 Integrate real-time purchase data with large volumes of historical pur -\nchase data and other sources of data to make a targeted recommenda -\ntion at the point of sale.\n \u2713 Provide customer service representatives with the knowledge to recom -\nmend the next best action for the customer.\n \u2713 Improve customer satisfaction and customer retention.\n \u2713 Deliver the right offer so that it is most likely to be accepted by the  \ncustomer.\nWhat does a next best action solution look like? Companies are integrating and \nanalyzing large volumes of unstructured and streaming data from e-mails, \ntext messages, call center notes, online surveys, voice recordings, GPS units, \nand social media. In some situations, companies are able to find new uses for \ndata that was too large, too fast, or of the wrong structure to be incorporated \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2900, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d9b91958-dff7-43d4-a0a5-804b04f3a4bb": {"__data__": {"id_": "d9b91958-dff7-43d4-a0a5-804b04f3a4bb", "embedding": null, "metadata": {"page_label": "259", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e28f238d-cc64-4ee2-9da4-b8008dbc10e3", "node_type": "4", "metadata": {"page_label": "259", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "520af54c034baf0121803941d7585a8faa0ac477312113033a0f71a87af87994", "class_name": "RelatedNodeInfo"}}, "text": "259  Chapter 22: Improving Business Processes with Big Data Analytics: A Real-World View\ninto analytics and predictive models before. The models that companies are \nable to build are more advanced and can incorporate real-time data from a \nvariety of sources. Company analysts are looking for patterns in the data that \nwill provide additional insight into customer opinions and behavior. Speed is \na top priority. Your model needs to predict the next best action very quickly \nif you want to be successful in this fast-paced mobile world.\nAdvanced technology is helping companies to generate actionable informa -\ntion in minutes instead of days or weeks. Predicting the next best action \noften requires the use of sophisticated machine-learning algorithms from a \ncognitive computing environment like IBM\u2019s Watson. Watson can be used to \nprocess large volumes of data and analyze data in motion and to understand \ncustomers and present an immediate response, using cognitive computing to \npersonalize offers. (Refer to Chapter 13 for information on Watson.)\nWe look at several real-world examples of companies in the financial services \nindustry that are investing heavily in new ways to understand and respond to \ncustomers.\nAn insurance company wants to increase the efficiency and effectiveness \nof its call center representatives. Agents could not quickly identify the full \nextent of a customer\u2019s mix of business, and therefore, it was hard to identify \ntop customers who needed special attention. In addition, agents found it very \ntime-consuming to search for call notes captured during previous calls with \na particular customer and found that information that might have helped \nto solve the problem was not located until it was too late. Unfortunately, a \ngrowing number of customer interactions resulted in dissatisfied customers. \nThis company implements a solution that transforms conversations from \nrecorded calls into text. Keywords are identified and analyzed. This data is \ncombined with historical data about the customer to identify high-priority \ncustomers who require immediate attention and to deliver a more timely and \nappropriate response to all customers.\nA global bank is concerned about the length of time it takes to access customer \ninformation. It wants to provide call center representatives with more infor -\nmation about customers and to have a better understanding of the network \nof customer relationships (family, business, and social networks). Executives \nhave large volumes of structured and unstructured information about cus -\ntomers, including e-mails, letters, call center notes, chats, and voice record -\nings. The bank implemented a big data analytics solution that improves the \nway its representatives support customers by providing them with an early \nindication of each customer\u2019s needs before they got on the phone. The platform \nuses social media data to understand relationships and can determine whom \nthe customer connected to. The solution combines multiple sources of data, \nboth internal and external. Some indication may exist of major life events \nthat are taking place for this customer. As a result, agents are able to take the \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3211, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "aab8a70e-38bf-425b-b434-56e56eac55f3": {"__data__": {"id_": "aab8a70e-38bf-425b-b434-56e56eac55f3", "embedding": null, "metadata": {"page_label": "260", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "1f08a1a1-ce81-463f-857f-be987b314208", "node_type": "4", "metadata": {"page_label": "260", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "9f76fd4da9e7e9034f255581b949800ebe9cb197af4bd408e3241e5250a98abb", "class_name": "RelatedNodeInfo"}}, "text": "260 Part VI: Big Data Solutions in the Real World \nnext best action. For example, a customer may have a child ready to graduate \nfrom high school, and this might be a good time to discuss a college loan.\nA credit card company wants to increase its capability to monitor customer \nexperience and take action based on each customer\u2019s unique situation. It \nwants to tailor its solution to the individual customer and not to a demo -\ngraphic. As a response, the company developed a big data analytics solution \nthat integrates information from traditional structured sources, such as cus -\ntomer transaction information, with unstructured and streaming data such \nas click-stream data, Twitter feeds, and other social media data. Its immedi -\nate goal is to create detailed microsegmentations of customers to be able to \nprovide targeted offers. The solution provides the company with an effective \napproach to analyzing lots of information quickly to identify customer intent \nto buy and create a personalized next best offer for that customer.\nPreventing Fraud with  \nBig Data Analytics\nBy many estimates, at least 10 percent of insurance company payments are for \nfraudulent claims, and the global sum of these fraudulent payments amounts \nto billions or possibly trillions of dollars. While insurance fraud is not a new \nproblem, the severity of the problem is increasing and perpetrators of insurance \nfraud are becoming increasingly sophisticated. Fraud occurs in all lines of the \ninsurance business, including automobile, health, workers\u2019 compensation, dis -\nability, and business insurance. Fraud may be committed by an individual who \nfalsifies a claim of a broken arm after staging a fall in a shopping mall or by any  \nnumber of business workers who have some association with the process of \nrepairing damage from accidents, treating medical injuries, or dealing with other \naspects of the claims process. The practice of insurance fraud is widespread \nand may include organized crime groups involved in car repairs, medical treat -\nment, legal work, home repairs, or other functions related to the claim.\nWhat is the role for big data analytics in helping insurance companies find \nways to detect fraud? Insurance companies want to stop fraud early before \nthey get involved in the processing of the claim. By developing predictive \nmodels based on both historical and real-time data on wages, medical claims, \nattorney costs, demographics, weather data, call center notes, and voice \nrecordings, companies are in a better position to identify suspected fraudu -\nlent claims in the early stages of interaction. For example, a personal injury \nclaim could potentially include fake medical claims or a staged accident. \nCompanies have seen an increase in sophisticated crime rings to perpetrate \nauto insurance or medical fraud. These rings may have similar methods of \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2896, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4266ad13-26af-4a8f-82e8-f696dc55e0f2": {"__data__": {"id_": "4266ad13-26af-4a8f-82e8-f696dc55e0f2", "embedding": null, "metadata": {"page_label": "261", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4079bcb0-96ba-47ac-a357-573754f2c0d1", "node_type": "4", "metadata": {"page_label": "261", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "8cb42f407a27fe3dc887a7487669bcca7251539c98b15b532772d3616234c73f", "class_name": "RelatedNodeInfo"}}, "text": "261  Chapter 22: Improving Business Processes with Big Data Analytics: A Real-World View\noperation that are enacted in different regions of the country or using differ -\nent aliases for the claimants. Big data analysis can quickly look for patterns in \nhistorical claims and identify similarities or bring up questions in a new claim \nbefore the process gets too far along.\nRisk and fraud experts at insurance companies, along with actuarial and under -\nwriting executives and insurance business managers, all see big data analytics \nas having the potential to deliver a huge benefit by helping to anticipate and \ndecrease attempted fraud. The goal is to identify fraudulent claims at the first \nnotice of loss \u2014 at the first point where you need an underwriter or actuary.\nConsider the following real-world example. An insurance company wants to \nimprove its ability to make real-time decisions when deciding how to process \na new claim. The company\u2019s cost outlay including litigation payments related \nto fraudulent claims has been rising steadily. The company has extensive \npolicies in place to help underwriters evaluate the legitimacy of claims, but the \nunderwriters often did not have the data they needed at the right time to make \nan informed decision. The company implemented a big data analytics platform \nto provide the integration and analysis of data from multiple sources. The \nplatform incorporates extensive use of social media data and streaming data \nto help provide a real-time view. Call center agents are able to have a much \ndeeper insight into possible patterns of behavior and relationships between \nother claimants and service providers when a call first comes in.\nFor example, an agent may receive an alert about a new claim that indicates \nthe claimant was a previous witness on a similar claim six months ago. After \nuncovering other unusual patterns of behavior and presenting this informa -\ntion to the claimant, the claim process may be halted before it really gets \ngoing. In other situations, social media data may indicate that conditions \ndescribed in a claim did not take place on the day in question. For example, \na claimant indicated that his car was totaled in a flood, but documentation \nfrom social media showed that the car had actually been in another city on \nthe day the flood occurred.\nInsurance fraud is such a huge cost for companies that executives are moving \nquickly to incorporate big data analytics and other advanced technology to \naddress the problem of insurance fraud. Insurance companies not only feel \nthe impact of these high costs, but the costs also have a negative impact on \ncustomers who are charged higher rates to account for the losses. By using \nbig data analytics to look for patterns of fraudulent behavior in enormous \namounts of unstructured and structured claims-related data, companies are \ndetecting fraud in real time. The return on investment for these companies \ncan be huge. They are able to analyze complex information and accident  \nscenarios in minutes as compared to days or months before implementing a \nbig data platform.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3129, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "006afd18-482d-4b2c-97b6-3347da9cdc05": {"__data__": {"id_": "006afd18-482d-4b2c-97b6-3347da9cdc05", "embedding": null, "metadata": {"page_label": "262", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2a3fa149-c9fe-484b-b498-3b6e16260e2f", "node_type": "4", "metadata": {"page_label": "262", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "9acbcd288a196a394df2def2deabbf06ded3e472941c7ace119b35f87ec2c0be", "class_name": "RelatedNodeInfo"}}, "text": "262 Part VI: Big Data Solutions in the Real World \nThe Business Benefit of Integrating  \nNew Sources of Data\nBig data analytics is providing companies with a new way to provide answers \nto some age-old questions. Businesses have traditionally focused on how to \nimprove customer service, provide the right offer to the right customer at the \nright time, and reduce risk and fraud. So what\u2019s changed? By integrating new \nsources of unstructured data such as web logs, call center notes, e-mails, log \ndata, and geospatial data with traditional sources of transaction, customer, \nand operational data, companies can look at their businesses much differently. \nThey can gather data they were not able to collect previously and use this data \nto look for patterns of behavior that provide a great insight to the business. \nIntegrating all these sources of data provides a way for companies to deepen \ntheir understanding of customers, products, and risk.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 969, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e78301e3-e53d-41f7-929e-cc68b4fac508": {"__data__": {"id_": "e78301e3-e53d-41f7-929e-cc68b4fac508", "embedding": null, "metadata": {"page_label": "263", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e49bd7fe-cef4-4d60-8c95-899999194d82", "node_type": "4", "metadata": {"page_label": "263", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "4f2d98a65b060b95faa59e27e495e1043c5646db651e2633110700c7a215531f", "class_name": "RelatedNodeInfo"}}, "text": "Part VII\n Find out what the top ten big data trends are at www.dummies.com/extras/\nbigdata .\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 111, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1644333f-489e-428b-953c-0c606e96cc97": {"__data__": {"id_": "1644333f-489e-428b-953c-0c606e96cc97", "embedding": null, "metadata": {"page_label": "264", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "074280b5-9381-47e0-913b-d0a73a9ca22b", "node_type": "4", "metadata": {"page_label": "264", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "7350e59a58fb9c4a28035b3534aaf0b094876b5a56d77ec09df2d36fae85b406", "class_name": "RelatedNodeInfo"}}, "text": "In this part . . .\n \u2713 Find out best practices for big data.\n \u2713 Understand big data resources.\n \u2713 Follow big data industry standards.\n \u2713 Track big data conferences.\n \u2713 Predict emerging data trends in the big data arena.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 237, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7bd55d71-5fca-411f-b3a7-318e1c440f42": {"__data__": {"id_": "7bd55d71-5fca-411f-b3a7-318e1c440f42", "embedding": null, "metadata": {"page_label": "265", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "718d3442-edca-4676-a5be-9d63921b8365", "node_type": "4", "metadata": {"page_label": "265", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "16478ae5f72f9eda15482ae31d2369104bd8043f5a940da080d9f79ad84d9763", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 23\nTen Big Data Best Practices\nIn This Chapter\n\u25b6 Understanding your goals\n\u25b6 Determining a road map\n\u25b6 Understanding what data you have and what data you need\n\u25b6 Govern and trust based on security\n\u25b6 Making sure that the data makes sense\nW \nhile we are at an early stage in the evolution of big data, it is never \ntoo early to get started with good practices so that you can lever -\nage what you are learning and the experience you are gaining. As with every \nimportant emerging technology, it is important to understand why you need \nto leverage the technology and have a concrete plan in place. In this chapter, \nwe provide you with the top-ten best practices you need to understand as \nyou begin the journey to manage big data.\nUnderstand Your Goals\nMany organizations start their big data journey by experimenting with a single \nproject that might provide some concrete benefit. By selecting a project, you \nhave the freedom of testing without risking capital expenditures. However, if all \nyou end up doing is a series of one-off projects, you will likely not have a good \nplan in place when you begin to understand the value of leveraging big data \nin the company. Therefore, after you conclude some experiments and have a \ngood initial understanding of what might be possible, you need to set some \ngoals \u2014 both short- and long-term. What do you hope to accomplish with big \ndata? Could parts of your business be more profitable with the infusion of \nmore data to predict customer behavior or buying patterns? It is important \nto have a collaboration between IT and business units to come up with well-\ndefined goals.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1647, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a75e25bd-b07b-471d-ad38-8358dfc2442a": {"__data__": {"id_": "a75e25bd-b07b-471d-ad38-8358dfc2442a", "embedding": null, "metadata": {"page_label": "266", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2792291b-915c-4cf2-bf46-7e775855dcb7", "node_type": "4", "metadata": {"page_label": "266", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "6829870dcd46b499faeed8ec86cf3cdc38f5e6f4d8050672f7f4d84ea074c202", "class_name": "RelatedNodeInfo"}}, "text": "266 Part VII: The Part of Tens \nAfter you understand the goals you have for leveraging big data, your work \nis just beginning. You now need to get to the meat of the issues. You need to \ninvolve all the stakeholders in the business. Big data affects every aspect of \nyour organization, including the historical data that you already store, the \ninformation sources managed by different business units. New data sources \nmay be considered in some business areas that few managers are even aware \nof. Getting a task force together is a great way to get representatives of the \nbusiness together so that they can see how their data management issues \nare related. This team can evolve into a team that can help various business \nunits with best practices. The task force should have representatives from \nupper-management leaders who are setting business strategy and direction.\nEstablish a Road Map\nAt this stage, you have experimented with big data and determined your com -\npany\u2019s goals and objectives. You have a good understanding of what upper \nmanagement and business units need to accomplish. It is time to establish a \nroad map. Your road map is your action plan. You clearly can\u2019t do all the proj -\nects and meet all the demands from your company simultaneously. Your road \nmap needs to begin with the set of foundational services that can help your \ncompany get started. Part of your road map should include the existing data \nservices. Make sure that your road map has benchmarks that are reasonable \nand achievable. If you take on too much, you will not be able to demonstrate to \nmanagement that you are executing well. Therefore, you don\u2019t need a ten-year \nroad map. Begin with a one- to two-year road map with well-defined goals and \noutcomes. You should include both business and technical goals as part of the \nroad map.\nDiscover Your Data\nNo company ever complains that it has too little data. In reality, companies \nare swimming in data. The problem is that companies often don\u2019t know how \nto use that data pragmatically to be able to predict the future, execute on \nimportant business processes, or simply gain new insights. The goal of your \nbig data strategy and plan should be to find a way to leverage data for more \npredictable business outcomes. But you need to walk before you run. We \nrecommend that you start by embarking on a discovery process. You need to \nget a handle on what data you already have, where it is, who owns and con -\ntrols it, and how it is currently used. What are the third-party data sources \nthat your company relies on? This process will give you a lot of insights. \nFor example, it will let you know how many data sources you have and how \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2709, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c402b563-ad80-4180-a397-59f6062c2ca5": {"__data__": {"id_": "c402b563-ad80-4180-a397-59f6062c2ca5", "embedding": null, "metadata": {"page_label": "267", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c4f00616-d4a2-4086-9099-0fdaf9da32a9", "node_type": "4", "metadata": {"page_label": "267", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "80b58577082878de13b0e3a1e1d92ec12ee6793f50cd763f5e6909e577de1837", "class_name": "RelatedNodeInfo"}}, "text": "267  Chapter 23: Ten Big Data Best Practices\nmuch overlap exists. This process will also help you to understand the gaps \nin knowledge about those sources. You might discover that lots of duplicate \ndata exists in one area of the business and almost no data exists in another \narea. You might discover that you are dependent on third-party data that \nisn\u2019t as accurate as it should be. Spend the time you need to do this discovery \nprocess because it will be the foundation for your planning and execution of \nyour big data strategy.\nFigure Out What Data You Don\u2019t Have\nNow that you have discovered what data you have, it is time to think about \nwhat is missing. Take advantage of the task force you have set up. Business \nleaders are your best source of information. These leaders will understand \nbetter than anyone else what is keeping them from making even better deci -\nsions. When you start this process of determining what you need and what is \nmissing, it is good to encourage people to think out of the box. For example, \nyou might want to ask something like this: \u201cIf you could have any information \nat any speed to support the business and cost were no issue, what would you \nwant?\u201d This doesn\u2019t mean that cost isn\u2019t an issue. Rather, you are looking for \nmanagement to think out of the box about what could really change the busi -\nness. With the innovation happening in the data space, some of these wild \nideas and hopes are actually possible.\nUnderstand the Technology Options\nAt this point, you understand your company\u2019s goals, you have an understand -\ning of what data you have, and you know what data is missing. But how do you \ntake actions to execute your strategy? You have to know what technologies \nare available and how they might be able to assist your company to produce \nbetter outcomes. Therefore, do your homework. Begin to understand the \nvalue of technologies such as Hadoop, streaming data offerings, and complex \nevent-processing products. You should look at different types of databases \nsuch as in-memory databases, spatial databases, and so on. You should get \nfamiliar with the tools and techniques that are emerging as part of the big data \necosystem. It is important that your team has enough of an understanding of \nthe technology available to make well-informed choices.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2330, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "a95a2261-b52f-4cb2-b594-765e61b95ab0": {"__data__": {"id_": "a95a2261-b52f-4cb2-b594-765e61b95ab0", "embedding": null, "metadata": {"page_label": "268", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0b7b095-d949-43ad-ab42-0aaef4861403", "node_type": "4", "metadata": {"page_label": "268", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "541fc6c5bd6423d3c8fbaddecf2ed6ac31fe61dbdb961afc4ef0112c78d051eb", "class_name": "RelatedNodeInfo"}}, "text": "268 Part VII: The Part of Tens \nPlan for Security in Context  \nwith Big Data\nWhile companies always list security of data as one of the most important \nissues they need to manage, they are often unprepared for the complexities \ninvolved in managing data that is highly distributed and highly complex. In \nthe early stages of big data analytics, the analyst will not secure the data, \nbecause only a small portion of that data will be saved for further analysis. \nHowever, when an analyst selects an amount of data that will be brought into \nthe company, the data has to be secured against internal and external risk. \nSome of this data will have private information that must be masked so that \nno one without authorization has access. For security to be effective in the \ncontext of big data, you need to have a well-defined plan.\nPlan a Data Governance Strategy\nInformation governance is the ability to create an information resource that \ncan be trusted by employees, partners, and customers. A governance strategy \nis the joint responsibility of IT and the business. It is key that concrete rules \nexist that dictate how big data will be governed. For example, rules exist that \ndetermine how data must be protected depending on the circumstance and \ngovernmental requirements. Healthcare data must be stored so that the iden -\ntity and personal data remain private. Financial markets have their own set \nof data governance requirements that have to be adhered to. Problems can \ndevelop when an analyst collects and analyzes huge volumes of information \nand does not remember to implement the right governance to protect that \ndata. In addition, data sources themselves may be proprietary. When these \nsources are used within an organization, restrictions may exist on how much \ndata is used and for what purposes. Accountability for managing data in the \nright way is the heart of a good data governance strategy.\nPlan for Data Stewardship\nIt is easy to fall into the trap of assuming that the results of data analytics are \ncorrect. Management likes numbers and likes to make decisions based on \nwhat the numbers say. But hazards can occur if the data isn\u2019t managed in the \nright way. For example, you might be using data from five or six different data \nsources. In a situation where a company is determining which customers are \npotentially the best targets for a new product offering, a company might want \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2434, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6cc36414-5cff-49a1-89e5-5fcb3a33d007": {"__data__": {"id_": "6cc36414-5cff-49a1-89e5-5fcb3a33d007", "embedding": null, "metadata": {"page_label": "269", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6c368936-c327-4db9-bedc-e02fdde7e855", "node_type": "4", "metadata": {"page_label": "269", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "57f8f3a881dec80855ab3084329b5c8d41be59cb0f80a232f04b248ba5053525", "class_name": "RelatedNodeInfo"}}, "text": "269  Chapter 23: Ten Big Data Best Practices\nto analyze 10 or 15 different sources of data to come up with the results. Do \nyou have common metadata across these data sources? If not, is a process \nin place to vet the viability of that source to make sure that it is accurate and \nusable? Using data sources that are based on different metadata and different \nassumptions can send a company off on the wrong direction. So, be careful \nand make sure that when you collect data that might be meaningful that it \ncan execute in a way that helps the company make the most informed and \naccurate decisions. This also means understanding how to integrate these \nnew data sources with historical data systems, such as the data warehouse.\nContinually Test Your Assumptions\nYou will begin to find that making use of new data sources and massive amounts \nof data that could never be processed in the past can help make your company \nmuch better at anticipating the future. You will be able to determine the best \nactions to take in near real time based on what your data tells you about a \ncustomer or a decision you need to make. Even if you have all the processes \nin place to ensure that you have the right controls and the right metadata \ndefined, it is still important to test continuously. What types of outcomes are \nyou getting from your analysis? Do the results seem accurate? If you are get -\nting results that seem hard to believe, it is important to evaluate outcomes. \nAfter you have more accurate data, you will be able to achieve better and \nmore accurate outcomes. However, in some cases, you may see a problem \nthat wasn\u2019t apparent. Therefore, don\u2019t just assume that the data is always \nright. Test your assumptions and what you know about your business.\nStudy Best Practices and  \nLeverage Patterns\nAs the big data market matures, companies will gain more experience with \nbest practices or techniques that are successful in getting the right results. \nYou can access best practices in several different ways. You can meet with \npeers who are investigating the ways to leverage big data to gain business \nresults. You can also look to vendors and systems integrators who have codi -\nfied best practices into patterns that are available to customers. It is always \nbetter to find ways to learn from others rather than to repeat a mistake \nthat someone else made and learned from. As the big data market begins to \nmature, you will be able to leverage many more codified best practices to \nmake your strategy and execution plan more successful.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2569, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "1025c895-8ee0-4681-9471-161f3a8531ee": {"__data__": {"id_": "1025c895-8ee0-4681-9471-161f3a8531ee", "embedding": null, "metadata": {"page_label": "270", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d477cdcb-e637-4e14-9def-91ec94af7e8d", "node_type": "4", "metadata": {"page_label": "270", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e3feb90d40a4418b8d1361bad73c5c896736953a144d1ac7bd0741a72a2872e5", "class_name": "RelatedNodeInfo"}}, "text": "270 Part VII: The Part of Tens \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 50, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "74a3fd7d-5c73-4d35-861a-584e94d83510": {"__data__": {"id_": "74a3fd7d-5c73-4d35-861a-584e94d83510", "embedding": null, "metadata": {"page_label": "271", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "aa670ec0-8c41-4f38-af7c-f5fafe50e08e", "node_type": "4", "metadata": {"page_label": "271", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "c5b8ccb92a13e7217fc2771f38f257a65f2074f0799613998429771a24cd1aa4", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 24\nTen Great Big Data Resources\nIn This Chapter\n\u25b6 Big data resources\n\u25b6 Big data standards\n\u25b6 Free resources\nY \nou will find lots of resources that can help you start making sense of \nthe big data world. Standard organizations are tackling some of the key \nemerging issues with getting data resources to work together effectively. Open \nsource offerings can help you experiment easily so that you can better under -\nstand what is possible with big data. Lots of big data conferences and research \ngroups are out there. Of course, all the vendors in the market have research, \nwhite papers, and best practices that they are happy to share. In this chapter, \nwe offer you some ideas of the resources that are out there to help you.\nHurwitz & Associates\nwww.hurwitz.com\nThe authors of this book are partners and associates at Hurwitz & Associates. \nWe\u2019re happy to help you with your questions about big data. We provide \ntraining, strategy guidance, blogs, and research services. If you\u2019re a big data \nvendor, we can help you understand customer requirements so that you can \nposition your company and offer products that will meet customer needs. We \ninvite you to subscribe to our blogs and visit our website.\nStandards Organizations\nFor big data to mature, standards are required. A number of organizations \nare working hard to bring vendors together to help move the process for -\nward. The following sections describe some of these organizations.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1473, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d2c64653-007c-4012-bc0c-7893c08fa521": {"__data__": {"id_": "d2c64653-007c-4012-bc0c-7893c08fa521", "embedding": null, "metadata": {"page_label": "272", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "32686e8e-99a2-477b-939f-69069aeea1a4", "node_type": "4", "metadata": {"page_label": "272", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "4acbc331d845179116eea90305816fd2e6b442c8aceef53f459bdee2a18d875e", "class_name": "RelatedNodeInfo"}}, "text": "272 Part VII: The Part of Tens \nThe Open Data Foundation\nwww.opendatafoundation.org\nThe Open Data Foundation (ODaF) is a nonprofit organization that is organized \nto help promote the adoption of global metadata standards as well as the \ndevelopment of open source for the use of statistical data. The organization \nfocuses on improving metadata in the fields of economics, finance, healthcare, \neducation, labor, social science, technology, agriculture, development, and the \nenvironment. \nThe Cloud Security Alliance\nhttps://cloudsecurityalliance.org/research/big-data\nThe Cloud Security Alliance (CSA) was established to promote the use of best \npractices for providing and ensuring security within cloud computing and to \neducate people about the uses of cloud computing to help secure all other \nforms of computing. The organization has established the Big Data Working \nGroup (BDWG) to help identify the scalable techniques for data-centric  \nsecurity and privacy problems in big data.\nNational Institute of Standards  \nand Technology\nwww.nist.gov/itl/ssd/is/big-data.cfm\nThe National Institute of Standards and Technology (NIST) is a U.S. government \nagency that focuses on emerging standards efforts. This organization has done \na considerable amount of work defining and providing good information on \neverything from cloud computing to big data. In March 2012, NIST started \na big data initiative. The focus of the new initiative is to help transform the \ncapability of organizations to use big data for scientific discovery, environ -\nmental and biomedical research, education, and national security. It will \ncollaborate with the National Science Foundation (NSF) Center for Hybrid \nMulticore Productivity Research (CHMPR) in convening a big data workshop. \nThe issues to be addressed include\n \u2713 State-of-the-art core technologies needed to collect, store, preserve, \nmanage, analyze, and share big data that could benefit from standardization\n \u2713 Potential measurements to ensure the accuracy and robustness of  \nmethods that harness these technologies\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2082, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "096b23e7-b4ae-469a-bed8-d4a66686fd7f": {"__data__": {"id_": "096b23e7-b4ae-469a-bed8-d4a66686fd7f", "embedding": null, "metadata": {"page_label": "273", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0173ec60-f3df-49b7-9002-876ed6df3477", "node_type": "4", "metadata": {"page_label": "273", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "331d3e92e1e116172b3d3df2d5c0ea4d1f8ec019c6f43346a9afabea8335ae25", "class_name": "RelatedNodeInfo"}}, "text": "273  Chapter 24: Ten Great Big Data Resources\nApache Software Foundation\nhttp://hadoop.apache.org\nThe Apache Software Foundation provides organizational, legal, and financial \nsupport for a broad range of open source software projects. It was founded \nin 1999 as a membership-based, not-for-profit corporation to ensure that the \nApache projects continue to exist beyond the participation of individual vol -\nunteers. One of the organization\u2019s key projects is its management of Hadoop. \nIt offers an open source software library that is a standards-based framework \nfor processing large data sets across clusters of computers.\nOASIS\nwww.oasis-open.org\nOne of the most important standards organizations is OASIS, the \nOrganization for the Advancement of Structured Information Standards. It is \na nonprofit organization that has started to focus on big data standards. This \nprocess is at an early stage, but we expect that the organization will begin to \nfocus on creating big data standards.\nVendor Sites\nAll the major data management vendors offer great resources online. We  \nrecommend that you check out vendors such as \nGoogle:  http://research.google.com/\nAmazon:  http://aws.amazon.com/big-data/\nIBM:  http://bigdatauniversity.com/  and http://www-01.ibm.\ncom/software/data/bigdata/\nOracle:  http://www.oracle.com/us/technologies/big-data/\nindex.html\nMicrosoft:  http://research.microsoft.com/en-us/projects/\nbigdata/\nCloudera:  http://www.cloudera.com/content/cloudera/en/\nwhy-cloudera/hadoop-and-big-data.html\nSAS Institute:  http://www.sas.com/  \nTeradata:  http://www.teradata.com/business-needs/Big-\nData-Analytics/  \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1648, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5a1f1315-8f77-45d7-a1b8-2cac6deb325c": {"__data__": {"id_": "5a1f1315-8f77-45d7-a1b8-2cac6deb325c", "embedding": null, "metadata": {"page_label": "274", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "432bf1da-96f3-48c4-a7d2-b33468577577", "node_type": "4", "metadata": {"page_label": "274", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "6bd45a2ae791df55ed532a035155099f6e6f7a221833843b17f9b4e5e491a80d", "class_name": "RelatedNodeInfo"}}, "text": "274 Part VII: The Part of Tens \nThis is only a partial list. Hundreds of companies are lining up to provide \ngreat big data information. Make sure to check out the blogs of some of these \ncompanies\u2019 thought leaders.\nOnline Collaborative Sites\nMany emerging groups encourage online collaboration around the topic of \nbig data. LinkedIn has a number of groups worth checking out at http://\nwww.linkedin.com/groups/Big-Data-Analytics-Strategy-FP-\n1814785?home=&gid=1814785&trk=anet_ug_hm . In addition, look at \nthe forums sponsored by the Apache Hadoop Initiative at http://hadoop.\napache.org/ .\nBig Data Conferences\nLots of data conferences are out there, and many of them are either initiating \nnew conferences on big data or have big data tracks at their meetings. Here are \nsome examples of the big data conferences that are springing up every day:\n \u2713 The Data Warehousing Institute (TDWI):  Sponsors many conferences, \nseminars, and educational forums on data warehouses and big data\n \u2713 Big Data Conference:  Provides analytics and applications for big data\n \u2713 Big Data Retail Forum:  A conference for companies looking to retailers \nand consumer goods manufacturers needing to analyze real-time  \ninformation\n \u2713 Hadoop World:  Sponsored by O\u2019Reilly\n \u2713 O\u2019Reilly Strata and StrataRx:  Visit http://strataconf.com . \n \u2713 StructureData:  Visit http://event.gigaom.com/structuredata .\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1401, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "de5e3052-ba47-4a01-a2b7-30f7caed1b37": {"__data__": {"id_": "de5e3052-ba47-4a01-a2b7-30f7caed1b37", "embedding": null, "metadata": {"page_label": "275", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cac38972-e8e3-47bb-8f57-364867319217", "node_type": "4", "metadata": {"page_label": "275", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "809bacedc38439577b3a3441c334ab1716c561cd1e927e5334899cbef8c6a76a", "class_name": "RelatedNodeInfo"}}, "text": "Chapter 25\nTen Big Data Do\u2019s and Don\u2019ts\nIn This Chapter\n\u25b6 Beginning with a clear plan\n\u25b6 Collaborating with the business\n\u25b6 Making big data part of your planning and execution process\nM \nany companies that are beginning their exploration of big data are in \nthe early stages of execution. Most companies are experimenting with \npilots to see whether they can leverage big data sources to transform deci -\nsion making. It is easy to make mistakes that can cause disruptions in your \nbusiness strategy. In this chapter, we give you some ideas about what you \nshould do and what you should avoid as you begin your journey to big data.\nDo Involve All Business Units  \nin Your Big Data Strategy\nBig data is not an isolated activity. Rather, it is the way that the business can \nleverage huge volumes of data to learn more about customers, processes, \nand events than would be possible with snapshots of data. If executed prop -\nerly, a big data strategy can have a huge impact on the effectiveness of a \nbusiness strategy. Companies that assume that data that is out of the norm \nis wrong may suddenly discover some new emerging patterns of customer \nrequirements. The business units can gain significant value when they are \nbrought into the process early.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1269, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d638a9e5-fc26-49f6-bcf2-5da508111468": {"__data__": {"id_": "d638a9e5-fc26-49f6-bcf2-5da508111468", "embedding": null, "metadata": {"page_label": "276", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "df4cf1d7-1eea-4ee4-be00-a8d3a7ee7e2a", "node_type": "4", "metadata": {"page_label": "276", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "28b8e067ad5b917dd9f1ccf9b863cdbf6200964cffdf1817d6252938947bf0e2", "class_name": "RelatedNodeInfo"}}, "text": "276 Part VII: The Part of Tens \nDo Evaluate All Delivery  \nModels for Big Data\nIt is natural to assume that if you are dealing with petabytes of data, the only \nway to store and manage that data is in the data center. However, technology \nis evolving so that it is possible and necessary to use cloud computing stor -\nage and compute resources to manage big data. Therefore, evaluate the type \nof services that are cloud based and determine which ones have the perfor -\nmance that you will need for certain tasks.\nDo Think about Your Traditional  \nData Sources as Part of Your  \nBig Data Strategy\nMany companies that have found value in big data analytics assume that they \nno longer have to think about the traditional data warehouse. This is not true. \nIn fact, it is critical that you plan to use the results of your big data analytics \nin conjunction with your data warehouse. The data warehouse includes the \ninformation about the way your company operates. Therefore, being able \nto compare the big data results against the benchmarks of your core data is \ncritical for decision making.\nDo Plan for Consistent Metadata\nWhen you complete the analysis of a massive data set, it is quite possible that \nyou will come up with data that all matches a pattern. This set of data now can \nlead your organization to begin analyzing a new issue in depth. Keep in mind \nthat this data might come from customer service sites or social media envi -\nronments that have not been cleansed. Therefore, before you trust the data, \nyou have to make sure that you are dealing with a consistent set of metadata \nso that you can bring this information into your organization and analyze it in \nconcert with the data from your systems of record.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1747, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "658f5b5e-c7f2-4d33-a9b0-30aeff752886": {"__data__": {"id_": "658f5b5e-c7f2-4d33-a9b0-30aeff752886", "embedding": null, "metadata": {"page_label": "277", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ac037533-6b34-4ce2-8369-93986affa13c", "node_type": "4", "metadata": {"page_label": "277", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "21d24b809656c9570289c370dd10e860e6ec82d7b293a526c8546230e763af5a", "class_name": "RelatedNodeInfo"}}, "text": "277  Chapter 25: Ten Big Data Do\u2019s and Don\u2019ts\nDo Distribute Your Data\nWhen you are dealing with big data, don\u2019t assume that you will be able to \nmanage all this information within a single server. Find out how to use dis -\ntributed computing techniques such as Hadoop to effectively manage the \nsize, variety, and required speed to manage your data.\nDon\u2019t Rely on a Single Approach  \nto Big Data Analytics\nSo much hype exists in the market around technologies such as Hadoop and \nMapReduce that you might lose sight of what you are actually trying to accom -\nplish. A lot of important technologies are available, such as text analytics, pre -\ndictive analytics, streaming data environments, and spatial data analysis, that \nmay be important for the job you are trying to accomplish. Spend the time to \ninvestigate the variety of technologies that can support you. Experiment and \ninvestigate the technology solutions that can make you successful.\nDon\u2019t Go Big Before You Are Ready\nYou are right to be excited about the potential that big data offers your com -\npany. Big data can mean the difference between jumping into an exciting new \nmarket before your competitors or being left behind. But walk before you \nrun. You need to start with pilot projects that can allow you to gain some \nexperience. You need to work with experts who can keep you from making \nhuge mistakes because of inexperience.\nDon\u2019t Overlook the Need to Integrate Data\nYour big data sources will not be effective if they live in isolation from each \nother. Good technologies in the market are focused on making it easier to \nintegrate the results of big data analytics with other data sources. Therefore, \nbe prepared not just to analyze but also to integrate.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1751, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8685dbb3-196e-4550-8c1d-f7562a6b54b6": {"__data__": {"id_": "8685dbb3-196e-4550-8c1d-f7562a6b54b6", "embedding": null, "metadata": {"page_label": "278", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4f866168-2ee3-41a4-bf09-83ab8875dd5e", "node_type": "4", "metadata": {"page_label": "278", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "7a2e53049c9e81d4239707ecd23d4836c3d554886a496c79181942a757cd2049", "class_name": "RelatedNodeInfo"}}, "text": "278 Part VII: The Part of Tens \nDon\u2019t Forget to Manage Data Securely\nWhen companies embark on big data analysis, they often forget to maintain \nthe same level of data security and governance that is assumed in traditional \ndata management environments. When you begin doing analysis of several \npetabytes or more of data, you typically won\u2019t mask out private information \nat the outset. However, when you have a subset of that initial data set that is \nnow critical to determining your next best action or your approach to a new \nmarket, you need to first secure that data so that it doesn\u2019t put your business \nat risk. Some of this data will now become corporate intellectual property \nthat has to be secured. You may also need to manage privacy requirements. \nThis security has to become part of your big data life cycle. In addition, \nsome of the data sources that you are using may come from third-party data \nsources that require licenses. Make sure that you are allowed to use this data \nand that you haven\u2019t violated governance rules.\nDon\u2019t Overlook the Need to Manage  \nthe Performance of Your Data\nBig data demonstrates that we are able to make use of more data than ever \nbefore at a faster rate of speed than was possible in the past. This capability \nto gain more insights is a huge benefit. However, if that data isn\u2019t managed in \nan effective way, it will cause huge problems for the company. Therefore, you \nneed to build manageability into your road map and plan for big data.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1511, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4f9c0e8e-cfec-4b58-96c1-b916343ae2b7": {"__data__": {"id_": "4f9c0e8e-cfec-4b58-96c1-b916343ae2b7", "embedding": null, "metadata": {"page_label": "279", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4ca81a9f-6ee9-461d-b538-3f9c4c814836", "node_type": "4", "metadata": {"page_label": "279", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "33500f79d938f2879d906012e608f2cf86d972ce4b25982eda8da227ec86c313", "class_name": "RelatedNodeInfo"}}, "text": "Glossary\nA\nabstraction: The idea of minimizing the complexity of something by hiding \nthe details and just providing the relevant information. It\u2019s about providing a \nhigh-level specification rather than going into lots of detail about how some -\nthing works. In the cloud, for instance, in an IaaS delivery model, the infra -\nstructure is abstracted from the user.\naccess control:  Determining who or what can go where, when, and how.\nACID: An acronym for atomicity, consistency, isolation, and durability,  which \nare the main requirements for guaranteed transaction processing.\nadvanced analytics:  Algorithms for complex analysis of either structured \nor unstructured data. It includes sophisticated statistical models, machine \nlearning, neural networks, text analytics, and other advanced data-mining \ntechniques Advanced analytics does not include database query and report -\ning and OLAP cubes.\nAPI (application programming interface):  A defined protocol that allows \ncomputer programs to use functionality and data from other software systems.\napplication life cycle:  The process of maintaining a piece of code so that it\u2019s \nconsistent and predictable as it\u2019s changed to support business requirements.\narchitecture: In information processing, the design approach taken in devel -\noping a program or system.\narchiving:  The process by which a database or file data that\u2019s seldom used \nor outdated, but that\u2019s required for historical or audit reasons, is copied to a \ncheaper form of storage. The storage medium may be online, tape, or optical \ndisc. Companies are using the cloud as a means of archiving data. \nasset management:  Software that allows organizations to record all informa -\ntion about their hardware and software. Most such applications capture cost \ninformation, license information, and so on. Such information belongs in the \nconfiguration management database. See also CMDB.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1922, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8566fca9-75cd-462f-8fe7-ac7de9624d8e": {"__data__": {"id_": "8566fca9-75cd-462f-8fe7-ac7de9624d8e", "embedding": null, "metadata": {"page_label": "280", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "96f2ad61-12f0-42da-9e10-2d218b3f2bd7", "node_type": "4", "metadata": {"page_label": "280", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "fe89f538defa990fac3fee1a8c98e8fadfa474e95ce227560d132e9dd23a99c2", "class_name": "RelatedNodeInfo"}}, "text": "280 Big Data For Dummies \naudit:  A check on the effectiveness of a task or set of tasks, and how the tasks \nare managed and documented. Auditing is also a process that is used within \norganizations to ensure that the data is secure and in compliance with regula -\ntory organizations.\naudit trail:  A trace of a sequence of events in a clerical or computer system. \nThis audit usually identifies the creation or modification of any element in \nthe system, who did it, and (possibly) why it was done.\nauthentication:  The process by which the identity of a person or computer \nprocess is verified.\nB\nbackup:  A utility that copies databases, files, or subsets of databases and \nfiles to a storage medium. This copy can be used to restore the data in case \nof system failure.\nbandwidth:  Technically, the range of frequencies over which a device can \nsend or receive signals. The term is also used to denote the maximum data \ntransfer rate, measured in bits per second, that a communications channel \ncan handle.\nbatch:  A noninteractive process that runs in a queue, usually when the \nsystem load is lowest, and generally used for processing batches of informa -\ntion in a serial and usually efficient manner. Early computers were capable of \nonly batch processing.\nbest practice:  An effective way of doing something. It can relate to anything \nfrom writing program code to IT governance.\nbig data:  The capability to manage a huge volume of disparate data, at the \nright speed and within the right time frame, to allow real-time analysis and \nreaction. Big data is typically broken down by three characteristics, including \nvolume (how much data), velocity (how fast that data is processed), and vari -\nety (the various types of data).\nBigtable:  Developed by Google to be a distributed storage system intended \nto manage highly scalable structured data. Data is organized into tables with \nrows and columns. Unlike a traditional relational database model, Bigtable is \na sparse, distributed, persistent, multidimensional sorted map. It is intended \nto store huge volumes of data across commodity servers.\nbinding:  Making the necessary connections among software components so \nthat they can interact.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2222, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "bb938d51-5035-446c-9dfb-77d292805a0a": {"__data__": {"id_": "bb938d51-5035-446c-9dfb-77d292805a0a", "embedding": null, "metadata": {"page_label": "281", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "50fd92c5-0328-4132-8215-8039142e4fc7", "node_type": "4", "metadata": {"page_label": "281", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "499f92b2fc1567902a5160feeeeccb9a5db592a331f30d403189858d09cb9234", "class_name": "RelatedNodeInfo"}}, "text": "281  Glossary\nbiometrics:  Using a person\u2019s unique physical characteristics to prove his \nidentity to a computer \u2014 for example, by using a fingerprint scanner or voice \nanalyzer.\nblack box:  A component or device with an input and an output whose inner \nworkings need not be understood by or accessible to the user.\nBPaaS: See Business Process as a Service.\nBPEL (Business Process Execution Language):  A computer language based on \nWSDL (Web Services Description Language, an XML format for describing web \nservices) and designed for programming business services. See also XML.\nBPM (business process management):  A technology and methodology for \ncontrolling the activities \u2014 both automated and manual \u2014 needed to make a \nbusiness function.\nbroker:  In computer programming, a program that accepts requests from \none software layer or component and translates them into a form that can be \nunderstood by another layer or component.\nbus: A technology that connects multiple components so they can talk to one \nanother. In essence, a bus is a connection capability. A bus can be software \n(such as an enterprise service bus) or hardware (such as a memory bus).\nbusiness process:  The codification of rules and practices that constitute a \nbusiness.\nBusiness Process as a Service (BPaaS): A whole business process is provided \nas a service involving little more than a software interface, such as a parcel \ndelivery service.\nbusiness process modeling:  A technique for transforming how business  \noperates into a codified source so that it can be translated into software.\nbusiness rules:  Constraints or actions that refer to the actual commercial \nworld but may need to be encapsulated in service management or business \napplications.\nbusiness service: An individual function or activity that is directly useful to \nthe business.\nC\ncache: An efficient method of storing data in memory so that future requests \nfor that data can be achieved more quickly.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1974, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "55155f27-0a56-4c1f-a11c-0f790c4c73b0": {"__data__": {"id_": "55155f27-0a56-4c1f-a11c-0f790c4c73b0", "embedding": null, "metadata": {"page_label": "282", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4d9c3278-680b-49d6-accc-1a6dae3f1514", "node_type": "4", "metadata": {"page_label": "282", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "c40f592aed566c1bce61e64a763eccb1822be1de28de014bfe5d04e005cd5056", "class_name": "RelatedNodeInfo"}}, "text": "282 Big Data For Dummies \ncenter of excellence:  A group of key people from all areas of the business \nand operations that focus on best practices. A center of excellence pro -\nvides a way for groups within the company to collaborate. This group also \nbecomes a force for change, because it can leverage its growing knowledge to \nhelp business units benefit from experience.\nchange management:  The management of change in operational processes \nand applications. Change management is critical when IT organizations are \nmanaging software infrastructure in conjunction with new development pro -\ncesses. All software elements have to be synchronized so that they work as \nintended. \ncloud computing:  A computing model that makes IT resources such as servers, \nmiddleware, and applications available as services to business organizations \nin a self-service manner.\nCMDB (configuration management database):  In general, a repository of  \nservice management data.\nCOBIT (Control Objectives for Information and Related Technology):  An IT \nframework with a focus on governance and managing technical and business \nrisks.\ncolumnar or column-oriented database:  A database that stores data across \ncolumns rather than rows. This is in contrast to a relational database that \nstores data in rows.\nComplex Event Processing (CEP):  A technique for tracking, analyzing, and \nprocessing data as an event happens. This information is then processed and \nmanaged based on a business rules and processes.\ncomponent:  A piece of computer software that can be used as a building \nblock in larger systems. Components can be parts of business applications \nthat have been made accessible through web service\u2013related standards and \ntechnologies, such as WSDL, SOAP, and XML. See also  web service.\nconfiguration:  The complete description of the way in which the constituent \nelements of a software product or system interrelate, both in functional and \nphysical terms.\nconfiguration management: The management of configurations, normally \ninvolving holding configuration data in a database so that the data can be \nmanaged and changed where necessary.\ncontainer:  In computer programming, a data structure or object used to \nmanage collections of other objects in an organized way.\ncontent management system:  A system that provides methods and tools to \ncapture, manage, store, preserve, and deliver content and documents related \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2434, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "00d8a7c8-2e1f-4e6a-acda-583aa001c458": {"__data__": {"id_": "00d8a7c8-2e1f-4e6a-acda-583aa001c458", "embedding": null, "metadata": {"page_label": "283", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dfceb8bc-14a0-4019-b033-f8e18e35621b", "node_type": "4", "metadata": {"page_label": "283", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "54c84ccba71ea733e46df78859dae11d8ec4c83c61395af622e25984966ae0fd", "class_name": "RelatedNodeInfo"}}, "text": "283  Glossary\nto organizational processes. The technologies include document manage -\nment, records management, imaging, workflow management, web content \nmanagement, and collaboration.\nCRM (customer relationship management):  Software designed to help you \nrun your sales force and customer support operations.\nD\ndata access: See access control.\ndata at rest: Data that is placed in storage rather than used in real time.\ndata cleansing:  Software used to identify potential data-quality problems. If a \ncustomer is listed multiple times in a customer database because of variations \nin the spelling of her name, the data-cleansing software makes corrections to \nhelp standardize the data.\ndata federation:  Data access to a variety of data stores, using consistent \nrules and definitions that enable all the data stores to be treated as a single \nresource.\ndata in motion:  Data that is moving across a network or in memory for  \nprocessing in real time.\ndata marts:  A subset of a data warehouse that is designed to focus on a  \nspecific set of business information. \ndata mining:  The process of exploring and analyzing large amounts of data to \nfind patterns.\ndata profiling:  A technique or process that helps you understand the content, \nstructure, and relationships of your data. This process also helps you validate \nyour data against technical and business rules.\ndata quality:  Characteristics of data such as consistency, accuracy, reliability, \ncompleteness, timeliness, reasonableness, and validity. Data-quality software \nensures that data elements are represented in a consistent way across dif -\nferent data stores or systems, making the data more trustworthy across the \nenterprise.\ndata transformation:  A process by which the format of data is changed so \nthat it can be used by different applications.\ndata warehouse:  A large data store containing the organization\u2019s historical \ndata, which is used primarily for data analysis and data mining. It is the data \nsystem of record.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2018, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4d412284-c69f-4ab6-8986-ce31b0f9ed86": {"__data__": {"id_": "4d412284-c69f-4ab6-8986-ce31b0f9ed86", "embedding": null, "metadata": {"page_label": "284", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f2ca6e81-467d-4a46-ba7d-25998dbbf796", "node_type": "4", "metadata": {"page_label": "284", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "6fb6f700d708036b313c5a1a82ca7aadca34b0fd6f615281bccb70e4abff1b9a", "class_name": "RelatedNodeInfo"}}, "text": "284 Big Data For Dummies \ndatabase: A computer system intended to store large amounts of information \nreliably and in an organized fashion. Most databases provide users with  \nconvenient access to the data, along with helpful search capabilities.\ndatabase management system  (DBMS):  Software that controls the storage, \naccess, deletion, security, and integrity of primarily structured data within a \ndatabase.\ndirectory:  A term used in both computing and telephony to indicate an  \norganized map of devices, files, or people.\ndistributed computing:  The ability to process and manage the processing of \nalgorithms across many different nodes in a computing environment.\nE\nearly binding: Defining the connections among applications before processing \nto improve speed. This also limits flexibility. Also see late binding.\nelasticity:  The capability to expand or shrink a computing resource in real \ntime, based on need.\nELT (extract, load, transform):  Tools for locating and loading data into a \nbusiness application so that it can be later transformed. This is similar to ETL \n(see its entry) but is associated with big data integration processes.\nemulation: When hardware, software, or a combination of both duplicates \nthe functionality of a computer system in a different, second system. The \nbehavior of the second system will closely resemble the original functionality \nof the first system. See also virtualization.\nEntity Relationship (ER) model:  A data management approach that graphically \nrepresents relationships between data. This allows developers to create new \nrelationships between data sources without complex programming.\nERP (enterprise resource planning):  A packaged set of business applications \nthat combines business rules, processes, and data management into a single \nintegrated environment to support a business.\nEnterprise Service Bus (ESB):  A packaged set of middleware services that are \nused to communicate between business services in a secure and predictable \nmanner. \nETL (extract, transform, and load):  Tools for locating and accessing data \nfrom a data store (data extraction), changing the structure or format of the \ndata so it can be used by the business application (data transformation), and \napplying the data to the business application (data load).\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2319, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "27908f14-4657-4f58-8ac4-bb99dca60cb2": {"__data__": {"id_": "27908f14-4657-4f58-8ac4-bb99dca60cb2", "embedding": null, "metadata": {"page_label": "285", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "edc59afa-33b8-4ec8-b57c-8a27a4eb794b", "node_type": "4", "metadata": {"page_label": "285", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "c1dc3a626d210410bfd2d4946b769bb021b67ab8a0e725ef6dd9325f29d09af3", "class_name": "RelatedNodeInfo"}}, "text": "285  Glossary\nF\nfault tolerance:  The capability of a system to provide uninterrupted service \ndespite the failure of one or more of the system\u2019s components.\nfederation: The combination of disparate things so that they can act as one \u2014 \nas in federated states, data, or identity management \u2014 and to make sure that \nall the right rules apply.\nframework:  A support structure for developing and managing software  \nproducts.\nG\ngovernance:  The ability to ensure that corporate or governmental rules and \nregulations are conformed with. Governance is combined with compliance \nand security issues across computing environments.\ngranularity:  An important software design concept, especially in relation to \ncomponents, referring to the amount of detail or functionality \u2014 from fine to \ncoarse \u2014 provided in a service component. One software component can do \nsomething quite simple, such as calculate a square root; another has a great \ndeal of detail and functionality to represent a complex business rule or work -\nflow. The first component is fine-grained, and the second is coarse-grained. \nDevelopers often aggregate fine-grained services into coarse-grained services \nto create a business service.\ngrid computing:  A step beyond distributed processing, involving large num -\nbers of networked computers (often geographically dispersed and possibly \nof different types and capabilities) that are harnessed to solve a common \nproblem. A grid computing model can be used instead of virtualization in \nsituations that require real time where latency is unacceptable.\nH\nHadoop: An Apache-managed software framework derived from MapReduce \nand Bigtable. Hadoop allows applications based on MapReduce to run on \nlarge clusters of commodity hardware. Hadoop is designed to parallelize data \nprocessing across computing nodes to speed computations and hide latency. \nTwo major components of Hadoop exist: a massively scalable distributed \nfile system that can support petabytes of data and a massively scalable \nMapReduce engine that computes results in batch.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2073, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6096d054-d143-42c7-95f5-c3dca4ed0fff": {"__data__": {"id_": "6096d054-d143-42c7-95f5-c3dca4ed0fff", "embedding": null, "metadata": {"page_label": "286", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0adea515-0864-4ac2-bc21-b9a208568437", "node_type": "4", "metadata": {"page_label": "286", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "19c1584dc3fee4301850c8c856ed7c1bec8c9fdc63f1dcd5385d057cbde8ff68", "class_name": "RelatedNodeInfo"}}, "text": "286 Big Data For Dummies \nHadoop Distributed File System (HDFS): A versatile, resilient, clustered \napproach to managing files in a big data environment. HDFS is not the final \ndestination for files. Rather, it is a data \u201cservice\u201d that offers a unique set of \ncapabilities needed when data volumes and velocity are high.\nhardware partitioning: The act of subdividing and isolating elements of a \nphysical server into fractions, each of which can run an operating system or \nan application.\nhybrid cloud:  A computing environment that includes the use of public and \nprivate clouds as well as data center resources in a coordinated fashion.\nhypervisor: Hardware that allows multiple operating systems to share a \nsingle host. The hypervisor sits at the lowest levels of the hardware environ -\nment and uses a thin layer of code in software to enable dynamic resource \nsharing. The hypervisor makes it seem like each operating system has the \nresources all to itself.\nI\nIaaS: See Infrastructure as a Service.\nidentity management:  Keeping track of a single user\u2019s (or asset\u2019s) identity \nthroughout an engagement with a system or set of systems.\ninformation integration:  A process using software to link data sources in \nvarious departments or regions of the organization with an overall goal of \ncreating more reliable, consistent, and trusted information.\ninfrastructure:  The fundamental systems necessary for the ordinary opera -\ntion of anything, be it a country or an IT department. The physical infrastruc -\nture that people rely on includes roads, electrical wiring, and water systems. \nIn IT, infrastructure includes basic computer hardware, networks, operating \nsystems, and other software that applications run on top of.\nInfrastructure as a Service (IaaS):  Infrastructure, including a management \ninterface and associated software, provided to companies from the cloud as \na service.\ninfrastructure services: Services provided by the infrastructure. In IT, these \nservices include all the software needed to make devices talk to one another, \nfor starters.\nin-memory database:  A database structure where information is managed \nand processed in memory rather than on disk.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2203, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "46734690-1a2d-4e0f-8135-15ee0fb9a561": {"__data__": {"id_": "46734690-1a2d-4e0f-8135-15ee0fb9a561", "embedding": null, "metadata": {"page_label": "287", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d39eb387-0597-445a-ad49-7c3663c012c2", "node_type": "4", "metadata": {"page_label": "287", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "195a0053b3320f2de2a09d969e46cb25679fbeca9de8514e0a3d065245324b7d", "class_name": "RelatedNodeInfo"}}, "text": "287  Glossary\ninteroperability:  The capability of a product to interface with many other \nproducts; usually used in the context of software.\nISO (International Organization for Standardization):  An organization that has \ndeveloped more than 17,000 international standards, including standards for IT \nservice management and corporate governance of information technology.\nITIL (Information Technology Infrastructure Library): A framework and set \nof standards for IT governance based on best practices.\nL\nLAMP (Linux, Apache, MySQL, PHP, Perl, or Python):  An increasingly popu -\nlar open source approach to building web applications. LAMP is a software \nbundle made up of the Linux operating system, the Apache web server, a \nMySQL database, and a scripting language such as PHP, Perl, or Python.\nlate binding:  Deferring the necessary connections among applications to when \nthe connection is first needed. Late binding allows more flexibility for changes \nthan early binding does, but it imposes some cost in processing time.\nlatency:  The amount of time lag before a service executes in an environment. \nSome applications require less latency and need to respond in near real time, \nwhereas other applications are less time-sensitive.\nlegacy application:  Any application that is more than a few years old. When \napplications can\u2019t be disposed of and replaced easily, they become legacy \napplications. The good news is that they\u2019re still doing something useful when \nselected pieces of code can be turned into business services with new stan -\ndardized interfaces.\nLinux:  An open source operating system based upon and similar to UNIX. In \ncloud computing, Linux is the dominant operating system, primarily because \nit is supported by a large number of vendors.\nLinux web hosting:  The vast majority of websites run on the Linux operating  \nsystem managed by a Linux web hosting service using the LAMP (Linux, \nApache, MySQL, PHP) software stack.\nloose coupling:  An approach to distributed software applications in which \ncomponents interact by passing data and requests to other components in \na standardized way that minimizes dependencies among components. The \nemphasis is on simplicity and autonomy. Each component offers a small \nrange of simple services to other components.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2308, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "89175899-d265-42f1-a1dd-6220f14490a5": {"__data__": {"id_": "89175899-d265-42f1-a1dd-6220f14490a5", "embedding": null, "metadata": {"page_label": "288", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c62f2bcf-e6f9-4264-a120-b63493861f62", "node_type": "4", "metadata": {"page_label": "288", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "1d8b8aedbb2c0d8d062adf37ff36bd669e36bdff63b48fa7cbcf2671131a4023", "class_name": "RelatedNodeInfo"}}, "text": "288 Big Data For Dummies \nM\nMapReduce: Designed by Google as a way of efficiently executing a set of \nfunctions against a large amount of data in batch mode. The \u201cmap\u201d compo -\nnent distributes the programming problem or tasks across a large number of \nsystems and handles the placement of the tasks in a way that balances the \nload and manages recovery from failures. After the distributed computation \nis completed, another function called \u201creduce\u201d aggregates all the elements \nback together to provide a result.\nmarkup language:  A way of encoding information that uses plain text contain -\ning special tags often delimited by angle brackets ( < and >). Specific markup \nlanguages are based on XML to standardize the interchange of information \nbetween different computer systems and services. See also XML.\nmashup: A program (possibly installed on a web page) that combines content \nfrom more than one source, such as Google Maps and a real estate listing \nservice.\nmetadata:  The definitions, mappings, and other characteristics used to describe \nhow to find, access, and use the company\u2019s data and software components.\nmetadata repository:  A container of consistent definitions of business data \nand rules for mapping data to its actual physical locations in the system.\nmiddleware:  Multipurpose software that lives at a layer between the operat -\ning system and application in distributed computing environments.\nmission-critical:  An application that a business cannot afford to be without at \nany time.\nMOM (Message Oriented Middleware):  A precursor to the enterprise service \nbus. See also Enterprise Service Bus ( ESB), a set of packaged middleware  \nservices.\nmultitenancy:  This refers to the situation where a single instance of an appli -\ncation runs on an SaaS vendor\u2019s servers, but serves multiple client organiza -\ntions (tenants), keeping all their data separate. In a multitenant architecture, \na software application partitions its data and configuration so that each cus -\ntomer has a customized virtual application instance.\nMySQL:  An open source option to SQL.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2106, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "c48f6eb0-5ff9-4873-be40-df8c3ad82e2f": {"__data__": {"id_": "c48f6eb0-5ff9-4873-be40-df8c3ad82e2f", "embedding": null, "metadata": {"page_label": "289", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3bdca548-0d7f-44f5-8d81-1242c901e58e", "node_type": "4", "metadata": {"page_label": "289", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "3ea750a0581164ecd31fe6b9e6075ea203dd3c63c01786e89d79fa16fc4d1f69", "class_name": "RelatedNodeInfo"}}, "text": "289  Glossary\nN\nnetwork:  The connection of computer systems (nodes) by communications \nchannels and appropriate software.\nNoSQL (not only SQL):  A set of technologies that created a broad array of \ndatabase management systems that are distinct from relational database \nsystems. One major difference is that SQL is not used as the primary query \nlanguage. These database management systems are also designed for distrib -\nuted data stores.\nO\nobject-oriented database management system (OODBMS):  A database man -\nagement system where data is stored as an object that is closely aligned with \nan application.\nopen source:  A movement in the software industry that makes programs \navailable along with the source code used to create them so that others can \ninspect and modify how programs work. Changes to source code are shared \nwith the community at large. \noperationalized analytics:  Making analytics part of a business process.\nP\nP2P (peer-to-peer):  A networking system in which nodes in a network \nexchange data directly instead of going through a central server.\nPaaS: See Platform as a Service.\npersistence: A guarantee that data stored in a database won\u2019t be changed with -\nout permissions and it will available as long as it is important to the business.\nPlatform as a Service  (PaaS): A cloud service that abstracts the computing \nservices, including the operating software and the development and deploy -\nment and management life cycle. It sits on top of Infrastructure as a Service.\nPostgreSQL: The most widely used open source relational database.\npredictive analytics: A statistical or data-mining solution consisting of algo -\nrithms and techniques that can be used on both structured and unstructured  \ndata (together or individually) to determine future outcomes. It can be deployed \nfor prediction, optimization, forecasting, simulation, and many other uses.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1898, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "77913d79-4179-4871-8bb2-07b32356ffa0": {"__data__": {"id_": "77913d79-4179-4871-8bb2-07b32356ffa0", "embedding": null, "metadata": {"page_label": "290", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "839e467c-8e94-443c-a96b-e329e3525e0e", "node_type": "4", "metadata": {"page_label": "290", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "3465e1fc6b8dad9aa8eed93764a2b7855464562780fa7b990017ebd81762f133", "class_name": "RelatedNodeInfo"}}, "text": "290 Big Data For Dummies \nprivate cloud:  As opposed to a public cloud, which is generally available, \na private cloud is a set of computing resources within the corporation that \nserves only the corporation, but that is set up to operate in a cloud-like \nmanner in regard to its management.\nprocess: A high-level, end-to-end structure useful for decision making and \nnormalizing how things get done in a company or organization.  See also   \nworkflow.\nprotocol: A set of rules that computers use to establish and maintain commu -\nnication among themselves.\nprovisioning: Making resources available to users and software. A provision -\ning system makes applications available to users and makes server resources \navailable to applications.\npublic cloud:  A resource that is available to any consumer either as a fee-per-\ntransaction service or as a free service. It does not have deep security or a \nwell-defined SLA.\nR\nreal-time:  A form of processing in which a computer system accepts and \nupdates data at the same time, feeding back immediate results that influence \nthe data source.\nreal-time event processing:  A class of applications that demand timely \nresponse to actions that take place out in the world. Typical examples \ninclude automated stock trading and RFID. See also RFID.\nregistry:  A single source for all the metadata needed to gain access to a web \nservice or software component.\nrelational database management system (RDBMS):  A database management \nsystem that organizes data in defined tables.\nrepository:  A database for software and components, with an emphasis on \nrevision control and configuration management (where they keep the good \nstuff, in other words).\nresource pool:  A set of compute, storage, or data services that are combined \nto be used across hybrid environments.\nresponse time:  The time from the moment at which a transaction is submit -\nted by a user or an application to the moment at which the final result of that \ntransaction is made known to the user or application.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2036, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f096c232-791e-4c23-b67d-77bb2d8944f3": {"__data__": {"id_": "f096c232-791e-4c23-b67d-77bb2d8944f3", "embedding": null, "metadata": {"page_label": "291", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "06f47be8-839b-4ace-857f-884f42468339", "node_type": "4", "metadata": {"page_label": "291", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "49b271805e247284528a2b5f8cac1d2db8fa1c2c52f171de40f54401211eb30e", "class_name": "RelatedNodeInfo"}}, "text": "291  Glossary\nREST (Representational State Transfer): Designed specifically for the \nInternet and is the most commonly used mechanism for connecting one \nweb resource (a server) to another web resource (a client). A RESTful API \nprovides a standardized way to create a temporary relationship (also called \n\u201cloose coupling\u201d) between and among web resources.\nRFID (radio frequency identification):  A technology that uses small, inex -\npensive chips attached to products (or even animals) that then transmit a \nunique identification number over a short distance to a special radio trans -\nmitter/receiver.\nRPC (remote procedure call):  A way for a program running on one computer \nto run a subprogram on another computer.\nS\nSaaS: See Software as a Service.\nSAML (Security Assertion Markup Language): A standard framework for \nexchanging authentication and authorization information (that is, creden -\ntials) in an XML format called assertions.\nSAN (storage-area network): A high-speed network of interconnected storage \ndevices. These storage devices might be servers, optical disc drives, or other \nstorage media. The difference between a SAN and an NAS (Network Attached \nStorage) is that a SAN runs at a higher speed than an NAS, while an NAS is \ngenerally easier to install and provides a file system.\nscalability:  In regard to hardware, the capability to go from small to large \namounts of processing power with the same architecture. It also applies to \nsoftware products such as databases, in which case it refers to the consis -\ntency of performance per unit of power as hardware resources increase.\nscripting language:  A computer programming language that is interpreted \nand has access to all or most operating system facilities. Common examples \ninclude Perl, Python, Ruby, and JavaScript. It is often easier to program in \na scripting language, but the resulting programs generally run more slowly \nthan those created in compiled languages such as C and C++.\nsemantics:  In computer programming, what the data means as opposed to \nthe formatting rules (syntax).\nservice:  A purposeful activity carried out for the benefit of a known target. \nServices are often made up of a group of component services, some of which \nmay also have component services. Services always transform something, \nand they complete by delivering an output.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2363, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7492ca2b-1c0f-4973-82e2-29417b34adad": {"__data__": {"id_": "7492ca2b-1c0f-4973-82e2-29417b34adad", "embedding": null, "metadata": {"page_label": "292", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fcd1ab92-e2e3-49bb-8a28-254534fe56a6", "node_type": "4", "metadata": {"page_label": "292", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "a0df3990dcd9c8f796c8e1d6fffe777dd08645decda28a39991b310b4b105781", "class_name": "RelatedNodeInfo"}}, "text": "292 Big Data For Dummies \nservice catalog:  A directory of IT services provided across the enterprise, \nincluding information such as service description, access rights, and  \nownership.\nservice desk:  A single point of contact for IT users and customers to report \nany issues they may have with the IT service (or, in some cases, with IT\u2019s \ncustomer service).\nservice management:  Monitoring and optimizing a service to ensure that it \nmeets the critical outcomes that the customer values and the stakeholders \nwant to provide.\nsilo: In IT, an application with a single narrow focus, such as human \nresources management or inventory control, with no intention or preparation \nfor use by others.\nSLA (service-level agreement):  A document that captures the understanding \nbetween a service user and a service provider regarding quality and timeliness.\nSOA (service-oriented architecture):  An approach to building applications that \nimplements business processes or services by using a set of loosely coupled \nblack-box components orchestrated to deliver a well-defined level of service.\nSOAP (Simple Object Access Protocol):  A protocol specification for exchang -\ning data. Along with REST, it is used for storing and retrieving data in the \nAmazon storage cloud. See also REST.\nSoftware as a Service (SaaS):  The delivery of computer applications over the \nInternet.\nspatial database:  A database that is optimized for data related to where an \nobject is in a given space.\nSQL (structured query language):  The most popular computer language for \naccessing and manipulating databases.\nSSL (Secure Sockets Layer):  A popular method for making secure connections \nover the Internet, first introduced by Netscape.\nstandards:  A core set of common, repeatable best practices and protocols \nthat have been agreed on by a business or industry group. Typically, vendors, \nindustry user groups, and end users collaborate to develop standards based \non the broad expertise of a large number of stakeholders. Organizations can \nleverage these standards as a common foundation and innovate on top of \nthem.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2117, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7d355e09-25dc-4c82-bf55-cd8e9dfffe43": {"__data__": {"id_": "7d355e09-25dc-4c82-bf55-cd8e9dfffe43", "embedding": null, "metadata": {"page_label": "293", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "25c9159a-3fe2-4aa8-aeb3-554d22bd9ba8", "node_type": "4", "metadata": {"page_label": "293", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "76d1347c27b59dcde718b01251e914ed304a913a5ed05b6dd820eda089adf002", "class_name": "RelatedNodeInfo"}}, "text": "293  Glossary\nstreaming data:  An analytic computing platform that is focused on speed. Data \nis continuously analyzed and transformed in memory before it is stored on a \ndisk. This platform allows the analyzing of large volumes of data in real time.\nstructured data:  Data that has a defined length and format. Examples of \nstructured data include numbers, dates, and groups of words and numbers \ncalled strings (for example, a customer\u2019s name, address, and so on).\nT\ntext analytics:  The process of analyzing unstructured text, extracting rel -\nevant information, and transforming it into structured information that can \nbe leveraged in various ways.\nthroughput:  The rate at which transactions are completed in a system.\nTLS (Transport Layer Security):  A newer name for SSL. See also SSL.\nTQM (Total Quality Management):  A popular quality-improvement program.\ntransaction:  A computer action that represents a business event, such as \ndebiting an account. When a transaction starts, it must either complete or \nnot happen at all.\nU\nunstructured data: Data that does not follow a specified data format. \nUnstructured data can be text, video, images, and so on. Also see  structured \ndata.\nutility computing:  A metered service that acts like a public service based on \npayment for the use of a measured amount of a component or asset.\nV\nvirtualization:  Virtual memory is the use of a disk to store active areas of \nmemory to make the available memory appear larger. In a virtual environment, \none computer runs software that allows it to emulate another machine. This \nkind of emulation is commonly known as virtualization. See also emulation.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1668, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "03c9eca8-4203-4a0a-b33a-8d12121551c2": {"__data__": {"id_": "03c9eca8-4203-4a0a-b33a-8d12121551c2", "embedding": null, "metadata": {"page_label": "294", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "40f2cb35-ac18-4c1e-85a5-67fb9c1707be", "node_type": "4", "metadata": {"page_label": "294", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f7c4d5025d956fe5cdfda68bf6a56d5af274017fb77821a8387bfb4e9e6e09e6", "class_name": "RelatedNodeInfo"}}, "text": "294 Big Data For Dummies \nW\nweb service:  A software component created with an interface consisting of \na WSDL definition, an XML schema definition, and a WS-Policy definition. \nCollectively, components could be called a service contract \u2014 or, alterna -\ntively, an API. See also API, WSDL (Web Standard Definition Language), WS \n(Web Standard), and XML (eXtended Markup Language).\nworkflow:  This is a sequence of task-oriented steps needed to carry out a \nbusiness process. See also process.\nWS (Web Standard): Policy framework that provides a way of expressing the \ncapabilities, requirements, and characteristics of software components in a \nWeb Services system.\nWSDL (Web Service Definition Language): An XML (eXtended Markup \nLanguage) format for describing web services.\nX\nXML (eXtensible Markup Language):  A way of presenting data as plain-text \nfiles that has become the lingua franca of SOA. In XML, as in HTML, data is \ndelimited in tags that are enclosed in angle brackets ( < and >), although the \ntags in XML can have many more meanings. See also SOA.\nXML Schema: A language for defining and describing the structure of XML \ndocuments.\nXSD (XML Schema Definition):  The description of what can be in an XML \ndocument.\nXSLT (eXtensible Stylesheet Language Transformation):  A computer language, \nbased on XML, that specifies how to change one XML document into another. \nSee also XML.\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1416, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "dbc64b9a-378f-424b-8ac2-c2fbb208aaa8": {"__data__": {"id_": "dbc64b9a-378f-424b-8ac2-c2fbb208aaa8", "embedding": null, "metadata": {"page_label": "295", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e36dffc6-f15f-4a3a-b31b-77e7ed36bbab", "node_type": "4", "metadata": {"page_label": "295", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "b9f6fafda06901c5c99b136dc2bc5ef008dd90d03690e70a63397fe8665d4d8b", "class_name": "RelatedNodeInfo"}}, "text": "Index\u2022 A \u2022\nabstraction\ndefined, 279\nand virtualization, 69\naccess control, defined, 279\nACID\nacronym, 279\natomicity, 55\nconsistency, 55\ndurability, 55\nisolation, 55\nadvanced analytics, 143\u2013144, 279\ndata-mining algorithms, 144\npredictive modeling, 144\nstatistical algorithms, 144\ntext analytics, 144\nAIIM (Association for Information and \nImage Management), 31\nAmazon EC2 cloud provider\nDynamoDB, 79\nHPC (High Performance Computing), 79\nMapReduce, 79\nRedShift, 79\nS3 (Simple Storage Service), 79\nAmazon website, 273\nanalysis, doing, 239\nanalysis and extraction\nconcepts, 159\u2013160\nevents, 159\nextracted information, 159\u2013160\nfacts, 159\nkeywords, 159\nNLP (Natural Language Processing), \n157\u2013159\nrelationships, 159\nsentiments, 160\ntaxonomies, 160\nterms, 159\nanalysis approaches\ncustom applications, 170\u2013172\nGoogle Prediction API, 172interactive, 172\nR environment, 171\u2013172\nsemi-custom applications, 173\u2013174\nanalysis characteristics\naction-oriented, 169\ndata driven, 169\ndecision-oriented, 169\nIaaS (Infrastructure as a Service), 170\niterative, 169\u2013170\nprogrammatic, 169\nuse of attributes, 169\nanalysis framework\nbatch processing, 175\nintegration with cloud deployments, 175\nleveraging existing algorithms, 175\nleveraging existing data, 175\nOpen Chorus, 176\u2013177\novercoming low latency, 175\nproviding cheap storage, 175\nsupport for data types, 174\nsupporting NoSQL, 175\nanalytics\nadvanced, 142\u2013144\nand advanced analytics, 58\nadvanced analytics, 279\nbasic, 142\u2013143\nbig data, 22\u201323\ndata warehouses, 22\ndetermining next best action, 257\u2013260\nkeeping in perspective, 241\u2013242\nmonetized, 142, 146\nneed for, 256\noperationalized, 142, 146, 289\npredictive, 289\npreventing fraud with, 260\u2013261\nreporting, 23\nreporting and dashboards, 58\nsocial media, 162\ntext, 155\u2013157, 256\u2013257\ntypes, 142\nvirtualization, 58\nvisualization, 23\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1824, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "0f49bcc0-5096-48b7-b8bc-36c425a36c0f": {"__data__": {"id_": "0f49bcc0-5096-48b7-b8bc-36c425a36c0f", "embedding": null, "metadata": {"page_label": "296", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2dda66d2-84c4-4abb-80dd-da765fabbc0b", "node_type": "4", "metadata": {"page_label": "296", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "a9ede18296795b96cabb9f68abf69524839fe3383a690871fc505dd9d99a190d", "class_name": "RelatedNodeInfo"}}, "text": "296 Big Data For Dummies \nanalytics implementation\nbusiness value to, 257\ncredit card company, 260\nglobal bank, 259\u2013260\ninsurance company, 259\nanalytics solutions\nIBM, 151\nOracle, 151\nPentaho, 151\nSAS, 151\nTableau, 151\nApache Hadoop software framework\ndefined, 22, 285, 111\u2013112\ndesign of, 112\nMapReduce engine, 112\nwebsite, 112\nYARN (Yet Another Resource Negotiator), \n122\u2013123\nApache S4, 197\u2013198\nApache Software Foundation, 273\nAPIs (application programming interfaces), \n53\u201354, 279\napplication life cycle, defined, 279\napplications\nbig data, 78\ncustom, 171\u2013172\ncustomization, 59\nflexibility, 173\nGeoTools, 173\nhorizontal, 59\nJUNG (Java Universal Network Graph), 173\nlog data, 59\nquality, 173\nsemi-custom, 171\u2013172\nspeed to deployment, 173\nstability, 173\nTA-Lib (Technical Analysis library), 173\nvertical, 59\nvirtualization, 65\u201366\narchitectural foundation\nfeeds, 18\ninterfaces, 18\nNoSQL (not only SQL), 19\u201320\noperational data sources, 19\u201320\nperformance, 20\u201322\nredundant physical infrastructure, 19\nsecurity infrastructure, 19architecture, defined, 279\narchiving, defined, 279\nasset management, defined, 279\nAttensity text analytics, 164\naudit, defined, 280\naudit trail, defined, 280\nauditing big data process, 230\u2013231\nauthentication, defined, 280\nAWS (Amazon Web Services), 185\n\u2022 B \u2022\nbackup utility, defined, 280\nbandwidth, defined, 280\nbasic analytics\nanomaly identification, 143\nmonitoring capabilities, 143\nslicing and dicing, 143\nbatch process, defined, 280\nbest practices\ndata governance strategy, 268\ndata integration, 191\u2013192\ndata stewardship, 268\u2013269\ndefined, 280\ndiscovering data, 266\u2013267\nidentifying missing data, 267\nleveraging patterns, 269\nplanning for security, 268\nsecurity, 233\nstudying, 269\ntechnology options, 267\ntesting assumptions, 269\nunderstanding goals, 265\nfor workflows, 206\u2013207\nbig data, 177\u2013178. See also  structured data\nacting on plan, 240\nadjusting impact, 241\napplications, 23\narchitectural foundation, 17\u201320\nas business planning tool, 238\ncharacteristics, 50\nchecking results of analysis, 239\u2013240\ndefined, 10, 280\ndoing analysis, 239\neconomics, 211\u2013217\nenabling experimentation, 241\nestablishing foundation for, 242\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2166, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "e679a1f8-c227-4bc8-bd9b-577c73a948e9": {"__data__": {"id_": "e679a1f8-c227-4bc8-bd9b-577c73a948e9", "embedding": null, "metadata": {"page_label": "297", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8fe758ca-5151-4dae-ba83-48e26e451a3e", "node_type": "4", "metadata": {"page_label": "297", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "6abb6ae6fa6e7e2fc163d1f04f6b2a0155e1f864089e36109efacae401d41b0b", "class_name": "RelatedNodeInfo"}}, "text": "297297  Index\nfunctional requirements, 16\u201317\ngovernance, 148\nimportance, 10\nlooking for patterns in, 183\nmanagement cycle, 17\nmanaging, 14\u201315\nmonitoring in real time, 240\nparadox, 177\u2013178\nplanning with, 238\u2013239\nversus small data, 177\u2013178\nsources of, 25\nstarting strategy, 242\u2013243\ntechnologies, 15\nvariety, 16\nvelocity, 16\nvolume, 16\nbig data analysis and extraction\nconcepts, 159\u2013160\nevents, 159\nextracted information, 159\u2013160\nfacts, 159\nkeywords, 159\nNLP (Natural Language Processing), \n157\u2013159\nrelationships, 159\nsentiments, 160\ntaxonomies, 160\nterms, 159\nbig data analysis approaches\ncustom applications, 170\u2013172\nGoogle Prediction API, 172\ninteractive, 172\nR environment, 171\u2013172\nsemi-custom applications, 173\u2013174\nbig data analysis characteristics\naction-oriented, 169\ndata driven, 169\ndecision-oriented, 169\nIaaS (Infrastructure as a Service), 170\niterative, 169\u2013170\nprogrammatic, 169\nuse of attributes, 169\nbig data analysis framework\nbatch processing, 175\nintegration with cloud deployments, 175\nleveraging existing algorithms, 175\nleveraging existing data, 175Open Chorus, 176\u2013177\novercoming low latency, 175\nproviding cheap storage, 175\nsupport for data types, 174\nsupporting NoSQL, 175\nbig data analytics\nadvanced, 142\u2013144\nand advanced analytics, 58\nadvanced analytics, 279\nbasic, 142\u2013143\nbig data, 22\u201323\ndata warehouses, 22\ndetermining next best action, 257\u2013260\nkeeping in perspective, 241\u2013242\nmonetized, 142, 146\nneed for, 256\noperationalized, 142, 146, 289\npredictive, 289\npreventing fraud with, 260\u2013261\nreporting, 23\nreporting and dashboards, 58\nsocial media, 162\ntext, 155\u2013157, 256\u2013257\ntypes, 142\nvirtualization, 58\nvisualization, 23\nbig data analytics implementation\nbusiness value to, 257\ncredit card company, 260\nglobal bank, 259\u2013260\ninsurance company, 259\nbig data analytics solutions\nIBM, 151\nOracle, 151\nPentaho, 151\nSAS, 151\nTableau, 151\nbig data applications, 78\nbig data architecture\nfeeds, 18\ninterfaces, 18\nNoSQL (not only SQL), 19\u201320\noperational data sources, 19\u201320\nperformance, 20\u201322\nredundant physical infrastructure, 19\nsecurity infrastructure, 19\nBig Data Conference, 274\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2120, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d2892b44-adb7-4445-b24b-023ae40964e8": {"__data__": {"id_": "d2892b44-adb7-4445-b24b-023ae40964e8", "embedding": null, "metadata": {"page_label": "298", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ac497d20-bfee-4308-ae18-c4fddeb64a62", "node_type": "4", "metadata": {"page_label": "298", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "2d665fdab352564c7f6522d7df9c00db4216312c81c6ba619c1d8e1c9584a4e4", "class_name": "RelatedNodeInfo"}}, "text": "298 Big Data For Dummies \nbig data economics\nbusiness process modifications, 215\ndata sources, 212\u2013214\ndata types, 212\u2013214\nfiguring, 211\u2013212\nfinding talent, 216\nfrequency of data usage, 214\ngetting started, 214\nmanaging steady state, 214\nownership of data, 214\nROI (return on investment), 216\u2013217\nbig data process, auditing, 230\u2013231\nbig data quality\ndata profiling tools, 190\u2013191\nprioritizing, 189\u2013191\ntwo-phase approach, 189\u2013191\nBig Data Retail Forum, 274\nbig data stack\nanalytical data warehouses, 56\u201357\ncoordination services, 56\ndiagram, 49\ndistributed file system, 56\nETL (extract, transform, load), 56\nLayer 0, 49\u201352\nLayer 1, 52\nLayer 2, 54\u201356\nLayer 3, 56\nLayer 4, 56\u201357\noperational databases, 54\u201356\norganizing data services and tools, 56\noverview, 48\nredundant physical infrastructure, 49\u201352\nsecurity infrastructure, 52\nserialization services, 56\nworkflow services, 56\nbig data tech stack, 18\nBig Table storage system, 22\nbig-data integration\nbusiness objective, 186\ndata definitions, 187\ndata quality, 186\u2013187\ndata services, 187\nELT (extract, load, transform), defined, 187\nETL (extract, transform, and load), 187\nMDM (Master Data Management), 187\nstreamlining, 187Bigtable, defined, 280\nbinding, defined, 280\nbiometrics, defined, 281\nblack box, defined, 281\nBLOBs (binary large objects), 13\nBPaaS (Business Process as a Service), 281\nBPEL (Business Process Execution \nLanguage), 281\nBPM (business process management), 281\nbroker, defined, 281\nbus, defined, 281\nbusiness intelligence products\nanalytical algorithms, 148\ndata, 147\ninfrastructure support, 148\u2013149\nmodifying, 147\u2013149\nNASA, 150\nNokia, 150\nbusiness processes\ndefined, 281\nmodeling, 281\nmodifying, 215\ntransforming, 244\nbusiness rules, defined, 281\nbusiness service, defined, 281\nbusiness units, involving in strategy, 275\n\u2022 C \u2022\ncache, defined, 281\ncenter of excellence, defined, 282\nCEP (Complex Event Processing),  \n194, 282\nimpact on business, 200\nversus streams, 199\nusing, 198\u2013199\nchange management, defined, 282\nClarabridge text analytics, 165\nclick-stream data, 27\ncloud\nprivate, 290\npublic, 290\ncloud computing\nbenefits, 72\ndefined, 71, 282\nleveraging, 72\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2150, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f703d695-03ea-4e5c-8de3-f92fc3ddae8f": {"__data__": {"id_": "f703d695-03ea-4e5c-8de3-f92fc3ddae8f", "embedding": null, "metadata": {"page_label": "299", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ae173f9b-290a-4fcc-ba3e-8749c78c1873", "node_type": "4", "metadata": {"page_label": "299", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "ceee316dbe4da1be5ec17c697a0965ebece260ad9afda1f165a1194e5ba253e0", "class_name": "RelatedNodeInfo"}}, "text": "299299  Index\ncloud delivery models\nDaaS (Data as a Service), 75\nIaaS (Infrastructure as a Service), 74, 77\nPaaS (Platform as a Service), 75, 77\nSaaS (Software as a Service), 75, 77\u201378\ncloud imperative\nelasticity, 76\nfault tolerance, 76\nPAYG (Pay as You Go), 76\nresource pooling, 76\nscalability, 76\nself-service, 76\nup-front costs, 76\ncloud providers\nAmazon EC2, 78\u201379\nGoogle services, 79\u201380\nMicrosoft Azure, 80\nOpenStack, 80\u201381\nCloud Security Alliance, 272\ncloud services\ncautions, 81\ncompliance, 81\ncosts, 81\ndata access, 81\ndata integrity, 81\ndata transport, 81\nlocation of data, 81\nperformance, 81\nCloudera website, 273\nclouds\nhybrid, 74, 77\nprivate versus public, 72\u201374, 77\nCMDB (configuration management \ndatabase), 282\nCMSs (content management systems), 31\nCOBIT (Control Objectives for Information \nand Related Technology), 282\nCodd, Edgar, 28\ncolumnar databases, 282\ndescribed, 94\nHBase, 94\u201395, 123\u2013124\ncomponent, defined, 282\nconferences\nBig Data Conference, 274\nBig Data Retail Forum, 274\nHadoop World, 274O\u2019Reilly Strata and StrataRx, 274\nStructureData, 274\nTDWI (The Data Warehousing  \nInstitute), 274\nconfiguration\ndefined, 282\nmanagement, 282\nconnector factory, implementing, 54\nconnectors, explained, 34\ncontainer, defined, 282\ncontent management, 13\u201314, 282\u2013283\nContinuity AppFabric\ncapabilities, 175\u2013176\nwebsites, 175\nCouchDB database\ncompaction, 94\ndescribed, 93\u201394\ndistributed services, 94\nimplementations, 94\nreplication, 94\nview model, 94\ncredit card company analytics, 260\nCRM (customer relationship  \nmanagement), 283\nCRUD (create, retrieve, update,  \ndelete), 86\ncustomer experience, improving with  \ntext analytics, 256\u2013257\ncustomer experience, optimizing,  \n161\u2013162\n\u2022 D \u2022\nDaaS (Data as a Service), 75\nDARPA, 38\u201339\ndata\ndiscovering, 266\u2013267\ndistributing, 277\nintegrating, 277\nin motion, 15\nat rest, 15, 283\nand storage virtualization, 67\nstructured versus unstructured, 157\nunstructured, 154\u2013155, 293\ndata cleansing, defined, 283\ndata conferences, 273\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1996, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6909d4ff-1ff7-42b4-ac80-1d198bcb6ef2": {"__data__": {"id_": "6909d4ff-1ff7-42b4-ac80-1d198bcb6ef2", "embedding": null, "metadata": {"page_label": "300", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2e307f49-24ee-4ed4-b584-e62e3511c3bb", "node_type": "4", "metadata": {"page_label": "300", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "6ca8efb5cc3b2458ec28a04e2aae32244c87cf6916e3bd34c8ee5eda2c6bd699", "class_name": "RelatedNodeInfo"}}, "text": "300 Big Data For Dummies \ndata federation, defined, 283\ndata governance\nbest practices, 233\ndefined, 285\nimportance of, 228\nkey stakeholders, 231\nunvetted employees, 230\nvisibility of data, 229\ndata in motion\ndata collection, 246\ndefined, 283\nmedical devices, 246\nmessages, 246\npoint-of-sale data, 246\nsensors, 246\nstreaming data, 247\ntelecommunications, 246\ndata integration, best practices,  \n191\u2013192\ndata management\ncontent management, 13\u201314\ndata structures, 11\u201312\nwaves, 11\u201315\nweb management, 13\u201314\ndata marts, 13, 22, 283\ndata mining\nalgorithms, 145\nclassification trees, 145\nclustering techniques, 145\ndefined, 283\nexplained, 145\u2013146\nK-nearest neighbors, 145\nlogistic regression, 145\nneural networks, 145\ndata performance, managing, 278\ndata profiling, defined, 283\ndata protection options\nanonymization, 228\ncloud database controls, 228\nencryption, 227\ntokenization, 228\ndata quality, defined, 283\ndata resources\nApache Software Foundation, 273\nCloud Security Alliance, 272\nHurwitz & Associates, 271\nNIST (National Institute of Standards and \nTechnology), 272OASIS, 273\nODaF (Open Data Foundation), 272\nstandards organizations, 271\ndata sources\nintegrating big data with, 262\nvariety of data, 10\nvelocity of data, 10\nvolumes of data, 10\ndata stewardship, planning for, 232,  \n268\u2013269\ndata stores. See operational databases\ndata streaming\nApache S4, 197\u2013198\nand CEP (Complex Event Processing), \n194, 199\nin energy industry, 252\u2013253\nwith environmental impact, 247\u2013249\nexample, 196\nexplained, 194, 293\nhealthcare industry, 251\nhistorical data sources, 253\nIBM InfoSphere Streams, 197\nimpact on business, 200\nmedical diagnostic group example, 196\nmetadata, 196\u2013197\noil exploration example, 196\npower plant example, 196\nprinciples, 195\npublic policy impact, 249\u2013250\nreal-time data sources, 253\nscientific research, 248\nsensors, 248\u2013249\ntelecommunications example, 196\nTwitter\u2019s Storm, 197\nuse by research institution, 253\nuse by wind farm, 253\nusefulness, 195\nusing, 194\u2013198\nvalue of, 247\ndata transformation, defined, 283\ndata types\ncharacteristics, 33\u201334\nconnectors, 34\nintegrating, 34\u201335\nmetadata, 35\ndata validity, 207\u2013208\ndata volatility, 208\u2013209\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2172, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8b793e6b-dedd-4d34-b2cc-ca0a449521bd": {"__data__": {"id_": "8b793e6b-dedd-4d34-b2cc-ca0a449521bd", "embedding": null, "metadata": {"page_label": "301", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3eb42a44-844a-4365-a6f0-390710a67927", "node_type": "4", "metadata": {"page_label": "301", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "08185f3019b423111bb39927acb5d3df54e9c70833ef187db076444ebc744c03", "class_name": "RelatedNodeInfo"}}, "text": "301301  Index\ndata warehouses, 12\u201313, 22\nappliance model, 136\nbig data analysis, 133\u2013135\nversus big data structures, 130\u2013131\nchanging role of, 135\u2013136\ncloud model, 137\ndata flows, 131, 133\ndefined, 283\ndeployment models, 136\u2013137\nextraction, 134\u2013135\nfuture of, 137\nhybrid process case study, 131\u2013132\nintegrating big data with, 129\u2013130\nintegration lynchpin, 134\nloading, 134\u2013135\nmanagement methods, 135\u2013136\noptimizing, 130\norigins, 129\ntransformation, 134\u2013135\ndata workflows\nbest practice, 206\u2013207\nexplained, 205\u2013206, 294\ntechnology impact of, 215\nworkload, 206\u2013207\ndatabase languages, 55\ndatabases. See also nonrelational \ndatabases; RDBMSs (relational \ndatabase management systems)\ncolumnar, 94\u201395, 282\ndefined, 284\ndocument, 91\u201394\ngraph, 95\u201397\nin-memory, 286\nKVP (key-value pair), 89\u201391\nspatial, 97\u201399, 292\ndata-source integration\nAWS (Amazon Web Services), 185\ncodifying stage, 184\nexploratory stage, 182\u2013183\nFlumeNG, 183\nidentifying data, 181\u2013182\nand incoporation, 184\u2013186\nlooking for patterns, 183\nDBMS (database management  \nsystem), 284\ndelivery models, evaluating, 276\ndiagnosing diseases, 203\u2013205\ndirectory, defined, 284\ndiseases, diagnosing, 203\u2013205distributed computing\nchanging economics, 40\u201341\nconsistent model, 39\nDARPA, 38\u201339\ndefined, 284\ndemand and solutions, 41\nevolution of, 42\nexplained, 37\nlatency, 41\nnecessity of, 40\nnodes, 42\nprotocols, 38\nRPCs (remote procedures calls), 39\ndistributed resources, using, 62\ndocument databases\nCouchDB, 93\u201394\ndescribed, 91\u201392\nJSON (JavaScript Object Notation), 92\nMongoDB, 92\u201393\ndo\u2019s and don\u2019ts\nconsistency of metadata, 276\ndata sources and strategy, 276\ndistributing data, 277\nevaluating delivery models, 276\nintegrating data, 277\ninvolving business units, 275\npacing growth, 277\nperformance of data, 278\nsecure data management, 278\nvarying approaches, 277\n\u2022 E \u2022\nearly binding, defined, 284\nEC2 cloud provider\nDynamoDB, 79\nHPC (High Performance Computing), 79\nMapReduce, 79\nRedShift, 79\nS3 (Simple Storage Service), 79\neconomics of big data\nbusiness process modifications, 215\ndata sources, 212\u2013214\ndata types, 212\u2013214\nfiguring, 211\u2013212\nfinding talent, 216\nfrequency of data usage, 214\ngetting started, 214\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2181, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "14baa58b-e434-48b5-8762-59b44635a00e": {"__data__": {"id_": "14baa58b-e434-48b5-8762-59b44635a00e", "embedding": null, "metadata": {"page_label": "302", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c712b2ec-cd93-408a-99f0-05b7a376fc5e", "node_type": "4", "metadata": {"page_label": "302", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f815f05d6f14ff796542562ab46c0fbc15dca29437cc80ec6edebf294b60caa2", "class_name": "RelatedNodeInfo"}}, "text": "302 Big Data For Dummies \neconomics of big data  (continued)\nmanaging steady state, 214\nownership of data, 214\nROI (return on investment), 216\u2013217\nEDM (enterprise data management)\narchitecture, 217\ndefining, 217\u2013218\ngovernance, 217\nmetadata, 217\nownerships, 217\npillars of, 217\nquality, 217\nsecurity, 217\ntenets, 218\nelasticity, defined, 284\nELT (extract, load, transform)\ndefined, 187, 189, 284\nusing Hadoop as, 191\nemulation, defined, 284\nencapsulation, 63\nencryption, weakness with, 227\nenergy industry, streaming data in, 252\u2013253\nER (Entity-Relationship) model, 12, 284\nERP (enterprise resource planning), 284\nESB (Enterprise Service Bus), 284\nETL (extract, transform, and load), 187, 284\nin batch processing, 188\ndata transformation, 188\u2013189\ninfrastructure for integration, 188\nextraction and analysis\nconcepts, 159\u2013160\nevents, 159\nextracted information, 159\u2013160\nfacts, 159\nkeywords, 159\nNLP (Natural Language Processing), \n157\u2013159\nrelationships, 159\nsentiments, 160\ntaxonomies, 160\nterms, 159\n\u2022 F \u2022\nfault tolerance, defined, 285\nfederation, defined, 285\nfeeds and interfaces, 53\u201354financial data, 27\nflat files, 28\nFlumeNG, using for big data  \nintegration, 183\nframework, defined, 285\nfraud, preventing with analytics,  \n260\u2013261\nfunctional programming\nexplained, 102\noperators in, 103\n\u2022 G \u2022\ngaming-related data, 27\nGeoTools, 173\nglobal bank analytics, 259\u2013260\ngoals, understanding, 265\nGoogle big data services\nBig Query, 80\nCompute Engine, 79\nPrediction API, 80\nGoogle Prediction API, 172\nGoogle website, 273\ngovernance\nbest practices, 233\ndefined, 285\nimportance of, 228\nkey stakeholders, 231\nunvetted employees, 230\nvisibility of data, 229\ngovernance policies, setting, 232\ngovernance strategy, planning, 268\ngranularity, defined, 285\ngraph databases\ndescribed, 95\u201396\nNeo4J, 96\u201397\ngrid computing, defined, 285\n\u2022 H \u2022\nHadoop ecosystem\nbig data foundation, 121\u2013122\nPig execution environment,  \n125\u2013126\nPig Latin language, 125\u2013126\nSqoop, 126\u2013127\nZookeeper, 127\u2013128\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1989, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "673ccc6e-c80f-4c76-a592-9988bb795da2": {"__data__": {"id_": "673ccc6e-c80f-4c76-a592-9988bb795da2", "embedding": null, "metadata": {"page_label": "303", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f29418e6-40d6-4cac-a141-21441c3975ae", "node_type": "4", "metadata": {"page_label": "303", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "a33a3c244bdbbbce8d489a148b70f23e953145a25092f03627c998a667847a27", "class_name": "RelatedNodeInfo"}}, "text": "303303  Index\nHadoop MapReduce\ncapabilities, 116\u2013117\ndata movement, 117\nmapping data, 118\npreparing data, 117\u2013118\nreduce and combine, 118\u2013119\nworkflow, 117\nHadoop software framework\ndefined, 22, 111\u2013112, 285\ndesign of, 112\nexplained, 111\u2013112\nMapReduce engine, 112\nwebsite, 112\nYARN (Yet Another Resource Negotiator), \n122\u2013123\nHadoop World conference, 274\nhardware partitioning, defined, 286\nHBase columnar database, 94\u201395\nclient API, 95\nconsistency, 95\nhigh availability, 95\nsharding, 95\nstoring big data with, 123\u2013124\nsupport for IT operations, 95\nHDFS (Hadoop Distributed File System)\nblocks, 113, 116\nchecksum validators, 114\ncluster, 113\ndata integrity, 114\ndata nodes, 114\u2013115\ndata pipelines, 116\ndefined, 286\nexplained, 112\nmetadata, 115\nNameNodes, 113\u2013114\nnamespace, 113\nhealthcare industry\ncapturing data stream, 251\nstreaming data in, 251\nhealthcare scenario, 202\u2013205\nHIPAA (Health Insurance Accountability \nand Portability Act), 226\nHive\nbuckets, 124\nmetadata, 125\nmining big data with, 124\u2013125\npartitions, 124\ntables, 124Hurwitz & Associates, 271\nhybrid cloud, defined, 286\nhypervisors\ndefined, 286\ndesign of, 68\nfabric, 68\nmanaging virtualization with, 68\ntypes of, 68\nusing with virtual machine, 64\n\u2022 I \u2022\nIaaS (Infrastructure as a Service),  \n74, 77, 286\nIBM \nanalytics solutions, 151\nInfoSphere Streams, 197\nwebsite, 273\nIBM Watson\nevidence-based learning, 163\nhypotheses, 163\u2013164\nNPL (Natural Language  \nProcessing), 163\nidentity management, defined, 286\nimplementation road map\nbeing holistic, 223\nbudgets, 219\u2013220\nbusiness urgency, 218\u2013219\nestablishing, 266\nexperimenting, 223\ngetting help, 222\ngetting training, 222\nmajor phases, 221\u2013222\nmilestones, 221\u2013223\nprojecting capacity, 219\nrisk, 220\nsetting expectations, 223\nskill sets, 219\u2013220\nsoftware development, 219\nstarting, 220\u2013223\ninformation integration, defined, 286\ninfrastructure\ndefined, 286\nservices, 286\nin-memory database, defined, 286\ninput data, 27\ninsurance company analytics, 259\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1980, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6a85ee32-279f-465f-a617-0f52da449dd1": {"__data__": {"id_": "6a85ee32-279f-465f-a617-0f52da449dd1", "embedding": null, "metadata": {"page_label": "304", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "38a78143-8d67-4ff3-b561-049e0eb4a416", "node_type": "4", "metadata": {"page_label": "304", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "607d9951feb31433441742f1a6b44466dd134e94b26c7606ffe474529c04ca61", "class_name": "RelatedNodeInfo"}}, "text": "304 Big Data For Dummies \nintegrating big data\nbusiness objective, 186\ndata definitions, 187\ndata quality, 186\u2013187\ndata services, 187\nELT (extract, load, transform),  \ndefined, 187\nETL (extract, transform, and load), 187\nMDM (Master Data Management), 187\nstreamlining, 187\ninterfaces and feeds, 53\u201354\nInternet connectivity model, 38\nInternet sites\nAIIM (Association for Information and \nImage Management), 31\nApache Software Foundation, 273\nAttensity, 164\nClarabridge text analytics, 165\nCloud Security Alliance, 272\nContinuity AppFabric, 175\nCouchDB database, 93\u201394\nHadoop software framework, 112\nHBase columnar database, 94\u201395\nHurwitz & Associates, 271\nIBM, 151\nIBM Content Analytics, 165\nMongoDB database, 92\u201393\nNeo4J graph database, 96\nNIST (National Institute of Standards and \nTechnology), 272\nOASIS, 273\nODaF (Open Data Foundation), 272\nOGC (Open Geospatial Consortium), 97\nonline collaborative, 273\nOpenChorus, 176\u2013177\nOpenGeo Suite, 98\nOpenStack cloud provider, 80\nOpenText text analytics, 165\u2013166\nOracle, 151\nO\u2019Reilly Strata and StrataRx  \nconference, 274\nPentaho, 151\nPostgreSQL, 29, 87\u201388\nRefractions Research, 98\nRevolution Analytics, 171\nRiak key-value database, 90\u201391\nSAS, 151\nSAS analytics solutions, 166\nTableau, 151interoperability, defined, 287\nISO (International Organization for \nStandardization), 287\nisolation, 63\nITIL (Information Technology \nInfrastructure Library), 287\n\u2022 J \u2022\nJSON (JavaScript Object Notation), 92\nJUNG (Java Universal Network Graph), 173\n\u2022 K \u2022\nKVP (key-value pair) databases\nRiak, 90\u201391\nsamples, 90\n\u2022 L \u2022\nLAMP (Linux, Apache, MySQL, PHP, Per, \nPython), 287\nlate binding, defined, 287\nlatency\ndefined, 287\nproblem with, 40\u201341\nlegacy application, defined, 287\nLinux\nexplained, 287\nweb hosting, 287\nlog data applications, 59\nloose coupling, defined, 287\n\u2022 M \u2022\nmanaging data\ncontent management, 13\u201314\ndata structures, 11\u201312\nwaves, 11\u201315\nweb management, 13\u201314\nMapReduce, 21\u201322, 79\nalgorithms, 105\nbehaviors, 107\ncode/data colocation, 107\ndata flow, 106\ndefined, 288\ndesign, 43\nexecution framework, 107\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2058, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "b5a2359b-376f-44af-93b8-a77535c6603e": {"__data__": {"id_": "b5a2359b-376f-44af-93b8-a77535c6603e", "embedding": null, "metadata": {"page_label": "305", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "13c6eb33-ce96-4569-9d97-621157f085e2", "node_type": "4", "metadata": {"page_label": "305", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "e276236333b36bf14d1c49037b02f3f5b1becafbfaf93a9a492e3c1788c0bf2c", "class_name": "RelatedNodeInfo"}}, "text": "305305  Index\nfault/error handling, 107\nimplementations, 43\nmap and reduce functions, 105\u2013107\nmap function, 103\u2013104\norigins, 101\u2013102\nreduce function, 104\u2013105\nscheduling, 107\nsynchronization, 107\nand virtualization, 70\nMapReduce tasks\nfile system, 108\u2013109\nhardware topology, 108\nnetwork topology, 108\nsynchronization, 108\nmarkup language, defined, 288\nmashup, defined, 288\nMDM (Master Data Management), 187\nmemory virtualization, 66\nmetadata\nconsistency of, 276\nexplained, 35, 288\nrepository, 288\nMicrosoft Azure cloud provider, 80\nMicrosoft website, 273\nmiddleware, defined, 288\nmission-critical, explained, 288\nMOM (Message Oriented Middleware), 288\nmonetized analytics, 146\nMongoDB database, 92\u201393\nmultitenancy, defined, 288\nMySQL, explained, 288\n\u2022 N \u2022\nNASA, use of predictive models, 150\nNeo4J graph database, 96\u201397\nimplementations, 97\nintegration with databases, 96\nquery language, 96\nresiliency, 96\nsynchronization services, 96\nnetwork, defined, 289\nnetwork data stores, 28\nnetwork virtualization, 66\nnext best action, determining, 257\u2013260\nNIST (National Institute of Standards and \nTechnology), 272NLP (Natural Language Processing), 54\ndiscourse-level analysis, 158\nexplained, 157\nlexical analysis, 158\nmorphological analysis, 158\nsemantic analysis, 158\nsyntactic analysis, 158\nnodes in distributed computing, 42\nNokia, 150\nnonrelational databases. See also  \ndatabases\ndata and query model, 89\nEventual Consistency, 89\nfeatures, 88\u201389\ninterface diversity, 89\nNoSQL (not only SQL), 88\npersistence design, 89\nscalability, 89\nNoSQL (not only SQL), 19\u201320, 55, 88, 289\nNPL (Natural Language Processing), 163\n\u2022 O \u2022\nOASIS (Organization for the  \nAdvancement of Structured \nInformation Standards), 273\noceans, providing real-time information \nabout, 248\u2013249\nODaF (Open Data Foundation), 272\nODBMS (object database management \nsystems), 13\nOGC (Open Geospatial Consortium), 97\nonline collaborative sites, 273\nOODBMS (object-oriented database \nmanagement system), 289\nopen source, explained, 289\nOpenChorus application framework, 176\u2013177\nOpenGeo Suite website, 98\nOpenStack cloud provider, 80\u201381\nOpenText text analytics, 165\u2013166\noperational databases, 54\u201356, 85\u201386\noperationalized analytics, 146, 289\noperationalizing big data\ndiagnosing diseases, 203\u2013205\nhealthcare, 202\u2013203\nintegration, 202\u2013203\npatient diagnostic process, 203\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2344, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4c03595c-6090-4b53-9d2d-876c2552ab33": {"__data__": {"id_": "4c03595c-6090-4b53-9d2d-876c2552ab33", "embedding": null, "metadata": {"page_label": "306", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ef44e6bd-7f6d-4c9e-ae47-3f0c9b171201", "node_type": "4", "metadata": {"page_label": "306", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "31aceb5150be5909e0a960916d360bd88fabf7fdbe6e53b35e5d0ee71f1640f7", "class_name": "RelatedNodeInfo"}}, "text": "306 Big Data For Dummies \nOracle analytics solutions, 151\nOracle website, 273\nO\u2019Reilly Strata and StrataRx  \nconference, 274\norganizational structure\ngovernance policy, 232\nputting in place, 231\u2013232\nrisk management, 232\nsetting quality policies, 232\nstewardship, 232\norganizing data services and tools, 56\n\u2022 P \u2022\nP2P (peer-to-peer), explained, 289\nPaaS (Platform as a Service), 75, 77, 289\npartioning, 63\npatient diagnostic process, 203\nPentaho analytics solutions, 151\nperformance\nBig Table storage system, 21\u201322\nconsiderations, 20\u201321\ndata services, 21\ndistributed computing, 42\nexecuting algorithms, 43\nHadoop software framework, 21\u201322\nimportance of, 63\nMapReduce, 21\u201322, 43\nscalability, 43\ntools, 21\npersistence, explained, 289\npetabytes of data, analyzing, 15\nPHI (personal health information),  \nsecurity of, 226\nphysical infrastructure redundancy\navailability, 49\ncomplexity, 50\u201351\ncost, 50\nexplained, 49\nflexibility, 50\nhardware, 51\nnetworks, 51\noperations, 51\nperformance, 49\nresiliency, 50\nscalability, 50servers, 51\nSLAs (service-level agreements),  \n50\u201351\nstorage, 51\nPig execution environment\nHadoop, 125\nlocal mode, 125\nmap and reduce jobs, 125\u2013126\nPig Latin language, 125\u2013126\nPig programs\nembedded, 126\nGrunt command interpreter, 126\noperators, 126\nrunning, 126\nscript file, 126\nPII (personal identifiable  \ninformation), 226\nplanning with data, 238\u2013239\npoint-of-sale data, 27\npolyglot persistence, 99\u2013100\nPostGIS/OpenGEO Suite, 98\ndescribed, 98\nGeoExt, 98\nGeoServer, 98\nGeoWebCache, 98\nOpenLayers, 98\nPostgreSQL\nexplained, 289\nrelational database, 87\u201388\nwebsite, 29\npredictive analytics, defined, 289\nprivate cloud, defined, 290\nprocedural programming, 102\nprocess, defined, 290\nprocessor virtualization, 66\nprogramming models\nfunctional, 102\nprocedural, 102\nprograms\nbig data, 78\ncustom, 171\u2013172\ncustomization, 59\nflexibility, 173\nGeoTools, 173\nhorizontal, 59\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1893, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "016092ed-5bda-4cc8-bf73-026a09585c59": {"__data__": {"id_": "016092ed-5bda-4cc8-bf73-026a09585c59", "embedding": null, "metadata": {"page_label": "307", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d56cca34-e357-4f35-8d3e-ab65d0c56b97", "node_type": "4", "metadata": {"page_label": "307", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "f1ce519c24514a2c19efdae440f1f6f251010c19e00e3a6d6c1af258ed5e7d9a", "class_name": "RelatedNodeInfo"}}, "text": "307307  Index\nJUNG (Java Universal Network  \nGraph), 173\nlog data, 59\nquality, 173\nsemi-custom, 171\u2013172\nspeed to deployment, 173\nstability, 173\nTA-Lib (Technical Analysis library), 173\nvertical, 59\nvirtualization, 65\u201366\nprotocol, defined, 290\nprovisioning, defined, 290\npublic cloud, defined, 290\npublic policy impact, streaming data with, \n249\u2013250\n\u2022 Q \u2022\nquality policies, setting, 232\n\u2022 R \u2022\nR environment, 171\u2013172\nRDBMSs (relational database management \nsystems). See also  databases\ncolumns, 86\ndata storage, 28\ndefined, 290\ndisadvantage, 29\nevolution of, 86\nfoundation of, 86\ninvention of, 28\nPostgreSQL, 29, 87\u201388\nprimary key, 86\nquerying tables, 28\u201329\nschema, 28\nsignificance of, 12\ntable relationships, 28\ntables, 86\nusing SQL in, 55\nreal-time, explained, 290\nreal-time data, benefits of, 249\nreal-time data sources, using streaming \ndata with, 253\nreal-time event processing,  \nexplained, 290real-time requirements\nlow latency, 33\nnative format, 33\nscalability, 33\nversatility, 33\nredundancy, importance of, 19\nredundant physical infrastructure\navailability, 49\ncomplexity, 50\u201351\ncost, 50\nexplained, 49\nflexibility, 50\nhardware, 51\nnetworks, 51\noperations, 51\nperformance, 49\nresiliency, 50\nscalability, 50\nservers, 51\nSLAs (service-level agreements),  \n50\u201351\nstorage, 51\nreference architecture, layers of, 168\nRefractions Research website, 98\nregistry, explained, 290\nreporting and visualization, 23\nrepository, defined, 290\nrequirements\nnon-real-time, 32\u201333\nreal-time, 32\u201333\nresource pool, defined, 290\nresources\nApache Software Foundation, 273\nCloud Security Alliance, 272\nHurwitz & Associates, 271\nNIST (National Institute of Standards  \nand Technology), 272\nOASIS, 273\nODaF (Open Data Foundation), 272\nstandards organizations, 271\nresponse time, defined, 290\nREST (Representational State Transfer), \n53, 291\nRevolution Analytics, 171\nRFID (radio frequency identification), 291\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1907, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f236a7d1-3426-4d21-91e2-b16e129f2c9e": {"__data__": {"id_": "f236a7d1-3426-4d21-91e2-b16e129f2c9e", "embedding": null, "metadata": {"page_label": "308", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "59f285a1-aaf8-44a7-8ea1-038853d64f85", "node_type": "4", "metadata": {"page_label": "308", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "46e965c5c7f9bab2304b547a693c93796d1aa4fa8c39b2c6e3d79538e3209218", "class_name": "RelatedNodeInfo"}}, "text": "308 Big Data For Dummies \nRiak key-value database\ndescribed, 90\u201391\nimplementations, 91\nlink walking, 91\nlinks, 91\nparallel processing, 91\nsearch, 91\nsecondary indexes, 91\nrisk, assessing for business, 226\u2013227\nrisk management, preparing for, 232\nrivers, providing real-time information \nabout, 248\u2013249\nroad map\nbeing holistic, 223\nbudgets, 219\u2013220\nbusiness urgency, 218\u2013219\nestablishing, 266\nexperimenting, 223\ngetting help, 222\ngetting training, 222\nmajor phases, 221\u2013222\nmilestones, 221\u2013223\nprojecting capacity, 219\nrisk, 220\nsetting expectations, 223\nskill sets, 219\u2013220\nsoftware development, 219\nstarting, 220\u2013223\nROI (return on investment), calculating, \n216\u2013217\nRPCs (remote procedures calls), 39, 291\n\u2022 S \u2022\nSaaS (Software as a Service), 75, 77\u201378\nSAN (storage-area-network),  \nexplained, 291\nSAS analytics solutions, 151, 166\nSAS Institute website, 273\nscalability\nas cloud imperative, 76\ndefined, 291\nimportance of, 43\nsupport for, 63\nschema, defined, 28\nscientific research, streaming data in, 248scripting language, explained, 291\nsearch, comparing to text analytics, 156\u2013157\nsecurity\nassessing risk, 226\nbest practices, 233\ncloud database controls, 228\nin context, 225\u2013226\ndata anonymization, 228\nof data management, 278\ngovernance, 233\nHIPAA (Health Insurance Accountability \nand Portability Act), 226\nPHI (personal health information), 226\nPII (personal identifiable  \ninformation), 226\nplanning for, 268\ntokenization, 228\nsecurity infrastructure\napplication access, 52\ndata access, 52\ndata encryption, 52\nthreat detection, 52\nsemantics, defined, 291\nsemi-structured data, 30\nsensor data, 26\nsensors, providing real-time info with, \n248\u2013249\nserver virtualization, 64\u201365\nservice, defined, 291\nservice catalog, explained, 292\nservice desk, explained, 292\nservice management, explained, 292\nsilo, defined, 292\nsites\nAIIM (Association for Information and \nImage Management), 31\nApache Software Foundation, 273\nAttensity, 164\nClarabridge text analytics, 165\nCloud Security Alliance, 272\nContinuity AppFabric, 175\nCouchDB database, 93\u201394\nHadoop software framework, 112\nHBase columnar database, 94\u201395\nHurwitz & Associates, 271\nIBM, 151\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2159, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6dc9a03b-10b0-451e-a49f-01db9c9210d9": {"__data__": {"id_": "6dc9a03b-10b0-451e-a49f-01db9c9210d9", "embedding": null, "metadata": {"page_label": "309", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "76deadd9-4dbd-412a-93ac-76b015f72d6e", "node_type": "4", "metadata": {"page_label": "309", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "9a6f417159d10a3394718a96975c49616be59850d908c0c8277a3ecb52901a5b", "class_name": "RelatedNodeInfo"}}, "text": "309309  Index\nIBM Content Analytics, 165\nMongoDB database, 92\u201393\nNeo4J graph database, 96\nNIST (National Institute of Standards and \nTechnology), 272\nOASIS, 273\nODaF (Open Data Foundation), 272\nOGC (Open Geospatial Consortium), 97\nonline collaborative, 273\nOpenChorus, 176\u2013177\nOpenGeo Suite, 98\nOpenStack cloud provider, 80\nOpenText text analytics, 165\u2013166\nOracle, 151\nO\u2019Reilly Strata and StrataRx  \nconference, 274\nPentaho, 151\nPostgreSQL, 29, 87\u201388\nRefractions Research, 98\nRevolution Analytics, 171\nRiak key-value database, 90\u201391\nSAS, 151\nSAS analytics solutions, 166\nTableau, 151\nSLAs (service-level agreements), 50\u201351, 292\nSOA (service-oriented architecture), \nexplained, 292\nSOAP (Simple Object Access Protocol), 292\nsocial media, 162\nsoftware\nbig data, 78\ncustom, 171\u2013172\ncustomization, 59\nflexibility, 173\nGeoTools, 173\nhorizontal, 59\nJUNG (Java Universal Network  \nGraph), 173\nlog data, 59\nquality, 173\nsemi-custom, 171\u2013172\nspeed to deployment, 173\nstability, 173\nTA-Lib (Technical Analysis library), 173\nvertical, 59\nvirtualization, 65\u201366spatial databases\ndescribed, 97\u201398\nexplained, 292\nPostGIS/OpenGEO Suite, 98\nSQL (structured query language), 292\nversus NoSQL, 55\nusing in relational model, 55\nSqoop (SQL-to-Hadoop) tool\nbulk import, 127\ndata export, 127\ndata interaction, 127\ndescribed, 126\u2013127\ndirect input, 127\nSSL (Secure Sockets Layer), explained, 292\nstandards, explained, 292\nstewardship, planning for, 232, 268\u2013269\nstorage virtualization, 67\nstreaming data\nApache S4, 197\u2013198\nand CEP (Complex Event Processing), 194\nversus CEP (Complex Event  \nProcessing), 199\nin energy industry, 252\u2013253\nwith environmental impact, 247\u2013249\nexample, 196\nexplained, 194, 293\nhealthcare industry, 251\nhistorical data sources, 253\nIBM InfoSphere Streams, 197\nimpact on business, 200\nmedical diagnostic group example, 196\nmetadata, 196\u2013197\noil exploration example, 196\npower plant example, 196\nprinciples, 195\npublic policy impact, 249\u2013250\nreal-time data sources, 253\nscientific research, 248\nsensors, 248\u2013249\ntelecommunications example, 196\nTwitter\u2019s Storm, 197\nuse by research institution, 253\nuse by wind farm, 253\nusefulness, 195\nusing, 194\u2013198\nvalue of, 247\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2182, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "57747c39-9ef5-4a53-a512-5da2590fa62f": {"__data__": {"id_": "57747c39-9ef5-4a53-a512-5da2590fa62f", "embedding": null, "metadata": {"page_label": "310", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f67621a1-6402-45e7-ab47-351c66d14993", "node_type": "4", "metadata": {"page_label": "310", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "6fa8e446ec07ba4817d1a7f83a6cba33ac50bd4125b695ef629d616770817d99", "class_name": "RelatedNodeInfo"}}, "text": "310 Big Data For Dummies \nstructured data. See also  big data; \nunstructured data\ncharacteristics, 34\nclick-stream, 27\ncomputer-generated, 26\u201327\ndefined, 26\nexplained, 293\nfinancial, 27\ngaming-related, 27\nhuman-generated, 26\u201327\ninput, 27\nmachine-generated, 26\u201327\npoint-of-sale, 27\nsensor, 26\nsources of, 26\u201327\nstrings, 26\nversus unstructured data, 157, 160\u2013161\nweb log, 27\nStructureData conference, 274\n\u2022 T \u2022\nTableau analytics solutions, 151\ntables\nquerying in RDBMSs, 28\u201329\nrelationships in RDBMSs, 28\nTA-Lib (Technical Analysis library), 173\nTDWI (The Data Warehousing Institute) \nconference, 274\ntechnology options, being aware of, 267\nTeradata website, 273\ntext analytics\ncall center records, 155\ncomparing to search, 156\u2013157\nexplained, 293\nimproving customer experience, 256\u2013257\nprocess of, 155\u2013156\ntext analytics tools\nAttensity, 164\nClarabridge, 165\nIBM Content Analytics, 165\nOpenText, 165\u2013166\nSAS analytics solutions, 166\nthroughput, defined, 293\ntips\nconsistency of metadata, 276\ndata sources and strategy, 276\ndistributing data, 277evaluating delivery models, 276\nintegrating data, 277\ninvolving business units, 275\npacing growth, 277\nperformance of data, 278\nsecure data management, 278\nvarying approaches, 277\nTLS (Transport Layer Security), 293\nTQM (Total Quality Management), 293\ntransaction, defined, 293\ntransactional behavior, support for, 55\nTwitter\u2019s Storm, 197\n\u2022 U \u2022\nunstructured data, 154\u2013155. See also  \nstructured data\ncharacteristics, 34\ndefined, 29\u201330\nexplained, 293\nhuman-generated, 30\nmachine-generated, 29\u201330\nmaking structured, 156\nmobile, 30\nphotographs, 30\nradar, 30\nsatellite images, 29\nscientific data, 29\nsocial media, 30\nsonar, 30\nsources of, 29\u201331\nversus structured data, 157\ntext, 30\nvideo, 30\nwebsite content, 30\nU.S. DARPA, 38\u201339\nutility computing, explained, 293\n\u2022 V \u2022\nvalidation, importance of, 17\nvalidity of data, 207\u2013208\nvirtualization\nand abstraction, 69\napplications, 65\u201366\nbenefit from, 70\ncharacteristics, 63\ndata and storage, 67\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1996, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5ad1dec1-3e0d-468c-8cca-cb735841e73a": {"__data__": {"id_": "5ad1dec1-3e0d-468c-8cca-cb735841e73a", "embedding": null, "metadata": {"page_label": "311", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d39bb574-eca5-4a10-bcca-7c7576f4486a", "node_type": "4", "metadata": {"page_label": "311", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "fd545cb171e0792396743adabf1b015c36a1d3f3d8a5beaa4fe0120faab9f85b", "class_name": "RelatedNodeInfo"}}, "text": "311311  Index\ndiagram, 62\ndistributed resources, 62\nencapsulation, 63\nexplained, 61, 293\nhypervisor, 64\nimplementing, 63\u201364, 69\u201370\nimportance of, 63\u201364\nisolation, 63\nmanagement challenges, 67\nmanaging with hypervisor, 68\nmemory, 66\nnetworks, 66\npartitioning, 63\nprocessors, 66\npurpose, 62\nsecurity challenges, 67\nservers, 64\u201365\nvisualization and reporting, 23\nVM (virtual machine), 64\n\u2022 W \u2022\nWatson. See IBM Watson\nweb log data, 27\nweb management, 13\u201314\nweb service, explained, 294\nwebsites\nAIIM (Association for Information and \nImage Management), 31\nApache Software Foundation, 273\nAttensity, 164\nClarabridge text analytics, 165\nCloud Security Alliance, 272\nContinuity AppFabric, 175\nCouchDB database, 93\u201394\nHadoop software framework, 112\nHBase columnar database, 94\u201395\nHurwitz & Associates, 271\nIBM, 151\nIBM Content Analytics, 165\nMongoDB database, 92\u201393\nNeo4J graph database, 96\nNIST (National Institute of Standards and \nTechnology), 272\nOASIS, 273\nODaF (Open Data Foundation), 272\nOGC (Open Geospatial Consortium), 97online collaborative, 273\nOpenChorus, 176\u2013177\nOpenGeo Suite, 98\nOpenStack cloud provider, 80\nOpenText text analytics, 165\u2013166\nOracle, 151\nO\u2019Reilly Strata and StrataRx  \nconference, 274\nPentaho, 151\nPostgreSQL, 29, 87\u201388\nRefractions Research, 98\nRevolution Analytics, 171\nRiak key-value database, 90\u201391\nSAS, 151\nSAS analytics solutions, 166\nTableau, 151\nworkflows\nbest practice, 206\u2013207\nexplained, 205\u2013206, 294\ntechnology impact of, 215\nworkload, 206\u2013207\nWS (Web Standard), explained, 294\nWSDL (Web Service Definition  \nLanguage), 294\n\u2022 X \u2022\nXML (eXtensible Markup Language),  \n54, 294\nXML Schema, explained, 294\nXSD (XML Schema Definition), 294\nXSLT (eXtensible Stylesheet Language \nTransformation), 294\n\u2022 Y \u2022\nYARN (Yet Another Resource Negotiator), \n122\u2013123\n\u2022 Z \u2022\nZookeeper\nconfiguration management, 128\ndescribed, 128\nprocess synchronization, 128\nreliable messaging, 128\nself-election, 128\nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1931, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "6c04c535-05a8-40a1-8762-59e30ea1ce48": {"__data__": {"id_": "6c04c535-05a8-40a1-8762-59e30ea1ce48", "embedding": null, "metadata": {"page_label": "312", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f081c0b1-99af-4936-992c-1f5abfa7dd1a", "node_type": "4", "metadata": {"page_label": "312", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "3b7124cd98c916e09702765e0d375acdafbff510e3a797aaf81a8d70d3ead6c4", "class_name": "RelatedNodeInfo"}}, "text": "312 Big Data For Dummies \nwww.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 44, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8ce7637f-c9a2-4957-b6c4-8d3924aaa684": {"__data__": {"id_": "8ce7637f-c9a2-4957-b6c4-8d3924aaa684", "embedding": null, "metadata": {"page_label": "313", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a32dcb52-2c33-47e8-bcda-4c22feac9df7", "node_type": "4", "metadata": {"page_label": "313", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "0d32116baf3711a9702b394d9f466fdabcbadeb4239d97597359a7a0d1bd01d9", "class_name": "RelatedNodeInfo"}}, "text": "www.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 18, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8fc992a9-4b4a-4fa1-9fdf-c453f32b2401": {"__data__": {"id_": "8fc992a9-4b4a-4fa1-9fdf-c453f32b2401", "embedding": null, "metadata": {"page_label": "314", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5a897cb8-b419-41f9-ba39-370aee42d13c", "node_type": "4", "metadata": {"page_label": "314", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "a451a5c48401da1b1d44f3631786a742bc3bc5e7aaf71405f0cf24d768d5fca8", "class_name": "RelatedNodeInfo"}}, "text": "www.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 18, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "f775dc87-397d-492e-b700-f28f3b97ce44": {"__data__": {"id_": "f775dc87-397d-492e-b700-f28f3b97ce44", "embedding": null, "metadata": {"page_label": "C3", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fb89882d-4944-4111-bcad-d457970cee84", "node_type": "4", "metadata": {"page_label": "C3", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}, "hash": "01eba540f099406f068e40c8b24b628aa07d5a3db2dbea875fc07f749fec8fe3", "class_name": "RelatedNodeInfo"}}, "text": "www.it-ebooks.info", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 18, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "4500c381-63f9-42c4-97dd-ca4993269ae9": {"__data__": {"id_": "4500c381-63f9-42c4-97dd-ca4993269ae9", "embedding": null, "metadata": {"page_label": "1", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "04ae6da3-b962-48a4-b04a-4b4ac9885277", "node_type": "4", "metadata": {"page_label": "1", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "0715e07dec909589ccb480951e563def34a042387c723257082f857da7eecca5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "20c2d42d-ac81-4cd9-85f5-99a89ddd8391", "node_type": "1", "metadata": {}, "hash": "1daf8645f89ef7c32f414a6885dc7a08a1b159f4c86f03ba2c7ba6a6e56e4afb", "class_name": "RelatedNodeInfo"}}, "text": "K\u1ef7 y\u1ebfu H\u1ed9i th\u1ea3o khoa h\u1ecdc \u201cTh\u1ed1ng k\u00ea Nh\u00e0 n\u01b0 \u1edbc v\u1edbi D\u1eef li\u1ec7u l\u1edbn\u201d \n \n9 \n 07/10/2015  \nT\u1ed4NG QUAN V \u1ec0 D\u1eee LI\u1ec6U L\u1edaN (BIGDATA)  \n \nKS. Nguy\u1ec5n C\u00f4ng Hoan  \nTrung T\u00e2m Th\u00f4ng tin khoa h \u1ecdc Th\u1ed1ng k\u00ea, Vi \u1ec7n KHTK  \n \nTr\u01b0\u1edbc \u0111\u00e2y, ch\u00fang ta m\u1edbi ch\u1ec9 bi\u1ebft \u0111\u1ebfn d\u1eef li\u1ec7u c\u00f3 c \u1ea5u tr\u00fac (structure data), ng\u00e0y \nnay, v \u1edbi s\u1ef1 k\u1ebft h\u1ee3p c\u1ee7a d\u1eef li\u1ec7u v\u00e0 internet, \u0111\u00e3 xu \u1ea5t hi\u1ec7n m\u1ed9t d\u1ea1ng kh\u00e1c c \u1ee7a d\u1eef li\u1ec7u - \nBig data (d \u1ecbch l\u00e0 \u201cd \u1eef li\u1ec7u l\u1edbn\u201d). D \u1eef li\u1ec7u n\u00e0y c\u00f3 th \u1ec3 t\u1eeb c\u00e1c ngu \u1ed3n nh\u01b0: h \u1ed3 s\u01a1 h\u00e0nh \nch\u00ednh,giao d \u1ecbch \u0111i \u1ec7n t\u1eed, d\u00f2n g tr\u1ea1ng th\u00e1i (status), chia s \u1ebb h\u00ecnh \u1ea3nh, b\u00ecnh lu \u1eadn, tin \nnh\u1eafn... c \u1ee7a ch\u00ednh ch\u00fang ta, n\u00f3i c\u00e1ch kh\u00e1c ch\u00fang l\u00e0 d \u1eef li\u1ec7u \u0111\u01b0 \u1ee3c s\u1ea3n sinh qua qu\u00e1 \ntr\u00ecnh chia s \u1ebb th\u00f4ng tin tr \u1ef1c tuy \u1ebfn li\u00ean t \u1ee5c c\u1ee7a ng\u01b0 \u1eddi s\u1eed d\u1ee5ng. \u0110 \u1ec3 cung c \u1ea5p c\u00e1i nh\u00ecn \nt\u1ed5ng quan, b\u00e0i vi \u1ebft n\u00e0y gi \u1edbi thi\u1ec7u t\u00f3m t \u1eaft nh\u1eefng n\u00e9t ch\u00ednh v \u1ec1 d\u1eef li\u1ec7u l\u1edbn c\u0169ng nh\u01b0 \nnh\u1eefng c\u01a1 h \u1ed9i v\u00e0 th\u00e1ch th \u1ee9c m\u00e0 d \u1eef li\u1ec7u l\u1edbn mang l \u1ea1i.    \n1.  Kh\u00e1i ni\u1ec7m, \u0111\u1eb7c tr\u01b0ng c\u1ee7a d\u1eef li\u1ec7u l\u1edbn v\u00e0 s\u1ef1 kh\u00e1c bi\u1ec7t v\u1edbi d\u1eef li\u1ec7u \ntruy\u1ec1n th\u1ed1ng  \n1.1. Kh\u00e1i ni\u1ec7m v\u1ec1 d\u1eef li\u1ec7u l\u1edbn  \n- Theo wikipedia : D\u1eef li\u1ec7u l\u1edbn (Big data ) l\u00e0 m \u1ed9t thu \u1eadt ng\u1eef ch\u1ec9 b\u1ed9 d\u1eef li\u1ec7u l\u1edbn \nho\u1eb7c ph\u1ee9c t\u1ea1p m\u00e0 c\u00e1c ph\u01b0\u01a1ng ph\u00e1p truy \u1ec1n th\u1ed1ng kh\u00f4ng \u0111 \u1ee7 c\u00e1c \u1ee9ng d\u1ee5ng \u0111\u1ec3 x\u1eed l\u00fd d\u1eef \nli\u1ec7u n\u00e0y.  \n- Theo Gartner : D\u1eef li\u1ec7u l\u1edbn l\u00e0 nh \u1eefng ngu \u1ed3n th\u00f4ng tin c\u00f3 \u0111 \u1eb7c \u0111i\u1ec3m chung kh \u1ed1i \nl\u01b0\u1ee3ng l\u1edbn, t\u1ed1c \u0111\u1ed9 nhanh v\u00e0 d \u1eef li\u1ec7u \u0111\u1ecbnh d\u1ea1ng d\u01b0 \u1edbi nhi\u1ec1u h\u00ecnh th \u1ee9c kh\u00e1c nhau, do \u0111\u00f3 \nmu\u1ed1n khai th\u00e1c \u0111\u01b0 \u1ee3c \u0111\u00f2i h \u1ecfi ph\u1ea3i c\u00f3 h\u00ecnh th \u1ee9c x\u1eed l\u00fd m\u1edbi \u0111\u1ec3 \u0111\u01b0a ra quy \u1ebft \u0111\u1ecbnh, kh\u00e1m \nph\u00e1 v\u00e0 t \u1ed1i \u01b0u h\u00f3a quy tr\u00ecnh.  \n1.2. Ngu\u1ed3n h\u00ecnh th\u00e0nh v\u00e0 ph\u01b0\u01a1ng ph\u00e1p khai th\u00e1c, qu\u1ea3n l\u00fd d\u1eef li\u1ec7u l\u1edbn  \nQua th \u1ed1ng k\u00ea v\u00e0 t \u1ed5ng h\u1ee3p, d\u1eef li\u1ec7u l\u1edbn \u0111\u01b0\u1ee3c h\u00ecnh th\u00e0nh ch \u1ee7 y\u1ebfu t\u1eeb 6 ngu \u1ed3n: (1) \nD\u1eef li\u1ec7u h\u00e0nh ch\u00ednh (ph\u00e1t sinh t \u1eeb ch\u01b0\u01a1ng tr\u00ecnh c \u1ee7a m\u1ed9t t\u1ed5 ch\u1ee9c, c\u00f3 th \u1ec3 l\u00e0 ch\u00ednh ph \u1ee7 \nhay phi ch\u00ednh ph \u1ee7). V\u00ed d \u1ee5, h\u1ed3 s\u01a1 y t \u1ebf \u0111i\u1ec7n t\u1eed \u1edf b\u1ec7nh vi \u1ec7n, h\u1ed3 s\u01a1 b\u1ea3o hi\u1ec3m, h\u1ed3 s\u01a1 ng\u00e2n \nh\u00e0ng...; (2) D \u1eef li\u1ec7u t\u1eeb ho\u1ea1t \u0111\u1ed9ng th\u01b0\u01a1ng m \u1ea1i (ph\u00e1t sin h t\u1eeb c\u00e1c giao d \u1ecbch gi \u1eefa hai th \u1ef1c \nth\u1ec3).", "mimetype": "text/plain", "start_char_idx": 2, "end_char_idx": 1892, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "20c2d42d-ac81-4cd9-85f5-99a89ddd8391": {"__data__": {"id_": "20c2d42d-ac81-4cd9-85f5-99a89ddd8391", "embedding": null, "metadata": {"page_label": "1", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "04ae6da3-b962-48a4-b04a-4b4ac9885277", "node_type": "4", "metadata": {"page_label": "1", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "0715e07dec909589ccb480951e563def34a042387c723257082f857da7eecca5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "4500c381-63f9-42c4-97dd-ca4993269ae9", "node_type": "1", "metadata": {"page_label": "1", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "5e8a65eafe884b535cb29a2ca7ff8c8cade896f987316f3ebbbf891de6b27e8e", "class_name": "RelatedNodeInfo"}}, "text": "V\u00ed d \u1ee5, h\u1ed3 s\u01a1 y t \u1ebf \u0111i\u1ec7n t\u1eed \u1edf b\u1ec7nh vi \u1ec7n, h\u1ed3 s\u01a1 b\u1ea3o hi\u1ec3m, h\u1ed3 s\u01a1 ng\u00e2n \nh\u00e0ng...; (2) D \u1eef li\u1ec7u t\u1eeb ho\u1ea1t \u0111\u1ed9ng th\u01b0\u01a1ng m \u1ea1i (ph\u00e1t sin h t\u1eeb c\u00e1c giao d \u1ecbch gi \u1eefa hai th \u1ef1c \nth\u1ec3). V\u00ed d \u1ee5, c\u00e1c giao d \u1ecbch th \u1ebb t\u00edn d\u1ee5ng, giao d \u1ecbch tr\u00ean m \u1ea1ng, bao g \u1ed3m c\u1ea3 c\u00e1c giao d \u1ecbch \nt\u1eeb c\u00e1c thi \u1ebft b\u1ecb di \u0111\u1ed9ng; (3) D \u1eef li\u1ec7u t\u1eeb c\u00e1c thi \u1ebft b\u1ecb c\u1ea3m bi\u1ebfn nh\u01b0 thi \u1ebft b\u1ecb ch\u1ee5p h\u00ecnh \u1ea3nh \nv\u1ec7 tinh, c \u1ea3m bi\u1ebfn \u0111\u01b0\u1eddng, c \u1ea3m bi\u1ebfn kh\u00ed h \u1eadu; (4) D\u1eef li\u1ec7u t\u1eeb c\u00e1c thi \u1ebft b\u1ecb theo d\u00f5i, v\u00ed d \u1ee5 \ntheo d\u00f5i d \u1eef li\u1ec7u t\u1eeb \u0111i\u1ec7n tho \u1ea1i di \u0111 \u1ed9ng, GPS; (5) D \u1eef li\u1ec7u t\u1eeb c\u00e1c h\u00e0nh vi, v\u00ed d \u1ee5 nh\u01b0 t\u00ecm \nki\u1ebfm tr\u1ef1c tuy \u1ebfn (t\u00ecm ki \u1ebfm s\u1ea3n ph \u1ea9m, d \u1ecbch v\u1ee5 hay th\u00f4ng tin kh\u00e1c), \u0111 \u1ecdc c\u00e1c trang \nm\u1ea1ng tr\u1ef1c tuy \u1ebfn...; (6) D \u1eef li\u1ec7u t\u1eeb c\u00e1c th\u00f4ng tin v \u1ec1 \u00fd ki\u1ebfn, quan \u0111i \u1ec3m c\u1ee7a c\u00e1c c\u00e1 nh\u00e2n, \nt\u1ed5 ch\u1ee9c, tr\u00ean c\u00e1c ph\u01b0\u01a1ng ti \u1ec7n th\u00f4ng tin x\u00e3 h \u1ed9i.", "mimetype": "text/plain", "start_char_idx": 1723, "end_char_idx": 2488, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "708f1710-f803-4a56-9401-819693801a4d": {"__data__": {"id_": "708f1710-f803-4a56-9401-819693801a4d", "embedding": null, "metadata": {"page_label": "2", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a24be4da-c327-4626-abac-e576c4dffa03", "node_type": "4", "metadata": {"page_label": "2", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "12778dd5aa1bf685534e12721f1244e1c73685da29c620af83483524a800896b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "abdf78e1-2fac-41d8-99de-bc5cc23e72a8", "node_type": "1", "metadata": {}, "hash": "33b3949aa691c9c8c3af62b4fba7b8dd8541647c82878173cbd903562a5f7881", "class_name": "RelatedNodeInfo"}}, "text": "K\u1ef7 y\u1ebfu H\u1ed9i th\u1ea3o khoa h\u1ecdc \u201cTh\u1ed1ng k\u00ea Nh\u00e0 n\u01b0 \u1edbc v\u1edbi D\u1eef li\u1ec7u l\u1edbn\u201d \n \n10 \n 07/10/2015  \nPh\u01b0\u01a1ng ph\u00e1p khai th\u00e1c v\u00e0 qu \u1ea3n l\u00fd d \u1eef li\u1ec7u l\u1edbn hi\u1ec7n nay \u0111\u01b0 \u1ee3c thi\u1ebft k\u1ebf ph\u00f9 h \u1ee3p \nd\u1ef1a theo c\u00e1c ngu \u1ed3n h\u00ecnh th\u00e0nh d \u1eef li\u1ec7u l\u1edbn. M \u1ed7i ngu \u1ed3n d\u1eef li\u1ec7u l\u1edbn kh\u00e1c nhau s \u1ebd c\u00f3 \nph\u01b0\u01a1ng ph\u00e1p k hai th\u00e1c v\u00e0 qu \u1ea3n l\u00fd d \u1eef li\u1ec7u l\u1edbn kh\u00e1c nhau. Tuy nhi\u00ean, hi \u1ec7n nay ph \u1ea7n \nl\u1edbn c\u00e1c t \u1ed5 ch\u1ee9c tr\u00ean th \u1ebf gi\u1edbi \u0111\u1ec1u d\u00f9ng Hadoop ecosystem l\u00e0 gi \u1ea3i ph\u00e1p t \u1ed1i \u01b0u \u0111 \u1ec3 khai \nth\u00e1c v\u00e0 qu \u1ea3n l\u00fd d \u1eef li\u1ec7u l\u1edbn. \n1.3. \u0110\u1eb7c tr\u01b0ng 5V c\u1ee7a d\u1eef li\u1ec7u l\u1edbn  \nD\u1eef li\u1ec7u l\u1edbn c\u00f3 5 \u0111 \u1eb7c tr\u01b0ng c\u01a1 b \u1ea3n nh\u01b0 sau  \n(m\u00f4 h\u00ecnh 5V9):   \n(1) Kh \u1ed1i l\u01b0\u1ee3ng d\u1eef li\u1ec7u (Volume)  \n\u0110\u00e2y l\u00e0 \u0111 \u1eb7c \u0111i\u1ec3m ti\u00eau bi \u1ec3u nh\u1ea5t c\u1ee7a d\u1eef li\u1ec7u \nl\u1edbn, kh \u1ed1i l\u01b0\u1ee3ng d\u1eef li\u1ec7u r\u1ea5t l\u1edbn. K\u00edch c \u1ee1 c\u1ee7a Big  \ndata \u0111ang t \u1eebng ng\u00e0y t\u0103ng l\u00ean, v\u00e0 t\u00ednh \u0111 \u1ebfn n\u0103m 2012 th\u00ec n\u00f3 c\u00f3 th \u1ec3 n\u1eb1m trong kho \u1ea3ng \nv\u00e0i ch \u1ee5c terabyte cho \u0111 \u1ebfn nhi \u1ec1u petabyte (1 petabyte = 1024 terabyte) ch \u1ec9 cho m \u1ed9t \nt\u1eadp h\u1ee3p d\u1eef li\u1ec7u. D\u1eef li\u1ec7u truy \u1ec1n th\u1ed1ng c\u00f3 th \u1ec3 l\u01b0u tr \u1eef tr\u00ean c\u00e1c thi \u1ebft b\u1ecb \u0111\u0129a m \u1ec1m, \u0111\u0129a \nc\u1ee9ng. Nh\u01b0ng v \u1edbi d\u1eef li\u1ec7u l\u1edbn ch\u00fang ta s \u1ebd s\u1eed d\u1ee5ng c\u00f4ng ngh \u1ec7 \u201c\u0111\u00e1m m\u00e2y\u201d m \u1edbi \u0111\u00e1p \u1ee9ng \nkh\u1ea3 n\u0103ng l\u01b0u tr \u1eef \u0111\u01b0\u1ee3c d\u1eef li\u1ec7u l\u1edbn. \n (2) T \u1ed1c \u0111\u1ed9 (Velocity)  \nT\u1ed1c \u0111\u1ed9 c\u00f3 th \u1ec3 hi\u1ec3u theo 2 kh\u00eda c \u1ea1nh: (a) Kh \u1ed1i l\u01b0\u1ee3ng d\u1eef li\u1ec7u gia t\u0103ng r \u1ea5t nhanh \n(m\u1ed7i gi\u00e2y c\u00f3 t \u1edbi 72.9 tri \u1ec7u c\u00e1c y\u00eau c \u1ea7u truy c \u1eadp t\u00ecm ki \u1ebfm tr\u00ean web b\u00e1n h\u00e0ng c \u1ee7a \nAmazon); (b) X \u1eed l\u00fd d\u1eef li\u1ec7u nhanh \u1edf m\u1ee9c th\u1eddi gian th \u1ef1c (real -time), c\u00f3 ngh\u0129a d \u1eef li\u1ec7u \n\u0111\u01b0\u1ee3c x\u1eed l\u00fd ngay t \u1ee9c th\u1eddi ngay sau khi ch\u00fang ph\u00e1t sinh (t\u00ednh \u0111 \u1ebfn b\u1eb1ng mili gi\u00e2y). C\u00e1c \n\u1ee9ng d\u1ee5ng ph \u1ed5 bi\u1ebfn tr\u00ean l\u0129nh v \u1ef1c Internet, T\u00e0i ch\u00ednh, Ng\u00e2n h\u00e0ng, H\u00e0ng kh\u00f4ng, Qu\u00e2n \ns\u1ef1, Y t \u1ebf \u2013 S\u1ee9c kh\u1ecfe nh\u01b0 hi \u1ec7n nay ph \u1ea7n l\u1edbn d\u1eef li\u1ec7u l\u1edbn \u0111\u01b0 \u1ee3c x\u1eed l\u00fd real -time. C\u00f4ng \nngh\u1ec7 x\u1eed l\u00fd d\u1eef li\u1ec7u l\u1edbn ng\u00e0y nay \u0111\u00e3 cho ph\u00e9p ch\u00fang ta x \u1eed l\u00fd t\u1ee9c th\u00ec tr\u01b0 \u1edbc khi ch\u00fang \n\u0111\u01b0\u1ee3c l\u01b0u tr \u1eef v\u00e0o c\u01a1 s \u1edf d\u1eef li\u1ec7u.", "mimetype": "text/plain", "start_char_idx": 2, "end_char_idx": 1747, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "abdf78e1-2fac-41d8-99de-bc5cc23e72a8": {"__data__": {"id_": "abdf78e1-2fac-41d8-99de-bc5cc23e72a8", "embedding": null, "metadata": {"page_label": "2", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a24be4da-c327-4626-abac-e576c4dffa03", "node_type": "4", "metadata": {"page_label": "2", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "12778dd5aa1bf685534e12721f1244e1c73685da29c620af83483524a800896b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "708f1710-f803-4a56-9401-819693801a4d", "node_type": "1", "metadata": {"page_label": "2", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "82ee8bb8f4bc2d264ad3da672f9c7b6fc97b34087f3419f17951d447b439319c", "class_name": "RelatedNodeInfo"}}, "text": "C\u00f4ng \nngh\u1ec7 x\u1eed l\u00fd d\u1eef li\u1ec7u l\u1edbn ng\u00e0y nay \u0111\u00e3 cho ph\u00e9p ch\u00fang ta x \u1eed l\u00fd t\u1ee9c th\u00ec tr\u01b0 \u1edbc khi ch\u00fang \n\u0111\u01b0\u1ee3c l\u01b0u tr \u1eef v\u00e0o c\u01a1 s \u1edf d\u1eef li\u1ec7u. \n(3) \u0110a d \u1ea1ng (Variety)  \n\u0110\u1ed1i v\u1edbi d\u1eef li\u1ec7u truy \u1ec1n th\u1ed1ng ch\u00fang ta hay n\u00f3i \u0111 \u1ebfn d\u1eef li\u1ec7u c\u00f3 c \u1ea5u tr\u00fac, th\u00ec ng\u00e0y \nnay h\u01a1n 80% d \u1eef li\u1ec7u \u0111\u01b0\u1ee3c sinh ra l\u00e0 phi c \u1ea5u tr\u00fac (t\u00e0i li \u1ec7u, blog, h\u00ecnh \u1ea3nh, vi deo, b\u00e0i \nh\u00e1t, d \u1eef li\u1ec7u t\u1eeb thi\u1ebft b\u1ecb c\u1ea3m bi\u1ebfn v\u1eadt l\u00fd, thi \u1ebft b\u1ecb ch\u0103m s\u00f3c s \u1ee9c kh\u1ecfe\u2026). Big data cho \nph\u00e9p li\u00ean k \u1ebft v\u00e0 ph\u00e2n t\u00edch nhi \u1ec1u d\u1ea1ng d\u1eef li\u1ec7u kh\u00e1c nhau. V\u00ed d \u1ee5, v\u1edbi c\u00e1c b\u00ecnh lu \u1eadn c\u1ee7a \nm\u1ed9t nh\u00f3m ng\u01b0 \u1eddi d\u00f9ng n\u00e0o \u0111\u00f3 tr\u00ean Facebook  v\u1edbi th\u00f4ng tin video \u0111\u01b0 \u1ee3c chia s \u1ebb t\u1eeb \nYoutube v\u00e0 Twitter.  \n                                              \n9 M\u00f4 h\u00ecnh 5Vs do Gartner  x\u00e2y d\u1ef1ng. Gartner l\u00e0 c\u00f4ng ty nghi\u00ean c\u1ee9u v\u00e0 t\u01b0 v\u1ea5n v\u1ec1 c\u00f4ng ngh\u1ec7 th\u00f4ng tin \nh\u00e0ng \u0111\u1ea7u th\u1ebf gi\u1edbi do m\u1ed9t ng\u01b0\u1eddi M\u1ef9 t\u00ean l\u00e0 Gideon Gartner s\u00e1ng l\u1eadp n\u0103m 1979. 5Vs: Kh\u1ed1i l\u01b0\u1ee3ng d\u1eef \nli\u1ec7u (Volume); T\u1ed1c \u0111\u1ed9 (Velocity); Gi\u00e1 tr\u1ecb (Value); \u0110\u1ed9 tin c\u1eady/ch\u00ednh x\u00e1c (Veracity); \u0110a d \u1ea1ng \n(Variety).", "mimetype": "text/plain", "start_char_idx": 1622, "end_char_idx": 2580, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "afe8f774-e47c-40b5-b02d-c1384702278e": {"__data__": {"id_": "afe8f774-e47c-40b5-b02d-c1384702278e", "embedding": null, "metadata": {"page_label": "3", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0c04306d-b09c-4369-87d5-9e6a357e17eb", "node_type": "4", "metadata": {"page_label": "3", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "817c64f520e5660aecc4b0463b898545befe95f23dc5825b5f58c6473131c304", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "da5d9e9c-cdf6-4eb9-8f24-eb986eb1a3bf", "node_type": "1", "metadata": {}, "hash": "3ce930e45ce91cb3fc118fed98ade297489e42dc5e9b25cf1c502a62a2cc803c", "class_name": "RelatedNodeInfo"}}, "text": "K\u1ef7 y\u1ebfu H\u1ed9i th\u1ea3o khoa h\u1ecdc \u201cTh\u1ed1ng k\u00ea Nh\u00e0 n\u01b0 \u1edbc v\u1edbi D\u1eef li\u1ec7u l\u1edbn\u201d \n \n11 \n 07/10/2015  \n(4) \u0110 \u1ed9 tin c\u1eady/ch\u00ednh x\u00e1c (Veracity)  \nM\u1ed9t trong nh \u1eefng t\u00ednh ch \u1ea5t ph\u1ee9c t\u1ea1p nh\u1ea5t c\u1ee7a D\u1eef li\u1ec7u l\u1edbn l\u00e0 \u0111\u1ed9 tin c\u1eady/ch\u00ednh x\u00e1c \nc\u1ee7a d\u1eef li\u1ec7u. V\u1edbi xu h\u01b0 \u1edbng ph\u01b0\u01a1ng ti \u1ec7n truy \u1ec1n th\u00f4ng x\u00e3 h \u1ed9i (Social Media) v\u00e0 m \u1ea1ng \nx\u00e3 h\u1ed9i (Social Network) ng\u00e0y nay v\u00e0 s \u1ef1 gia t\u0103ng m \u1ea1nh m \u1ebd t\u00ednh t\u01b0\u01a1ng t\u00e1c v\u00e0 chia s \u1ebb \nc\u1ee7a ng\u01b0 \u1eddi d\u00f9ng Mobile l\u00e0m cho b \u1ee9c tranh x\u00e1c \u0111 \u1ecbnh v\u1ec1 \u0111\u1ed9 tin c\u1eady & ch\u00ed nh x\u00e1c c \u1ee7a d\u1eef \nli\u1ec7u ng\u00e0y m \u1ed9t kh\u00f3 kh\u0103n h\u01a1n. B\u00e0i to\u00e1n ph\u00e2n t\u00edch v\u00e0 lo \u1ea1i b\u1ecf d\u1eef li\u1ec7u thi\u1ebfu ch\u00ednh x\u00e1c v\u00e0 \nnhi\u1ec5u \u0111ang l\u00e0 t\u00ednh ch \u1ea5t quan tr \u1ecdng c\u1ee7a Big  data. \n (5) Gi\u00e1 tr \u1ecb (Value)  \nGi\u00e1 tr \u1ecb l\u00e0 \u0111\u1eb7c \u0111i\u1ec3m quan tr \u1ecdng nh \u1ea5t c\u1ee7a d\u1eef li\u1ec7u l\u1edbn, v\u00ec khi b \u1eaft \u0111\u1ea7u tri\u1ec3n khai x\u00e2y \nd\u1ef1ng d\u1eef li\u1ec7u l\u1edbn th\u00ec vi \u1ec7c \u0111\u1ea7u ti\u00ean ch\u00fang ta c \u1ea7n ph\u1ea3i l\u00e0m \u0111\u00f3 l\u00e0 x\u00e1c \u0111 \u1ecbnh \u0111\u01b0 \u1ee3c gi\u00e1 tr \u1ecb \nc\u1ee7a th\u00f4ng tin mang l \u1ea1i nh\u01b0 th \u1ebf n\u00e0o, khi \u0111\u00f3 ch\u00fang ta m \u1edbi c\u00f3 quy \u1ebft \u0111\u1ecbnh c\u00f3 n\u00ean tri \u1ec3n \nkhai d \u1eef li\u1ec7u l\u1edbn hay kh\u00f4ng. N \u1ebfu ch\u00fang ta c\u00f3 d \u1eef li\u1ec7u l\u1edbn m\u00e0 ch \u1ec9 nh\u1eadn \u0111\u01b0\u1ee3c 1% l \u1ee3i \u00edch \nt\u1eeb n\u00f3, th\u00ec kh\u00f4ng n\u00ean \u0111 \u1ea7u t\u01b0 ph\u00e1t tri \u1ec3n d\u1eef li\u1ec7u l\u1edbn. K\u1ebft qu\u1ea3 d\u1ef1 b\u00e1o ch\u00ednh x\u00e1c th \u1ec3 hi\u1ec7n \nr\u00f5 n\u00e9t nh \u1ea5t v\u1ec1 gi\u00e1 tr \u1ecb c\u1ee7a d\u1eef li\u1ec7u l\u1edbn mang l \u1ea1i. V\u00ed d \u1ee5, t\u1eeb kh\u1ed1i d\u1eef li\u1ec7u ph\u00e1t sinh trong \nqu\u00e1 tr\u00ecnh kh\u00e1m, ch \u1eefa b\u1ec7nh s\u1ebd gi\u00fap d \u1ef1 b\u00e1o v \u1ec1 s\u1ee9c kh\u1ecfe \u0111\u01b0\u1ee3c ch\u00ednh x\u00e1c h\u01a1n, s \u1ebd gi\u1ea3m \n\u0111\u01b0\u1ee3c chi ph\u00ed \u0111i \u1ec1u tr\u1ecb v\u00e0 c\u00e1c chi ph\u00ed li\u00ean quan \u0111 \u1ebfn y t\u1ebf.  \n1.4. S \u1ef1 kh\u00e1c bi \u1ec7t gi\u1eefa d\u1eef li\u1ec7u l\u1edbn v\u1edbi d\u1eef li\u1ec7u truy \u1ec1n th\u1ed1ng  \nD\u1eef li\u1ec7u l\u1edbn kh\u00e1c v \u1edbi d\u1eef li\u1ec7u truy \u1ec1n th\u1ed1ng (v\u00ed d \u1ee5, kho d \u1eef li\u1ec7u - Data \nWarehouse) \u1edf 4 \u0111i\u1ec3m c\u01a1 b \u1ea3n: D\u1eef li\u1ec7u \u0111a d \u1ea1ng h\u01a1n; l\u01b0u tr \u1eef d\u1eef li\u1ec7u l\u1edbn h\u01a1n; tru y v\u1ea5n \nd\u1eef li\u1ec7u nhanh h\u01a1n; \u0111 \u1ed9 ch\u00ednh x\u00e1c cao h\u01a1n.  \n(1) D\u1eef li\u1ec7u \u0111a d \u1ea1ng h\u01a1n : Khi khai th\u00e1c d \u1eef li\u1ec7u truy \u1ec1n th\u1ed1ng (d \u1eef li\u1ec7u c\u00f3 c \u1ea5u \ntr\u00fac), ch\u00fang ta th\u01b0 \u1eddng ph \u1ea3i tr\u1ea3 l\u1eddi c\u00e1c c\u00e2u h \u1ecfi: D\u1eef li\u1ec7u l\u1ea5y ra ki \u1ec3u g\u00ec? \u0111 \u1ecbnh d\u1ea1ng d\u1eef \nli\u1ec7u nh\u01b0 th \u1ebf n\u00e0o? \u0110 \u1ed1i v\u1edbi d\u1eef li\u1ec7u l\u1edbn, kh\u00f4ng ph \u1ea3i tr\u1ea3 l\u1eddi c\u00e1c c\u00e2u h \u1ecfi tr\u00ean.", "mimetype": "text/plain", "start_char_idx": 2, "end_char_idx": 1847, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "da5d9e9c-cdf6-4eb9-8f24-eb986eb1a3bf": {"__data__": {"id_": "da5d9e9c-cdf6-4eb9-8f24-eb986eb1a3bf", "embedding": null, "metadata": {"page_label": "3", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "0c04306d-b09c-4369-87d5-9e6a357e17eb", "node_type": "4", "metadata": {"page_label": "3", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "817c64f520e5660aecc4b0463b898545befe95f23dc5825b5f58c6473131c304", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "afe8f774-e47c-40b5-b02d-c1384702278e", "node_type": "1", "metadata": {"page_label": "3", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "51b335e187cd783002a231053db943d98b21957e9ccad265ff3b691b10630ff4", "class_name": "RelatedNodeInfo"}}, "text": "\u0111 \u1ecbnh d\u1ea1ng d\u1eef \nli\u1ec7u nh\u01b0 th \u1ebf n\u00e0o? \u0110 \u1ed1i v\u1edbi d\u1eef li\u1ec7u l\u1edbn, kh\u00f4ng ph \u1ea3i tr\u1ea3 l\u1eddi c\u00e1c c\u00e2u h \u1ecfi tr\u00ean. Hay n\u00f3i \nkh\u00e1c, khi khai th\u00e1c, ph\u00e2n t\u00edch d \u1eef li\u1ec7u l\u1edbn ch\u00fang ta kh\u00f4ng c \u1ea7n quan t\u00e2m \u0111 \u1ebfn ki\u1ec3u d\u1eef \nli\u1ec7u v\u00e0 \u0111 \u1ecbnh d\u1ea1ng c\u1ee7a ch\u00fang; \u0111i \u1ec1u quan t\u00e2m l\u00e0 gi\u00e1 tr \u1ecb m\u00e0 d \u1eef li\u1ec7u mang l \u1ea1i c\u00f3 \u0111\u00e1p \u1ee9ng \n\u0111\u01b0\u1ee3c cho c\u00f4ng vi \u1ec7c hi\u1ec7n t\u1ea1i v\u00e0 t\u01b0\u01a1ng lai hay kh\u00f4ng.  \n(2) L\u01b0u tr \u1eef d\u1eef li\u1ec7u l\u1edbn h\u01a1n : L\u01b0u tr \u1eef d\u1eef li\u1ec7u truy \u1ec1n th\u1ed1ng v\u00f4 c\u00f9ng ph \u1ee9c t\u1ea1p v\u00e0 \nlu\u00f4n \u0111 \u1eb7t ra c\u00e2u h \u1ecfi l\u01b0u nh\u01b0 th \u1ebf n\u00e0o? dung l\u01b0 \u1ee3ng kho l\u01b0u tr \u1eef bao nhi\u00eau l\u00e0 \u0111 \u1ee7? g\u1eafn \nk\u00e8m v \u1edbi c\u00e2u h \u1ecfi \u0111\u00f3 l\u00e0 chi ph\u00ed \u0111 \u1ea7u t\u01b0 t\u01b0\u01a1ng \u1ee9ng. C\u00f4ng ngh \u1ec7 l\u01b0u tr \u1eef  d\u1eef li\u1ec7u l\u1edbn hi\u1ec7n \nnay \u0111\u00e3 ph \u1ea7n n\u00e0o c\u00f3 th \u1ec3 gi\u1ea3i quy \u1ebft \u0111\u01b0\u1ee3c v\u1ea5n \u0111\u1ec1 tr\u00ean nh \u1edd nh\u1eefng c\u00f4ng ngh \u1ec7 l\u01b0u tr \u1eef \n\u0111\u00e1m m\u00e2y, ph\u00e2n ph \u1ed1i l\u01b0u tr \u1eef d\u1eef li\u1ec7u ph\u00e2n t\u00e1n v\u00e0 c\u00f3 th \u1ec3 k\u1ebft h\u1ee3p c\u00e1c d \u1eef li\u1ec7u ph\u00e2n t\u00e1n \nl\u1ea1i v\u1edbi nhau m \u1ed9t c\u00e1ch ch\u00ednh x\u00e1c v\u00e0 x \u1eed l\u00fd nhanh trong th \u1eddi gian th \u1ef1c. \n(3) Truy v \u1ea5n d\u1eef li\u1ec7u nhanh h\u01a1n : D\u1eef li\u1ec7u l\u1edbn \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt li\u00ean t \u1ee5c, trong khi \n\u0111\u00f3 kho d \u1eef li\u1ec7u truy \u1ec1n th\u1ed1ng th\u00ec l\u00e2u l\u00e2u m \u1edbi \u0111\u01b0\u1ee3c c\u1eadp nh\u1eadt v\u00e0 trong t\u00ecnh tr \u1ea1ng kh\u00f4ng \ntheo d\u00f5i th\u01b0 \u1eddng xuy\u00ean g\u00e2y ra t\u00ecnh tr \u1ea1ng l\u1ed7i c\u1ea5u tr\u00fac truy v \u1ea5n d\u1eabn \u0111\u1ebfn kh\u00f4ng t\u00ecm ki \u1ebfm \n\u0111\u01b0\u1ee3c th\u00f4ng tin \u0111\u00e1p \u1ee9ng theo y\u00eau c \u1ea7u.", "mimetype": "text/plain", "start_char_idx": 1753, "end_char_idx": 2898, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cfd3c2b7-bd34-4f76-be5e-7731939a6a97": {"__data__": {"id_": "cfd3c2b7-bd34-4f76-be5e-7731939a6a97", "embedding": null, "metadata": {"page_label": "4", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "47148a91-2dfb-453e-b8d9-21bb004c04ef", "node_type": "4", "metadata": {"page_label": "4", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "2c8aea143fcb9f4b87e5191df3fc70aa1b490c57f8e918c2da5e35a06cb60efe", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5ac2b47d-5f5f-4075-a174-cff6781e87a8", "node_type": "1", "metadata": {}, "hash": "333a4ff81c2c5f9721ec87c5f497e0f854284546e3111de32b5024a62aa5d937", "class_name": "RelatedNodeInfo"}}, "text": "K\u1ef7 y\u1ebfu H\u1ed9i th\u1ea3o khoa h\u1ecdc \u201cTh\u1ed1ng k\u00ea Nh\u00e0 n\u01b0 \u1edbc v\u1edbi D\u1eef li\u1ec7u l\u1edbn\u201d \n \n12 \n 07/10/2015  \n(4) \u0110\u1ed9 ch\u00ednh x\u00e1c cao h\u01a1n : D\u1eef li\u1ec7u l\u1edbn khi \u0111\u01b0a v\u00e0o s \u1eed d\u1ee5ng th\u01b0 \u1eddng \u0111\u01b0 \u1ee3c ki\u1ec3m \n\u0111\u1ecbnh l\u1ea1i d\u1eef li\u1ec7u v\u1edbi nh\u1eefng \u0111i \u1ec1u ki\u1ec7n ch\u1eb7t ch\u1ebd, s\u1ed1 l\u01b0\u1ee3ng th\u00f4ng tin \u0111\u01b0 \u1ee3c ki\u1ec3m tra th\u00f4ng \nth\u01b0\u1eddng r\u1ea5t l\u1edbn, v\u00e0 \u0111 \u1ea3m b\u1ea3o v\u1ec1 ngu\u1ed3n l\u1ea5y d\u1eef li\u1ec7u kh\u00f4ng c\u00f3 s \u1ef1 t\u00e1c \u0111 \u1ed9ng c\u1ee7a con ng\u01b0 \u1eddi \nv\u00e0o thay \u0111 \u1ed5i s\u1ed1 li\u1ec7u thu th \u1eadp. \n2. B\u1ee9c tranh t\u1ed5ng th\u1ec3 \u1ee9ng d\u1ee5ng d\u1eef li\u1ec7u l\u1edbn  \n D\u1eef li\u1ec7u l\u1edbn \u0111\u00e3 \u0111\u01b0 \u1ee3c \u1ee9ng d\u1ee5ng trong nhi \u1ec1u l\u0129nh v \u1ef1c nh\u01b0: ho \u1ea1t \u0111\u1ed9ng ch\u00ednh tr \u1ecb; \ngiao th\u00f4ng; y t \u1ebf; th\u1ec3 thao; t\u00e0i ch\u00ednh; th\u01b0\u01a1ng m \u1ea1i; th\u1ed1ng k\u00ea... d\u01b0 \u1edbi \u0111\u00e2y l\u00e0 m \u1ed9t s\u1ed1 v\u00ed d\u1ee5 \nv\u1ec1 \u1ee9ng d\u1ee5ng d\u1eef li\u1ec7u l\u1edbn. \n2.1. \u1ee8ng d\u1ee5ng d\u1eef li\u1ec7u l\u1edbn trong ho \u1ea1t \u0111\u1ed9ng ch\u00ednh tr \u1ecb \nH\u00ecnh b\u00ean cho th \u1ea5y T \u1ed5ng th \u1ed1ng M \u1ef9 \nObama \u0111\u00e3 s \u1eed d\u1ee5ng d\u1eef li\u1ec7u d\u1eef li\u1ec7u l\u1edbn \u0111\u1ec3 ph\u1ee5c \nv\u1ee5 cho cu \u1ed9c tranh c \u1eed T\u1ed5ng th \u1ed1ng c \u1ee7a m\u00ecnh. \n\u00d4ng x\u00e2y d \u1ef1ng m \u1ed9t \u0111\u1ed9i ng\u0169 nh\u00e2n vi\u00ean chuy\u00ean \u0111i \nthu th \u1eadp th\u00f4ng tin v\u00e0 ph\u00e2n t\u00edch d \u1eef li\u1ec7u thu \u0111\u01b0 \u1ee3c \ntrong d \u1ef1 \u00e1n tri \u1ec3n khai v \u1ec1 d\u1eef li\u1ec7u l\u1edbn. \u0110\u1ed9i ng\u0169 \nnh\u00e2n vi\u00ean n\u00e0y thu th \u1eadp t\u1ea5t c\u1ea3 th\u00f4ng tin v \u1ec1 ng\u01b0\u1eddi d\u00e2n \u1edf c\u00e1c khu v \u1ef1c, sau \u0111\u00f3 ph\u00e2n t\u00edch \nv\u00e0 ch \u1ec9 ra m\u1ed9t s\u1ed1 th\u00f4ng tin quan tr \u1ecdng v\u1ec1 ng\u01b0\u1eddi d\u00e2n M \u1ef9 nh\u01b0: Th\u00edch \u0111 \u1ecdc s\u00e1ch g\u00ec, th\u00edch \nmua lo \u1ea1i thu\u1ed1c g\u00ec, th\u00edch s \u1eed d\u1ee5ng ph\u01b0\u01a1ng  ti\u1ec7n g\u00ec\u2026 Th \u1eadm ch\u00ed c\u00f2n bi \u1ebft \u0111\u01b0\u1ee3c c\u1ea3 th\u00f4ng \ntin v\u1ec1 m\u1eb9 c\u1ee7a c\u1eed tri \u0111\u00f3 \u0111\u00e3 b \u1ecf phi\u1ebfu t\u00edn nhi \u1ec7m ai \u1edf l\u1ea7n b\u1ea7u c\u1eed tr\u01b0\u1edbc. Tr\u00ean c\u01a1 s \u1edf nh\u1eefng \nth\u00f4ng tin n\u00e0y, T \u1ed5ng th \u1ed1ng Obama \u0111\u00e3 \u0111\u01b0a ra k \u1ebf ho\u1ea1ch v\u1eadn \u0111\u1ed9ng ph\u00f9 h \u1ee3p, gi\u00fap \u00f4ng t\u00e1i \n\u0111\u1eafc c\u1eed T\u1ed5ng th \u1ed1ng n\u01b0 \u1edbc M\u1ef9 l\u1ea7n th\u1ee9 2. \n Ngo\u00e0i ra  m\u1ed9t s\u1ed1 \u1ee9ng d\u1ee5ng kh\u00e1c trong l\u0129nh v \u1ef1c ch\u00ednh tr \u1ecb m\u00e0 d \u1eef li\u1ec7u l\u1edbn \u0111\u01b0\u1ee3c \u00e1p \nd\u1ee5ng nh\u01b0: H\u1ec7 th\u1ed1ng ch\u00ednh ph\u1ee7 \u0111i\u1ec7n t\u1eed; ph\u00e2n t\u00edch quy \u0111\u1ecbnh v\u00e0 vi\u1ec7c tu\u00e2n th\u1ee7 quy \u0111\u1ecbnh; \nph\u00e2n t\u00edch, gi\u00e1m s\u00e1t, theo d\u00f5i v\u00e0 ph\u00e1t hi\u1ec7n gian l\u1eadn, m\u1ed1i \u0111e d\u1ecda, an ninh m\u1ea1ng.  \n2.2. \u1ee8ng d\u1ee5ng d\u1eef li\u1ec7u l\u1edbn trong giao th\u00f4ng  \nS\u1eed d\u1ee5ng s\u1ed1 li\u1ec7u CDR trong qu\u00e1 kh \u1ee9 \u0111\u1ec3 \u01b0\u1edbc \nl\u01b0\u1ee3ng c\u00e1c d\u00f2ng giao th\u00f4ng trong th\u00e0nh ph \u1ed1 v\u00e0o \nc\u00e1c gi \u1edd cao \u0111i \u1ec3m, t\u1eeb \u0111\u00f3 c\u00f3 nh \u1eefng k\u1ebf ho\u1ea1ch ph\u00e2n \nlu\u1ed3ng giao th\u00f4ng chi ti \u1ebft, h\u1ee3p l\u00fd gi\u00fap gi \u1ea3m thi \u1ec3u \nk\u1eb9t xe.", "mimetype": "text/plain", "start_char_idx": 2, "end_char_idx": 1941, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "5ac2b47d-5f5f-4075-a174-cff6781e87a8": {"__data__": {"id_": "5ac2b47d-5f5f-4075-a174-cff6781e87a8", "embedding": null, "metadata": {"page_label": "4", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "47148a91-2dfb-453e-b8d9-21bb004c04ef", "node_type": "4", "metadata": {"page_label": "4", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "2c8aea143fcb9f4b87e5191df3fc70aa1b490c57f8e918c2da5e35a06cb60efe", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cfd3c2b7-bd34-4f76-be5e-7731939a6a97", "node_type": "1", "metadata": {"page_label": "4", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "81cfe3b495ee9ff74b3d5cf93c6b261d288d20ffc07e6c4206d5c11283e61697", "class_name": "RelatedNodeInfo"}}, "text": "Ngo\u00e0i ra c\u00f2n \u0111\u01b0a ra th\u00f4ng tin cho ng\u01b0 \u1eddi \ntham gia giao th\u00f4ng \u0111\u01b0 \u1ee3c bi\u1ebft n\u1ebfu mu \u1ed1n \u0111i t \u1eeb n\u01a1i \nn\u00e0y \u0111 \u1ebfn n\u01a1i kh\u00e1c th\u00ec n\u00ean \u0111i v\u00e0o gi \u1edd n\u00e0o \u0111 \u1ec3 tr\u00e1nh k \u1eb9t xe, ho \u1eb7c \u0111i \u0111\u01b0 \u1eddng n\u00e0o l\u00e0 ng \u1eafn \nnh\u1ea5t, v.v... Ngo\u00e0i ra, d \u1eef li\u1ec7u l\u1edbn c\u00f2n gi\u00fap ph\u00e2n t\u00edch \u0111 \u1ecbnh v\u1ecb ng\u01b0\u1eddi d\u00f9ng thi \u1ebft b\u1ecb di \n\u0111\u1ed9ng, g hi nh\u1eadn chi ti\u1ebft cu\u1ed9c g\u1ecdi trong th\u1eddi gian th\u1ef1c ; v\u00e0 gi\u1ea3m thi\u1ec3u t\u00ecnh tr\u1ea1ng \u00f9n t\u1eafc \ngiao th\u00f4ng.  \n2.3. \u1ee8ng d\u1ee5ng d\u1eef li\u1ec7u l\u1edbn trong y t \u1ebf", "mimetype": "text/plain", "start_char_idx": 1942, "end_char_idx": 2358, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "cbe918ba-a372-41d9-9f6b-8928a66de82c": {"__data__": {"id_": "cbe918ba-a372-41d9-9f6b-8928a66de82c", "embedding": null, "metadata": {"page_label": "5", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "de3e8180-22eb-41c7-bbfa-28db5c4634bc", "node_type": "4", "metadata": {"page_label": "5", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "2a5beb406d275563dfcf9023ed64f2604b0f2dc2e7961acf06bf38e5eef045a5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "21b93860-97c3-4066-a9b4-b1de7c0a238d", "node_type": "1", "metadata": {}, "hash": "dd7a1fc248c3cbb7b5efb4983152240363ef11e7bb3a1045efdd6c8a64d30506", "class_name": "RelatedNodeInfo"}}, "text": "K\u1ef7 y\u1ebfu H\u1ed9i th\u1ea3o khoa h\u1ecdc \u201cTh\u1ed1ng k\u00ea Nh\u00e0 n\u01b0 \u1edbc v\u1edbi D\u1eef li\u1ec7u l\u1edbn\u201d \n \n13 \n 07/10/2015  \nTrong y h \u1ecdc c\u00e1c b\u00e1c s\u0129 d \u1ef1a v\u00e0o s \u1ed1 li\u1ec7u \ntrong c\u00e1c b \u1ec7nh \u00e1n \u0111 \u1ec3 \u0111\u01b0a ra d \u1ef1 \u0111o\u00e1n v \u1ec1 nguy c\u01a1 \nm\u1eafc b\u1ec7nh. \u0110 \u1ed3ng th \u1eddi c\u0169ng \u0111\u01b0a ra \u0111\u01b0 \u1ee3c xu \nh\u01b0\u1edbng l\u00e2y lan c \u1ee7a b\u1ec7nh. V\u00ed d \u1ee5, \u1ee9ng d \u1ee5ng \nGoogle Flu Trend l\u00e0 m \u1ed9t trong nh \u1eefng \u1ee9ng d\u1ee5ng \nth\u00e0nh c\u00f4ng c \u1ee7a Google \u1ee9ng d\u1ee5ng n\u00e0y d \u1ef1a tr\u00ean \nt\u1eeb kh\u00f3a t\u00ecm ki \u1ebfm \u1edf m\u1ed9t khu v \u1ef1c n\u00e0o \u0111\u00f3, sau \u0111\u00f3 \nb\u1ed9 m\u00e1y ph\u00e2n t\u00edch c \u1ee7a Google s \u1ebd ph\u00e2n t\u00edch v\u00e0 \u0111 \u1ed1i chi\u1ebfu k\u1ebft qu\u1ea3 t\u00ecm ki \u1ebfm \u0111\u00f3, sau c\u00f9ng \nl\u00e0 \u0111\u01b0a ra d \u1ef1 b\u00e1o v \u1ec1 xu h\u01b0 \u1edbng d\u1ecbch c\u00fam t \u1ea1i khu v \u1ef1c \u0111\u00f3. Qua \u0111\u00f3 cho bi \u1ebft t\u00ecnh h\u00ecnh \nc\u00fam t \u1ea1i khu v \u1ef1c \u0111\u00f3 s \u1ebd di\u1ec5n ra nh\u01b0 th \u1ebf n\u00e0o \u0111 \u1ec3 \u0111\u01b0a ra c\u00e1c gi \u1ea3i ph\u00e1p ph\u00f2ng tr\u00e1nh. \nNh\u1eefng k\u1ebft qu\u1ea3 m\u00e0 Google Flu Trend \u0111\u01b0a ra, ho\u00e0n to\u00e0n ph\u00f9 h \u1ee3p v\u1edbi b\u00e1o c\u00e1o c \u1ee7a T\u1ed5 \nch\u1ee9c Y t \u1ebf Th\u1ebf gi\u1edbi WHO v \u1ec1 t\u00ecnh h\u00ecnh b \u1ec7nh c\u00fam t\u1ea1i c\u00e1c khu v \u1ef1c \u0111\u00f3.  \n2.4. \u1ee8ng d\u1ee5ng d\u1eef li\u1ec7u l\u1edbn trong th \u1ec3 thao \nPh\u00e2n t\u00edch m\u00f4 h\u00ecnh h \u1ec7 th\u1ed1ng c\u1ea5u tr\u00fac s\u01a1 \u0111 \u1ed3 \nchi\u1ebfn thu \u1eadt c\u1ee7a \u0111\u1ed9i tuy\u1ec3n \u0110\u1ee9c (h\u00ecnh b\u00ean) \u0111\u00e3 \u0111\u01b0a \nra nh \u1eefng \u0111i \u1ec3m b\u1ea5t h\u1ee3p l\u00fd trong c \u1ea5u tr\u00fac c \u1ee7a \u0111\u1ed9i \ntuy\u1ec3n \u0110\u1ee9c, t\u1eeb \u0111\u00f3 gi\u00fap cho \u0111 \u1ed9i tuy \u1ec3n \u0110\u1ee9c kh\u1eafc \nph\u1ee5c \u0111\u01b0 \u1ee3c \u0111i\u1ec3m y\u1ebfu v\u00e0 \u0111\u00e3 d\u00e0nh \u0111\u01b0 \u1ee3c World \ncup 2014.  \n2.5. \u1ee8ng d\u1ee5ng d\u1eef li\u1ec7u l\u1edbn trong t\u00e0i ch\u00ednh  \nT\u1eeb nh\u1eefng d\u1eef li\u1ec7u ch\u00ednh x\u00e1c, k \u1ecbp th\u1eddi thu th \u1eadp \u0111\u01b0\u1ee3c th\u00f4ng qua c\u00e1c giao d \u1ecbch c\u1ee7a \nkh\u00e1ch h\u00e0ng, ti \u1ebfn h\u00e0nh ph\u00e2n t\u00edch, x \u1ebfp h\u1ea1ng v\u00e0 qu \u1ea3n l\u00fd c\u00e1c r \u1ee7i ro trong \u0111 \u1ea7u t\u01b0 t\u00e0i \nch\u00ednh, t\u00edn d \u1ee5ng. \n2.6. \u1ee8ng d\u1ee5ng d\u1eef li\u1ec7u l\u1edbn trong th\u01b0\u01a1ng m \u1ea1i \nTrong th\u01b0\u01a1ng m \u1ea1i d\u1eef li\u1ec7u l\u1edbn gi\u00fap cho ch\u00fang ta th \u1ef1c hi\u1ec7n \u0111\u01b0 \u1ee3c m\u1ed9t s\u1ed1 c\u00f4ng \nvi\u1ec7c sau: Ph\u00e2n kh\u00fac th \u1ecb tr\u01b0\u1eddng v\u00e0 kh\u00e1ch h\u00e0ng; ph\u00e2n t\u00edch h\u00e0nh vi kh\u00e1ch h\u00e0ng t \u1ea1i c\u1eeda \nh\u00e0ng; ti \u1ebfp th\u1ecb tr\u00ean n \u1ec1n t\u1ea3ng \u0111\u1ecbnh v\u1ecb; ph\u00e2n t\u00edch ti \u1ebfp th\u1ecb ch\u00e9o k\u00eanh, ti \u1ebfp th\u1ecb \u0111a k\u00eanh; \nqu\u1ea3n l\u00fd c\u00e1c chi \u1ebfn d\u1ecbch ti\u1ebfp th\u1ecb v\u00e0 kh\u00e1ch h\u00e0ng th\u00e2n thi \u1ebft; So s\u00e1nh gi\u00e1; Ph\u00e2n t\u00edch v\u00e0 \nqu\u1ea3n l\u00fd chu \u1ed7i cung \u1ee9ng; Ph\u00e2n t\u00edch h\u00e0nh vi, th\u00f3i quen ng\u01b0 \u1eddi ti\u00eau d\u00f9ng.  \n2.7.", "mimetype": "text/plain", "start_char_idx": 2, "end_char_idx": 1820, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "21b93860-97c3-4066-a9b4-b1de7c0a238d": {"__data__": {"id_": "21b93860-97c3-4066-a9b4-b1de7c0a238d", "embedding": null, "metadata": {"page_label": "5", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "de3e8180-22eb-41c7-bbfa-28db5c4634bc", "node_type": "4", "metadata": {"page_label": "5", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "2a5beb406d275563dfcf9023ed64f2604b0f2dc2e7961acf06bf38e5eef045a5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "cbe918ba-a372-41d9-9f6b-8928a66de82c", "node_type": "1", "metadata": {"page_label": "5", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "1ba2bfd6b8e723797e44e75d471dab0fd832c924a787607fb6ca5c3d6e3f1705", "class_name": "RelatedNodeInfo"}}, "text": "2.7. \u1ee8ng d\u1ee5ng d\u1eef li\u1ec7u l\u1edbn trong th \u1ed1ng k\u00ea  \nNh\u1eadn th\u1ea5y nh\u1eefng l\u1ee3i \u00edch to l \u1edbn v\u00e0 th\u00e1ch th \u1ee9c c\u1ee7a Bigdata \u0111 \u1ed1i v\u1edbi th\u1ed1ng k\u00ea nh\u00e0 \nn\u01b0\u1edbc, \u1ee6y ban Th \u1ed1ng k\u00ea Li\u00ean h \u1ee3p qu\u1ed1c c\u0169ng nh\u01b0 c\u00e1c t \u1ed5 ch\u1ee9c th\u1ed1ng k\u00ea khu v \u1ef1c v\u00e0 C\u01a1 \nquan th \u1ed1ng k\u00ea  qu\u1ed1c gia c \u1ee7a nhi \u1ec1u n\u01b0 \u1edbc \u0111\u00e3 tri \u1ec3n khai h\u00e0ng lo \u1ea1t c\u00e1c ho \u1ea1t \u0111\u1ed9ng v \u1ec1 \nBigdata nh\u01b0: H\u00e0n Qu \u1ed1c s\u1eed d\u1ee5ng \u1ea3nh v \u1ec7 tinh \u0111 \u1ec3 th\u1ed1ng k\u00ea n\u00f4ng nghi \u1ec7p v\u00e0 m \u1ed9t s\u1ed1 \nl\u0129nhv \u1ef1c kh\u00e1c; Australia s \u1eed d\u1ee5ng \u1ea3nh v\u1ec7 tinh \u0111 \u1ec3 th\u1ed1ng k\u00ea di \u1ec7n t\u00edch \u0111 \u1ea5t n\u00f4ng nghi \u1ec7p v\u00e0 \nn\u0103ng su \u1ea5t; Italia s \u1eed d\u1ee5ng d\u1eef li\u1ec7u \u0111i\u1ec7n tho \u1ea1i di \u0111 \u1ed9ng \u0111\u1ec3 th\u1ed1ng k\u00ea di c\u01b0; Bhutan d\u00f9ng", "mimetype": "text/plain", "start_char_idx": 1816, "end_char_idx": 2377, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "36342893-0d2c-4d49-85c3-b4391c3a5981": {"__data__": {"id_": "36342893-0d2c-4d49-85c3-b4391c3a5981", "embedding": null, "metadata": {"page_label": "6", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3a9f6220-ff32-498a-9b17-aea74197e7b4", "node_type": "4", "metadata": {"page_label": "6", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "48e9dd4abc4af265b140c9b81b510aad580c0fea2fc09182252a7ddcbbe83916", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "109a33ef-38d9-4aa1-a956-052c8f35dae8", "node_type": "1", "metadata": {}, "hash": "9d7e6623beeaf5a0ed7bdaa554de7413714e8976e17189e8d3cfc26780d8b08b", "class_name": "RelatedNodeInfo"}}, "text": "K\u1ef7 y\u1ebfu H\u1ed9i th\u1ea3o khoa h\u1ecdc \u201cTh\u1ed1ng k\u00ea Nh\u00e0 n\u01b0 \u1edbc v\u1edbi D\u1eef li\u1ec7u l\u1edbn\u201d \n \n14 \n 07/10/2015  \nthi\u1ebft b\u1ecb di \u0111\u1ed9ng \u0111\u1ec3 t\u00ednh to\u00e1n ch \u1ec9 s\u1ed1 gi\u00e1 ti\u00eau d\u00f9ng; Estonia d\u00f9ng \u0111i \u1ec7n tho \u1ea1i di \u0111 \u1ed9ng \n\u0111\u1ecbnh v\u1ecb v\u1ec7 tinh \u0111 \u1ec3 th\u1ed1ng k\u00ea du l \u1ecbch; EuroStat s \u1eed d\u1ee5ng d\u1eef li\u1ec7u v\u1ec1 s\u1eed d\u1ee5ng \u0111i \u1ec7n tho \u1ea1i di \n\u0111\u1ed9ng \u0111\u1ec3 th\u1ed1ng k\u00ea du l \u1ecbch10. \n3. C\u01a1 h\u1ed9i v\u00e0 th\u00e1ch th\u1ee9c khi \u1ee9ng d\u1ee5ng d\u1eef li\u1ec7u l\u1edbn  trong th\u1ed1ng k\u00ea Nh\u00e0 n\u01b0\u1edbc  \n3.1 C\u01a1 h \u1ed9i  \n(1) Ti \u1ebfp c\u1eadn v\u00e0 nghi\u00ean c \u1ee9u v\u1ec1 d\u1eef li\u1ec7u l\u1edbn s\u1ebd gi\u00fap cho ch\u00fang ta c\u00f3 th\u00eam ph\u01b0\u01a1ng \n\u00e1n gi \u1ea3i quy \u1ebft, x\u1eed l\u00fd v\u00e0 \u0111 \u1ed1i ph\u00f3 v \u1edbi nh\u1eefng th\u00e1ch th \u1ee9c \u0111\u1ed1i s\u1ea3n xu\u1ea5t s\u1ed1 li\u1ec7u th\u1ed1ng k\u00ea \nnh\u00e0 n\u01b0 \u1edbc trong hi \u1ec7n t\u1ea1i v\u00e0 t\u01b0\u01a1ng lai. Nh \u1eefng nghi\u00ean c \u1ee9u th\u1ef1c nghi \u1ec7m c\u1ea7n ph\u1ea3i \u0111\u01b0\u1ee3c \nti\u1ebfn h\u00e0nh \u0111 \u1ec3 kh\u00e1m ph\u00e1 nh \u1eefng \u1ee9ng d\u1ee5ng ti\u1ec1m n\u0103ng c \u1ee7a d\u1eef li\u1ec7u l\u1edbn trong s \u1ed1 li\u1ec7u th\u1ed1ng \nk\u00ea nh\u00e0 n\u01b0 \u1edbc, v\u00e0 nghi\u00ean c \u1ee9u th\u1ef1c nghi \u1ec7m \u0111\u00f3 ph \u1ea3i l\u00e0 m \u1ed9t ph\u1ea7n trong Quy tr\u00ecnh s \u1ea3n \nxu\u1ea5t s\u1ed1 li\u1ec7u th\u1ed1ng k\u00ea . \n(2) Nghi\u00ean c \u1ee9u v\u1ec1 d\u1eef li\u1ec7u l\u1edbn c\u1ea7n ph\u1ea3i c\u00f3 c\u01a1 s \u1edf h\u1ea1 t\u1ea7ng c\u00f4ng ngh \u1ec7 th\u00f4ng tin \nhi\u1ec7n \u0111\u1ea1i, \u0111\u00e1p \u1ee9ng c\u00e1c y\u00eau c \u1ea7u x\u1eed l\u00fd kh \u1ed1i l\u01b0\u1ee3ng l\u1edbn d\u1eef li\u1ec7u v\u00e0 nhanh, \u0111 \u1ed3ng th \u1eddi c\u00f3 \nth\u1ec3 t\u1eadp h\u1ee3p d\u1eef li\u1ec7u t\u1eeb nhi\u1ec1u ngu \u1ed3n kh\u00e1c nhau. Th \u1ef1c hi\u1ec7n \u0111\u01b0\u1ee3c \u0111i\u1ec1u n\u00e0y ch\u00fang ta c\u00f3 \n\u0111\u01b0\u1ee3c \u0111\u1ed9i ng\u0169 n gu\u1ed3n nh\u00e2n l \u1ef1c v\u1ec1 qu\u1ea3n l\u00fd v\u00e0 khai th\u00e1c Big data v \u1eefng v\u00e0ng v \u1ec1 chuy\u00ean \nm\u00f4n v\u00e0 \u0111\u01b0 \u1ee3c tr\u1ea3i qua kinh nghi \u1ec7m th\u1ef1c t\u1ebf. \n(3) Ti \u1ebfp c\u1eadn v\u00e0 nghi\u00ean c \u1ee9u v\u1ec1 d\u1eef li\u1ec7u l\u1edbn s\u1ebd gi\u00fap ch\u00fang ta c\u00f3 \u0111\u01b0 \u1ee3c nh\u1eefng v\u0103n \nb\u1ea3n ph\u00e1p l\u00fd b \u1ed5 sung c\u00f3 th \u1ec3 gi\u00fap cho C\u01a1 quan th \u1ed1ng k\u00ea  nh\u00e0 n\u01b0 \u1edbc c\u00f3 \u0111i \u1ec1u ki\u1ec7n \u0111\u1ec3 th\u1ef1c \nhi\u1ec7n \u0111\u01b0\u1ee3c khai th\u00e1c d \u1eef li\u1ec7u th\u00f4ng qua h \u1ed3 s\u01a1 h\u00e0nh ch\u00ednh, ngo\u00e0i ra d \u1eef li\u1ec7u c\u0169ng \u0111\u01b0 \u1ee3c \nb\u1ea3o \u0111\u1ea3m v\u00e0 gi \u1eef b\u00ed m\u1eadt nh\u1edd nh\u1eefng v\u0103n b \u1ea3n ph\u00e1p l\u00fd b \u1ed5 sung n\u00e0y.  \n(4) S \u1eed d\u1ee5ng d\u1eef li\u1ec7u l\u1edbn \u0111em l \u1ea1i ni\u1ec1m tin c \u1ee7a c\u1ed9ng \u0111\u1ed3ng v\u1edbi th\u1ed1ng k\u00ea nh\u00e0 n\u01b0 \u1edbc \ndo qu\u00e1 tr\u00ecnh tr\u00ecnh s \u1ea3n xu\u1ea5t s\u1ed1 li\u1ec7u th\u1ed1ng k\u00ea nh\u00e0 n\u01b0 \u1edbc v\u1edbi d\u1eef li\u1ec7u l\u1edbn ho\u00e0n to\u00e0n kh\u00f4ng \nc\u00f3 s\u1ef1 t\u00e1c \u0111 \u1ed9ng ch \u1ee7 \u00fd c\u1ee7a con ng\u01b0 \u1eddi. \n3.2 Th\u00e1ch th \u1ee9c  \n(1) T\u00e0i ch\u00ednh  \nNhi\u1ec1u \u0111\u01a1n v\u1ecb, t\u1ed5 ch\u1ee9c kh\u00f4ng \u0111o l\u01b0\u1eddng \u0111\u01b0\u1ee3c v\u1ea5n \u0111\u1ec1 s\u1ebd ph\u00e1t sinh trong qu\u00e1 tr\u00ecnh \ntri\u1ec3n khai th\u1ef1c hi\u1ec7n, d\u1ef1 to\u00e1n kinh ph\u00ed ch\u01b0a ch\u00edn h x\u00e1c, do v\u1eady d\u1ef1 \u00e1n kh\u00f4ng th\u1ef1c hi\u1ec7n \n\u0111\u01b0\u1ee3c.", "mimetype": "text/plain", "start_char_idx": 2, "end_char_idx": 1966, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "109a33ef-38d9-4aa1-a956-052c8f35dae8": {"__data__": {"id_": "109a33ef-38d9-4aa1-a956-052c8f35dae8", "embedding": null, "metadata": {"page_label": "6", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3a9f6220-ff32-498a-9b17-aea74197e7b4", "node_type": "4", "metadata": {"page_label": "6", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "48e9dd4abc4af265b140c9b81b510aad580c0fea2fc09182252a7ddcbbe83916", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "36342893-0d2c-4d49-85c3-b4391c3a5981", "node_type": "1", "metadata": {"page_label": "6", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "182a943e6c861409064d14bc1a00d250f563062c256c7459e28bbcfb2baa601a", "class_name": "RelatedNodeInfo"}}, "text": "3.2 Th\u00e1ch th \u1ee9c  \n(1) T\u00e0i ch\u00ednh  \nNhi\u1ec1u \u0111\u01a1n v\u1ecb, t\u1ed5 ch\u1ee9c kh\u00f4ng \u0111o l\u01b0\u1eddng \u0111\u01b0\u1ee3c v\u1ea5n \u0111\u1ec1 s\u1ebd ph\u00e1t sinh trong qu\u00e1 tr\u00ecnh \ntri\u1ec3n khai th\u1ef1c hi\u1ec7n, d\u1ef1 to\u00e1n kinh ph\u00ed ch\u01b0a ch\u00edn h x\u00e1c, do v\u1eady d\u1ef1 \u00e1n kh\u00f4ng th\u1ef1c hi\u1ec7n \n\u0111\u01b0\u1ee3c. \u0110\u1ec3 tri\u1ec3n khai \u0111\u01b0\u1ee3c th\u00e0nh c\u00f4ng, y\u1ebfu t\u1ed1 t\u00e0i ch\u00ednh c\u00f3 \u00fd ngh\u0129a r\u1ea5t quan tr\u1ecdng, m\u1ed9t \ns\u1ed1 t\u1eadp \u0111o\u00e0n th\u01b0\u01a1ng m\u1ea1i l\u1edbn c\u00f3 ti\u1ec1m l\u1ef1c t\u00e0i ch\u00ednh v\u1eefng ch\u1eafc \u0111\u00e3 x\u00e2y d\u1ef1ng thu\u1eadn l\u1ee3i h\u1ec7 \nth\u1ed1ng d\u1eef li\u1ec7u Big data nh\u01b0 IBM, website b\u00e1n  h\u00e0ng th\u01b0\u01a1ng m\u1ea1i \u0111i\u1ec7n t\u1eed Amazon ... \n(2) Ch\u00ednh s\u00e1ch, quy \u0111\u1ecbnh Lu\u1eadt ph\u00e1p v\u1ec1 truy c\u1eadp v\u00e0 s\u1eed d\u1ee5ng d\u1eef li\u1ec7u  \nVi\u1ec7c s\u1eed d\u1ee5ng v\u00e0 khai th\u00e1c d\u1eef li\u1ec7u l\u1edbn ph\u1ee5 thu\u1ed9c v\u00e0o Lu\u1eadt quy \u0111\u1ecbnh c\u1ee7a m\u1ed7i  \nqu\u1ed1c gia.  \n                                              \n10 Xem B\u00e1o c\u00e1o \u201cTh\u1ed1ng k\u00ea Nh\u00e0 n\u01b0\u1edbc v\u1edbi Big data: Kinh nghi\u1ec7m qu\u1ed1c t\u1ebf v\u00e0 \u0111\u1ecbnh h\u01b0\u1edbng c\u1ee7a Th\u1ed1ng \nk\u00ea Vi\u1ec7t Nam\u201d", "mimetype": "text/plain", "start_char_idx": 1762, "end_char_idx": 2521, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "d9a439cf-4879-4d21-92b8-cd54a59b2e40": {"__data__": {"id_": "d9a439cf-4879-4d21-92b8-cd54a59b2e40", "embedding": null, "metadata": {"page_label": "7", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b76c7696-66f0-4561-a858-b996bb766375", "node_type": "4", "metadata": {"page_label": "7", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "97a9693cacce216843314ceb9c925269dbd9a783ddbe285eaec07de6938cd8d3", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "8eb20c70-20c2-466c-82e4-69dbdc633c87", "node_type": "1", "metadata": {}, "hash": "b620072f8cb6224f5ec092d8a39b800930ecd9157faf92c4e6d3f2833ce9ce2c", "class_name": "RelatedNodeInfo"}}, "text": "K\u1ef7 y\u1ebfu H\u1ed9i th\u1ea3o khoa h\u1ecdc \u201cTh\u1ed1ng k\u00ea Nh\u00e0 n\u01b0 \u1edbc v\u1edbi D\u1eef li\u1ec7u l\u1edbn\u201d \n \n15 \n 07/10/2015  \n V\u00ed d\u1ee5: \u1edf Canada ng\u01b0\u1eddi d\u00f9ng c\u00f3 th\u1ec3 \u0111\u01b0\u1ee3c ti\u1ebfp c\u1eadn d\u1eef li\u1ec7u t\u1eeb c\u1ea3 hai t\u1ed5 ch\u1ee9c \nch\u00ednh ph\u1ee7 v\u00e0 phi ch\u00ednh ph\u1ee7, nh\u01b0ng \u1edf nh\u1eefng n\u01b0\u1edbc kh\u00e1c nh\u01b0 Ireland th\u00ec ph\u1ea3i \u0111\u01b0\u1ee3c s\u1ef1 \ncho ph\u00e9p t\u1eeb c\u00e1c c\u01a1 quan ch\u00ednh ph\u1ee7. \u0110i\u1ec1u n\u00e0y c\u00f3 th\u1ec3 d\u1eabn \u0111\u1ebfn nh\u1eefng h\u1ea1n ch\u1ebf \u0111\u1ec3 truy \nc\u1eadp v\u00e0o m\u1ed9t s\u1ed1 lo\u1ea1i d\u1eef li\u1ec7u l\u1edbn.  \n(3) Tr\u00ecnh \u0111\u1ed9 khai th\u00e1c v\u00e0 qu\u1ea3n l\u00fd d\u1eef li\u1ec7u  \nDo Lu\u1eadt quy \u0111\u1ecbnh s\u1eed d\u1ee5ng v\u00e0 khai th\u00e1c \u1edf m\u1ed7i qu\u1ed1c gia l\u00e0 kh\u00e1c nhau n\u00ean c\u00e1ch \nqu\u1ea3n l\u00fd l\u00e0 c\u0169ng kh\u00e1c nhau tuy nhi\u00ean, m\u1ed9t v\u1ea5n \u0111\u1ec1 li\u00ean quan \u0111\u1ebfn qu\u1ea3n l\u00fd th\u00f4ng tin hi\u1ec7n \nnay l\u00e0 ngu\u1ed3n nh\u00e2n l\u1ef1c. Khoa h\u1ecdc d\u1eef li\u1ec7u l\u1edbn \u0111ang ph\u00e1t tri\u1ec3n m\u1ea1nh trong nh\u1eefng t\u1ed5 \nch\u1ee9c t\u01b0 nh\u00e2n, trong khi \u0111\u00f3 b \u1ed9 ph\u1eadn n\u00e0y ch\u01b0a \u0111\u01b0\u1ee3c li\u00ean k\u1ebft v\u1edbi nh\u1eefng t\u1ed5 ch\u1ee9c c\u1ee7a \nch\u00ednh ph\u1ee7 m\u1ed9t c\u00e1ch ch\u1eb7t ch\u1ebd d\u1eabn \u0111\u1ebfn vi\u1ec7c qu\u1ea3n l\u00fd v\u1eabn c\u00f2n nhi\u1ec1u v\u01b0\u1edbng m\u1eafc.  \n(4) H\u1ea1 t\u1ea7ng c\u00f4ng ngh\u1ec7 th\u00f4ng tin  \nC\u1ea7n ph\u1ea3i c\u1ea3i thi\u1ec7n t\u1ed1c \u0111\u1ed9 d\u1eef li\u1ec7u truy c\u1eadp v\u00e0o c\u00e1c d\u1eef li\u1ec7u h\u00e0nh ch\u00ednh ngh\u0129a l\u00e0 \nc\u00f3 th\u1ec3 s\u1eed d\u1ee5ng giao  di\u1ec7n \u1ee9ng d\u1ee5ng c\u1ee7a Ch\u01b0\u01a1ng tr\u00ecnh chuy\u00ean s\u00e2u ti\u00eau chu\u1ea9n (API) \u0111\u1ec3 \ntruy c\u1eadp d\u1eef li\u1ec7u. B\u1eb1ng c\u00e1ch n\u00e0y, n\u00f3 c\u00f3 th\u1ec3 k\u1ebft n\u1ed1i c\u00e1c \u1ee9ng d\u1ee5ng cho d\u1eef li\u1ec7u thu v\u1ec1 v\u00e0 \nx\u1eed l\u00fd d\u1eef li\u1ec7u tr\u1ef1c ti\u1ebfp v\u1edbi d\u1eef li\u1ec7u h\u00e0nh ch\u00ednh. Ngo\u00e0i ra h\u1ec7 th\u1ed1ng khai th\u00e1c d\u1eef li\u1ec7u l\u1edbn \nc\u0169ng c\u1ea7n ph\u1ea3i \u0111\u01b0\u1ee3c t\u00ednh to\u00e1n \u0111\u1ec3 c\u00f3 th\u1ec3 k\u1ebft n\u1ed1i v\u00e0o \u0111\u01b0\u1ee3c kho c\u01a1 s\u1edf d\u1eef li\u1ec7u truy\u1ec1n \nth\u1ed1ng, \u0111\u00f3 c\u0169ng l\u00e0 m\u1ed9t trong nh\u1eefng th\u00e1ch th\u1ee9c l\u1edbn c\u1ea7n \u0111\u01b0\u1ee3c gi\u1ea3i quy\u1ebft.  \nT\u00f3m l \u1ea1i \nTrong b\u00e0i nghi\u00ean c \u1ee9u tr\u00ean ch\u00fang t\u00f4i \u0111\u00e3 \u0111\u01b0a ra \u0111\u01b0 \u1ee3c nh\u1eefng th\u00f4ng tin c\u01a1 b \u1ea3n v\u1ec1 \nBig data, nh \u1eefng l\u1ee3i \u00edch m\u00e0 Big data ma ng l\u1ea1i. B\u00ean c \u1ea1nh \u0111\u00f3 c\u0169ng ch \u1ec9 ra nh \u1eefng th\u00e1ch \nth\u1ee9c khi tri \u1ec3n khai \u00e1p d \u1ee5ng khai th\u00e1c Big data.  \n\u0110i\u1ec1u quan tr \u1ecdng nh \u1ea5t trong b\u00e1o c\u00e1o n\u00e0y \u0111\u00e3 \u0111\u01b0a ra nh \u1eefng \u01b0u \u0111i \u1ec3m c\u1ee7a Big data \n\u0111\u00f3 l\u00e0 cung c \u1ea5pth\u00f4ng tin \u0111 \u1ec3 chung ta x \u1eed l\u00fd \u0111\u01b0 \u1ee3c t\u00ecnh hu \u1ed1ng nhanh nh \u1ea5t, ch\u00ednh x\u00e1c \nnh\u1ea5t v\u00e0 gi\u00e1 tr \u1ecb c\u1ee7a Big data mang l \u1ea1i lu\u00f4n c\u00f3 t\u00ednh \u0111 \u1ecbnh h\u01b0 \u1edbng \u0111\u1ebfn t\u01b0\u01a1ng lai?; Gi \u1ea3i \n\u0111\u00e1p nh \u1eefng c\u00e2u h \u1ecfi t\u1ea1i sao vi \u1ec7c \u1ea5y l\u1ea1i x\u1ea3y ra?; Sau chuy \u1ec7n \u0111\u00f3 th\u00ec \u0111i \u1ec1u g\u00ec s \u1ebd s\u1ea3y ra? v\u00e0 \nch\u00fang ta n\u00ean \u1ee9ng ph\u00f3 nh\u01b0 th \u1ebf n\u00e0o trong ho\u00e0n c \u1ea3nh \u0111\u00f3?  \nT\u00e0i li \u1ec7u tham kh \u1ea3o \n1.", "mimetype": "text/plain", "start_char_idx": 2, "end_char_idx": 1996, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8eb20c70-20c2-466c-82e4-69dbdc633c87": {"__data__": {"id_": "8eb20c70-20c2-466c-82e4-69dbdc633c87", "embedding": null, "metadata": {"page_label": "7", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b76c7696-66f0-4561-a858-b996bb766375", "node_type": "4", "metadata": {"page_label": "7", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "97a9693cacce216843314ceb9c925269dbd9a783ddbe285eaec07de6938cd8d3", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d9a439cf-4879-4d21-92b8-cd54a59b2e40", "node_type": "1", "metadata": {"page_label": "7", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}, "hash": "3ca4bd5a1fe0974a3f0333e6938cb15d811e2701bbccc2540e274e5499ebe80f", "class_name": "RelatedNodeInfo"}}, "text": "; Sau chuy \u1ec7n \u0111\u00f3 th\u00ec \u0111i \u1ec1u g\u00ec s \u1ebd s\u1ea3y ra? v\u00e0 \nch\u00fang ta n\u00ean \u1ee9ng ph\u00f3 nh\u01b0 th \u1ebf n\u00e0o trong ho\u00e0n c \u1ea3nh \u0111\u00f3?  \nT\u00e0i li \u1ec7u tham kh \u1ea3o \n1. T\u00e0i li \u1ec7u c\u01a1 h \u1ed9i v\u00e0 th\u00e1ch th \u1ee9c v\u1edbi bigdata \u2013E c\u1ee7a Li\u00ean h \u1ee3p qu\u1ed1c: \nhttp://unstats.un.org/unsd/statcom/doc14/2014 -11-BigData -E.pdf  \n2. B\u00e1o c\u00e1o H \u1ed9i th\u1ea3o v\u1ec1 t\u01b0\u01a1ng lai c \u1ee7a Th\u1ed1ng k\u00ea h \u1ecdc London: \nhttps://statistics.stanford.edu/statistics -and-science -london -workshop -report  \n3. T\u00e0i li \u1ec7u v\u1ec1 c\u00e1c kh\u00e1i ni \u1ec7m v\u00e0 \u0111 \u1eb7c tr\u01b0ng c \u1ee7a Big data: \nhttps://viblo.asia/dovv/posts/3OEqGjWwv9bL", "mimetype": "text/plain", "start_char_idx": 1869, "end_char_idx": 2382, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/metadata": {"1c499b06-8d39-4018-8cba-3072a31162a2": {"doc_hash": "563c33d69d041c21fce0901677202a1f010be628e6b9679e27353c15c0f635f4", "ref_doc_id": "990d5a0a-ff21-49ae-9f9b-aca070ee1d3b"}, "bfa46f02-06da-4e91-99e9-73c82ebc0422": {"doc_hash": "5fc3dde0218b9a9afc5152381895776ec19152b3b78698904078ccb49cb896ce", "ref_doc_id": "7da7c154-5ce3-4f09-bcce-23bad9759c26"}, "627b8055-2ea7-4761-aac0-ee50e34d6e65": {"doc_hash": "03f14dd96b60b74f60cbeefd2f3830f54e9d035263beb5ae5e2c60dc684e9c3e", "ref_doc_id": "30588c47-3769-4559-9150-191e3ee64deb"}, "dceb6d32-1239-45f8-b672-48fd07225ad1": {"doc_hash": "1c641c51dd7ca2c8e520dd2a95e0b9ea72ddb7756463c8d30106bd645635d414", "ref_doc_id": "a9d49cfa-13a0-4363-b27e-da21f2171d12"}, "8ca971c7-6224-40d6-b8bf-d36fd949c430": {"doc_hash": "fa9f4d42a9b8fcbf0c4bb5062920118351bb9ddad05f922546cf9590f1422ad6", "ref_doc_id": "623c07c6-dc64-48ec-b3e2-3a11e8eca303"}, "22cc4735-9ae6-4ca6-9759-2f4ba7402ca3": {"doc_hash": "1c5256e82a3adf5d8a00c726811e65a7ad7891bcceff989ef7e5507173298a9d", "ref_doc_id": "182ed2b9-c4bb-44dd-b185-688eee6a42f8"}, "4f41a260-27fa-4fc8-924c-14c518735e49": {"doc_hash": "a9d4ae61d96f199053377b8d8cacf12d75a20523169976580cf5cbb379292afe", "ref_doc_id": "fdd210c7-6472-4898-9275-488f37d13d07"}, "f632140f-2f08-48a4-a0b5-b6e1985a0b4f": {"doc_hash": "82eaa5164e7dcf68f906f62d93ca2a73cc5bbcd48b812b2a09116beda313601e", "ref_doc_id": "5eb4a6a2-51f8-4512-bc8c-5970d58995a6"}, "64db8ff5-b779-4d6c-93ce-c0417d026c47": {"doc_hash": "5ddeb02bba0516fa785f8e8845d2ea796dbc225d2c8658ad2ae4d5d38443a094", "ref_doc_id": "1515bd40-cb74-46a7-b259-d7ada9c2b694"}, "52191274-fa0f-4415-ab2a-ff42f4525039": {"doc_hash": "d895565d5a036a8075fa1a700b1602bf2a96caca85e7f310616a8bb8c625ad20", "ref_doc_id": "ee1eb0b2-ca53-47ac-b549-cfbac4f2ef9e"}, "10cd6d67-a197-4ee6-a965-58939962ac27": {"doc_hash": "b305576528f7db70f91b0b5ee3772a7a88f6e9257cd871f1b1a2b8f33aa5f386", "ref_doc_id": "5f5b7b95-c49a-4d68-9add-63261a940cd6"}, "0c9fdd17-2bbf-4291-b81b-ff72b815ac0f": {"doc_hash": "b33cb06b05a292e89e6df8aa2bc9b15d5c8d4d86770a288697fdb8f20a8d50d6", "ref_doc_id": "db087b54-6335-4f07-b24c-9484120257b8"}, "58257069-7df7-448f-b3cb-7c42c8988c86": {"doc_hash": "3c24cd1b77cca0f16ba3281427c10c8b2e92a90b7ddc128856735d57e05f9ca9", "ref_doc_id": "1afbaf7a-26b1-4a39-9785-630dc7dff1b7"}, "b5a639e0-00fb-4377-a143-1dd97e22ba7f": {"doc_hash": "13637b9186fb7e9a6c6374934dc8a7e3f5cf7583cc66fd98910b99baa6f4418f", "ref_doc_id": "4e6f2ad7-d964-400b-9090-04bd5f064076"}, "b46bd0b9-cb37-4f9b-98b9-70b522c48cd5": {"doc_hash": "399cf2dee9d092cf8a2a9aa2e4fe082d54bda324ba0ca7d97a1fdd3af06a754e", "ref_doc_id": "add41a6d-9cd4-4329-96b7-1fc9fb599b59"}, "b7f6a232-4405-428e-b5f4-ff10e689b86b": {"doc_hash": "e0cb07ac7a0f6da493f636a4ae97e774180fd94a490117538e77a60381cf4536", "ref_doc_id": "24c290db-6e80-4b5d-ab45-2a4f277f0da2"}, "1a7469ed-d316-4acb-9c87-72301c2a0cc3": {"doc_hash": "a3b28051f3c30b2edc0b4b128cc28c39fcba0d627c62ce29e19f6d9b0f1ac405", "ref_doc_id": "38193ee0-f7f2-4ac6-a473-4769d7153f8a"}, "1c18d600-cb18-4830-8d16-cc45f9f449fb": {"doc_hash": "6f313a8c4902694c76b78e3f8e17fc3513313b9c4b983b9d4093965b142d1ed4", "ref_doc_id": "e5f26531-e198-4035-bff8-1af96ff50c08"}, "84a2e502-7962-4995-aa49-7c39b285357c": {"doc_hash": "20d020627b3b9b513619b670da9ad6de397bacb6f33d03c8572c41164e1f21ff", "ref_doc_id": "f9c9bf02-14ff-44f0-b6b4-e176d85f1243"}, "7df46486-3d2d-4d7b-a149-fe5aedf8abba": {"doc_hash": "fe7c98933fb88811fc8048674884cd8af7b11381628ffbcb6d90120c833303f7", "ref_doc_id": "7bde4a0c-3abb-4812-a776-0081cb0f041d"}, "a127573a-66cf-4185-80e8-efc416c418c3": {"doc_hash": "2c432fa211069e6f782c8279c7b61b958bd97ff4bdcc477787a041552767a90d", "ref_doc_id": "0fc55273-b276-416c-9c81-358af7196828"}, "ede77671-55ee-4ccf-a1e0-f64f6ca95335": {"doc_hash": "2407aa6479311c0bde0f563cf9d6a155878009ba42707c0a974b9e2b5eccd2af", "ref_doc_id": "1f06629b-27e4-4894-9d8b-0b07da8e72da"}, "1f20346c-450b-4af7-8b32-eb4b1ff9ee95": {"doc_hash": "68692da20bf4bc29ba576d0129b474870b23fafcfa94950610284cef00d58e08", "ref_doc_id": "f7694119-2b09-4d92-a212-8997d53de37f"}, "b4838e3b-5c31-40aa-aa36-fcbdefd53486": {"doc_hash": "26d0590b717eb8362522c99c3a698b333565cc490a44383b366eed7de310a721", "ref_doc_id": "e9e1d51a-6ebe-45a3-8078-ef5a067f60b3"}, "7dba5258-79b1-4fd1-b861-c5885f73f725": {"doc_hash": "b104e0a85c6c143062e514961eb0df679ed8abd33ed30fac29bae0a4b23fc0fd", "ref_doc_id": "fdee8dbf-d211-425d-bfdf-ac1c031e3456"}, "71d3b5d7-0e4f-44fd-94ff-28dfe80b0cc3": {"doc_hash": "707f2086736cd2d06425e1b1d6074c877b5ac07343f695bf72c987c9b49a39a3", "ref_doc_id": "687719a0-d285-44c5-88d4-815633ba23ac"}, "e8eb14d5-7623-48de-949f-e2a0e40d9545": {"doc_hash": "f21300548330fec5e3ae6739391610ad6cae7a0dd818e0da696965fe4ff8f086", "ref_doc_id": "cbdd4b20-05a2-440a-b858-75c72c490441"}, "cc598e55-3726-463d-a41c-e3f164fed00f": {"doc_hash": "43e598c3be396535d3c3f9696d8dd4de932ddad4c72f9a2de4b68fdc6dc49037", "ref_doc_id": "9fd7f062-5d6b-45af-ab7e-045f9e8f93e8"}, "6912f116-7f59-4849-bf1a-dc01e725e38d": {"doc_hash": "ef6f65cf33605216c262d88a3cb459f88bd9b6416fcc3b87e37b1a5d0013656c", "ref_doc_id": "c709785d-1ba9-49cd-a20c-2af8e62503e9"}, "96d1d749-48e1-4036-a7d1-18486720c458": {"doc_hash": "2a33e33d25adf3833c796f51b878f13a75a898ddb50572512c90d88e3ad36e90", "ref_doc_id": "18404ac8-1ea3-4b5a-ba6e-3be614d4c79b"}, "f30623c8-d72f-40ec-9ddc-966bfbe57c7f": {"doc_hash": "09ec5b42bb5b198d3240b5cf60acedb64af12ef7abfdba6c75f7fb1ec9111d60", "ref_doc_id": "2833af7b-0f23-46eb-a7f4-0ab540839ee7"}, "fc0a2d95-b0c1-490e-af6d-c13f356b2b08": {"doc_hash": "f6fe8f3f4aa5203c9b7bd329b218ef9ea2f4e5defcdb79692832c9148b7a0bc4", "ref_doc_id": "f881c3f0-275c-4869-8d2b-9b3cb254d004"}, "df827497-e7f8-47f0-bd42-900afc0c851c": {"doc_hash": "905c9c7749fda58d057cf61fcb2a263e234b26da64594aaeff7a0e8105db495e", "ref_doc_id": "dc7b01c0-4fe2-4f7b-9ae3-5bcd84cbbb6f"}, "416304b8-e98c-4eb1-af50-e8278024caa7": {"doc_hash": "7141d3484fe622e0efdb9ccceeb8f95340ad08602a4df421a12f0fc4ff5a5a6a", "ref_doc_id": "aad7331f-3acb-45f6-9c15-598b82182840"}, "83647c3a-18a1-497e-8fe3-8fc7c1b8f57b": {"doc_hash": "b3ce0ba692a050f01da9b3a70eb03d17b152c8a63750131e5524c18ebe12722d", "ref_doc_id": "f83de73f-8a35-4668-940e-d1d2009b49aa"}, "aa09dd1a-df2d-405d-87e9-c474b6085fde": {"doc_hash": "712ab055044848777f3b1018323751796f14b984b0bb334c57380be769638483", "ref_doc_id": "770f4e5d-7f66-45fa-9613-a346e9166ba9"}, "f75ad44c-6312-4d54-bdf2-660cc74eb0f6": {"doc_hash": "275f04fc99e293cc911cb7b51d1b418d3744681a76b1a547eb75eefc7f700dd8", "ref_doc_id": "25badc8a-7be7-428a-bd7c-3c24b46a02da"}, "b23dc2fa-1750-4014-8fd0-c73df41ddde5": {"doc_hash": "d046b3ea33f66e1382534e1d2792a47a00d6fcbe37751a15fe150994cf4a69ff", "ref_doc_id": "7d898864-7f27-4f06-b4f0-e27bed0645dd"}, "016cf1bc-154a-4154-a7d2-12ee63880b6a": {"doc_hash": "57c27e9506d11ad084fd91938cbeecdaa8a1a012a4191ec0fbb03f3553f96b10", "ref_doc_id": "53d20576-64c6-48ff-8fde-7f89b326f1b4"}, "f056b2e8-cba1-4c65-948a-cd4e8c818767": {"doc_hash": "7e6f38cb1180cb286ca18349f9f16f3070894658f66ad46ed5a4777c45c2df1d", "ref_doc_id": "18197570-beb4-4df9-96a1-3515edd0435e"}, "05927414-2f6d-4783-ac0f-c50b84b61425": {"doc_hash": "b6ffbb97a1f1e879ed6f4615aafab0204c97ba37c43476b7e38c6cf6e77d5dbf", "ref_doc_id": "ae261330-b637-4903-97f6-c898d15dda64"}, "6bad8a95-b7f9-42a2-bc1a-99fa597fe34f": {"doc_hash": "aa6e05d87b9942654d0e9480d30b973502c490dd45e5fc37c70468685ff9c7a9", "ref_doc_id": "70b35b3e-f04d-45fd-860a-1b1c97c568c0"}, "b9172eb0-ec3b-4bbb-bdab-6526d904b1f4": {"doc_hash": "3096f100cc32e252c4441c65aa4eed948291747339064e6df9de8daae8fc7f3f", "ref_doc_id": "b4ecd103-8507-4004-ad74-c205df9e9ffd"}, "38a35138-9888-490c-9112-205ee13926cb": {"doc_hash": "f0612299921ad451cc712e100568deb0145f0d4651368306f2ab858d23578769", "ref_doc_id": "154704b8-3bcc-411c-8901-8d3fe0c953f9"}, "01b12f0c-a34c-4d14-86a9-06d77d785dc4": {"doc_hash": "3d976e5fab98e8bd282f5f5a4c191b0b7d7021fb3ec15453579499f3ce2a9daf", "ref_doc_id": "2be2394a-cc8c-4a4e-ae04-1811d458e1ef"}, "9e6db758-6838-45fc-a3fc-3165f2035758": {"doc_hash": "1d825cc0fe0f53b6cb237c03e153b9933f98f8fd33394212a3bd0fde14349534", "ref_doc_id": "6b2ab650-88c9-4865-9b72-d01ca08b4929"}, "9c74de90-8788-45c4-bc89-78cbd3771056": {"doc_hash": "d36f183eb58669bedfe00d10e6e5da87cd9941df7b7b560c570916f7fd923e2e", "ref_doc_id": "861d2581-e95f-45d9-b4b8-9c8543eb9da4"}, "69a52692-289e-4636-ba2f-2908048d16d3": {"doc_hash": "7eaffc3a9371698d02956471abf4b37989881efd7f383b8aef7b298716538071", "ref_doc_id": "d7f54e9a-aa39-4e06-a0c7-345c072dece2"}, "ae862104-0c74-4494-9bdf-5527bc020690": {"doc_hash": "3766dd385a25aebf07eb1b78fddbaf8059f1bf45df4edad7823447d5f97134cc", "ref_doc_id": "abb4fca6-7932-4eb8-8e20-52f63333a267"}, "7f72acc5-8565-421b-8bf6-2e11ed905a42": {"doc_hash": "d9084575ba234b559b9961f384d4be1f0458b814d16f9a04150d43ce1b84d3d3", "ref_doc_id": "9da4a0cf-c59c-4a80-8d23-5b1d11bd8ce0"}, "d5befd32-df74-4378-9322-2ed57576b223": {"doc_hash": "86813f3ed381f82e83bf78caf3fa9ee90a72753f03cd34919b91a5abd7435876", "ref_doc_id": "e9e1582e-fbc9-43c7-9d78-e84159661848"}, "6430b7fc-dcfe-4574-9881-6c8b779fd948": {"doc_hash": "89cf549b73820ab3cb12b1728efa647fd0aff6da262857cca09a1883ac7da366", "ref_doc_id": "a35943a2-5165-409b-9bc3-1a9558727e77"}, "55b64325-ab98-4cc9-97b3-e0b39b4e320c": {"doc_hash": "c64cc6858fa24a7c97c67113e2df1df2a301a35e4f41949d8ad58afd5f4602fb", "ref_doc_id": "8809e13c-4214-4be4-be77-d93d7ba83c97"}, "dfd7f519-1ec6-419d-b84e-85eddd64770c": {"doc_hash": "7865bfbc0571bd442545d060da23a29e818dfbaaf6584c6bbca5d3f9498e8330", "ref_doc_id": "1909214c-21c4-4888-9bda-6690844f028a"}, "f2743124-a7bd-4731-969b-800724abb3f8": {"doc_hash": "02177b666f30164b1018e07a572c0f2c8854812046a094521f740ffa2b7d0d41", "ref_doc_id": "cc067170-9481-4d84-8161-f23f85ade5fe"}, "04eddde6-058f-4932-b0cb-2d2d3b1f5f82": {"doc_hash": "67b4ca7c042f125be9051798977cd9eadaaae51b5db2ba20a91a96570f67f5e2", "ref_doc_id": "0b8ca2ee-09fb-472f-a47e-efb41df0646b"}, "5a367bc0-214a-4e17-8fdd-d03f9493ca1b": {"doc_hash": "b04e4f73820505852f9b8f003fd8329a9e30bf4e0e6310586f24f47df2157d45", "ref_doc_id": "3c2ec10b-1923-4ad3-9fbb-0d652108f56b"}, "b7fb92d5-6add-4256-adfd-54dc952d4c63": {"doc_hash": "94f154f236354393f0ceb3ee75bb75d4032b4f0ff7fce446655c984030d83686", "ref_doc_id": "762f1898-543d-42ee-be6c-c3b7b90defd3"}, "502d0435-d232-4e3c-aeca-66c6b2c71ecd": {"doc_hash": "f908cecacbcc0f569f3ed47121ea37bfc82772a22dbc4cd6be86050ed7560591", "ref_doc_id": "5c26ff28-7c69-43d7-9c40-25dc6211b963"}, "bc98d551-60fb-43ec-ba2e-cdb19241d1fc": {"doc_hash": "b9fe2c135ff392abdac61dd179bf9b8b72ab96376bb2ecf73eea2f51a76c1812", "ref_doc_id": "6e0023b3-5f56-4b61-a6f4-50b2662c018b"}, "b50a1121-caf0-436e-8467-33958573a814": {"doc_hash": "e4b6dc915d210ea0d3ca930438b892e14901f6ef791ec02c8d5edccab5833e39", "ref_doc_id": "3df96586-7106-476d-996c-012bfd1592f6"}, "6309e7f6-f92e-454d-95a5-4a731837255e": {"doc_hash": "c9b8627ec168bdaecaca2d17a963cba27bbedc712e3627181382390f5463573a", "ref_doc_id": "303f05e2-b71d-41b1-9d97-28f005575751"}, "a9b56321-12a6-44fc-8fa0-676d49e9d4fe": {"doc_hash": "e1564aba857f0b48a11d233ad247c4f9236627bb01660c3b82bb681d1a27ae78", "ref_doc_id": "088e07f9-527f-436d-8c73-67a0dd9afc08"}, "7776f955-0cfe-44e9-ba7d-876bbe43b324": {"doc_hash": "ba1662236d81d3bf6301dc8981d77e735bd6fc059186edc34c606c68b1ec213c", "ref_doc_id": "e7a6ce7c-c408-4304-ab3e-7718c3e93b9c"}, "c7658495-35b6-45c2-b355-e76c894149e6": {"doc_hash": "b446d4ee210a2fc62eefe4f1a0b6d7d0ef16dffb928407d51354c6b2a81ede89", "ref_doc_id": "072532b4-2f84-44c4-8cef-569391b26b73"}, "1e11589e-23ec-48c8-af3d-b465df560fda": {"doc_hash": "133a2ab7e6503d2aa3c4e868e7e725ecfb0cfbb71ba7bbaf6fca974e12fb0a32", "ref_doc_id": "789c9478-0b05-45cb-935d-f9f7b9d87cb8"}, "9990a41c-7e4c-40c5-96d8-29eeb007ca68": {"doc_hash": "df213b4ffdf188871087c677cf4275917151e9b1a4d85d09a6d141dfdc83ce4c", "ref_doc_id": "7db26a35-d98b-4751-838a-8933cac6676b"}, "960bd5b6-4b6c-4bb0-98fe-f06926fd2aa2": {"doc_hash": "c8e3c4230ee294b5da5047d6634138e57a40dcf721a0a347ecd7d009d06cab8d", "ref_doc_id": "76cc42c2-df4f-4bad-aa4f-14b325a6474e"}, "41ca92cc-eb5f-4f66-b141-ca1721a17825": {"doc_hash": "d26c941e6c936039b7a9b3b4e3e0103821812ce449997f276da5bfb1aef988d3", "ref_doc_id": "5363b295-01e7-403c-b0b5-d29f3934f425"}, "9d2aa456-fc45-463e-8247-7fc7fcd0210b": {"doc_hash": "e2d3a2995c81bbbd85411cb4fc690be7fe4f90d10fc7d78fbac6bd797d532e0f", "ref_doc_id": "47acf3aa-98be-465d-9ed4-3cdf86aaba5a"}, "c76dd16f-008e-4de5-9e1f-c406e8b5eb49": {"doc_hash": "5e259e60c2fad89a3fcbca2d5ce5e9a320189333541c23a2a5b74de468ec5f8d", "ref_doc_id": "b80b644c-5dda-4322-a136-3db5f90ccf26"}, "caf662cd-0c3d-40a0-b885-146aa789d234": {"doc_hash": "5259e0a68e660231b237accee2cfb36fcc0493ac4ba823fff821dd894b72aac9", "ref_doc_id": "f1ff4e11-dcdb-4d7e-a025-db7809aab15c"}, "7cee21fa-d803-4944-b75d-33b15171618f": {"doc_hash": "297961a4d22127cd044060bd932fb7d8f9575c196cbec7260bd6f78f7526d223", "ref_doc_id": "8935afab-06b2-41a1-b0e5-4029f432f945"}, "2276c69c-564d-4470-b324-be564794219d": {"doc_hash": "58c7aa189a3fe2829c88c58092198b1a1c7adace79233c6fd9fbeb92f6224a4e", "ref_doc_id": "33aae2a5-2d40-40c3-8832-6532e2371a06"}, "bd4f6ce9-d856-48f5-ad5d-be1a99e77b1f": {"doc_hash": "2a0339035ceaead2ce77dae69c1dc94c4c40b728d2fe32f2b7d95cea895deddc", "ref_doc_id": "8cba6683-5b9b-44a1-8faa-7e06016af901"}, "ebfc7bda-02ed-465a-b48a-90466196fc53": {"doc_hash": "ee3e3f9282f19f278a352c66d88f92704e05f801086079baca4046391097953f", "ref_doc_id": "76391841-6341-4597-af7a-4aee02407493"}, "85a7a65b-447b-4cf3-af73-dab1117fac79": {"doc_hash": "d938feffc089439851e7278ece56bf3e8e79622d319a2ce2dee1dfc4774ddd08", "ref_doc_id": "19087e09-d00a-4d9c-8c64-4315a80e911b"}, "62ff0e38-0e10-489a-8345-d9f6f675d966": {"doc_hash": "953c1de3d914b5f0b44d27c0b7784d217a0ea57b70e7d59a7b72c834043922bb", "ref_doc_id": "b1cd56ba-e4f5-4fca-9775-de169ba162fd"}, "dda11bf1-21cb-4f7f-bdf9-52db52f9f714": {"doc_hash": "b98bf631d037bd8dff18a954469935fde8a582e205e8515090b022bf0d4b3f4d", "ref_doc_id": "1fe1f4fa-8305-4991-aabe-0a0127461246"}, "e30c08ed-ee03-405a-8aeb-1d04c0e66263": {"doc_hash": "66b8236fdf0c147857231059e986bbba482d6ec73ad0be79a3ae7cd4d89ab463", "ref_doc_id": "633a5fb3-f11e-49fc-826e-91286aea444c"}, "4aa43e2b-e3ae-4c9e-aebc-ac5b1af341b5": {"doc_hash": "dfbcecf87f3e450557a408181596b17a06e3604c7c83e7ff51f1004df5e6602b", "ref_doc_id": "9e9b96d5-141b-4a8c-968f-e486b32a9b31"}, "bf33f898-0d9e-4f80-8bba-b5de0bf0e42c": {"doc_hash": "97633eb2606b1c9a7998338aee37120fbd5a1a3ab17dc5cabf6aae879c9c8428", "ref_doc_id": "e456140c-c4a7-4997-b815-afc82a507e96"}, "b7d470a0-0207-4ffb-85ae-08907cbdff90": {"doc_hash": "25d467f3c2d77c7762dac2a05ce9253e7c2f7a9766de6498e02ca8d9f91ca6ed", "ref_doc_id": "412e1c50-ae5f-4a0c-a918-4cf8c9b848de"}, "f06c7da4-ef89-4e2c-a5c3-addc83b3f5ff": {"doc_hash": "e5cf30da2812d1d2780448a1469462b0437fe43a85c90bef7f3c9cabde5764c8", "ref_doc_id": "1f689f58-d141-45e7-9cb9-fb05deebe3b7"}, "b29b117b-4ea0-4501-a217-53ff442e269c": {"doc_hash": "92be80b2aaef114edf8d79c63b3946e5ea9139500e22f0077ca3adce687cd058", "ref_doc_id": "f664c88d-2230-4779-812e-628fa91613d9"}, "68984963-ea1c-4802-b377-c491dbe52d90": {"doc_hash": "e85e041cc058342b628b791647fd8d4569473b058fa785e1c1c1f84215ff73b6", "ref_doc_id": "54e22b93-1866-49b1-8741-72f3dde3e9ba"}, "ddf4f988-2163-4b79-8a1f-51b587ba0c2d": {"doc_hash": "204fceeaeeead9d4ae3cb869745a227a277d9126970a9c6ecf49ba50e09c38ae", "ref_doc_id": "d76bf612-b91e-4cb5-b167-319e6b4124de"}, "d37c0e91-f60c-4aec-8497-39047c9184ea": {"doc_hash": "467edbebd85bf0e2ca1cb22ca37d52f7f17f78afaecb99990c629df1a65fe634", "ref_doc_id": "78896c01-86dc-462c-8d8d-c63c69bf06a9"}, "ab073368-dd14-459d-99cc-af03886c3d5e": {"doc_hash": "2b54a80710d4463ece14e597a48c1d370720f7a41d29d7f50146c29f021e8317", "ref_doc_id": "d08cc022-e77d-4013-8578-624a3b43eede"}, "7be23bdb-4de7-41b3-bae7-37388f301f18": {"doc_hash": "83bc33cdcbfa34c614a69a1326df55d59ad6c11ba7c873961c94124f6021bde7", "ref_doc_id": "44970fc6-30f1-4d13-b461-959a2ad61167"}, "29218d44-dac3-405d-9b58-466b9ef8c329": {"doc_hash": "3575323e0adf9f947dded87be35bf185264266f4a9fa9c55bf0a3ce711015ec1", "ref_doc_id": "6da3cef6-fdad-450e-ad0d-208b2ff8c5ff"}, "74540af3-2d2d-4898-a9fa-3d4537aa1c8c": {"doc_hash": "9ba328c35a6ddf94724d07f70dafbb92523105f1f626d2afe43b729800006e3b", "ref_doc_id": "986f52c2-566a-48bc-a216-8b5872a16c09"}, "a9fa857d-3ffa-46a8-8ba7-5c60d84183f6": {"doc_hash": "d2080ee3ff2cf89073b7f83b926f7248a5812411e334d296ce8e42769d6d66c4", "ref_doc_id": "3394eadc-6c2f-441f-8359-0198d175d268"}, "5314a636-f37a-43bf-8718-a246afa4ae9e": {"doc_hash": "7d32d48d3cd2845a41ee084eb715910ee5402e127472b15fa4139375f80f1cf4", "ref_doc_id": "de99e74a-2c30-4f13-957f-8a25b3bede74"}, "7d045b72-b4cc-407b-b64a-b3de06aede07": {"doc_hash": "10dc32de48fb613c8b080603cf04b7a033f93fbe3e5a9d648911317ab10a402f", "ref_doc_id": "fb8fccac-e91c-4977-a1f9-5fbf1b34cf4f"}, "1dfc56be-d193-452f-9c34-20a80657fe04": {"doc_hash": "cf35e4d58dc84d02d967cef366f19493c90ea280e3f28c0d8e0f4276c7ea4ef7", "ref_doc_id": "ae516bc4-5ccf-4779-9c39-d9acc60c3f64"}, "a47226cf-5a76-448e-bb32-450c147a5998": {"doc_hash": "3d509e970d299a9b16de00f91685172d8061bd396a643418e4c396e9ef7b60e5", "ref_doc_id": "03d2c4f7-df57-4bb9-87d3-b55a57ca5d21"}, "0a1ef699-6293-4029-beec-37d44eeb1968": {"doc_hash": "b9e17cabeb7834571cf5c6996e20315ce7b29da0b1b6ac20ba250eb446b5ff07", "ref_doc_id": "cda25f40-70c8-486d-a777-93bfa479f9c2"}, "23556950-35ac-459d-a3ab-d434064db509": {"doc_hash": "20e2054b29950f32995fb2be3d23af6236c437d8d71d597c2f5fe0ecc54548ea", "ref_doc_id": "9c3444f2-48ef-4e90-9211-d05861dfaae9"}, "ff7f3970-740a-43e4-aa8f-3f9dc9af42d0": {"doc_hash": "f8ca52114874a54b1f9a1b0ca98fe64b9776951e68b8624709bf9cd55e28d8a5", "ref_doc_id": "a739f3b5-bf8f-4b6a-9ece-7abacfa5a660"}, "a3e21b2a-6c7a-4f34-bedd-b141ef208024": {"doc_hash": "16d7a7b588e7c14ac487f235081a523cdbb2d745b91bba1548b22400d5fdd425", "ref_doc_id": "a41d8a6b-be4c-4a89-a872-3f358da6b866"}, "8a31455f-da85-4e18-b8ee-0a69f5d824e7": {"doc_hash": "ba306aa0cfe664fad56580e71547f062c6ea75ac864eca6eb0cc5165a90ddc71", "ref_doc_id": "d8799478-d6bf-4e85-9097-4b0b675635f0"}, "177b540d-6dae-4cc6-98e9-71f82acc42e7": {"doc_hash": "1c91834b652e8c7e702f674e5c42c35320dd0f3c49569e1bf65f4077e2cdfc6c", "ref_doc_id": "e75d13be-0ea3-42a3-b1bb-3a9b9b9939cb"}, "c0e5fe3b-2145-4ad8-b20d-5469d0f5f00d": {"doc_hash": "ed4b05e1c459e71c9c13f45a04960483f316f7f329a0bd3765675e47d6a8ced8", "ref_doc_id": "dca8bc72-a99e-48f3-90c8-0245b68c6c1f"}, "7a2124bb-0138-40a5-9fe4-76b05b1c1bc3": {"doc_hash": "fb89807cc6a60256c7a39d572bb19dcd0e1057a9e3d14baa265c35e3e3d0f548", "ref_doc_id": "15931bbb-acee-45d5-90d2-0a11f8fc0dc7"}, "131564d1-950b-49c8-9ae6-3ca3b86e146f": {"doc_hash": "a8281ecc46764299db60448405dcb5a3dce7ca7f680f8883e8d7049d9f15f62f", "ref_doc_id": "30c0cb4f-6dae-4b23-b289-5734fa1cf420"}, "53a00819-b6ff-4ea4-9867-b50bcbcbfedd": {"doc_hash": "90c9d7bc86a256da6e0b87e160e1b3fcb0b984808bc7c04ac7f6e9e117acfec6", "ref_doc_id": "bf4ef3aa-1181-4fe7-833d-7a68debe7970"}, "12b31851-6d68-4be0-b653-52c2ec71c4ab": {"doc_hash": "e47d7f0177c738ad3d05ef094e052c518c0ca7b74850e551ac25d025563fe520", "ref_doc_id": "42954911-3ae9-4797-acae-34d650a3f095"}, "08c54504-5425-4a62-9ea8-5ca85eb22b12": {"doc_hash": "d8e872367393a3d5911c431eee7e2696670b778228dd3a4b695a3ee798513519", "ref_doc_id": "4e574ffe-6153-42e5-9101-3e19b510d963"}, "7043b65a-8750-4091-b134-582ec10c469a": {"doc_hash": "5e66daa999537ef0e58c4cbb4077f95a3a1ff040b7bb4238abe750604a4dc1c0", "ref_doc_id": "a727e92c-2721-44fb-8086-5dc21b8d475f"}, "f8bbb83a-88ba-45c7-b905-2e07809b89d9": {"doc_hash": "f484188ddc5a3be5534ad29baa87da4acda853ad12a374c18fecf2c2ab6fd12f", "ref_doc_id": "50121ec2-bf5d-4276-91b0-b8279ce0b6a5"}, "a008c3d5-6b50-45c8-b0ba-5ebccc740031": {"doc_hash": "edf74b2b40a9133ed37290cf577634f427bfb9e4119f2860a740adaa9a680864", "ref_doc_id": "11562404-ee4c-4378-a6c9-38873abf84bc"}, "49afd5db-5f93-410e-a0d5-cf86b2b5300d": {"doc_hash": "b369e3fb62693adebb8afbfbfb0a055654eec60b30a939f3a6c5f6aef13b8369", "ref_doc_id": "5a1de1e8-e4cc-44be-a79d-7bec9639a418"}, "226f359a-074b-436b-85ef-fa4d40c17b19": {"doc_hash": "19591e36d75825c8375a4d7685783aef46214c12e421b4cf9221a4a11f14f857", "ref_doc_id": "fc95085a-b367-4450-acc3-39991f245592"}, "9c2afb38-f3ba-4405-9a2b-83ca8a81347c": {"doc_hash": "a298642cc9c056a542cca0f6fd4e509becbc1d8e8cf2f5523fec733c36e8fee4", "ref_doc_id": "2fed310c-d99f-4914-af00-9cfd1edf5c8d"}, "c501d914-3063-4c0b-ba96-1497a7c3f9e3": {"doc_hash": "17da5b47d82f6858353ae60ebaba5c88915acdbfc6937e2bc8c4366e06ffaae8", "ref_doc_id": "985c4003-99ea-46af-87c6-f23d3920fb49"}, "b7ca40e3-9714-4e7f-8070-d82575fd2548": {"doc_hash": "8df9cd50feb43afb823e80968f40696c53ceab5a6d821a16bd9a3a3b80a77567", "ref_doc_id": "84388be3-b343-45dc-a1be-89fbc616966b"}, "582dfdf5-d75c-4f10-86ec-866eb0d1490c": {"doc_hash": "b5fa6900b3591cc8bbcd78ca08f3885556320f7946f523b67cf8f3610189ce70", "ref_doc_id": "e2ca1895-345f-43b6-b3cb-6b7d7b6cec42"}, "8c17afb1-a5e9-45f1-846b-3b30162ae0ee": {"doc_hash": "705f8acb7e936148f7a3b52686165d1a5d29de887fa43cd79ac4c20e0ac5bd44", "ref_doc_id": "3bfc1ed3-75e5-461b-87d5-d5e80fe20dfb"}, "40a39e11-487a-4915-8029-502b34edf3b6": {"doc_hash": "41ac3be94c23116faa072014b13c31f9e5dc1da3fc1839ca7b25f6df71bb4b97", "ref_doc_id": "60762a95-36a3-4f99-b922-0a96833e579b"}, "bc6884ea-e205-4298-8b41-797205be4142": {"doc_hash": "e31071ae93c9c600d5926841aef36370e100002a08804998ba7b0fe513b10e31", "ref_doc_id": "ecfd3451-e53d-493d-a5b1-b0a47a24fd94"}, "bae3b027-7b2c-4921-9f63-2efbc47233f7": {"doc_hash": "144ff083d06baf5265880d0c79b27a30bc4974ae2a5fd7f3ad82cd8822f92557", "ref_doc_id": "04782910-5c75-4a27-b415-9423f2fb07c3"}, "090199fe-f9b7-436b-9e83-fc79914a9296": {"doc_hash": "97e3ccdd6a47be01a115760b58d78afa91490bfb3824992a6175f599cda9140c", "ref_doc_id": "ef38ed6c-d8ad-414d-b869-128da4daddc1"}, "1353ea0b-94a0-4fc4-a4a5-297eb0e60691": {"doc_hash": "68c504119fcce44f8eeb06fc9feefe96c111aec2cdb3761f3b2e7d609787ff69", "ref_doc_id": "f3834d20-5606-44b2-b911-7935bf1d292c"}, "c057261c-a501-45dc-a099-7cdeb22feb36": {"doc_hash": "98b1302e521e7f72f54068c8f7b1326da6c72077ec33f25e4d9203890063ce0a", "ref_doc_id": "b70e0913-30c3-41f1-ac0a-2dd402b83f51"}, "9268b3d7-ff2d-4d8f-9f15-43a72703093a": {"doc_hash": "3512f03bc46af740dfb45cc7de53a398e3199d15413cc2dffeeeff303a3c4df2", "ref_doc_id": "21adf69b-fc47-4828-8c6f-fbae2db02fa9"}, "d4a55e6b-8522-485d-89b8-9465eeb3b9a1": {"doc_hash": "6bb1c9a2f8f82336e0dc823be7e79d6e16280aa4fa573aa31734c023039ce7a8", "ref_doc_id": "9ce19be9-61f5-4d69-b481-617b1922f5c0"}, "71342e00-1109-422e-9fe8-c757f48741b4": {"doc_hash": "257a9f8a28b6ec7c780f7816712fc252e48da0b15d66437811f75c7e4c8316ce", "ref_doc_id": "c0d0a84f-e771-4b13-b06f-ca6e2041cab2"}, "4c164064-3a09-4208-89ed-92fd83736a51": {"doc_hash": "94df5ac5a3373fe882de8d4e5e97f1c53a8f4bd82ff47ea620bf0d20fe297b90", "ref_doc_id": "c524f821-32eb-417b-bcb8-6cd8f0ca9f16"}, "de4c71be-a561-4016-9616-8b4c985a151c": {"doc_hash": "09914582d083d5621c448598107681edc7e20492a29eaf91a65c3bc219f9c51e", "ref_doc_id": "3261e380-3a91-4b3e-a136-971526a18607"}, "60421461-3fd4-48ea-8b42-22271ba8cae3": {"doc_hash": "550481a64eea829fad8c8135684fafe24a8027ddca509f71877e88b91ccd6ec6", "ref_doc_id": "c6dd19ed-61cf-44d3-baf0-87fc43508e1f"}, "1b17192b-9e01-4cea-b6dc-9529a1414002": {"doc_hash": "46e217c7089710b83f9b030221e91cb2e1044c3e055137f5d3dc9054dd976dad", "ref_doc_id": "3a73dffe-4e6a-4495-95a3-0348c8664854"}, "63c69f18-3b24-47b0-8fff-2c47db5da3be": {"doc_hash": "48b559103627dd94943019ba455fc8babb7b806058c14e17067e6c37fb7781e3", "ref_doc_id": "e40c7a69-06d6-4bb2-8d33-26e0bf054ff0"}, "5a0550ad-c6b0-4ccd-9c4d-9f35c50bf449": {"doc_hash": "57d7250033474b0dd3159d2d8c3774f3a66266a00faf44de437f8ab0971210b1", "ref_doc_id": "e5dcb41e-2d51-4278-a6a8-7e5e2e3dca5d"}, "d3e18d7e-8032-4712-a630-dd0fdfbf2523": {"doc_hash": "61e6b4bbbb795ac7419a2eb82fb53c96ecb75bfdd52a820c6b7015b2ec4567ab", "ref_doc_id": "109cfe8d-fd10-4a0e-ab6c-c2f639183f2f"}, "22d41dc1-f3bd-4328-83d6-25a6bde1a943": {"doc_hash": "53dd473b61e3bce96d3ed8f99037fd3cf1093bf8466bfcc09f1cc78267542f1a", "ref_doc_id": "dff7fa52-7736-4ae4-9f0d-380d53c73877"}, "1d8f6226-57b3-466c-8a5f-84f8a565a36d": {"doc_hash": "048411000d6f6b25fc5f884c2d7e8d07c2cc51e9b0efd7ed87ee686a55874c3a", "ref_doc_id": "27260ff1-70de-48b1-b837-9a9510ac9bb1"}, "1e99d6ff-b880-4834-a578-9a108e5f46b5": {"doc_hash": "7a098093b33e4ee4370892d5fa03ac4871349f6dbb7b3cd152d0f88848850e60", "ref_doc_id": "992b8d06-7416-448b-bbb3-7c206d4f1a8e"}, "4ee70a80-f6d8-440b-959a-fb64052f299f": {"doc_hash": "d8c6ac8fb3cb9a1654629699d2f15eece794be5fa89df1ed7229e16470777cb7", "ref_doc_id": "6978a3c3-da68-4d33-85c5-6cb0538b2b7d"}, "addf5725-5d60-4777-bad3-006193e06936": {"doc_hash": "1f62bdfff2ff175a882ea2e9f0f1669f10fc259929cf0b9beb5c9296af6e515b", "ref_doc_id": "7e04fb56-d42d-4807-a128-efaffb57ee50"}, "e88e0e0d-2bba-4733-8422-25e1e585e8a9": {"doc_hash": "fb7e75368bf757cce20c13721267a436b0c32fdf5e658a3c5a36608c3a667f99", "ref_doc_id": "4b42ac66-4176-405c-909f-74cd1bf7e951"}, "75617170-eaba-4b5b-a6bd-0b56238e1bfd": {"doc_hash": "464c14009b075cec69a9fa570245be39ae31b9b701f11db894ea78129ef64d87", "ref_doc_id": "0d1577cb-cc8d-4395-b748-5e5f797fe3a2"}, "e8fe5931-a1c5-4f0c-8b31-78058795fbae": {"doc_hash": "b7e9a5e8cbc4e64dbada09274bc268b71712f629174649aa4d0028b9881416bc", "ref_doc_id": "bf737236-2d14-4c86-bb36-e03124d8abdf"}, "166ef137-449c-41f0-92b1-b97259a7efc4": {"doc_hash": "386e3b4a70b16b5528ba33fd8bf34ad5b0b4d1c993ddc84a436e241ff724ed6c", "ref_doc_id": "8145bcb0-7836-46a3-9b16-85913dd17f20"}, "b22e1372-451f-458a-8553-beed2e233b8d": {"doc_hash": "0a7d737189f38c9084d2b760cca30983184fe6e3442c762fe772fb14ebac643f", "ref_doc_id": "1f0cdad7-dd8c-4e4d-8d5a-a891c00b9da0"}, "69f1bf57-1b50-4a29-b2ed-04b32aae71cd": {"doc_hash": "c155c72c6751ed519c71fe556bc14a92fc72723413ca42b885960aa23ffdffe8", "ref_doc_id": "3aa657a6-1ef2-4af6-b934-fb39d4108f9a"}, "3ffe51f6-d3f7-489e-8469-049c1d8f248d": {"doc_hash": "632e85d4318e8531e339830ae03ec88ff9b2343a507cbf408f5e493f103cbaec", "ref_doc_id": "8967fb6e-efa6-441a-9f77-7281f80d40c7"}, "2b42510c-2015-43d1-954e-606425171f02": {"doc_hash": "67e935dc23ed2ecbbfee8dc1737082384581da66b45bedf7d29a0d3906efc14d", "ref_doc_id": "aff292cf-2942-4648-bfed-6c1b96a5f9cb"}, "0ac2e938-eaed-4b2a-8c9d-db62ff6eca76": {"doc_hash": "40c50736ccfeb701ce8e510aca312b7d5b79b4da54f926d138fd78d3af109481", "ref_doc_id": "2c657f58-c861-4e4d-8727-f421c3aa745a"}, "6381b36e-1635-4380-b063-c85e902910df": {"doc_hash": "d4c3d5b46b2a0a391c544dab59bbb0a4c8426c3c7252d52b19eebe77bdc76def", "ref_doc_id": "7795691c-4c99-49fa-aa90-fac43a60a560"}, "030b8e7f-96bf-46ec-8c76-89f822f226eb": {"doc_hash": "599477af82a512571c0ff674af735912767ba73f8738457282b50cfce3b0be82", "ref_doc_id": "caa8dacf-1d1b-4319-8ca9-81254b3e522b"}, "f2d74d87-78a1-4a12-91a0-ec4a422bded8": {"doc_hash": "3d7194f45db77f5ae34df501668933a6c6f3fd1fc8676900c5d5552b02a5455c", "ref_doc_id": "30a98276-5886-49a6-b612-20184c4cad60"}, "0b3ab66c-50a7-4f39-81b1-88e0a98253e7": {"doc_hash": "760eb6891e5e218de57e63d6429eee1f3027dbebda80b36b0c5c94cba76fe9a0", "ref_doc_id": "266377b4-5118-4b88-83aa-7f26007c0abb"}, "acfa7a96-04c4-4cf0-a234-f7c847e458ef": {"doc_hash": "351fe42e78afd69a14402a47756aa7d3020b9ff91d2ace826615d4af1c3456c8", "ref_doc_id": "a9496ea4-471a-4d69-9a8e-3f902f475cf7"}, "2ba884d1-9545-490c-b8f3-f6453bd16751": {"doc_hash": "932973158d937f0de5069e32ff73082e16cb2dd3d466b07d1b3d42158c163d98", "ref_doc_id": "864d3b95-7691-449a-a756-aa000aeaa200"}, "9f6e0f27-d4fe-4e34-b8de-37387c99d503": {"doc_hash": "4e3be7ab43125fe63ac81a87a9615c4ebf6a19e70f01289af8b3af1a8e4ce19e", "ref_doc_id": "504e2291-c837-4391-8d6b-39a18181cd54"}, "164d8055-4a46-4db4-bdee-b0c84438027a": {"doc_hash": "09cbe664e5f42b111caac4941d7eff65cf0d76e01e4b67396fdd7fee2c5d3f92", "ref_doc_id": "a6a98b1a-3756-40bd-9e8e-0e61a6b87226"}, "2dcea841-c1ec-44a7-85d0-f2e3a109b8ac": {"doc_hash": "6a0eba1de908c52f23dcc5902c52c8fdb77949991a096866717342dd36935928", "ref_doc_id": "dd7072d0-368a-4fb7-8e63-dbc240774852"}, "b0b060d3-d29d-4938-9313-6d4de3d707fc": {"doc_hash": "91d71297b08f8d4a34e486ab6db3f754b6947a5b152b29e38e045622b96becf8", "ref_doc_id": "73978b02-9659-4555-b940-72d26889017c"}, "d326c348-d64e-4d8b-b4d8-dce37accd50a": {"doc_hash": "4b24e9b9622a284377e41f0579a302ea8360fb255a71ee2168a0b003284b337e", "ref_doc_id": "5fdeeac9-d706-4ff6-a0ed-6f33685dd04d"}, "6d4ae1c7-5e42-4a90-87e6-69bd4110d68a": {"doc_hash": "e9cb2e4c15f72c6b25c0db3c450a321c9a8eba2ae5de9404b5e0970699e64fbf", "ref_doc_id": "7064b587-22ce-4b9a-9a0a-5c384351c6ea"}, "e6aca770-0b4c-4436-98f7-3fcb07bbbd92": {"doc_hash": "b687aa2aabbc6e26147110c044be67f2cd25287203977fe95f0ece20065acfee", "ref_doc_id": "a0567cb2-fb8d-4934-8e8b-5613f6e1db5c"}, "d4243450-9b40-44cf-b13a-62abc6bca613": {"doc_hash": "cb1f7d6ff6fc05d462406ca400ed5b6332a1d515952a3818ff9989f52671ad3c", "ref_doc_id": "6a577882-8b30-4af5-a55e-a0c320479633"}, "1554ed40-a15e-4479-9d13-019eb88eb67f": {"doc_hash": "9095e66678ee24f7430b644567c9b7a8315ecf02e5d52b21b1c30bd5220beef9", "ref_doc_id": "b62fe408-28b8-47e1-9663-3d4f5598c72a"}, "82dffe9d-624b-46e1-bd0a-d926071b468d": {"doc_hash": "f0358c94c46bc9712f1ce9744ce906afc8efc51ffae860ce368f71b085606529", "ref_doc_id": "0411dbb5-a5da-406d-822e-ec7df5ee4fe7"}, "dee7bf8c-0af3-4a61-aebc-1ba057a68cec": {"doc_hash": "44871bc343867147a3d49521b6580824d749a942b1cc3385079433adc973f3f1", "ref_doc_id": "3ecd962d-7655-4729-bb2e-61346c76fdda"}, "4fdcd4cb-bcef-48e2-bb66-e33a3871724e": {"doc_hash": "8bcb763f401d0c6776d2b4923e57bcd374fd7ebd19b7e5c0fdf4ded9a1f35b7a", "ref_doc_id": "45f2b2e7-91a1-4c6b-b6b7-4cf29cb7c730"}, "8171fd5d-7c56-41ce-82c9-d6f1533b04d9": {"doc_hash": "11bda90d560a0f828b6a021bec2adf26c7f3e30eacb9db3ca503baa5490f84f6", "ref_doc_id": "d9f9d2d6-bb91-4f4a-b4df-704c2c4b0413"}, "c4116b72-c129-455e-a6c7-f7b1715eebe0": {"doc_hash": "36c0dade2a57afd3116b2288974aaa95501092f354684ed3dab1ecf160e68ca8", "ref_doc_id": "2a9f80df-3a9b-4472-8ec6-a3e3cb111f45"}, "2178cb5a-4876-4d51-bac1-2bc9eb50ce5f": {"doc_hash": "6272571c090a180ef529498c5e647a3a4fd55d3bf6ce11f34f4085ef3cc20f0c", "ref_doc_id": "d7346a3c-606e-40a2-b703-19e9536b77f1"}, "432f18a0-5579-4d97-8412-4ec94d454970": {"doc_hash": "8dbb74196077fbeccc2c66f5a3ac205a0fa2fb7c099eab3f4dc214da49beb020", "ref_doc_id": "bfbfb084-58ea-4f60-aed8-9e3fa2d7eb79"}, "bea3172b-04c3-4fe3-9c67-28eb70412558": {"doc_hash": "e872719d3b328b2945f052608176e8883cb03ead054281d293c36fabfe36f96b", "ref_doc_id": "f3f1c77b-86f8-4f9e-8a52-8c1e123a7870"}, "05bb1699-dc49-44de-bb35-c4dd54446470": {"doc_hash": "944836635c967b3b81f707744a43c22efdb03897992b17bef6a93c81bde51694", "ref_doc_id": "68afc25a-164b-4270-bd3d-4f3cca5766e8"}, "a27d215a-61e0-4133-aac1-7070cb9e0081": {"doc_hash": "ad365e7ac7203157ea50e20d3ad4f7a99a6b5f2da39d476b8eac851c81b2c323", "ref_doc_id": "a2c7c947-01a4-4d88-b38c-66619394fef9"}, "a37ef74e-a8ab-40f4-8fdf-6084ce42cec2": {"doc_hash": "5b88223fc735edc9892639000c1cd9568041e74ae691241622ff0f54c4a8051c", "ref_doc_id": "c6408129-2b9c-4f52-96cc-67bfafd23142"}, "af294b54-ca40-4efc-9069-925cf54a1cb3": {"doc_hash": "bd0f892f7cdf6acb77bc2307fb9f20675e484b003179b3650ac8346c419b23aa", "ref_doc_id": "087831a0-c35a-4ee9-bf4b-571a2e9c80e4"}, "3eff921e-d8c3-4bb0-bcf4-6fcb0cff3eea": {"doc_hash": "931a7dfbf54f14b080b37f60ecbedcb5c733ed7477ec028f9298b4cc2bdfdf25", "ref_doc_id": "09dcac7c-6707-41d5-9d39-2ec35ec9c540"}, "1542497e-c0ab-4a1b-a3dc-ba61c48d2a19": {"doc_hash": "254ae3c8a2978c4fecece2f275b339e394e313d0d996d4e4ef3937de55be7e56", "ref_doc_id": "6e3885c4-da36-47e4-8b4c-73ca310ff2ec"}, "cc39aa99-3775-4b81-b935-c8c18d9517be": {"doc_hash": "a846615130de45b72e75987936f498da1986182b3b887c8ff4e5c19db85a4471", "ref_doc_id": "0a7572d9-3d53-44c4-a30d-e7b3e290041e"}, "8b7e55e5-36b7-48de-b64a-fd55f11464d0": {"doc_hash": "8c793521f97cbd36c7c02691c102eea294331f2a203182a10c8a496c59ee28b1", "ref_doc_id": "965edd30-c4db-4ecf-82de-96a1a7db8cd0"}, "345e5fc3-e46f-491b-b0d6-0913117e47c7": {"doc_hash": "77c70c5345ca47addb70cca0d801e376d573c31fd12c6a9bdc8ba9c58a68965d", "ref_doc_id": "b6075e6e-b7c9-4ec1-b2ba-80aa6d80c889"}, "63e5195b-9d47-4641-83c7-25f230180877": {"doc_hash": "827c193cdc429731fca4b46ab04df0c438da074e9e0a46f922fd4a84ea7b8754", "ref_doc_id": "bc97e1d5-4d52-4e0a-8986-1e7ecded7826"}, "84f2af73-a280-4687-8fe2-7c6999ff93cc": {"doc_hash": "025708979fea134fa0f3fcbe10630e11b0c9ee3554e91f60a84855d2de0f43fc", "ref_doc_id": "23e704cb-317f-4c89-8f26-01497829db42"}, "adb9d066-e0f4-48ee-9341-fe41c1dff0d7": {"doc_hash": "ca4791623e31ec3dbd4ec416680f6da18d8384ceb808c47eef9d27df6ae42566", "ref_doc_id": "9c97f423-d185-40ce-86d1-bdc79b51bb31"}, "dc3e47d4-bc7e-4e42-a172-0e3406197ed4": {"doc_hash": "bd5c7936663269ca635ce6bbb7365110ea04839acaf44286b399fe559aed9376", "ref_doc_id": "80e07c50-f880-4bee-b69e-c3652f9bf262"}, "d8823b6e-d2a4-4dae-916c-89ecb90c4526": {"doc_hash": "7a0509b78e1a12e2ef913e7cb687c1f9f2c3c8d113fc76c36be32a5476cbe3e4", "ref_doc_id": "28b09737-9e31-47fb-ab99-c6705ae39c2b"}, "398383c4-129f-4e3a-962a-31e9697ed43d": {"doc_hash": "307bfb73a680878ee5614ce7fa39a8b2550c90471db6c251969ebab07f7924e3", "ref_doc_id": "068b52ad-ecd2-4c5c-b5d8-2fd9a52b75f5"}, "f0cb22b2-4e6c-4e55-8e1e-15425c2a1cb3": {"doc_hash": "8b3345a1b69645ffb38fb881df879615ec6a669b3e8a004b0602097c017ca221", "ref_doc_id": "1e9e7d80-5e07-4968-81f8-c0750c0d9f3d"}, "1d7a692a-985c-44e5-aac6-981d93fcb829": {"doc_hash": "569aeed30774b9580af97af1df7c8f20820f2123ae05cfbc53b92e06460e4047", "ref_doc_id": "513f6e02-adc8-4c1c-b036-e60699f8c545"}, "9be3c6d3-5945-4e6c-b98c-638ee602bf9a": {"doc_hash": "7a398946932f91c1761b776c2d565afbcce655c1c2e0b388c11ce278ec35a6c2", "ref_doc_id": "fff125c2-910a-4948-9f8d-470063e1ddfd"}, "e45e8984-3536-499a-8b10-e41d432df4b9": {"doc_hash": "093a5ed18d597c1a06a9cac81e4b91aa2648626a5739f719b7b9ac55fd3cc134", "ref_doc_id": "8fdcccca-be0b-42f3-891c-8ec061c62edc"}, "f01d666d-be9b-4c5f-8688-de72965d8e04": {"doc_hash": "63d91d00bc1db267ff8fd3061e53a11a3502abec82443932798dd1d1834f3c87", "ref_doc_id": "ec1a5fb8-2b9d-4d7a-820f-41fab35a5a0c"}, "7129647b-1cf0-487c-9e44-de2edfa1ee4b": {"doc_hash": "99732edc8652dce4591141bae9e0f12e0a37e3e96f44e22143abfb4d31315106", "ref_doc_id": "6274f166-8516-4889-b0f6-c161ba6ed760"}, "58bb0c78-54c3-4ddc-9abd-da977406c9d8": {"doc_hash": "21c2ec18d3724d874a10ddb3b785cb8697095852d4bd891bc08f98e85dedf72a", "ref_doc_id": "b5988093-3b8f-4640-8a66-97ba862d7bdb"}, "03e75fce-8874-4085-900d-9ce4c1548e7b": {"doc_hash": "1ba33a18815fa8b59c0c3c198ed39ea660ebef0cd43ae3a4617ccbcd0de03ee0", "ref_doc_id": "841382a7-a849-41aa-965d-1df29959ed8d"}, "8961b22d-5941-48f4-9607-020ce16e89ce": {"doc_hash": "097cdaf4661d97d1aaf115c3d4242148d7647732c8f7ffa2731fa8df85825ee4", "ref_doc_id": "9d4c54b0-b6dc-4732-837d-cc255eff7b54"}, "7e1f9f87-5da4-4c9c-a71d-cd5ac6a62938": {"doc_hash": "588a2350c45938dc5abf33f5e95fd9fe2756a23730efa8eaca75b85d37824077", "ref_doc_id": "3f090516-cc06-4f9c-81ea-01d59ede926c"}, "5737c67e-8da9-45c7-b52c-e1e481649bca": {"doc_hash": "9dd61aef137af6a50037fa5114aeb07b9a3cf272ac1842a9f881d33cb4c0aa04", "ref_doc_id": "cb8673c3-84a7-4c6f-97bd-aeb3e932c3cb"}, "47370352-5441-4135-acc5-72b775e007c5": {"doc_hash": "0c49f02544910b52514573d709afc54b4d7bd2ac8f435510a22af5627d95df38", "ref_doc_id": "b3068d4d-5c3a-43a1-a0c0-cb6bbcf7c4f9"}, "26388164-d4fc-42e9-98de-70738d4e0654": {"doc_hash": "762270ed700012bb2a610e8986231d0c857a3c50441852860277c67260576ef9", "ref_doc_id": "03d3bbfc-eef0-42d7-a04c-b3c291dc4195"}, "2922dbdb-578f-4fe9-bbaa-313cb221ec19": {"doc_hash": "6f4def721dbf38356b69479bb0a06a7a2b20f0cdad1730a154064d5c37125efb", "ref_doc_id": "317095a3-46d1-4447-b2fa-9476cde3113f"}, "aa956ec2-3e27-4b9e-a902-6746361f27ee": {"doc_hash": "835cbb53c5a8ed831305d14ab3aa6a73f4e7bc83121f15ef428730f3819df52e", "ref_doc_id": "56b692a4-4121-4598-a50b-f15ce6370fe5"}, "684377bf-4b23-477d-9140-be0e72412887": {"doc_hash": "9fc0e0e5bf3edfe95f8b37d48c448b2ffc6b30bb30c61810b4d7d86e6d7104d2", "ref_doc_id": "4b4df9f8-8086-4cae-9a19-ff2b1ca4d1df"}, "54fffd8f-d07e-4f9c-810c-a35f16227ffb": {"doc_hash": "cd7436deae37dabe0a18aafe3aea2cea320116926538b300c5ea57044794be4a", "ref_doc_id": "2d77bafc-963c-4325-87bc-45f8befa7d81"}, "9a1306c5-7607-4931-b7b4-e0144a3892e7": {"doc_hash": "4c1e08ac70146e8e96229572d8849fc6389214ee755dde9079925c5bd6e56bf8", "ref_doc_id": "583118d2-406f-44a0-9b3d-4596e26559fb"}, "648ab0c4-ebff-4b59-b30c-d496d26e6fb1": {"doc_hash": "baf2472368364ea72603d5fdd5b6cb8a626bc7703e008f2c9be641f043b4ae02", "ref_doc_id": "c234d193-a6cc-46f6-b6cc-f86604bf6462"}, "756f9485-3d82-4ba1-8a75-040c7c21e68b": {"doc_hash": "1c0b0eb4a56cfedb3cb7b4063180e017f1eb222f55e05e03df9bad7ef5497771", "ref_doc_id": "b3027740-f03c-47f2-9d90-c6741c1cdaf3"}, "08138a5e-c66a-417f-b4b5-d812f6ee4513": {"doc_hash": "f546f1587d677cbdbb22d3f53e1b1bb3e4eb7060facce49de120a1f6914ca9f4", "ref_doc_id": "9e9d71c9-1366-4ec9-a85a-ac5e85d413c0"}, "79242a63-bfdd-4135-9800-79022e60bf69": {"doc_hash": "bb3daffd6efaba8dc90944771cf605aaa9d2c24c63c98ed2e5e894d69510b1b9", "ref_doc_id": "17b5f466-f8b1-4e2b-8df2-563e1ccc7110"}, "08d773ff-9bbb-4985-ac2f-afaa12f5dc74": {"doc_hash": "e56a325d3378c03941bab1ea048f652f86869c9aed6c6e0ff4ade97225bbe2ed", "ref_doc_id": "9fd6f81e-fe19-4479-9266-e57be6951284"}, "d338d7c4-e3af-4640-8944-ce147fd80895": {"doc_hash": "bb50998b00f29c06f6ac622adf7196898e274efea05df7f517b5db0746517966", "ref_doc_id": "26e6bb9d-c06b-436c-b549-13da6c371087"}, "28095953-bc85-42cd-9ddb-eb96412f7e2a": {"doc_hash": "d2788191214e13a0ca4d8acfab1b9808458ffd9f4e479209d68cf26b419b1f35", "ref_doc_id": "baf650c7-2a9b-4405-a815-61c8cc71b30f"}, "b6fc5a84-3f11-4c5f-a512-f7b44a612276": {"doc_hash": "ffc99a78e961b99fc9145b8bc8c6281ceeca2f9d4450926f0ebf85e922fc69aa", "ref_doc_id": "b9143be8-6470-4063-ab00-a612b8a9fb98"}, "160d837e-0c67-4e24-b457-0284cc01b110": {"doc_hash": "5f6654a8836ad445c5c0b0795bcd3daf091b28aab707d7ca3bd6515729c18a97", "ref_doc_id": "4714f68c-a079-472c-bb5f-04ab2b17924c"}, "a519ca91-88f4-45ef-81b9-23e605effe1a": {"doc_hash": "f21d47841a0e85cb5fd6727785000be05a4c83db70b22a6a8f77dbdd7fd9c623", "ref_doc_id": "3f2bc7d5-6d4e-4313-934f-8a0736c839ae"}, "e38db428-75de-4144-aee1-38e2700aba09": {"doc_hash": "77475bdb8bc2946b4b7e7af20bb0be47f7590ac409782bed92b1295a7bcb9b5a", "ref_doc_id": "4c201736-8d6f-4591-933b-313a1c9c7351"}, "81f2a4c4-6c9b-41d8-aeb7-cf19ffd8837b": {"doc_hash": "714ddc2c910e7322c59b2b1868e43924ab43208294deca0fe4bc7adebcb6b6be", "ref_doc_id": "73dba28a-5f11-4adc-a332-cbfb0234face"}, "06d4c177-f080-416a-9b7b-1004ce7de1db": {"doc_hash": "79ff5fa56cc2347a059caef38a8f9022f27cd5c24fd944b822cda1b6f14d6c3a", "ref_doc_id": "065236b5-729e-436f-8c74-f2e89c9e634b"}, "b13f1d8e-5245-4f13-ab28-857e17ead86a": {"doc_hash": "7b4a328a72875f324d781b2382ffeb2bda3c1ab6daaed50c845c7ca5b83b2e31", "ref_doc_id": "0ad74638-7752-4dc4-b30d-23e7dc52f682"}, "a280161d-0cb5-4d54-b5a5-ae533994d8b6": {"doc_hash": "d9f3d008fb4d7171f810cd4852ecd575a43ed28ce86a9de5218ad5e9930dc518", "ref_doc_id": "f8c383cc-b035-4431-94aa-9d957e842b6d"}, "a7d3c3bc-1788-49b8-8ff7-bce2be469e25": {"doc_hash": "bba8afffb7f9984c405392dc2fd08fe96e03cdac5d7deb56c220fe6d116cc456", "ref_doc_id": "c4606470-21dc-460f-874f-a41779700f6c"}, "65fc3742-7feb-42bf-8fbc-2a35c46dccb6": {"doc_hash": "1b02809ec1ebc0e77e53987a02e1079a79f393c5dac9279fa99abeec34656f31", "ref_doc_id": "c64aa61a-ca33-4c64-8e7c-46131d3fe0d1"}, "e588e2da-aaff-4647-b454-e683bff43533": {"doc_hash": "148955dbb65e1565cd0d38d6fe6578f03365d2c1df2a29b59436edd1bfb35683", "ref_doc_id": "0ac6ddbf-ce29-40aa-8595-46d95b2607e7"}, "b444a56b-ad3a-476d-93e2-ae26ef21f3f9": {"doc_hash": "ab9fbb68001975dc4bef9e76628c56d2f6c48730367bd59d3c56c3527c3bbd03", "ref_doc_id": "0c9945ad-eabf-41cd-a7a7-38cf7ca307e9"}, "ce638535-07aa-49d2-9b03-fdcc805c6065": {"doc_hash": "9d7837d0bb1b4dc41bb7e64d0d35a729e6f043585ea6c9f93c02c97883361628", "ref_doc_id": "461e488f-5088-4a7e-bcf5-ca42555c2506"}, "b9bee75b-87ff-413c-bbde-4b6006b99e75": {"doc_hash": "e4e3f35ef0e7da7475a42137b77447c6e8002a9966a6a36c31cfa9adc15bd58f", "ref_doc_id": "b5c2c895-999a-4a96-95e7-6a3210bbef21"}, "565c6c22-e11c-45da-ad1c-076de4da6e0b": {"doc_hash": "1cc2b9eb83a2c4893ac3e9fab1a4203c881699dd69d1c14ab47e55f4b1993e20", "ref_doc_id": "1181f5a1-6863-494e-9a0a-f0af64a323f7"}, "6d3902a4-f8bf-4c23-bd4d-834640dd3755": {"doc_hash": "12a5eea7a174daf500f7a44e16bfead506c259b93059a9cd0e7042bda779eac9", "ref_doc_id": "cde1d9a7-ce24-406d-9b69-de336bad310e"}, "26a25a94-518d-4420-8a3c-18a529617c10": {"doc_hash": "a33153bf1d5897fcb2188c427bacec1a60b8e2dd529642fd0c584d768bd21b41", "ref_doc_id": "2ac90a08-2902-4429-83bc-9e2ec9d19168"}, "6f90733c-a74d-49d4-b4f6-4b9362b7abb2": {"doc_hash": "5dc48dc46550b97aa6cafde96c02da5a8c9bfdde8bc4e635a235be0c70ac7830", "ref_doc_id": "807b8b05-0e36-405f-9e45-38fb7345b68a"}, "035a58a1-e26c-422a-87ad-7892b869c5ef": {"doc_hash": "c550a7549933299eb4b02eca0687b01cbee0cf3942665345bf89adb43265a833", "ref_doc_id": "296e1811-93af-4857-8de1-d5999abd3dc7"}, "c256693d-98ab-42f1-96c8-3f09c61b77d0": {"doc_hash": "ff84f73235f2643be12fc65bb8c1d5a1559ee80b21ba51de5d33d77e0aaeca9e", "ref_doc_id": "d0896d9f-8bb1-4fcd-8922-8bd5c57607be"}, "0abcaff8-cb51-4145-ae0d-5acbc0bca447": {"doc_hash": "a6456c5df157000eb501702d7e2f141b519128ed5a6d64c2a366b595be5b5bfc", "ref_doc_id": "afad88eb-21a9-41df-93d9-dafa4407ad54"}, "d34af4bd-dd6a-4a5a-856d-641c1c79a3c0": {"doc_hash": "da72e37094a963468a5be36c68d7cf720bddfc82cb446720331fcb571968be6f", "ref_doc_id": "97663dda-cd53-44bf-8b54-0d682609ac3a"}, "38f1e3d4-d9b4-45ea-9194-7dec706d42e0": {"doc_hash": "38da6a2165c6a132a22bfdb8dd6b03a95d7492131bfaa7b9b7a6e38a6e727a0d", "ref_doc_id": "289c9a0f-5208-4c5a-85b7-74e11c474114"}, "9fdc4343-1ff5-44fd-83ca-15a427c50918": {"doc_hash": "b9cc677366bf1c8b8d93cacc7c7091698ea6aa49bea527dab01dace7e7038f6d", "ref_doc_id": "a4454e8e-cf39-45f5-b164-eeef340d1f74"}, "72017dbf-147c-4d10-b1c4-ee12a34a6cc2": {"doc_hash": "d9d15d30d0bf77fe48c113dfa9e680f7533ba558be5a8d32c0713bfee9a907c9", "ref_doc_id": "7050e2cf-3b8a-44e1-8930-e2e15ad257ea"}, "c117b427-cf16-447e-9a2c-b74939c6ca28": {"doc_hash": "e44c5ad49cc6bd970d8c3b49ad57e642ee495771d407a0b2c764e9cbef530004", "ref_doc_id": "b5b21e9b-f5fe-4b74-b480-fc55a6e15eb8"}, "402743a0-2d94-4e48-bc45-7350a9f47493": {"doc_hash": "b1f6b3b22ea4a406892dcfb4b476dd4dd36b3344bc42f7337e856b07ea7eb78f", "ref_doc_id": "f6d35e9a-bc55-457d-8b43-b03c5d44c65e"}, "ef815dba-4f17-4f92-b82c-e965a5ac7389": {"doc_hash": "2974f2402de0814b65d2d39cb3ab9d95d03498566333bc1da44ead9884f0a436", "ref_doc_id": "b25bd757-99b1-4da2-b2b6-4e14bfb342ba"}, "c6b86ce8-3717-42fb-8aac-63eecb2144f8": {"doc_hash": "2aa2bc1c08945436393f187ebf62e1a5e209013b715d48e5166de220bf9475a2", "ref_doc_id": "9af2a35e-c949-4228-aeab-23f3cd733856"}, "03344cbe-ad47-43aa-b440-ca51a70768b5": {"doc_hash": "60555f0538271089aa5ca3d6efa7d79f78a96c9d54edc347b25289af4352cc1b", "ref_doc_id": "4d104773-bc31-4081-8418-f9a6bb50f835"}, "a4855dc1-a69e-476d-889d-5b9f60464611": {"doc_hash": "ae0702c1b1fe1c653bf78d88b5ebf58d3e0f9aed348d68337bb800fe7cab9d0b", "ref_doc_id": "b57b3f93-aa17-4adf-af2b-21e9a5128472"}, "b9bd91bc-855a-4cb3-b8a8-35f19afe278a": {"doc_hash": "2d6ef1247c8e80ead670d800886bcbf23db08bcfa4ede67585322ad147dff2a3", "ref_doc_id": "4ccb95f3-13ba-4cc6-b2ab-26689d84b124"}, "d6472d5f-037b-45d5-9f46-93638b4f18e0": {"doc_hash": "15c159a6f17db6dbf4066d08567f86dee9eaaa14f22c9841cc971009bba309dc", "ref_doc_id": "97dbb027-c699-4352-ab8d-b489f5d6420d"}, "e7ea517e-9f19-49ec-91b0-99c38bba23ba": {"doc_hash": "f526b8315cd4fefbc676d563f07b9502e2a98d29fb8082cf6e45dbb78439bea4", "ref_doc_id": "4eed4177-b25d-4871-9f7c-69f38d10d948"}, "9e461e0d-487e-4525-83ef-83fd38364240": {"doc_hash": "acd48204edef50b19f0be7f7ba077a082abe52a83ca5cfe187338f43299995a7", "ref_doc_id": "da1fd3f0-4d12-4689-aa96-7d1018484872"}, "c77e6d3f-999b-4089-8a5c-a6c73c1b4165": {"doc_hash": "dc4027edceb145270a093128452785cfe24a4791344c71ea159a37bb6d0c8208", "ref_doc_id": "7201e3c1-d82a-4a25-bec8-eb3a436980ff"}, "6c8f4143-449c-418e-8d23-2e93297d2e8b": {"doc_hash": "5cd44ea139aff2ac6b5da09e583d2be3e13c284d5d1d2345d6a5b05438c608c7", "ref_doc_id": "f186b7ff-c986-4836-bde8-9dfe98881ad7"}, "63cc13b3-659a-4560-b2e0-4d4816289844": {"doc_hash": "fa44f18b152820aa24e02506e72419847d464b7fdb84311167c4cbdf2630bc74", "ref_doc_id": "f14dc418-4cd5-4819-aa7e-77e359b7fab4"}, "9729dc55-73cd-4032-8bc1-ceb8cd19ee42": {"doc_hash": "b67d0eaaa605a70e628e13791d7e9dd6474aa7eebc4fdd98876d0b916ff16aa3", "ref_doc_id": "7aabe694-f51a-45b0-96ee-da321ab0d900"}, "eee79fa8-48bb-4271-bebe-f000ad300ccb": {"doc_hash": "a1ab90a29ffb96c3ae297b1e37da75f2563512e2182abd181ce85f13a26cebd6", "ref_doc_id": "e9b9e98c-67e9-4d6b-8c97-d8d6532cfe1d"}, "08bad362-b5d7-46df-bd82-c53ba090cfee": {"doc_hash": "864da225dd2da78d59f71be8017fea4399b651c585d5f18523502b1800e5d54a", "ref_doc_id": "d8b8baed-0785-4b0b-82f4-2866b9cf2aba"}, "cef72f88-821f-41f9-8df1-f394f1ad4185": {"doc_hash": "1ed3a3dfe8422a2cb1a63a055082dabe7c1438773745a980119c7469e9a55159", "ref_doc_id": "cd719117-5c20-4c7c-8489-7826ede9f7e7"}, "40d1a7c3-9a69-45bc-a6c0-bea351c7f718": {"doc_hash": "fa2d4b6201e5d109d114c41d09037c119e69a534d92c2c88994ef55a7382b2a0", "ref_doc_id": "0fef8586-e4c9-48c9-ab00-878fd3461a6d"}, "2d7ae344-20d3-4a6b-87ff-44e2960816f7": {"doc_hash": "4b8f4c4d8f0eba50849ba142d04d1062358034951e09bbc9206ba09ecc33e70b", "ref_doc_id": "f53e7f8d-782b-48bb-9aaf-eb025797580f"}, "680a2335-a304-4de6-b125-c477adf81855": {"doc_hash": "18133a62c1cc567f0fee7209222538b9bc6570bd56a12a9a1b18b6cfbaa44c79", "ref_doc_id": "cdc7ccb5-4307-4ada-9404-3bcd9e030d58"}, "f52d4a60-60a8-4243-bbe9-244bcef3501b": {"doc_hash": "fb5134204ec32c7fc48835a8b476f881ba1ec9e2ba5c9c9173f442b795888dfb", "ref_doc_id": "a16f95c5-8624-4e67-905f-8384714645c7"}, "63c11f09-18da-4d4d-b8e1-ed641b0ef4ab": {"doc_hash": "93bcea763ee95ae890a327a3c9e4b2c8d7d7aca18d850797d07d027c7ebfddd0", "ref_doc_id": "fe667dc0-9a19-4878-9a5f-0a010b3788bb"}, "002a43d7-c9ee-4df5-b1aa-dbbd49c51c63": {"doc_hash": "5122a27a8156172d8acc237fa5358c53997e5ecbaedd181b7d6f42dbb8bfd091", "ref_doc_id": "66ad42e2-f95d-48ce-ac0f-a63e88b80d52"}, "7542225a-3ff7-4985-853f-93747ca154bf": {"doc_hash": "66aa5ed4c001661bffb30dbbf6b5b0e10defa2e35c14d2b3f44797f3ada33161", "ref_doc_id": "5cd65b97-c15d-4e9b-8924-b023880d55d5"}, "d18465ff-9846-40a4-8878-de4449291098": {"doc_hash": "42ec7002f739fe4aa30136d907f07552722eb8415c6a5d485be522619abedef1", "ref_doc_id": "05e8d5a1-deff-4b52-afe1-9b15f18f425c"}, "357b9157-be6f-4823-98b1-b07ba021bc09": {"doc_hash": "25c8c76c1051823a80a6c1378ab0bccd4e84c7354c5d75034c710e05b5742e94", "ref_doc_id": "0067d163-a186-4e00-a7bf-bf5054baa37c"}, "34298bbb-2b4d-42c4-8e99-bd66c2b8c7ab": {"doc_hash": "f92bd2ba1d40d8803869e214c35884555c75ec7baf918c153d45ac555f77f0f4", "ref_doc_id": "a4b8d008-5d65-4242-96ff-f62ece8c6afb"}, "40c896da-47d3-4c74-8ca0-3c09ec20ec80": {"doc_hash": "55d16f6073b0c7f6cddd0997eec7e991934aef7ecb8d2371ab85c4b3f595c5a8", "ref_doc_id": "f0b5e696-90c7-4b83-9896-bb7181c3605a"}, "34f619b5-fdba-4922-9f5a-bed2b7ee008c": {"doc_hash": "274a05606be0899b2293ae91d269a6a21360d7922129475d468b5a5afa0b525c", "ref_doc_id": "4066711e-891c-4db3-9c78-ca0c32daaa37"}, "83febfb1-20b0-4873-b2a3-8fa6af0adf64": {"doc_hash": "40c6e5269c1225cb0970c58525e618fb6512652896ff70da963fddf949285952", "ref_doc_id": "bb0bce83-0c15-4816-9dab-0305e6d4bf49"}, "6bcbc51b-0a2d-4fa6-b860-6c58a861851b": {"doc_hash": "84fd4c959ad17ed8e7d8b25f63141ff94b811ab60c95a0802805daa426c576fa", "ref_doc_id": "b5f540bd-7311-4ee5-b8dd-17e1e284a3c4"}, "f128258a-e07e-413f-94e7-d4e9baeb2c31": {"doc_hash": "b23f23767203ba18a2dbb27fde69474a0fe2ef18fce9dd093fc66121ef45efb9", "ref_doc_id": "f612b985-3947-432c-91ac-4f277bc3fa8d"}, "2ca5a89b-a827-4122-b3a7-4ae861d7e031": {"doc_hash": "9a18dff1bfff5814caf6d2b8c8a91069f6610bb5c87cd63306d23d2377ae3ee0", "ref_doc_id": "15622a6f-14b6-4d45-9d1a-a8d704eb1c39"}, "4f349a33-9cfb-428f-a321-1137cf2a372a": {"doc_hash": "00d79abd6f912b8768ce21a6cc41e16645e3dc367e602150614d294fca688758", "ref_doc_id": "a79e89c0-84b7-4dc1-95c5-3ee03d54884f"}, "fc11c467-8676-4047-8127-028ee7b354c7": {"doc_hash": "2516ad23dae221497b95d00860f5f767495ce10bd22e4c9db9f56d14a3d2850c", "ref_doc_id": "4f01354a-ace1-437d-a796-11f63ae8ca2b"}, "5eb7a21a-1640-46ae-b9fe-bbe56ab522df": {"doc_hash": "ec4478825932a1c30d98a1840cea208d1d3bc171b66d7aad91b1f93db00a25bd", "ref_doc_id": "f097dc9f-5ba0-4f6d-a184-ab7e4f6d772c"}, "4de0ad38-8785-40d4-8859-3e90f07f0c6d": {"doc_hash": "1f89912c7da7c2c6b5c7fe4949ed312fe78b6f46d9b755a90952fc6434eef253", "ref_doc_id": "9e601ce1-80eb-487f-b2c6-db37a867a07f"}, "501032c1-cec0-4513-b820-c0ae1496de60": {"doc_hash": "f0e9d079a066527be3960e873f3b3d6e0fa8fec53cde51180ee132ba730a2c87", "ref_doc_id": "1324f456-7239-4f92-bafc-c4ef27d9b1ea"}, "879952e4-8e9f-4e53-81fb-bf6a1b10d260": {"doc_hash": "c6d1b11a9ab0e90d07383c7dfc831e734ba6a7768a33b9b964194f6ee52ae56c", "ref_doc_id": "5ccb8656-5185-4b8d-a3de-200af453f479"}, "69eafcf0-9577-4d60-be8a-c3611e11a187": {"doc_hash": "5316d5cef35bd281f320725f58582a60d77fe2b03e6b322d420984bc333d311b", "ref_doc_id": "e7d2d1f6-258e-4529-99b2-c46b028381ab"}, "93e83c50-5fc1-43f1-a171-41052a5823d6": {"doc_hash": "8917835bb8e3d3e7a856308c1563024178aba84e0ba88f616b5146ef7440012f", "ref_doc_id": "9fd5da10-d98b-4e3f-a678-3578dd9e92e8"}, "4a8ef1fd-ad8b-4da4-a309-9a5c75612421": {"doc_hash": "b3a8b63fe6300275d866a9607f5a2b08744a5bb561d78910cb9a0397830cfe82", "ref_doc_id": "d1fbaf09-caca-4d6f-b7ec-f561b9de3b1e"}, "ad9cbca2-ff01-4569-8aa8-e11e12e018fb": {"doc_hash": "2c85e4fd8d6cd6abfe9fe5062f4bee5fea0f67b2a28fc84091bb95e9731b4f6e", "ref_doc_id": "a04bf7f8-dde8-4990-9569-cff522891e88"}, "d2104e10-ef87-47c9-bce2-4b401e0dcb8a": {"doc_hash": "1148f6c9df868ad51f24ae3d6d94367cb69118b748c9530606c0b543f5ebb4d4", "ref_doc_id": "2c8988be-e73b-498c-9133-96c0e95bfd76"}, "23dd86b9-e523-42db-9f08-7b5fc30d2c0d": {"doc_hash": "423fa29f34e1a24289c9dc1d30fb46f3910d6b7b699ac2a452482a8dd83bf5a9", "ref_doc_id": "8c402393-850d-4bcb-a7ce-fe45e06d7ec6"}, "d9b91958-dff7-43d4-a0a5-804b04f3a4bb": {"doc_hash": "520af54c034baf0121803941d7585a8faa0ac477312113033a0f71a87af87994", "ref_doc_id": "e28f238d-cc64-4ee2-9da4-b8008dbc10e3"}, "aab8a70e-38bf-425b-b434-56e56eac55f3": {"doc_hash": "9f76fd4da9e7e9034f255581b949800ebe9cb197af4bd408e3241e5250a98abb", "ref_doc_id": "1f08a1a1-ce81-463f-857f-be987b314208"}, "4266ad13-26af-4a8f-82e8-f696dc55e0f2": {"doc_hash": "8cb42f407a27fe3dc887a7487669bcca7251539c98b15b532772d3616234c73f", "ref_doc_id": "4079bcb0-96ba-47ac-a357-573754f2c0d1"}, "006afd18-482d-4b2c-97b6-3347da9cdc05": {"doc_hash": "9acbcd288a196a394df2def2deabbf06ded3e472941c7ace119b35f87ec2c0be", "ref_doc_id": "2a3fa149-c9fe-484b-b498-3b6e16260e2f"}, "e78301e3-e53d-41f7-929e-cc68b4fac508": {"doc_hash": "4f2d98a65b060b95faa59e27e495e1043c5646db651e2633110700c7a215531f", "ref_doc_id": "e49bd7fe-cef4-4d60-8c95-899999194d82"}, "1644333f-489e-428b-953c-0c606e96cc97": {"doc_hash": "7350e59a58fb9c4a28035b3534aaf0b094876b5a56d77ec09df2d36fae85b406", "ref_doc_id": "074280b5-9381-47e0-913b-d0a73a9ca22b"}, "7bd55d71-5fca-411f-b3a7-318e1c440f42": {"doc_hash": "16478ae5f72f9eda15482ae31d2369104bd8043f5a940da080d9f79ad84d9763", "ref_doc_id": "718d3442-edca-4676-a5be-9d63921b8365"}, "a75e25bd-b07b-471d-ad38-8358dfc2442a": {"doc_hash": "6829870dcd46b499faeed8ec86cf3cdc38f5e6f4d8050672f7f4d84ea074c202", "ref_doc_id": "2792291b-915c-4cf2-bf46-7e775855dcb7"}, "c402b563-ad80-4180-a397-59f6062c2ca5": {"doc_hash": "80b58577082878de13b0e3a1e1d92ec12ee6793f50cd763f5e6909e577de1837", "ref_doc_id": "c4f00616-d4a2-4086-9099-0fdaf9da32a9"}, "a95a2261-b52f-4cb2-b594-765e61b95ab0": {"doc_hash": "541fc6c5bd6423d3c8fbaddecf2ed6ac31fe61dbdb961afc4ef0112c78d051eb", "ref_doc_id": "a0b7b095-d949-43ad-ab42-0aaef4861403"}, "6cc36414-5cff-49a1-89e5-5fcb3a33d007": {"doc_hash": "57f8f3a881dec80855ab3084329b5c8d41be59cb0f80a232f04b248ba5053525", "ref_doc_id": "6c368936-c327-4db9-bedc-e02fdde7e855"}, "1025c895-8ee0-4681-9471-161f3a8531ee": {"doc_hash": "e3feb90d40a4418b8d1361bad73c5c896736953a144d1ac7bd0741a72a2872e5", "ref_doc_id": "d477cdcb-e637-4e14-9def-91ec94af7e8d"}, "74a3fd7d-5c73-4d35-861a-584e94d83510": {"doc_hash": "c5b8ccb92a13e7217fc2771f38f257a65f2074f0799613998429771a24cd1aa4", "ref_doc_id": "aa670ec0-8c41-4f38-af7c-f5fafe50e08e"}, "d2c64653-007c-4012-bc0c-7893c08fa521": {"doc_hash": "4acbc331d845179116eea90305816fd2e6b442c8aceef53f459bdee2a18d875e", "ref_doc_id": "32686e8e-99a2-477b-939f-69069aeea1a4"}, "096b23e7-b4ae-469a-bed8-d4a66686fd7f": {"doc_hash": "331d3e92e1e116172b3d3df2d5c0ea4d1f8ec019c6f43346a9afabea8335ae25", "ref_doc_id": "0173ec60-f3df-49b7-9002-876ed6df3477"}, "5a1f1315-8f77-45d7-a1b8-2cac6deb325c": {"doc_hash": "6bd45a2ae791df55ed532a035155099f6e6f7a221833843b17f9b4e5e491a80d", "ref_doc_id": "432bf1da-96f3-48c4-a7d2-b33468577577"}, "de5e3052-ba47-4a01-a2b7-30f7caed1b37": {"doc_hash": "809bacedc38439577b3a3441c334ab1716c561cd1e927e5334899cbef8c6a76a", "ref_doc_id": "cac38972-e8e3-47bb-8f57-364867319217"}, "d638a9e5-fc26-49f6-bcf2-5da508111468": {"doc_hash": "28b8e067ad5b917dd9f1ccf9b863cdbf6200964cffdf1817d6252938947bf0e2", "ref_doc_id": "df4cf1d7-1eea-4ee4-be00-a8d3a7ee7e2a"}, "658f5b5e-c7f2-4d33-a9b0-30aeff752886": {"doc_hash": "21d24b809656c9570289c370dd10e860e6ec82d7b293a526c8546230e763af5a", "ref_doc_id": "ac037533-6b34-4ce2-8369-93986affa13c"}, "8685dbb3-196e-4550-8c1d-f7562a6b54b6": {"doc_hash": "7a2e53049c9e81d4239707ecd23d4836c3d554886a496c79181942a757cd2049", "ref_doc_id": "4f866168-2ee3-41a4-bf09-83ab8875dd5e"}, "4f9c0e8e-cfec-4b58-96c1-b916343ae2b7": {"doc_hash": "33500f79d938f2879d906012e608f2cf86d972ce4b25982eda8da227ec86c313", "ref_doc_id": "4ca81a9f-6ee9-461d-b538-3f9c4c814836"}, "8566fca9-75cd-462f-8fe7-ac7de9624d8e": {"doc_hash": "fe89f538defa990fac3fee1a8c98e8fadfa474e95ce227560d132e9dd23a99c2", "ref_doc_id": "96f2ad61-12f0-42da-9e10-2d218b3f2bd7"}, "bb938d51-5035-446c-9dfb-77d292805a0a": {"doc_hash": "499f92b2fc1567902a5160feeeeccb9a5db592a331f30d403189858d09cb9234", "ref_doc_id": "50fd92c5-0328-4132-8215-8039142e4fc7"}, "55155f27-0a56-4c1f-a11c-0f790c4c73b0": {"doc_hash": "c40f592aed566c1bce61e64a763eccb1822be1de28de014bfe5d04e005cd5056", "ref_doc_id": "4d9c3278-680b-49d6-accc-1a6dae3f1514"}, "00d8a7c8-2e1f-4e6a-acda-583aa001c458": {"doc_hash": "54c84ccba71ea733e46df78859dae11d8ec4c83c61395af622e25984966ae0fd", "ref_doc_id": "dfceb8bc-14a0-4019-b033-f8e18e35621b"}, "4d412284-c69f-4ab6-8986-ce31b0f9ed86": {"doc_hash": "6fb6f700d708036b313c5a1a82ca7aadca34b0fd6f615281bccb70e4abff1b9a", "ref_doc_id": "f2ca6e81-467d-4a46-ba7d-25998dbbf796"}, "27908f14-4657-4f58-8ac4-bb99dca60cb2": {"doc_hash": "c1dc3a626d210410bfd2d4946b769bb021b67ab8a0e725ef6dd9325f29d09af3", "ref_doc_id": "edc59afa-33b8-4ec8-b57c-8a27a4eb794b"}, "6096d054-d143-42c7-95f5-c3dca4ed0fff": {"doc_hash": "19c1584dc3fee4301850c8c856ed7c1bec8c9fdc63f1dcd5385d057cbde8ff68", "ref_doc_id": "0adea515-0864-4ac2-bc21-b9a208568437"}, "46734690-1a2d-4e0f-8135-15ee0fb9a561": {"doc_hash": "195a0053b3320f2de2a09d969e46cb25679fbeca9de8514e0a3d065245324b7d", "ref_doc_id": "d39eb387-0597-445a-ad49-7c3663c012c2"}, "89175899-d265-42f1-a1dd-6220f14490a5": {"doc_hash": "1d8b8aedbb2c0d8d062adf37ff36bd669e36bdff63b48fa7cbcf2671131a4023", "ref_doc_id": "c62f2bcf-e6f9-4264-a120-b63493861f62"}, "c48f6eb0-5ff9-4873-be40-df8c3ad82e2f": {"doc_hash": "3ea750a0581164ecd31fe6b9e6075ea203dd3c63c01786e89d79fa16fc4d1f69", "ref_doc_id": "3bdca548-0d7f-44f5-8d81-1242c901e58e"}, "77913d79-4179-4871-8bb2-07b32356ffa0": {"doc_hash": "3465e1fc6b8dad9aa8eed93764a2b7855464562780fa7b990017ebd81762f133", "ref_doc_id": "839e467c-8e94-443c-a96b-e329e3525e0e"}, "f096c232-791e-4c23-b67d-77bb2d8944f3": {"doc_hash": "49b271805e247284528a2b5f8cac1d2db8fa1c2c52f171de40f54401211eb30e", "ref_doc_id": "06f47be8-839b-4ace-857f-884f42468339"}, "7492ca2b-1c0f-4973-82e2-29417b34adad": {"doc_hash": "a0df3990dcd9c8f796c8e1d6fffe777dd08645decda28a39991b310b4b105781", "ref_doc_id": "fcd1ab92-e2e3-49bb-8a28-254534fe56a6"}, "7d355e09-25dc-4c82-bf55-cd8e9dfffe43": {"doc_hash": "76d1347c27b59dcde718b01251e914ed304a913a5ed05b6dd820eda089adf002", "ref_doc_id": "25c9159a-3fe2-4aa8-aeb3-554d22bd9ba8"}, "03c9eca8-4203-4a0a-b33a-8d12121551c2": {"doc_hash": "f7c4d5025d956fe5cdfda68bf6a56d5af274017fb77821a8387bfb4e9e6e09e6", "ref_doc_id": "40f2cb35-ac18-4c1e-85a5-67fb9c1707be"}, "dbc64b9a-378f-424b-8ac2-c2fbb208aaa8": {"doc_hash": "b9f6fafda06901c5c99b136dc2bc5ef008dd90d03690e70a63397fe8665d4d8b", "ref_doc_id": "e36dffc6-f15f-4a3a-b31b-77e7ed36bbab"}, "0f49bcc0-5096-48b7-b8bc-36c425a36c0f": {"doc_hash": "a9ede18296795b96cabb9f68abf69524839fe3383a690871fc505dd9d99a190d", "ref_doc_id": "2dda66d2-84c4-4abb-80dd-da765fabbc0b"}, "e679a1f8-c227-4bc8-bd9b-577c73a948e9": {"doc_hash": "6abb6ae6fa6e7e2fc163d1f04f6b2a0155e1f864089e36109efacae401d41b0b", "ref_doc_id": "8fe758ca-5151-4dae-ba83-48e26e451a3e"}, "d2892b44-adb7-4445-b24b-023ae40964e8": {"doc_hash": "2d665fdab352564c7f6522d7df9c00db4216312c81c6ba619c1d8e1c9584a4e4", "ref_doc_id": "ac497d20-bfee-4308-ae18-c4fddeb64a62"}, "f703d695-03ea-4e5c-8de3-f92fc3ddae8f": {"doc_hash": "ceee316dbe4da1be5ec17c697a0965ebece260ad9afda1f165a1194e5ba253e0", "ref_doc_id": "ae173f9b-290a-4fcc-ba3e-8749c78c1873"}, "6909d4ff-1ff7-42b4-ac80-1d198bcb6ef2": {"doc_hash": "6ca8efb5cc3b2458ec28a04e2aae32244c87cf6916e3bd34c8ee5eda2c6bd699", "ref_doc_id": "2e307f49-24ee-4ed4-b584-e62e3511c3bb"}, "8b793e6b-dedd-4d34-b2cc-ca0a449521bd": {"doc_hash": "08185f3019b423111bb39927acb5d3df54e9c70833ef187db076444ebc744c03", "ref_doc_id": "3eb42a44-844a-4365-a6f0-390710a67927"}, "14baa58b-e434-48b5-8762-59b44635a00e": {"doc_hash": "f815f05d6f14ff796542562ab46c0fbc15dca29437cc80ec6edebf294b60caa2", "ref_doc_id": "c712b2ec-cd93-408a-99f0-05b7a376fc5e"}, "673ccc6e-c80f-4c76-a592-9988bb795da2": {"doc_hash": "a33a3c244bdbbbce8d489a148b70f23e953145a25092f03627c998a667847a27", "ref_doc_id": "f29418e6-40d6-4cac-a141-21441c3975ae"}, "6a85ee32-279f-465f-a617-0f52da449dd1": {"doc_hash": "607d9951feb31433441742f1a6b44466dd134e94b26c7606ffe474529c04ca61", "ref_doc_id": "38a78143-8d67-4ff3-b561-049e0eb4a416"}, "b5a2359b-376f-44af-93b8-a77535c6603e": {"doc_hash": "e276236333b36bf14d1c49037b02f3f5b1becafbfaf93a9a492e3c1788c0bf2c", "ref_doc_id": "13c6eb33-ce96-4569-9d97-621157f085e2"}, "4c03595c-6090-4b53-9d2d-876c2552ab33": {"doc_hash": "31aceb5150be5909e0a960916d360bd88fabf7fdbe6e53b35e5d0ee71f1640f7", "ref_doc_id": "ef44e6bd-7f6d-4c9e-ae47-3f0c9b171201"}, "016092ed-5bda-4cc8-bf73-026a09585c59": {"doc_hash": "f1ce519c24514a2c19efdae440f1f6f251010c19e00e3a6d6c1af258ed5e7d9a", "ref_doc_id": "d56cca34-e357-4f35-8d3e-ab65d0c56b97"}, "f236a7d1-3426-4d21-91e2-b16e129f2c9e": {"doc_hash": "46e965c5c7f9bab2304b547a693c93796d1aa4fa8c39b2c6e3d79538e3209218", "ref_doc_id": "59f285a1-aaf8-44a7-8ea1-038853d64f85"}, "6dc9a03b-10b0-451e-a49f-01db9c9210d9": {"doc_hash": "9a6f417159d10a3394718a96975c49616be59850d908c0c8277a3ecb52901a5b", "ref_doc_id": "76deadd9-4dbd-412a-93ac-76b015f72d6e"}, "57747c39-9ef5-4a53-a512-5da2590fa62f": {"doc_hash": "6fa8e446ec07ba4817d1a7f83a6cba33ac50bd4125b695ef629d616770817d99", "ref_doc_id": "f67621a1-6402-45e7-ab47-351c66d14993"}, "5ad1dec1-3e0d-468c-8cca-cb735841e73a": {"doc_hash": "fd545cb171e0792396743adabf1b015c36a1d3f3d8a5beaa4fe0120faab9f85b", "ref_doc_id": "d39bb574-eca5-4a10-bcca-7c7576f4486a"}, "6c04c535-05a8-40a1-8762-59e30ea1ce48": {"doc_hash": "3b7124cd98c916e09702765e0d375acdafbff510e3a797aaf81a8d70d3ead6c4", "ref_doc_id": "f081c0b1-99af-4936-992c-1f5abfa7dd1a"}, "8ce7637f-c9a2-4957-b6c4-8d3924aaa684": {"doc_hash": "0d32116baf3711a9702b394d9f466fdabcbadeb4239d97597359a7a0d1bd01d9", "ref_doc_id": "a32dcb52-2c33-47e8-bcda-4c22feac9df7"}, "8fc992a9-4b4a-4fa1-9fdf-c453f32b2401": {"doc_hash": "a451a5c48401da1b1d44f3631786a742bc3bc5e7aaf71405f0cf24d768d5fca8", "ref_doc_id": "5a897cb8-b419-41f9-ba39-370aee42d13c"}, "f775dc87-397d-492e-b700-f28f3b97ce44": {"doc_hash": "01eba540f099406f068e40c8b24b628aa07d5a3db2dbea875fc07f749fec8fe3", "ref_doc_id": "fb89882d-4944-4111-bcad-d457970cee84"}, "4500c381-63f9-42c4-97dd-ca4993269ae9": {"doc_hash": "5e8a65eafe884b535cb29a2ca7ff8c8cade896f987316f3ebbbf891de6b27e8e", "ref_doc_id": "04ae6da3-b962-48a4-b04a-4b4ac9885277"}, "20c2d42d-ac81-4cd9-85f5-99a89ddd8391": {"doc_hash": "916d74495fce7d1088f0c3fb7ce85a8116f8fb7962a2890c2d4653faf7921f2f", "ref_doc_id": "04ae6da3-b962-48a4-b04a-4b4ac9885277"}, "708f1710-f803-4a56-9401-819693801a4d": {"doc_hash": "82ee8bb8f4bc2d264ad3da672f9c7b6fc97b34087f3419f17951d447b439319c", "ref_doc_id": "a24be4da-c327-4626-abac-e576c4dffa03"}, "abdf78e1-2fac-41d8-99de-bc5cc23e72a8": {"doc_hash": "936b6089e7858b8890ac2cdc56732ca794009798e60d0e5d926322674bf39dde", "ref_doc_id": "a24be4da-c327-4626-abac-e576c4dffa03"}, "afe8f774-e47c-40b5-b02d-c1384702278e": {"doc_hash": "51b335e187cd783002a231053db943d98b21957e9ccad265ff3b691b10630ff4", "ref_doc_id": "0c04306d-b09c-4369-87d5-9e6a357e17eb"}, "da5d9e9c-cdf6-4eb9-8f24-eb986eb1a3bf": {"doc_hash": "2ef5ed245f7e5a25e7e0605f0c83858000c99547f481d98f61badd0fcba9de79", "ref_doc_id": "0c04306d-b09c-4369-87d5-9e6a357e17eb"}, "cfd3c2b7-bd34-4f76-be5e-7731939a6a97": {"doc_hash": "81cfe3b495ee9ff74b3d5cf93c6b261d288d20ffc07e6c4206d5c11283e61697", "ref_doc_id": "47148a91-2dfb-453e-b8d9-21bb004c04ef"}, "5ac2b47d-5f5f-4075-a174-cff6781e87a8": {"doc_hash": "36af93a43f42498ce78246241ecc90a0da80ebc390e15108568ac561cd50d050", "ref_doc_id": "47148a91-2dfb-453e-b8d9-21bb004c04ef"}, "cbe918ba-a372-41d9-9f6b-8928a66de82c": {"doc_hash": "1ba2bfd6b8e723797e44e75d471dab0fd832c924a787607fb6ca5c3d6e3f1705", "ref_doc_id": "de3e8180-22eb-41c7-bbfa-28db5c4634bc"}, "21b93860-97c3-4066-a9b4-b1de7c0a238d": {"doc_hash": "e0c891e55e5afd063c886607579ce79bbf7f6383114f80c213e02514b777b79d", "ref_doc_id": "de3e8180-22eb-41c7-bbfa-28db5c4634bc"}, "36342893-0d2c-4d49-85c3-b4391c3a5981": {"doc_hash": "182a943e6c861409064d14bc1a00d250f563062c256c7459e28bbcfb2baa601a", "ref_doc_id": "3a9f6220-ff32-498a-9b17-aea74197e7b4"}, "109a33ef-38d9-4aa1-a956-052c8f35dae8": {"doc_hash": "9cdc881767c349d86134fa5e3a1260a2790fd56735c9213937d9462764bf2b33", "ref_doc_id": "3a9f6220-ff32-498a-9b17-aea74197e7b4"}, "d9a439cf-4879-4d21-92b8-cd54a59b2e40": {"doc_hash": "3ca4bd5a1fe0974a3f0333e6938cb15d811e2701bbccc2540e274e5499ebe80f", "ref_doc_id": "b76c7696-66f0-4561-a858-b996bb766375"}, "8eb20c70-20c2-466c-82e4-69dbdc633c87": {"doc_hash": "e2fc33f44604cc99c1c6db379e08a62b478874076f4ce7690b77579be8941e65", "ref_doc_id": "b76c7696-66f0-4561-a858-b996bb766375"}}, "docstore/ref_doc_info": {"990d5a0a-ff21-49ae-9f9b-aca070ee1d3b": {"node_ids": ["1c499b06-8d39-4018-8cba-3072a31162a2"], "metadata": {"page_label": "C1", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "7da7c154-5ce3-4f09-bcce-23bad9759c26": {"node_ids": ["bfa46f02-06da-4e91-99e9-73c82ebc0422"], "metadata": {"page_label": "C2", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "30588c47-3769-4559-9150-191e3ee64deb": {"node_ids": ["627b8055-2ea7-4761-aac0-ee50e34d6e65"], "metadata": {"page_label": "i", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a9d49cfa-13a0-4363-b27e-da21f2171d12": {"node_ids": ["dceb6d32-1239-45f8-b672-48fd07225ad1"], "metadata": {"page_label": "ii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "623c07c6-dc64-48ec-b3e2-3a11e8eca303": {"node_ids": ["8ca971c7-6224-40d6-b8bf-d36fd949c430"], "metadata": {"page_label": "iii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "182ed2b9-c4bb-44dd-b185-688eee6a42f8": {"node_ids": ["22cc4735-9ae6-4ca6-9759-2f4ba7402ca3"], "metadata": {"page_label": "iv", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "fdd210c7-6472-4898-9275-488f37d13d07": {"node_ids": ["4f41a260-27fa-4fc8-924c-14c518735e49"], "metadata": {"page_label": "v", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "5eb4a6a2-51f8-4512-bc8c-5970d58995a6": {"node_ids": ["f632140f-2f08-48a4-a0b5-b6e1985a0b4f"], "metadata": {"page_label": "vi", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "1515bd40-cb74-46a7-b259-d7ada9c2b694": {"node_ids": ["64db8ff5-b779-4d6c-93ce-c0417d026c47"], "metadata": {"page_label": "vii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "ee1eb0b2-ca53-47ac-b549-cfbac4f2ef9e": {"node_ids": ["52191274-fa0f-4415-ab2a-ff42f4525039"], "metadata": {"page_label": "viii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "5f5b7b95-c49a-4d68-9add-63261a940cd6": {"node_ids": ["10cd6d67-a197-4ee6-a965-58939962ac27"], "metadata": {"page_label": "ix", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "db087b54-6335-4f07-b24c-9484120257b8": {"node_ids": ["0c9fdd17-2bbf-4291-b81b-ff72b815ac0f"], "metadata": {"page_label": "x", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "1afbaf7a-26b1-4a39-9785-630dc7dff1b7": {"node_ids": ["58257069-7df7-448f-b3cb-7c42c8988c86"], "metadata": {"page_label": "xi", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4e6f2ad7-d964-400b-9090-04bd5f064076": {"node_ids": ["b5a639e0-00fb-4377-a143-1dd97e22ba7f"], "metadata": {"page_label": "xii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "add41a6d-9cd4-4329-96b7-1fc9fb599b59": {"node_ids": ["b46bd0b9-cb37-4f9b-98b9-70b522c48cd5"], "metadata": {"page_label": "xiii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "24c290db-6e80-4b5d-ab45-2a4f277f0da2": {"node_ids": ["b7f6a232-4405-428e-b5f4-ff10e689b86b"], "metadata": {"page_label": "xiv", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "38193ee0-f7f2-4ac6-a473-4769d7153f8a": {"node_ids": ["1a7469ed-d316-4acb-9c87-72301c2a0cc3"], "metadata": {"page_label": "xv", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e5f26531-e198-4035-bff8-1af96ff50c08": {"node_ids": ["1c18d600-cb18-4830-8d16-cc45f9f449fb"], "metadata": {"page_label": "xvi", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f9c9bf02-14ff-44f0-b6b4-e176d85f1243": {"node_ids": ["84a2e502-7962-4995-aa49-7c39b285357c"], "metadata": {"page_label": "xvii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "7bde4a0c-3abb-4812-a776-0081cb0f041d": {"node_ids": ["7df46486-3d2d-4d7b-a149-fe5aedf8abba"], "metadata": {"page_label": "xviii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "0fc55273-b276-416c-9c81-358af7196828": {"node_ids": ["a127573a-66cf-4185-80e8-efc416c418c3"], "metadata": {"page_label": "xix", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "1f06629b-27e4-4894-9d8b-0b07da8e72da": {"node_ids": ["ede77671-55ee-4ccf-a1e0-f64f6ca95335"], "metadata": {"page_label": "xx", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f7694119-2b09-4d92-a212-8997d53de37f": {"node_ids": ["1f20346c-450b-4af7-8b32-eb4b1ff9ee95"], "metadata": {"page_label": "xxi", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e9e1d51a-6ebe-45a3-8078-ef5a067f60b3": {"node_ids": ["b4838e3b-5c31-40aa-aa36-fcbdefd53486"], "metadata": {"page_label": "xxii", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "fdee8dbf-d211-425d-bfdf-ac1c031e3456": {"node_ids": ["7dba5258-79b1-4fd1-b861-c5885f73f725"], "metadata": {"page_label": "1", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "687719a0-d285-44c5-88d4-815633ba23ac": {"node_ids": ["71d3b5d7-0e4f-44fd-94ff-28dfe80b0cc3"], "metadata": {"page_label": "2", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "cbdd4b20-05a2-440a-b858-75c72c490441": {"node_ids": ["e8eb14d5-7623-48de-949f-e2a0e40d9545"], "metadata": {"page_label": "3", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "9fd7f062-5d6b-45af-ab7e-045f9e8f93e8": {"node_ids": ["cc598e55-3726-463d-a41c-e3f164fed00f"], "metadata": {"page_label": "4", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "c709785d-1ba9-49cd-a20c-2af8e62503e9": {"node_ids": ["6912f116-7f59-4849-bf1a-dc01e725e38d"], "metadata": {"page_label": "5", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "18404ac8-1ea3-4b5a-ba6e-3be614d4c79b": {"node_ids": ["96d1d749-48e1-4036-a7d1-18486720c458"], "metadata": {"page_label": "6", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "2833af7b-0f23-46eb-a7f4-0ab540839ee7": {"node_ids": ["f30623c8-d72f-40ec-9ddc-966bfbe57c7f"], "metadata": {"page_label": "7", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f881c3f0-275c-4869-8d2b-9b3cb254d004": {"node_ids": ["fc0a2d95-b0c1-490e-af6d-c13f356b2b08"], "metadata": {"page_label": "8", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "dc7b01c0-4fe2-4f7b-9ae3-5bcd84cbbb6f": {"node_ids": ["df827497-e7f8-47f0-bd42-900afc0c851c"], "metadata": {"page_label": "9", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "aad7331f-3acb-45f6-9c15-598b82182840": {"node_ids": ["416304b8-e98c-4eb1-af50-e8278024caa7"], "metadata": {"page_label": "10", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f83de73f-8a35-4668-940e-d1d2009b49aa": {"node_ids": ["83647c3a-18a1-497e-8fe3-8fc7c1b8f57b"], "metadata": {"page_label": "11", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "770f4e5d-7f66-45fa-9613-a346e9166ba9": {"node_ids": ["aa09dd1a-df2d-405d-87e9-c474b6085fde"], "metadata": {"page_label": "12", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "25badc8a-7be7-428a-bd7c-3c24b46a02da": {"node_ids": ["f75ad44c-6312-4d54-bdf2-660cc74eb0f6"], "metadata": {"page_label": "13", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "7d898864-7f27-4f06-b4f0-e27bed0645dd": {"node_ids": ["b23dc2fa-1750-4014-8fd0-c73df41ddde5"], "metadata": {"page_label": "14", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "53d20576-64c6-48ff-8fde-7f89b326f1b4": {"node_ids": ["016cf1bc-154a-4154-a7d2-12ee63880b6a"], "metadata": {"page_label": "15", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "18197570-beb4-4df9-96a1-3515edd0435e": {"node_ids": ["f056b2e8-cba1-4c65-948a-cd4e8c818767"], "metadata": {"page_label": "16", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "ae261330-b637-4903-97f6-c898d15dda64": {"node_ids": ["05927414-2f6d-4783-ac0f-c50b84b61425"], "metadata": {"page_label": "17", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "70b35b3e-f04d-45fd-860a-1b1c97c568c0": {"node_ids": ["6bad8a95-b7f9-42a2-bc1a-99fa597fe34f"], "metadata": {"page_label": "18", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b4ecd103-8507-4004-ad74-c205df9e9ffd": {"node_ids": ["b9172eb0-ec3b-4bbb-bdab-6526d904b1f4"], "metadata": {"page_label": "19", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "154704b8-3bcc-411c-8901-8d3fe0c953f9": {"node_ids": ["38a35138-9888-490c-9112-205ee13926cb"], "metadata": {"page_label": "20", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "2be2394a-cc8c-4a4e-ae04-1811d458e1ef": {"node_ids": ["01b12f0c-a34c-4d14-86a9-06d77d785dc4"], "metadata": {"page_label": "21", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "6b2ab650-88c9-4865-9b72-d01ca08b4929": {"node_ids": ["9e6db758-6838-45fc-a3fc-3165f2035758"], "metadata": {"page_label": "22", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "861d2581-e95f-45d9-b4b8-9c8543eb9da4": {"node_ids": ["9c74de90-8788-45c4-bc89-78cbd3771056"], "metadata": {"page_label": "23", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d7f54e9a-aa39-4e06-a0c7-345c072dece2": {"node_ids": ["69a52692-289e-4636-ba2f-2908048d16d3"], "metadata": {"page_label": "24", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "abb4fca6-7932-4eb8-8e20-52f63333a267": {"node_ids": ["ae862104-0c74-4494-9bdf-5527bc020690"], "metadata": {"page_label": "25", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "9da4a0cf-c59c-4a80-8d23-5b1d11bd8ce0": {"node_ids": ["7f72acc5-8565-421b-8bf6-2e11ed905a42"], "metadata": {"page_label": "26", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e9e1582e-fbc9-43c7-9d78-e84159661848": {"node_ids": ["d5befd32-df74-4378-9322-2ed57576b223"], "metadata": {"page_label": "27", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a35943a2-5165-409b-9bc3-1a9558727e77": {"node_ids": ["6430b7fc-dcfe-4574-9881-6c8b779fd948"], "metadata": {"page_label": "28", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "8809e13c-4214-4be4-be77-d93d7ba83c97": {"node_ids": ["55b64325-ab98-4cc9-97b3-e0b39b4e320c"], "metadata": {"page_label": "29", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "1909214c-21c4-4888-9bda-6690844f028a": {"node_ids": ["dfd7f519-1ec6-419d-b84e-85eddd64770c"], "metadata": {"page_label": "30", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "cc067170-9481-4d84-8161-f23f85ade5fe": {"node_ids": ["f2743124-a7bd-4731-969b-800724abb3f8"], "metadata": {"page_label": "31", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "0b8ca2ee-09fb-472f-a47e-efb41df0646b": {"node_ids": ["04eddde6-058f-4932-b0cb-2d2d3b1f5f82"], "metadata": {"page_label": "32", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "3c2ec10b-1923-4ad3-9fbb-0d652108f56b": {"node_ids": ["5a367bc0-214a-4e17-8fdd-d03f9493ca1b"], "metadata": {"page_label": "33", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "762f1898-543d-42ee-be6c-c3b7b90defd3": {"node_ids": ["b7fb92d5-6add-4256-adfd-54dc952d4c63"], "metadata": {"page_label": "34", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "5c26ff28-7c69-43d7-9c40-25dc6211b963": {"node_ids": ["502d0435-d232-4e3c-aeca-66c6b2c71ecd"], "metadata": {"page_label": "35", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "6e0023b3-5f56-4b61-a6f4-50b2662c018b": {"node_ids": ["bc98d551-60fb-43ec-ba2e-cdb19241d1fc"], "metadata": {"page_label": "36", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "3df96586-7106-476d-996c-012bfd1592f6": {"node_ids": ["b50a1121-caf0-436e-8467-33958573a814"], "metadata": {"page_label": "37", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "303f05e2-b71d-41b1-9d97-28f005575751": {"node_ids": ["6309e7f6-f92e-454d-95a5-4a731837255e"], "metadata": {"page_label": "38", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "088e07f9-527f-436d-8c73-67a0dd9afc08": {"node_ids": ["a9b56321-12a6-44fc-8fa0-676d49e9d4fe"], "metadata": {"page_label": "39", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e7a6ce7c-c408-4304-ab3e-7718c3e93b9c": {"node_ids": ["7776f955-0cfe-44e9-ba7d-876bbe43b324"], "metadata": {"page_label": "40", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "072532b4-2f84-44c4-8cef-569391b26b73": {"node_ids": ["c7658495-35b6-45c2-b355-e76c894149e6"], "metadata": {"page_label": "41", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "789c9478-0b05-45cb-935d-f9f7b9d87cb8": {"node_ids": ["1e11589e-23ec-48c8-af3d-b465df560fda"], "metadata": {"page_label": "42", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "7db26a35-d98b-4751-838a-8933cac6676b": {"node_ids": ["9990a41c-7e4c-40c5-96d8-29eeb007ca68"], "metadata": {"page_label": "43", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "76cc42c2-df4f-4bad-aa4f-14b325a6474e": {"node_ids": ["960bd5b6-4b6c-4bb0-98fe-f06926fd2aa2"], "metadata": {"page_label": "44", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "5363b295-01e7-403c-b0b5-d29f3934f425": {"node_ids": ["41ca92cc-eb5f-4f66-b141-ca1721a17825"], "metadata": {"page_label": "45", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "47acf3aa-98be-465d-9ed4-3cdf86aaba5a": {"node_ids": ["9d2aa456-fc45-463e-8247-7fc7fcd0210b"], "metadata": {"page_label": "46", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b80b644c-5dda-4322-a136-3db5f90ccf26": {"node_ids": ["c76dd16f-008e-4de5-9e1f-c406e8b5eb49"], "metadata": {"page_label": "47", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f1ff4e11-dcdb-4d7e-a025-db7809aab15c": {"node_ids": ["caf662cd-0c3d-40a0-b885-146aa789d234"], "metadata": {"page_label": "48", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "8935afab-06b2-41a1-b0e5-4029f432f945": {"node_ids": ["7cee21fa-d803-4944-b75d-33b15171618f"], "metadata": {"page_label": "49", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "33aae2a5-2d40-40c3-8832-6532e2371a06": {"node_ids": ["2276c69c-564d-4470-b324-be564794219d"], "metadata": {"page_label": "50", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "8cba6683-5b9b-44a1-8faa-7e06016af901": {"node_ids": ["bd4f6ce9-d856-48f5-ad5d-be1a99e77b1f"], "metadata": {"page_label": "51", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "76391841-6341-4597-af7a-4aee02407493": {"node_ids": ["ebfc7bda-02ed-465a-b48a-90466196fc53"], "metadata": {"page_label": "52", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "19087e09-d00a-4d9c-8c64-4315a80e911b": {"node_ids": ["85a7a65b-447b-4cf3-af73-dab1117fac79"], "metadata": {"page_label": "53", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b1cd56ba-e4f5-4fca-9775-de169ba162fd": {"node_ids": ["62ff0e38-0e10-489a-8345-d9f6f675d966"], "metadata": {"page_label": "54", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "1fe1f4fa-8305-4991-aabe-0a0127461246": {"node_ids": ["dda11bf1-21cb-4f7f-bdf9-52db52f9f714"], "metadata": {"page_label": "55", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "633a5fb3-f11e-49fc-826e-91286aea444c": {"node_ids": ["e30c08ed-ee03-405a-8aeb-1d04c0e66263"], "metadata": {"page_label": "56", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "9e9b96d5-141b-4a8c-968f-e486b32a9b31": {"node_ids": ["4aa43e2b-e3ae-4c9e-aebc-ac5b1af341b5"], "metadata": {"page_label": "57", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e456140c-c4a7-4997-b815-afc82a507e96": {"node_ids": ["bf33f898-0d9e-4f80-8bba-b5de0bf0e42c"], "metadata": {"page_label": "58", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "412e1c50-ae5f-4a0c-a918-4cf8c9b848de": {"node_ids": ["b7d470a0-0207-4ffb-85ae-08907cbdff90"], "metadata": {"page_label": "59", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "1f689f58-d141-45e7-9cb9-fb05deebe3b7": {"node_ids": ["f06c7da4-ef89-4e2c-a5c3-addc83b3f5ff"], "metadata": {"page_label": "60", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f664c88d-2230-4779-812e-628fa91613d9": {"node_ids": ["b29b117b-4ea0-4501-a217-53ff442e269c"], "metadata": {"page_label": "61", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "54e22b93-1866-49b1-8741-72f3dde3e9ba": {"node_ids": ["68984963-ea1c-4802-b377-c491dbe52d90"], "metadata": {"page_label": "62", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d76bf612-b91e-4cb5-b167-319e6b4124de": {"node_ids": ["ddf4f988-2163-4b79-8a1f-51b587ba0c2d"], "metadata": {"page_label": "63", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "78896c01-86dc-462c-8d8d-c63c69bf06a9": {"node_ids": ["d37c0e91-f60c-4aec-8497-39047c9184ea"], "metadata": {"page_label": "64", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d08cc022-e77d-4013-8578-624a3b43eede": {"node_ids": ["ab073368-dd14-459d-99cc-af03886c3d5e"], "metadata": {"page_label": "65", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "44970fc6-30f1-4d13-b461-959a2ad61167": {"node_ids": ["7be23bdb-4de7-41b3-bae7-37388f301f18"], "metadata": {"page_label": "66", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "6da3cef6-fdad-450e-ad0d-208b2ff8c5ff": {"node_ids": ["29218d44-dac3-405d-9b58-466b9ef8c329"], "metadata": {"page_label": "67", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "986f52c2-566a-48bc-a216-8b5872a16c09": {"node_ids": ["74540af3-2d2d-4898-a9fa-3d4537aa1c8c"], "metadata": {"page_label": "68", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "3394eadc-6c2f-441f-8359-0198d175d268": {"node_ids": ["a9fa857d-3ffa-46a8-8ba7-5c60d84183f6"], "metadata": {"page_label": "69", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "de99e74a-2c30-4f13-957f-8a25b3bede74": {"node_ids": ["5314a636-f37a-43bf-8718-a246afa4ae9e"], "metadata": {"page_label": "70", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "fb8fccac-e91c-4977-a1f9-5fbf1b34cf4f": {"node_ids": ["7d045b72-b4cc-407b-b64a-b3de06aede07"], "metadata": {"page_label": "71", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "ae516bc4-5ccf-4779-9c39-d9acc60c3f64": {"node_ids": ["1dfc56be-d193-452f-9c34-20a80657fe04"], "metadata": {"page_label": "72", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "03d2c4f7-df57-4bb9-87d3-b55a57ca5d21": {"node_ids": ["a47226cf-5a76-448e-bb32-450c147a5998"], "metadata": {"page_label": "73", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "cda25f40-70c8-486d-a777-93bfa479f9c2": {"node_ids": ["0a1ef699-6293-4029-beec-37d44eeb1968"], "metadata": {"page_label": "74", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "9c3444f2-48ef-4e90-9211-d05861dfaae9": {"node_ids": ["23556950-35ac-459d-a3ab-d434064db509"], "metadata": {"page_label": "75", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a739f3b5-bf8f-4b6a-9ece-7abacfa5a660": {"node_ids": ["ff7f3970-740a-43e4-aa8f-3f9dc9af42d0"], "metadata": {"page_label": "76", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a41d8a6b-be4c-4a89-a872-3f358da6b866": {"node_ids": ["a3e21b2a-6c7a-4f34-bedd-b141ef208024"], "metadata": {"page_label": "77", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d8799478-d6bf-4e85-9097-4b0b675635f0": {"node_ids": ["8a31455f-da85-4e18-b8ee-0a69f5d824e7"], "metadata": {"page_label": "78", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e75d13be-0ea3-42a3-b1bb-3a9b9b9939cb": {"node_ids": ["177b540d-6dae-4cc6-98e9-71f82acc42e7"], "metadata": {"page_label": "79", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "dca8bc72-a99e-48f3-90c8-0245b68c6c1f": {"node_ids": ["c0e5fe3b-2145-4ad8-b20d-5469d0f5f00d"], "metadata": {"page_label": "80", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "15931bbb-acee-45d5-90d2-0a11f8fc0dc7": {"node_ids": ["7a2124bb-0138-40a5-9fe4-76b05b1c1bc3"], "metadata": {"page_label": "81", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "30c0cb4f-6dae-4b23-b289-5734fa1cf420": {"node_ids": ["131564d1-950b-49c8-9ae6-3ca3b86e146f"], "metadata": {"page_label": "82", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "bf4ef3aa-1181-4fe7-833d-7a68debe7970": {"node_ids": ["53a00819-b6ff-4ea4-9867-b50bcbcbfedd"], "metadata": {"page_label": "83", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "42954911-3ae9-4797-acae-34d650a3f095": {"node_ids": ["12b31851-6d68-4be0-b653-52c2ec71c4ab"], "metadata": {"page_label": "84", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4e574ffe-6153-42e5-9101-3e19b510d963": {"node_ids": ["08c54504-5425-4a62-9ea8-5ca85eb22b12"], "metadata": {"page_label": "85", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a727e92c-2721-44fb-8086-5dc21b8d475f": {"node_ids": ["7043b65a-8750-4091-b134-582ec10c469a"], "metadata": {"page_label": "86", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "50121ec2-bf5d-4276-91b0-b8279ce0b6a5": {"node_ids": ["f8bbb83a-88ba-45c7-b905-2e07809b89d9"], "metadata": {"page_label": "87", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "11562404-ee4c-4378-a6c9-38873abf84bc": {"node_ids": ["a008c3d5-6b50-45c8-b0ba-5ebccc740031"], "metadata": {"page_label": "88", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "5a1de1e8-e4cc-44be-a79d-7bec9639a418": {"node_ids": ["49afd5db-5f93-410e-a0d5-cf86b2b5300d"], "metadata": {"page_label": "89", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "fc95085a-b367-4450-acc3-39991f245592": {"node_ids": ["226f359a-074b-436b-85ef-fa4d40c17b19"], "metadata": {"page_label": "90", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "2fed310c-d99f-4914-af00-9cfd1edf5c8d": {"node_ids": ["9c2afb38-f3ba-4405-9a2b-83ca8a81347c"], "metadata": {"page_label": "91", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "985c4003-99ea-46af-87c6-f23d3920fb49": {"node_ids": ["c501d914-3063-4c0b-ba96-1497a7c3f9e3"], "metadata": {"page_label": "92", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "84388be3-b343-45dc-a1be-89fbc616966b": {"node_ids": ["b7ca40e3-9714-4e7f-8070-d82575fd2548"], "metadata": {"page_label": "93", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e2ca1895-345f-43b6-b3cb-6b7d7b6cec42": {"node_ids": ["582dfdf5-d75c-4f10-86ec-866eb0d1490c"], "metadata": {"page_label": "94", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "3bfc1ed3-75e5-461b-87d5-d5e80fe20dfb": {"node_ids": ["8c17afb1-a5e9-45f1-846b-3b30162ae0ee"], "metadata": {"page_label": "95", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "60762a95-36a3-4f99-b922-0a96833e579b": {"node_ids": ["40a39e11-487a-4915-8029-502b34edf3b6"], "metadata": {"page_label": "96", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "ecfd3451-e53d-493d-a5b1-b0a47a24fd94": {"node_ids": ["bc6884ea-e205-4298-8b41-797205be4142"], "metadata": {"page_label": "97", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "04782910-5c75-4a27-b415-9423f2fb07c3": {"node_ids": ["bae3b027-7b2c-4921-9f63-2efbc47233f7"], "metadata": {"page_label": "98", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "ef38ed6c-d8ad-414d-b869-128da4daddc1": {"node_ids": ["090199fe-f9b7-436b-9e83-fc79914a9296"], "metadata": {"page_label": "99", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f3834d20-5606-44b2-b911-7935bf1d292c": {"node_ids": ["1353ea0b-94a0-4fc4-a4a5-297eb0e60691"], "metadata": {"page_label": "100", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b70e0913-30c3-41f1-ac0a-2dd402b83f51": {"node_ids": ["c057261c-a501-45dc-a099-7cdeb22feb36"], "metadata": {"page_label": "101", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "21adf69b-fc47-4828-8c6f-fbae2db02fa9": {"node_ids": ["9268b3d7-ff2d-4d8f-9f15-43a72703093a"], "metadata": {"page_label": "102", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "9ce19be9-61f5-4d69-b481-617b1922f5c0": {"node_ids": ["d4a55e6b-8522-485d-89b8-9465eeb3b9a1"], "metadata": {"page_label": "103", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "c0d0a84f-e771-4b13-b06f-ca6e2041cab2": {"node_ids": ["71342e00-1109-422e-9fe8-c757f48741b4"], "metadata": {"page_label": "104", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "c524f821-32eb-417b-bcb8-6cd8f0ca9f16": {"node_ids": ["4c164064-3a09-4208-89ed-92fd83736a51"], "metadata": {"page_label": "105", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "3261e380-3a91-4b3e-a136-971526a18607": {"node_ids": ["de4c71be-a561-4016-9616-8b4c985a151c"], "metadata": {"page_label": "106", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "c6dd19ed-61cf-44d3-baf0-87fc43508e1f": {"node_ids": ["60421461-3fd4-48ea-8b42-22271ba8cae3"], "metadata": {"page_label": "107", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "3a73dffe-4e6a-4495-95a3-0348c8664854": {"node_ids": ["1b17192b-9e01-4cea-b6dc-9529a1414002"], "metadata": {"page_label": "108", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e40c7a69-06d6-4bb2-8d33-26e0bf054ff0": {"node_ids": ["63c69f18-3b24-47b0-8fff-2c47db5da3be"], "metadata": {"page_label": "109", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e5dcb41e-2d51-4278-a6a8-7e5e2e3dca5d": {"node_ids": ["5a0550ad-c6b0-4ccd-9c4d-9f35c50bf449"], "metadata": {"page_label": "110", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "109cfe8d-fd10-4a0e-ab6c-c2f639183f2f": {"node_ids": ["d3e18d7e-8032-4712-a630-dd0fdfbf2523"], "metadata": {"page_label": "111", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "dff7fa52-7736-4ae4-9f0d-380d53c73877": {"node_ids": ["22d41dc1-f3bd-4328-83d6-25a6bde1a943"], "metadata": {"page_label": "112", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "27260ff1-70de-48b1-b837-9a9510ac9bb1": {"node_ids": ["1d8f6226-57b3-466c-8a5f-84f8a565a36d"], "metadata": {"page_label": "113", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "992b8d06-7416-448b-bbb3-7c206d4f1a8e": {"node_ids": ["1e99d6ff-b880-4834-a578-9a108e5f46b5"], "metadata": {"page_label": "114", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "6978a3c3-da68-4d33-85c5-6cb0538b2b7d": {"node_ids": ["4ee70a80-f6d8-440b-959a-fb64052f299f"], "metadata": {"page_label": "115", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "7e04fb56-d42d-4807-a128-efaffb57ee50": {"node_ids": ["addf5725-5d60-4777-bad3-006193e06936"], "metadata": {"page_label": "116", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4b42ac66-4176-405c-909f-74cd1bf7e951": {"node_ids": ["e88e0e0d-2bba-4733-8422-25e1e585e8a9"], "metadata": {"page_label": "117", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "0d1577cb-cc8d-4395-b748-5e5f797fe3a2": {"node_ids": ["75617170-eaba-4b5b-a6bd-0b56238e1bfd"], "metadata": {"page_label": "118", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "bf737236-2d14-4c86-bb36-e03124d8abdf": {"node_ids": ["e8fe5931-a1c5-4f0c-8b31-78058795fbae"], "metadata": {"page_label": "119", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "8145bcb0-7836-46a3-9b16-85913dd17f20": {"node_ids": ["166ef137-449c-41f0-92b1-b97259a7efc4"], "metadata": {"page_label": "120", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "1f0cdad7-dd8c-4e4d-8d5a-a891c00b9da0": {"node_ids": ["b22e1372-451f-458a-8553-beed2e233b8d"], "metadata": {"page_label": "121", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "3aa657a6-1ef2-4af6-b934-fb39d4108f9a": {"node_ids": ["69f1bf57-1b50-4a29-b2ed-04b32aae71cd"], "metadata": {"page_label": "122", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "8967fb6e-efa6-441a-9f77-7281f80d40c7": {"node_ids": ["3ffe51f6-d3f7-489e-8469-049c1d8f248d"], "metadata": {"page_label": "123", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "aff292cf-2942-4648-bfed-6c1b96a5f9cb": {"node_ids": ["2b42510c-2015-43d1-954e-606425171f02"], "metadata": {"page_label": "124", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "2c657f58-c861-4e4d-8727-f421c3aa745a": {"node_ids": ["0ac2e938-eaed-4b2a-8c9d-db62ff6eca76"], "metadata": {"page_label": "125", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "7795691c-4c99-49fa-aa90-fac43a60a560": {"node_ids": ["6381b36e-1635-4380-b063-c85e902910df"], "metadata": {"page_label": "126", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "caa8dacf-1d1b-4319-8ca9-81254b3e522b": {"node_ids": ["030b8e7f-96bf-46ec-8c76-89f822f226eb"], "metadata": {"page_label": "127", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "30a98276-5886-49a6-b612-20184c4cad60": {"node_ids": ["f2d74d87-78a1-4a12-91a0-ec4a422bded8"], "metadata": {"page_label": "128", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "266377b4-5118-4b88-83aa-7f26007c0abb": {"node_ids": ["0b3ab66c-50a7-4f39-81b1-88e0a98253e7"], "metadata": {"page_label": "129", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a9496ea4-471a-4d69-9a8e-3f902f475cf7": {"node_ids": ["acfa7a96-04c4-4cf0-a234-f7c847e458ef"], "metadata": {"page_label": "130", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "864d3b95-7691-449a-a756-aa000aeaa200": {"node_ids": ["2ba884d1-9545-490c-b8f3-f6453bd16751"], "metadata": {"page_label": "131", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "504e2291-c837-4391-8d6b-39a18181cd54": {"node_ids": ["9f6e0f27-d4fe-4e34-b8de-37387c99d503"], "metadata": {"page_label": "132", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a6a98b1a-3756-40bd-9e8e-0e61a6b87226": {"node_ids": ["164d8055-4a46-4db4-bdee-b0c84438027a"], "metadata": {"page_label": "133", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "dd7072d0-368a-4fb7-8e63-dbc240774852": {"node_ids": ["2dcea841-c1ec-44a7-85d0-f2e3a109b8ac"], "metadata": {"page_label": "134", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "73978b02-9659-4555-b940-72d26889017c": {"node_ids": ["b0b060d3-d29d-4938-9313-6d4de3d707fc"], "metadata": {"page_label": "135", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "5fdeeac9-d706-4ff6-a0ed-6f33685dd04d": {"node_ids": ["d326c348-d64e-4d8b-b4d8-dce37accd50a"], "metadata": {"page_label": "136", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "7064b587-22ce-4b9a-9a0a-5c384351c6ea": {"node_ids": ["6d4ae1c7-5e42-4a90-87e6-69bd4110d68a"], "metadata": {"page_label": "137", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a0567cb2-fb8d-4934-8e8b-5613f6e1db5c": {"node_ids": ["e6aca770-0b4c-4436-98f7-3fcb07bbbd92"], "metadata": {"page_label": "138", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "6a577882-8b30-4af5-a55e-a0c320479633": {"node_ids": ["d4243450-9b40-44cf-b13a-62abc6bca613"], "metadata": {"page_label": "139", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b62fe408-28b8-47e1-9663-3d4f5598c72a": {"node_ids": ["1554ed40-a15e-4479-9d13-019eb88eb67f"], "metadata": {"page_label": "140", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "0411dbb5-a5da-406d-822e-ec7df5ee4fe7": {"node_ids": ["82dffe9d-624b-46e1-bd0a-d926071b468d"], "metadata": {"page_label": "141", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "3ecd962d-7655-4729-bb2e-61346c76fdda": {"node_ids": ["dee7bf8c-0af3-4a61-aebc-1ba057a68cec"], "metadata": {"page_label": "142", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "45f2b2e7-91a1-4c6b-b6b7-4cf29cb7c730": {"node_ids": ["4fdcd4cb-bcef-48e2-bb66-e33a3871724e"], "metadata": {"page_label": "143", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d9f9d2d6-bb91-4f4a-b4df-704c2c4b0413": {"node_ids": ["8171fd5d-7c56-41ce-82c9-d6f1533b04d9"], "metadata": {"page_label": "144", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "2a9f80df-3a9b-4472-8ec6-a3e3cb111f45": {"node_ids": ["c4116b72-c129-455e-a6c7-f7b1715eebe0"], "metadata": {"page_label": "145", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d7346a3c-606e-40a2-b703-19e9536b77f1": {"node_ids": ["2178cb5a-4876-4d51-bac1-2bc9eb50ce5f"], "metadata": {"page_label": "146", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "bfbfb084-58ea-4f60-aed8-9e3fa2d7eb79": {"node_ids": ["432f18a0-5579-4d97-8412-4ec94d454970"], "metadata": {"page_label": "147", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f3f1c77b-86f8-4f9e-8a52-8c1e123a7870": {"node_ids": ["bea3172b-04c3-4fe3-9c67-28eb70412558"], "metadata": {"page_label": "148", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "68afc25a-164b-4270-bd3d-4f3cca5766e8": {"node_ids": ["05bb1699-dc49-44de-bb35-c4dd54446470"], "metadata": {"page_label": "149", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a2c7c947-01a4-4d88-b38c-66619394fef9": {"node_ids": ["a27d215a-61e0-4133-aac1-7070cb9e0081"], "metadata": {"page_label": "150", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "c6408129-2b9c-4f52-96cc-67bfafd23142": {"node_ids": ["a37ef74e-a8ab-40f4-8fdf-6084ce42cec2"], "metadata": {"page_label": "151", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "087831a0-c35a-4ee9-bf4b-571a2e9c80e4": {"node_ids": ["af294b54-ca40-4efc-9069-925cf54a1cb3"], "metadata": {"page_label": "152", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "09dcac7c-6707-41d5-9d39-2ec35ec9c540": {"node_ids": ["3eff921e-d8c3-4bb0-bcf4-6fcb0cff3eea"], "metadata": {"page_label": "153", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "6e3885c4-da36-47e4-8b4c-73ca310ff2ec": {"node_ids": ["1542497e-c0ab-4a1b-a3dc-ba61c48d2a19"], "metadata": {"page_label": "154", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "0a7572d9-3d53-44c4-a30d-e7b3e290041e": {"node_ids": ["cc39aa99-3775-4b81-b935-c8c18d9517be"], "metadata": {"page_label": "155", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "965edd30-c4db-4ecf-82de-96a1a7db8cd0": {"node_ids": ["8b7e55e5-36b7-48de-b64a-fd55f11464d0"], "metadata": {"page_label": "156", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b6075e6e-b7c9-4ec1-b2ba-80aa6d80c889": {"node_ids": ["345e5fc3-e46f-491b-b0d6-0913117e47c7"], "metadata": {"page_label": "157", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "bc97e1d5-4d52-4e0a-8986-1e7ecded7826": {"node_ids": ["63e5195b-9d47-4641-83c7-25f230180877"], "metadata": {"page_label": "158", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "23e704cb-317f-4c89-8f26-01497829db42": {"node_ids": ["84f2af73-a280-4687-8fe2-7c6999ff93cc"], "metadata": {"page_label": "159", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "9c97f423-d185-40ce-86d1-bdc79b51bb31": {"node_ids": ["adb9d066-e0f4-48ee-9341-fe41c1dff0d7"], "metadata": {"page_label": "160", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "80e07c50-f880-4bee-b69e-c3652f9bf262": {"node_ids": ["dc3e47d4-bc7e-4e42-a172-0e3406197ed4"], "metadata": {"page_label": "161", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "28b09737-9e31-47fb-ab99-c6705ae39c2b": {"node_ids": ["d8823b6e-d2a4-4dae-916c-89ecb90c4526"], "metadata": {"page_label": "162", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "068b52ad-ecd2-4c5c-b5d8-2fd9a52b75f5": {"node_ids": ["398383c4-129f-4e3a-962a-31e9697ed43d"], "metadata": {"page_label": "163", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "1e9e7d80-5e07-4968-81f8-c0750c0d9f3d": {"node_ids": ["f0cb22b2-4e6c-4e55-8e1e-15425c2a1cb3"], "metadata": {"page_label": "164", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "513f6e02-adc8-4c1c-b036-e60699f8c545": {"node_ids": ["1d7a692a-985c-44e5-aac6-981d93fcb829"], "metadata": {"page_label": "165", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "fff125c2-910a-4948-9f8d-470063e1ddfd": {"node_ids": ["9be3c6d3-5945-4e6c-b98c-638ee602bf9a"], "metadata": {"page_label": "166", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "8fdcccca-be0b-42f3-891c-8ec061c62edc": {"node_ids": ["e45e8984-3536-499a-8b10-e41d432df4b9"], "metadata": {"page_label": "167", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "ec1a5fb8-2b9d-4d7a-820f-41fab35a5a0c": {"node_ids": ["f01d666d-be9b-4c5f-8688-de72965d8e04"], "metadata": {"page_label": "168", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "6274f166-8516-4889-b0f6-c161ba6ed760": {"node_ids": ["7129647b-1cf0-487c-9e44-de2edfa1ee4b"], "metadata": {"page_label": "169", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b5988093-3b8f-4640-8a66-97ba862d7bdb": {"node_ids": ["58bb0c78-54c3-4ddc-9abd-da977406c9d8"], "metadata": {"page_label": "170", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "841382a7-a849-41aa-965d-1df29959ed8d": {"node_ids": ["03e75fce-8874-4085-900d-9ce4c1548e7b"], "metadata": {"page_label": "171", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "9d4c54b0-b6dc-4732-837d-cc255eff7b54": {"node_ids": ["8961b22d-5941-48f4-9607-020ce16e89ce"], "metadata": {"page_label": "172", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "3f090516-cc06-4f9c-81ea-01d59ede926c": {"node_ids": ["7e1f9f87-5da4-4c9c-a71d-cd5ac6a62938"], "metadata": {"page_label": "173", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "cb8673c3-84a7-4c6f-97bd-aeb3e932c3cb": {"node_ids": ["5737c67e-8da9-45c7-b52c-e1e481649bca"], "metadata": {"page_label": "174", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b3068d4d-5c3a-43a1-a0c0-cb6bbcf7c4f9": {"node_ids": ["47370352-5441-4135-acc5-72b775e007c5"], "metadata": {"page_label": "175", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "03d3bbfc-eef0-42d7-a04c-b3c291dc4195": {"node_ids": ["26388164-d4fc-42e9-98de-70738d4e0654"], "metadata": {"page_label": "176", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "317095a3-46d1-4447-b2fa-9476cde3113f": {"node_ids": ["2922dbdb-578f-4fe9-bbaa-313cb221ec19"], "metadata": {"page_label": "177", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "56b692a4-4121-4598-a50b-f15ce6370fe5": {"node_ids": ["aa956ec2-3e27-4b9e-a902-6746361f27ee"], "metadata": {"page_label": "178", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4b4df9f8-8086-4cae-9a19-ff2b1ca4d1df": {"node_ids": ["684377bf-4b23-477d-9140-be0e72412887"], "metadata": {"page_label": "179", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "2d77bafc-963c-4325-87bc-45f8befa7d81": {"node_ids": ["54fffd8f-d07e-4f9c-810c-a35f16227ffb"], "metadata": {"page_label": "180", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "583118d2-406f-44a0-9b3d-4596e26559fb": {"node_ids": ["9a1306c5-7607-4931-b7b4-e0144a3892e7"], "metadata": {"page_label": "181", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "c234d193-a6cc-46f6-b6cc-f86604bf6462": {"node_ids": ["648ab0c4-ebff-4b59-b30c-d496d26e6fb1"], "metadata": {"page_label": "182", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b3027740-f03c-47f2-9d90-c6741c1cdaf3": {"node_ids": ["756f9485-3d82-4ba1-8a75-040c7c21e68b"], "metadata": {"page_label": "183", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "9e9d71c9-1366-4ec9-a85a-ac5e85d413c0": {"node_ids": ["08138a5e-c66a-417f-b4b5-d812f6ee4513"], "metadata": {"page_label": "184", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "17b5f466-f8b1-4e2b-8df2-563e1ccc7110": {"node_ids": ["79242a63-bfdd-4135-9800-79022e60bf69"], "metadata": {"page_label": "185", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "9fd6f81e-fe19-4479-9266-e57be6951284": {"node_ids": ["08d773ff-9bbb-4985-ac2f-afaa12f5dc74"], "metadata": {"page_label": "186", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "26e6bb9d-c06b-436c-b549-13da6c371087": {"node_ids": ["d338d7c4-e3af-4640-8944-ce147fd80895"], "metadata": {"page_label": "187", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "baf650c7-2a9b-4405-a815-61c8cc71b30f": {"node_ids": ["28095953-bc85-42cd-9ddb-eb96412f7e2a"], "metadata": {"page_label": "188", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b9143be8-6470-4063-ab00-a612b8a9fb98": {"node_ids": ["b6fc5a84-3f11-4c5f-a512-f7b44a612276"], "metadata": {"page_label": "189", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4714f68c-a079-472c-bb5f-04ab2b17924c": {"node_ids": ["160d837e-0c67-4e24-b457-0284cc01b110"], "metadata": {"page_label": "190", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "3f2bc7d5-6d4e-4313-934f-8a0736c839ae": {"node_ids": ["a519ca91-88f4-45ef-81b9-23e605effe1a"], "metadata": {"page_label": "191", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4c201736-8d6f-4591-933b-313a1c9c7351": {"node_ids": ["e38db428-75de-4144-aee1-38e2700aba09"], "metadata": {"page_label": "192", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "73dba28a-5f11-4adc-a332-cbfb0234face": {"node_ids": ["81f2a4c4-6c9b-41d8-aeb7-cf19ffd8837b"], "metadata": {"page_label": "193", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "065236b5-729e-436f-8c74-f2e89c9e634b": {"node_ids": ["06d4c177-f080-416a-9b7b-1004ce7de1db"], "metadata": {"page_label": "194", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "0ad74638-7752-4dc4-b30d-23e7dc52f682": {"node_ids": ["b13f1d8e-5245-4f13-ab28-857e17ead86a"], "metadata": {"page_label": "195", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f8c383cc-b035-4431-94aa-9d957e842b6d": {"node_ids": ["a280161d-0cb5-4d54-b5a5-ae533994d8b6"], "metadata": {"page_label": "196", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "c4606470-21dc-460f-874f-a41779700f6c": {"node_ids": ["a7d3c3bc-1788-49b8-8ff7-bce2be469e25"], "metadata": {"page_label": "197", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "c64aa61a-ca33-4c64-8e7c-46131d3fe0d1": {"node_ids": ["65fc3742-7feb-42bf-8fbc-2a35c46dccb6"], "metadata": {"page_label": "198", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "0ac6ddbf-ce29-40aa-8595-46d95b2607e7": {"node_ids": ["e588e2da-aaff-4647-b454-e683bff43533"], "metadata": {"page_label": "199", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "0c9945ad-eabf-41cd-a7a7-38cf7ca307e9": {"node_ids": ["b444a56b-ad3a-476d-93e2-ae26ef21f3f9"], "metadata": {"page_label": "200", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "461e488f-5088-4a7e-bcf5-ca42555c2506": {"node_ids": ["ce638535-07aa-49d2-9b03-fdcc805c6065"], "metadata": {"page_label": "201", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b5c2c895-999a-4a96-95e7-6a3210bbef21": {"node_ids": ["b9bee75b-87ff-413c-bbde-4b6006b99e75"], "metadata": {"page_label": "202", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "1181f5a1-6863-494e-9a0a-f0af64a323f7": {"node_ids": ["565c6c22-e11c-45da-ad1c-076de4da6e0b"], "metadata": {"page_label": "203", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "cde1d9a7-ce24-406d-9b69-de336bad310e": {"node_ids": ["6d3902a4-f8bf-4c23-bd4d-834640dd3755"], "metadata": {"page_label": "204", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "2ac90a08-2902-4429-83bc-9e2ec9d19168": {"node_ids": ["26a25a94-518d-4420-8a3c-18a529617c10"], "metadata": {"page_label": "205", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "807b8b05-0e36-405f-9e45-38fb7345b68a": {"node_ids": ["6f90733c-a74d-49d4-b4f6-4b9362b7abb2"], "metadata": {"page_label": "206", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "296e1811-93af-4857-8de1-d5999abd3dc7": {"node_ids": ["035a58a1-e26c-422a-87ad-7892b869c5ef"], "metadata": {"page_label": "207", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d0896d9f-8bb1-4fcd-8922-8bd5c57607be": {"node_ids": ["c256693d-98ab-42f1-96c8-3f09c61b77d0"], "metadata": {"page_label": "208", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "afad88eb-21a9-41df-93d9-dafa4407ad54": {"node_ids": ["0abcaff8-cb51-4145-ae0d-5acbc0bca447"], "metadata": {"page_label": "209", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "97663dda-cd53-44bf-8b54-0d682609ac3a": {"node_ids": ["d34af4bd-dd6a-4a5a-856d-641c1c79a3c0"], "metadata": {"page_label": "210", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "289c9a0f-5208-4c5a-85b7-74e11c474114": {"node_ids": ["38f1e3d4-d9b4-45ea-9194-7dec706d42e0"], "metadata": {"page_label": "211", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a4454e8e-cf39-45f5-b164-eeef340d1f74": {"node_ids": ["9fdc4343-1ff5-44fd-83ca-15a427c50918"], "metadata": {"page_label": "212", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "7050e2cf-3b8a-44e1-8930-e2e15ad257ea": {"node_ids": ["72017dbf-147c-4d10-b1c4-ee12a34a6cc2"], "metadata": {"page_label": "213", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b5b21e9b-f5fe-4b74-b480-fc55a6e15eb8": {"node_ids": ["c117b427-cf16-447e-9a2c-b74939c6ca28"], "metadata": {"page_label": "214", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f6d35e9a-bc55-457d-8b43-b03c5d44c65e": {"node_ids": ["402743a0-2d94-4e48-bc45-7350a9f47493"], "metadata": {"page_label": "215", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b25bd757-99b1-4da2-b2b6-4e14bfb342ba": {"node_ids": ["ef815dba-4f17-4f92-b82c-e965a5ac7389"], "metadata": {"page_label": "216", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "9af2a35e-c949-4228-aeab-23f3cd733856": {"node_ids": ["c6b86ce8-3717-42fb-8aac-63eecb2144f8"], "metadata": {"page_label": "217", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4d104773-bc31-4081-8418-f9a6bb50f835": {"node_ids": ["03344cbe-ad47-43aa-b440-ca51a70768b5"], "metadata": {"page_label": "218", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b57b3f93-aa17-4adf-af2b-21e9a5128472": {"node_ids": ["a4855dc1-a69e-476d-889d-5b9f60464611"], "metadata": {"page_label": "219", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4ccb95f3-13ba-4cc6-b2ab-26689d84b124": {"node_ids": ["b9bd91bc-855a-4cb3-b8a8-35f19afe278a"], "metadata": {"page_label": "220", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "97dbb027-c699-4352-ab8d-b489f5d6420d": {"node_ids": ["d6472d5f-037b-45d5-9f46-93638b4f18e0"], "metadata": {"page_label": "221", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4eed4177-b25d-4871-9f7c-69f38d10d948": {"node_ids": ["e7ea517e-9f19-49ec-91b0-99c38bba23ba"], "metadata": {"page_label": "222", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "da1fd3f0-4d12-4689-aa96-7d1018484872": {"node_ids": ["9e461e0d-487e-4525-83ef-83fd38364240"], "metadata": {"page_label": "223", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "7201e3c1-d82a-4a25-bec8-eb3a436980ff": {"node_ids": ["c77e6d3f-999b-4089-8a5c-a6c73c1b4165"], "metadata": {"page_label": "224", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f186b7ff-c986-4836-bde8-9dfe98881ad7": {"node_ids": ["6c8f4143-449c-418e-8d23-2e93297d2e8b"], "metadata": {"page_label": "225", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f14dc418-4cd5-4819-aa7e-77e359b7fab4": {"node_ids": ["63cc13b3-659a-4560-b2e0-4d4816289844"], "metadata": {"page_label": "226", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "7aabe694-f51a-45b0-96ee-da321ab0d900": {"node_ids": ["9729dc55-73cd-4032-8bc1-ceb8cd19ee42"], "metadata": {"page_label": "227", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e9b9e98c-67e9-4d6b-8c97-d8d6532cfe1d": {"node_ids": ["eee79fa8-48bb-4271-bebe-f000ad300ccb"], "metadata": {"page_label": "228", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d8b8baed-0785-4b0b-82f4-2866b9cf2aba": {"node_ids": ["08bad362-b5d7-46df-bd82-c53ba090cfee"], "metadata": {"page_label": "229", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "cd719117-5c20-4c7c-8489-7826ede9f7e7": {"node_ids": ["cef72f88-821f-41f9-8df1-f394f1ad4185"], "metadata": {"page_label": "230", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "0fef8586-e4c9-48c9-ab00-878fd3461a6d": {"node_ids": ["40d1a7c3-9a69-45bc-a6c0-bea351c7f718"], "metadata": {"page_label": "231", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f53e7f8d-782b-48bb-9aaf-eb025797580f": {"node_ids": ["2d7ae344-20d3-4a6b-87ff-44e2960816f7"], "metadata": {"page_label": "232", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "cdc7ccb5-4307-4ada-9404-3bcd9e030d58": {"node_ids": ["680a2335-a304-4de6-b125-c477adf81855"], "metadata": {"page_label": "233", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a16f95c5-8624-4e67-905f-8384714645c7": {"node_ids": ["f52d4a60-60a8-4243-bbe9-244bcef3501b"], "metadata": {"page_label": "234", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "fe667dc0-9a19-4878-9a5f-0a010b3788bb": {"node_ids": ["63c11f09-18da-4d4d-b8e1-ed641b0ef4ab"], "metadata": {"page_label": "235", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "66ad42e2-f95d-48ce-ac0f-a63e88b80d52": {"node_ids": ["002a43d7-c9ee-4df5-b1aa-dbbd49c51c63"], "metadata": {"page_label": "236", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "5cd65b97-c15d-4e9b-8924-b023880d55d5": {"node_ids": ["7542225a-3ff7-4985-853f-93747ca154bf"], "metadata": {"page_label": "237", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "05e8d5a1-deff-4b52-afe1-9b15f18f425c": {"node_ids": ["d18465ff-9846-40a4-8878-de4449291098"], "metadata": {"page_label": "238", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "0067d163-a186-4e00-a7bf-bf5054baa37c": {"node_ids": ["357b9157-be6f-4823-98b1-b07ba021bc09"], "metadata": {"page_label": "239", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a4b8d008-5d65-4242-96ff-f62ece8c6afb": {"node_ids": ["34298bbb-2b4d-42c4-8e99-bd66c2b8c7ab"], "metadata": {"page_label": "240", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f0b5e696-90c7-4b83-9896-bb7181c3605a": {"node_ids": ["40c896da-47d3-4c74-8ca0-3c09ec20ec80"], "metadata": {"page_label": "241", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4066711e-891c-4db3-9c78-ca0c32daaa37": {"node_ids": ["34f619b5-fdba-4922-9f5a-bed2b7ee008c"], "metadata": {"page_label": "242", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "bb0bce83-0c15-4816-9dab-0305e6d4bf49": {"node_ids": ["83febfb1-20b0-4873-b2a3-8fa6af0adf64"], "metadata": {"page_label": "243", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "b5f540bd-7311-4ee5-b8dd-17e1e284a3c4": {"node_ids": ["6bcbc51b-0a2d-4fa6-b860-6c58a861851b"], "metadata": {"page_label": "244", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f612b985-3947-432c-91ac-4f277bc3fa8d": {"node_ids": ["f128258a-e07e-413f-94e7-d4e9baeb2c31"], "metadata": {"page_label": "245", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "15622a6f-14b6-4d45-9d1a-a8d704eb1c39": {"node_ids": ["2ca5a89b-a827-4122-b3a7-4ae861d7e031"], "metadata": {"page_label": "246", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a79e89c0-84b7-4dc1-95c5-3ee03d54884f": {"node_ids": ["4f349a33-9cfb-428f-a321-1137cf2a372a"], "metadata": {"page_label": "247", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4f01354a-ace1-437d-a796-11f63ae8ca2b": {"node_ids": ["fc11c467-8676-4047-8127-028ee7b354c7"], "metadata": {"page_label": "248", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f097dc9f-5ba0-4f6d-a184-ab7e4f6d772c": {"node_ids": ["5eb7a21a-1640-46ae-b9fe-bbe56ab522df"], "metadata": {"page_label": "249", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "9e601ce1-80eb-487f-b2c6-db37a867a07f": {"node_ids": ["4de0ad38-8785-40d4-8859-3e90f07f0c6d"], "metadata": {"page_label": "250", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "1324f456-7239-4f92-bafc-c4ef27d9b1ea": {"node_ids": ["501032c1-cec0-4513-b820-c0ae1496de60"], "metadata": {"page_label": "251", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "5ccb8656-5185-4b8d-a3de-200af453f479": {"node_ids": ["879952e4-8e9f-4e53-81fb-bf6a1b10d260"], "metadata": {"page_label": "252", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e7d2d1f6-258e-4529-99b2-c46b028381ab": {"node_ids": ["69eafcf0-9577-4d60-be8a-c3611e11a187"], "metadata": {"page_label": "253", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "9fd5da10-d98b-4e3f-a678-3578dd9e92e8": {"node_ids": ["93e83c50-5fc1-43f1-a171-41052a5823d6"], "metadata": {"page_label": "254", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d1fbaf09-caca-4d6f-b7ec-f561b9de3b1e": {"node_ids": ["4a8ef1fd-ad8b-4da4-a309-9a5c75612421"], "metadata": {"page_label": "255", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a04bf7f8-dde8-4990-9569-cff522891e88": {"node_ids": ["ad9cbca2-ff01-4569-8aa8-e11e12e018fb"], "metadata": {"page_label": "256", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "2c8988be-e73b-498c-9133-96c0e95bfd76": {"node_ids": ["d2104e10-ef87-47c9-bce2-4b401e0dcb8a"], "metadata": {"page_label": "257", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "8c402393-850d-4bcb-a7ce-fe45e06d7ec6": {"node_ids": ["23dd86b9-e523-42db-9f08-7b5fc30d2c0d"], "metadata": {"page_label": "258", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e28f238d-cc64-4ee2-9da4-b8008dbc10e3": {"node_ids": ["d9b91958-dff7-43d4-a0a5-804b04f3a4bb"], "metadata": {"page_label": "259", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "1f08a1a1-ce81-463f-857f-be987b314208": {"node_ids": ["aab8a70e-38bf-425b-b434-56e56eac55f3"], "metadata": {"page_label": "260", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4079bcb0-96ba-47ac-a357-573754f2c0d1": {"node_ids": ["4266ad13-26af-4a8f-82e8-f696dc55e0f2"], "metadata": {"page_label": "261", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "2a3fa149-c9fe-484b-b498-3b6e16260e2f": {"node_ids": ["006afd18-482d-4b2c-97b6-3347da9cdc05"], "metadata": {"page_label": "262", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e49bd7fe-cef4-4d60-8c95-899999194d82": {"node_ids": ["e78301e3-e53d-41f7-929e-cc68b4fac508"], "metadata": {"page_label": "263", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "074280b5-9381-47e0-913b-d0a73a9ca22b": {"node_ids": ["1644333f-489e-428b-953c-0c606e96cc97"], "metadata": {"page_label": "264", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "718d3442-edca-4676-a5be-9d63921b8365": {"node_ids": ["7bd55d71-5fca-411f-b3a7-318e1c440f42"], "metadata": {"page_label": "265", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "2792291b-915c-4cf2-bf46-7e775855dcb7": {"node_ids": ["a75e25bd-b07b-471d-ad38-8358dfc2442a"], "metadata": {"page_label": "266", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "c4f00616-d4a2-4086-9099-0fdaf9da32a9": {"node_ids": ["c402b563-ad80-4180-a397-59f6062c2ca5"], "metadata": {"page_label": "267", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a0b7b095-d949-43ad-ab42-0aaef4861403": {"node_ids": ["a95a2261-b52f-4cb2-b594-765e61b95ab0"], "metadata": {"page_label": "268", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "6c368936-c327-4db9-bedc-e02fdde7e855": {"node_ids": ["6cc36414-5cff-49a1-89e5-5fcb3a33d007"], "metadata": {"page_label": "269", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d477cdcb-e637-4e14-9def-91ec94af7e8d": {"node_ids": ["1025c895-8ee0-4681-9471-161f3a8531ee"], "metadata": {"page_label": "270", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "aa670ec0-8c41-4f38-af7c-f5fafe50e08e": {"node_ids": ["74a3fd7d-5c73-4d35-861a-584e94d83510"], "metadata": {"page_label": "271", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "32686e8e-99a2-477b-939f-69069aeea1a4": {"node_ids": ["d2c64653-007c-4012-bc0c-7893c08fa521"], "metadata": {"page_label": "272", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "0173ec60-f3df-49b7-9002-876ed6df3477": {"node_ids": ["096b23e7-b4ae-469a-bed8-d4a66686fd7f"], "metadata": {"page_label": "273", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "432bf1da-96f3-48c4-a7d2-b33468577577": {"node_ids": ["5a1f1315-8f77-45d7-a1b8-2cac6deb325c"], "metadata": {"page_label": "274", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "cac38972-e8e3-47bb-8f57-364867319217": {"node_ids": ["de5e3052-ba47-4a01-a2b7-30f7caed1b37"], "metadata": {"page_label": "275", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "df4cf1d7-1eea-4ee4-be00-a8d3a7ee7e2a": {"node_ids": ["d638a9e5-fc26-49f6-bcf2-5da508111468"], "metadata": {"page_label": "276", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "ac037533-6b34-4ce2-8369-93986affa13c": {"node_ids": ["658f5b5e-c7f2-4d33-a9b0-30aeff752886"], "metadata": {"page_label": "277", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4f866168-2ee3-41a4-bf09-83ab8875dd5e": {"node_ids": ["8685dbb3-196e-4550-8c1d-f7562a6b54b6"], "metadata": {"page_label": "278", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4ca81a9f-6ee9-461d-b538-3f9c4c814836": {"node_ids": ["4f9c0e8e-cfec-4b58-96c1-b916343ae2b7"], "metadata": {"page_label": "279", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "96f2ad61-12f0-42da-9e10-2d218b3f2bd7": {"node_ids": ["8566fca9-75cd-462f-8fe7-ac7de9624d8e"], "metadata": {"page_label": "280", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "50fd92c5-0328-4132-8215-8039142e4fc7": {"node_ids": ["bb938d51-5035-446c-9dfb-77d292805a0a"], "metadata": {"page_label": "281", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "4d9c3278-680b-49d6-accc-1a6dae3f1514": {"node_ids": ["55155f27-0a56-4c1f-a11c-0f790c4c73b0"], "metadata": {"page_label": "282", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "dfceb8bc-14a0-4019-b033-f8e18e35621b": {"node_ids": ["00d8a7c8-2e1f-4e6a-acda-583aa001c458"], "metadata": {"page_label": "283", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f2ca6e81-467d-4a46-ba7d-25998dbbf796": {"node_ids": ["4d412284-c69f-4ab6-8986-ce31b0f9ed86"], "metadata": {"page_label": "284", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "edc59afa-33b8-4ec8-b57c-8a27a4eb794b": {"node_ids": ["27908f14-4657-4f58-8ac4-bb99dca60cb2"], "metadata": {"page_label": "285", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "0adea515-0864-4ac2-bc21-b9a208568437": {"node_ids": ["6096d054-d143-42c7-95f5-c3dca4ed0fff"], "metadata": {"page_label": "286", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d39eb387-0597-445a-ad49-7c3663c012c2": {"node_ids": ["46734690-1a2d-4e0f-8135-15ee0fb9a561"], "metadata": {"page_label": "287", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "c62f2bcf-e6f9-4264-a120-b63493861f62": {"node_ids": ["89175899-d265-42f1-a1dd-6220f14490a5"], "metadata": {"page_label": "288", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "3bdca548-0d7f-44f5-8d81-1242c901e58e": {"node_ids": ["c48f6eb0-5ff9-4873-be40-df8c3ad82e2f"], "metadata": {"page_label": "289", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "839e467c-8e94-443c-a96b-e329e3525e0e": {"node_ids": ["77913d79-4179-4871-8bb2-07b32356ffa0"], "metadata": {"page_label": "290", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "06f47be8-839b-4ace-857f-884f42468339": {"node_ids": ["f096c232-791e-4c23-b67d-77bb2d8944f3"], "metadata": {"page_label": "291", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "fcd1ab92-e2e3-49bb-8a28-254534fe56a6": {"node_ids": ["7492ca2b-1c0f-4973-82e2-29417b34adad"], "metadata": {"page_label": "292", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "25c9159a-3fe2-4aa8-aeb3-554d22bd9ba8": {"node_ids": ["7d355e09-25dc-4c82-bf55-cd8e9dfffe43"], "metadata": {"page_label": "293", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "40f2cb35-ac18-4c1e-85a5-67fb9c1707be": {"node_ids": ["03c9eca8-4203-4a0a-b33a-8d12121551c2"], "metadata": {"page_label": "294", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "e36dffc6-f15f-4a3a-b31b-77e7ed36bbab": {"node_ids": ["dbc64b9a-378f-424b-8ac2-c2fbb208aaa8"], "metadata": {"page_label": "295", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "2dda66d2-84c4-4abb-80dd-da765fabbc0b": {"node_ids": ["0f49bcc0-5096-48b7-b8bc-36c425a36c0f"], "metadata": {"page_label": "296", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "8fe758ca-5151-4dae-ba83-48e26e451a3e": {"node_ids": ["e679a1f8-c227-4bc8-bd9b-577c73a948e9"], "metadata": {"page_label": "297", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "ac497d20-bfee-4308-ae18-c4fddeb64a62": {"node_ids": ["d2892b44-adb7-4445-b24b-023ae40964e8"], "metadata": {"page_label": "298", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "ae173f9b-290a-4fcc-ba3e-8749c78c1873": {"node_ids": ["f703d695-03ea-4e5c-8de3-f92fc3ddae8f"], "metadata": {"page_label": "299", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "2e307f49-24ee-4ed4-b584-e62e3511c3bb": {"node_ids": ["6909d4ff-1ff7-42b4-ac80-1d198bcb6ef2"], "metadata": {"page_label": "300", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "3eb42a44-844a-4365-a6f0-390710a67927": {"node_ids": ["8b793e6b-dedd-4d34-b2cc-ca0a449521bd"], "metadata": {"page_label": "301", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "c712b2ec-cd93-408a-99f0-05b7a376fc5e": {"node_ids": ["14baa58b-e434-48b5-8762-59b44635a00e"], "metadata": {"page_label": "302", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f29418e6-40d6-4cac-a141-21441c3975ae": {"node_ids": ["673ccc6e-c80f-4c76-a592-9988bb795da2"], "metadata": {"page_label": "303", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "38a78143-8d67-4ff3-b561-049e0eb4a416": {"node_ids": ["6a85ee32-279f-465f-a617-0f52da449dd1"], "metadata": {"page_label": "304", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "13c6eb33-ce96-4569-9d97-621157f085e2": {"node_ids": ["b5a2359b-376f-44af-93b8-a77535c6603e"], "metadata": {"page_label": "305", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "ef44e6bd-7f6d-4c9e-ae47-3f0c9b171201": {"node_ids": ["4c03595c-6090-4b53-9d2d-876c2552ab33"], "metadata": {"page_label": "306", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d56cca34-e357-4f35-8d3e-ab65d0c56b97": {"node_ids": ["016092ed-5bda-4cc8-bf73-026a09585c59"], "metadata": {"page_label": "307", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "59f285a1-aaf8-44a7-8ea1-038853d64f85": {"node_ids": ["f236a7d1-3426-4d21-91e2-b16e129f2c9e"], "metadata": {"page_label": "308", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "76deadd9-4dbd-412a-93ac-76b015f72d6e": {"node_ids": ["6dc9a03b-10b0-451e-a49f-01db9c9210d9"], "metadata": {"page_label": "309", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f67621a1-6402-45e7-ab47-351c66d14993": {"node_ids": ["57747c39-9ef5-4a53-a512-5da2590fa62f"], "metadata": {"page_label": "310", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "d39bb574-eca5-4a10-bcca-7c7576f4486a": {"node_ids": ["5ad1dec1-3e0d-468c-8cca-cb735841e73a"], "metadata": {"page_label": "311", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "f081c0b1-99af-4936-992c-1f5abfa7dd1a": {"node_ids": ["6c04c535-05a8-40a1-8762-59e30ea1ce48"], "metadata": {"page_label": "312", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "a32dcb52-2c33-47e8-bcda-4c22feac9df7": {"node_ids": ["8ce7637f-c9a2-4957-b6c4-8d3924aaa684"], "metadata": {"page_label": "313", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "5a897cb8-b419-41f9-ba39-370aee42d13c": {"node_ids": ["8fc992a9-4b4a-4fa1-9fdf-c453f32b2401"], "metadata": {"page_label": "314", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "fb89882d-4944-4111-bcad-d457970cee84": {"node_ids": ["f775dc87-397d-492e-b700-f28f3b97ce44"], "metadata": {"page_label": "C3", "file_name": "Big Data For Dummies.pdf", "file_path": "D:\\vector\\data\\Big Data For Dummies.pdf", "file_type": "pdf", "file_size": 23893328, "creation_date": "2025-04-21", "last_modified_date": "2025-04-02"}}, "04ae6da3-b962-48a4-b04a-4b4ac9885277": {"node_ids": ["4500c381-63f9-42c4-97dd-ca4993269ae9", "20c2d42d-ac81-4cd9-85f5-99a89ddd8391"], "metadata": {"page_label": "1", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}}, "a24be4da-c327-4626-abac-e576c4dffa03": {"node_ids": ["708f1710-f803-4a56-9401-819693801a4d", "abdf78e1-2fac-41d8-99de-bc5cc23e72a8"], "metadata": {"page_label": "2", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}}, "0c04306d-b09c-4369-87d5-9e6a357e17eb": {"node_ids": ["afe8f774-e47c-40b5-b02d-c1384702278e", "da5d9e9c-cdf6-4eb9-8f24-eb986eb1a3bf"], "metadata": {"page_label": "3", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}}, "47148a91-2dfb-453e-b8d9-21bb004c04ef": {"node_ids": ["cfd3c2b7-bd34-4f76-be5e-7731939a6a97", "5ac2b47d-5f5f-4075-a174-cff6781e87a8"], "metadata": {"page_label": "4", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}}, "de3e8180-22eb-41c7-bbfa-28db5c4634bc": {"node_ids": ["cbe918ba-a372-41d9-9f6b-8928a66de82c", "21b93860-97c3-4066-a9b4-b1de7c0a238d"], "metadata": {"page_label": "5", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}}, "3a9f6220-ff32-498a-9b17-aea74197e7b4": {"node_ids": ["36342893-0d2c-4d49-85c3-b4391c3a5981", "109a33ef-38d9-4aa1-a956-052c8f35dae8"], "metadata": {"page_label": "6", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}}, "b76c7696-66f0-4561-a858-b996bb766375": {"node_ids": ["d9a439cf-4879-4d21-92b8-cd54a59b2e40", "8eb20c70-20c2-466c-82e4-69dbdc633c87"], "metadata": {"page_label": "7", "file_name": "BigData.pdf", "file_path": "D:\\vector\\data\\BigData.pdf", "file_type": "pdf", "file_size": 456441, "creation_date": "2025-04-21", "last_modified_date": "2025-04-21"}}}}